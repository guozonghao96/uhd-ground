./checkpoints_new/llava-uhd-144-13b
[2024-08-15 20:55:15,751] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-15 20:55:18,087] [INFO] [runner.py:571:main] cmd = srun -n 16 --nodes 2 --gpus 16 --export=ALL,PYTHONPATH=/home/test/test08/gzh/LLaVA-UHD /home/test/test08/anaconda3/envs/llava_uhd/bin/python -u llava/train/train_mem.py --deepspeed ./scripts/zero2_slurm.json --model_name_or_path ./pretrained_models/vicuna-13b-v1.5 --version plain --data_path ./playground/data/LLaVA-Pretrain/blip_laion_cc_sbu_558k.json --image_folder ./playground/data/LLaVA-Pretrain/images --vision_tower ./pretrained_models/clip-vit-large-patch14-336 --mm_projector_type adapt_spatial_resampler --tune_mm_mlp_adapter True --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --bf16 True --output_dir ./checkpoints_new/llava-uhd-144-13b --num_train_epochs 1 --per_device_train_batch_size 32 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --evaluation_strategy no --save_strategy steps --save_steps 24000 --save_total_limit 1 --learning_rate 1e-3 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to wandb --single True
[2024-08-15 20:55:22,032] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-15 20:55:22,033] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-15 20:55:22,034] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-15 20:55:22,036] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-15 20:55:22,070] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-15 20:55:22,073] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-15 20:55:22,074] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-15 20:55:22,098] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-15 20:55:23,763] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-15 20:55:23,763] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-15 20:55:23,763] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-15 20:55:23,764] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-15 20:55:23,764] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-15 20:55:23,764] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-15 20:55:23,765] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-15 20:55:23,766] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:  33%|███▎      | 1/3 [00:56<01:53, 56.58s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:31<00:43, 43.60s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:39<00:00, 27.37s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:39<00:00, 33.05s/it]
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
---------init adapt_vision_model---------
Loading checkpoint shards:  33%|███▎      | 1/3 [00:56<01:53, 56.70s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:31<00:43, 43.53s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:39<00:00, 27.35s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:39<00:00, 33.04s/it]
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
---------init adapt_vision_model---------
Loading checkpoint shards:  33%|███▎      | 1/3 [00:57<01:55, 57.63s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:33<00:44, 44.81s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:40<00:00, 27.49s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:40<00:00, 33.45s/it]
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
---------init adapt_vision_model---------
Loading checkpoint shards:  33%|███▎      | 1/3 [01:01<02:03, 61.84s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:42<00:49, 49.64s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:55<00:00, 32.69s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:55<00:00, 38.48s/it]
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
---------init adapt_vision_model---------
Formatting inputs...Skip in lazy mode
mm_projector.pos_embed
mm_projector.query
mm_projector.proj
mm_projector.kv_proj.weight
mm_projector.attn.in_proj_weight
mm_projector.attn.in_proj_bias
mm_projector.attn.out_proj.weight
mm_projector.attn.out_proj.bias
mm_projector.ln_q.weight
mm_projector.ln_q.bias
mm_projector.ln_kv.weight
mm_projector.ln_kv.bias
mm_projector.ln_post.weight
mm_projector.ln_post.bias
Formatting inputs...Skip in lazy mode
mm_projector.pos_embed
mm_projector.query
mm_projector.proj
mm_projector.kv_proj.weight
mm_projector.attn.in_proj_weight
mm_projector.attn.in_proj_bias
mm_projector.attn.out_proj.weight
mm_projector.attn.out_proj.bias
mm_projector.ln_q.weight
mm_projector.ln_q.bias
mm_projector.ln_kv.weight
mm_projector.ln_kv.bias
mm_projector.ln_post.weight
mm_projector.ln_post.bias
Formatting inputs...Skip in lazy mode
mm_projector.pos_embed
mm_projector.query
mm_projector.proj
mm_projector.kv_proj.weight
mm_projector.attn.in_proj_weight
mm_projector.attn.in_proj_bias
mm_projector.attn.out_proj.weight
mm_projector.attn.out_proj.bias
mm_projector.ln_q.weight
mm_projector.ln_q.bias
mm_projector.ln_kv.weight
mm_projector.ln_kv.bias
mm_projector.ln_post.weight
mm_projector.ln_post.bias
Loading checkpoint shards:  33%|███▎      | 1/3 [01:02<02:05, 62.66s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:43<00:50, 50.02s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:58<00:00, 33.94s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:58<00:00, 39.54s/it]
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
---------init adapt_vision_model---------
Loading checkpoint shards:  33%|███▎      | 1/3 [01:01<02:02, 61.42s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:43<00:50, 50.12s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:59<00:00, 34.31s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:59<00:00, 39.71s/it]
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards:  33%|███▎      | 1/3 [01:02<02:05, 62.63s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:44<00:50, 50.41s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:59<00:00, 34.24s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:59<00:00, 39.83s/it]
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
---------init adapt_vision_model---------
---------init adapt_vision_model---------
Loading checkpoint shards:  33%|███▎      | 1/3 [01:02<02:05, 62.64s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [01:44<00:50, 50.43s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:59<00:00, 34.37s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:59<00:00, 39.93s/it]
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
---------init adapt_vision_model---------
wandb: Tracking run with wandb version 0.17.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.17.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.17.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Formatting inputs...Skip in lazy mode
mm_projector.pos_embed
mm_projector.query
mm_projector.proj
mm_projector.kv_proj.weight
mm_projector.attn.in_proj_weight
mm_projector.attn.in_proj_bias
mm_projector.attn.out_proj.weight
mm_projector.attn.out_proj.bias
mm_projector.ln_q.weight
mm_projector.ln_q.bias
mm_projector.ln_kv.weight
mm_projector.ln_kv.bias
mm_projector.ln_post.weight
mm_projector.ln_post.bias
  0%|          | 0/2181 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/test/test08/gzh/LLaVA-UHD/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/home/test/test08/gzh/LLaVA-UHD/llava/train/train.py", line 1031, in train
    trainer.train()
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 2795, in compute_loss
    outputs = model(**inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 171, in forward
    raise RuntimeError("module must have its parameters and buffers "
RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu
  0%|          | 0/2181 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/test/test08/gzh/LLaVA-UHD/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/home/test/test08/gzh/LLaVA-UHD/llava/train/train.py", line 1031, in train
    trainer.train()
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 2795, in compute_loss
    outputs = model(**inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 171, in forward
    raise RuntimeError("module must have its parameters and buffers "
RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu
  0%|          | 0/2181 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/test/test08/gzh/LLaVA-UHD/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/home/test/test08/gzh/LLaVA-UHD/llava/train/train.py", line 1031, in train
    trainer.train()
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 2795, in compute_loss
    outputs = model(**inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 171, in forward
    raise RuntimeError("module must have its parameters and buffers "
RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/test/test08/gzh/LLaVA-UHD/wandb/offline-run-20240815_205741-h7wk9wt5
wandb: Find logs at: ./wandb/offline-run-20240815_205741-h7wk9wt5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/test/test08/gzh/LLaVA-UHD/wandb/offline-run-20240815_205741-lj9qpmec
wandb: Find logs at: ./wandb/offline-run-20240815_205741-lj9qpmec/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/test/test08/gzh/LLaVA-UHD/wandb/offline-run-20240815_205741-m20dyqrc
wandb: Find logs at: ./wandb/offline-run-20240815_205741-m20dyqrc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Formatting inputs...Skip in lazy mode
mm_projector.pos_embed
mm_projector.query
mm_projector.proj
mm_projector.kv_proj.weight
mm_projector.attn.in_proj_weight
mm_projector.attn.in_proj_bias
mm_projector.attn.out_proj.weight
mm_projector.attn.out_proj.bias
mm_projector.ln_q.weight
mm_projector.ln_q.bias
mm_projector.ln_kv.weight
mm_projector.ln_kv.bias
mm_projector.ln_post.weight
mm_projector.ln_post.bias
Formatting inputs...Skip in lazy mode
mm_projector.pos_embed
mm_projector.query
mm_projector.proj
mm_projector.kv_proj.weight
mm_projector.attn.in_proj_weight
mm_projector.attn.in_proj_bias
mm_projector.attn.out_proj.weight
mm_projector.attn.out_proj.bias
mm_projector.ln_q.weight
mm_projector.ln_q.bias
mm_projector.ln_kv.weight
mm_projector.ln_kv.bias
mm_projector.ln_post.weight
mm_projector.ln_post.bias
Formatting inputs...Skip in lazy mode
mm_projector.pos_embed
mm_projector.query
mm_projector.proj
mm_projector.kv_proj.weight
mm_projector.attn.in_proj_weight
mm_projector.attn.in_proj_bias
mm_projector.attn.out_proj.weight
mm_projector.attn.out_proj.bias
mm_projector.ln_q.weight
mm_projector.ln_q.bias
mm_projector.ln_kv.weight
mm_projector.ln_kv.bias
mm_projector.ln_post.weight
mm_projector.ln_post.bias
wandb: Tracking run with wandb version 0.17.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Formatting inputs...Skip in lazy mode
mm_projector.pos_embed
mm_projector.query
mm_projector.proj
mm_projector.kv_proj.weight
mm_projector.attn.in_proj_weight
mm_projector.attn.in_proj_bias
mm_projector.attn.out_proj.weight
mm_projector.attn.out_proj.bias
mm_projector.ln_q.weight
mm_projector.ln_q.bias
mm_projector.ln_kv.weight
mm_projector.ln_kv.bias
mm_projector.ln_post.weight
mm_projector.ln_post.bias
srun: error: g73: task 7: Exited with exit code 1
wandb: Tracking run with wandb version 0.17.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.17.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.17.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
srun: error: g73: task 5: Exited with exit code 1
wandb: Tracking run with wandb version 0.17.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
srun: error: g73: task 4: Exited with exit code 1
  0%|          | 0/2181 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/test/test08/gzh/LLaVA-UHD/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/home/test/test08/gzh/LLaVA-UHD/llava/train/train.py", line 1031, in train
    trainer.train()
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 2795, in compute_loss
    outputs = model(**inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 171, in forward
    raise RuntimeError("module must have its parameters and buffers "
RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/test/test08/gzh/LLaVA-UHD/wandb/offline-run-20240815_205758-t5ggd8uh
wandb: Find logs at: ./wandb/offline-run-20240815_205758-t5ggd8uh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
  0%|          | 0/2181 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/test/test08/gzh/LLaVA-UHD/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/home/test/test08/gzh/LLaVA-UHD/llava/train/train.py", line 1031, in train
    trainer.train()
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 2795, in compute_loss
    outputs = model(**inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 171, in forward
    raise RuntimeError("module must have its parameters and buffers "
RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu
  0%|          | 0/2181 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/test/test08/gzh/LLaVA-UHD/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/home/test/test08/gzh/LLaVA-UHD/llava/train/train.py", line 1031, in train
    trainer.train()
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 2795, in compute_loss
    outputs = model(**inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 171, in forward
    raise RuntimeError("module must have its parameters and buffers "
RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/test/test08/gzh/LLaVA-UHD/wandb/offline-run-20240815_205801-olxygdfs
wandb: Find logs at: ./wandb/offline-run-20240815_205801-olxygdfs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/test/test08/gzh/LLaVA-UHD/wandb/offline-run-20240815_205801-bhmei7yt
wandb: Find logs at: ./wandb/offline-run-20240815_205801-bhmei7yt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
  0%|          | 0/2181 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/test/test08/gzh/LLaVA-UHD/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/home/test/test08/gzh/LLaVA-UHD/llava/train/train.py", line 1031, in train
    trainer.train()
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 2795, in compute_loss
    outputs = model(**inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 171, in forward
    raise RuntimeError("module must have its parameters and buffers "
RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/test/test08/gzh/LLaVA-UHD/wandb/offline-run-20240815_205802-cdybhn9p
wandb: Find logs at: ./wandb/offline-run-20240815_205802-cdybhn9p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
srun: error: g73: task 6: Exited with exit code 1
  0%|          | 0/2181 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/test/test08/gzh/LLaVA-UHD/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/home/test/test08/gzh/LLaVA-UHD/llava/train/train.py", line 1031, in train
    trainer.train()
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/transformers/trainer.py", line 2795, in compute_loss
    outputs = model(**inputs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py", line 171, in forward
    raise RuntimeError("module must have its parameters and buffers "
RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cpu
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/test/test08/gzh/LLaVA-UHD/wandb/offline-run-20240815_205801-5ghkgj5u
wandb: Find logs at: ./wandb/offline-run-20240815_205801-5ghkgj5u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
srun: error: g73: task 1: Exited with exit code 1
srun: error: g73: task 3: Exited with exit code 1
srun: error: g73: task 2: Exited with exit code 1
srun: error: g73: task 0: Exited with exit code 1
slurmstepd: error: *** JOB 885 ON g73 CANCELLED AT 2024-08-15T21:00:03 ***
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
