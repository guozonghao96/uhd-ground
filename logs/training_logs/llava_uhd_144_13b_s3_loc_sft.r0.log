nohup: ignoring input
./checkpoints_new/llava-uhd-144-13b-loc-unpad
[2024-08-29 16:38:39,122] torch.distributed.run: [WARNING] 
[2024-08-29 16:38:39,122] torch.distributed.run: [WARNING] *****************************************
[2024-08-29 16:38:39,122] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-08-29 16:38:39,122] torch.distributed.run: [WARNING] *****************************************
[2024-08-29 16:39:48,130] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-29 16:39:48,134] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-29 16:39:48,147] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-29 16:39:48,162] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-29 16:39:48,162] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-29 16:39:48,162] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-29 16:39:48,177] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-29 16:39:48,188] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-08-29 16:39:49,921] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-29 16:39:49,921] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-29 16:39:49,934] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-29 16:39:49,935] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-29 16:39:49,954] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-29 16:39:49,955] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-29 16:39:49,960] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-08-29 16:39:49,960] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
[2024-08-29 16:39:50,022] [INFO] [comm.py:637:init_distributed] cdb=None
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are using a model of type llama to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.32s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:48, 24.12s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:24<00:49, 24.86s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:25<00:50, 25.34s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:25<00:51, 25.60s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:25<00:51, 25.63s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:25<00:51, 25.78s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:25<00:51, 25.89s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.47s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:45<00:22, 22.75s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:47<00:23, 23.37s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:23, 23.78s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.08s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.10s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.21s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.24s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:51<00:00, 14.96s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:51<00:00, 17.15s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:51<00:00, 15.09s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:51<00:00, 17.32s/it]
---------init adapt_vision_model---------
---------init adapt_vision_model---------
Loading checkpoint shards: 100%|██████████| 3/3 [00:56<00:00, 16.82s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:56<00:00, 18.74s/it]
---------init adapt_vision_model---------
Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 17.29s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:57<00:00, 19.20s/it]
---------init adapt_vision_model---------
Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 17.48s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.43s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 17.47s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.44s/it]
---------init adapt_vision_model---------
Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 17.50s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.45s/it]
---------init adapt_vision_model---------
---------init adapt_vision_model---------
Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 17.52s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:58<00:00, 19.47s/it]
---------init adapt_vision_model---------
embed_tokens.weight
layers.0.self_attn.q_proj.weight
layers.0.self_attn.k_proj.weight
layers.0.self_attn.v_proj.weight
layers.0.self_attn.o_proj.weight
layers.0.mlp.gate_proj.weight
layers.0.mlp.up_proj.weight
layers.0.mlp.down_proj.weight
layers.0.input_layernorm.weight
layers.0.post_attention_layernorm.weight
layers.1.self_attn.q_proj.weight
layers.1.self_attn.k_proj.weight
layers.1.self_attn.v_proj.weight
layers.1.self_attn.o_proj.weight
layers.1.mlp.gate_proj.weight
layers.1.mlp.up_proj.weight
layers.1.mlp.down_proj.weight
layers.1.input_layernorm.weight
layers.1.post_attention_layernorm.weight
layers.2.self_attn.q_proj.weight
layers.2.self_attn.k_proj.weight
layers.2.self_attn.v_proj.weight
layers.2.self_attn.o_proj.weight
layers.2.mlp.gate_proj.weight
layers.2.mlp.up_proj.weight
layers.2.mlp.down_proj.weight
layers.2.input_layernorm.weight
layers.2.post_attention_layernorm.weight
layers.3.self_attn.q_proj.weight
layers.3.self_attn.k_proj.weight
layers.3.self_attn.v_proj.weight
layers.3.self_attn.o_proj.weight
layers.3.mlp.gate_proj.weight
layers.3.mlp.up_proj.weight
layers.3.mlp.down_proj.weight
layers.3.input_layernorm.weight
layers.3.post_attention_layernorm.weight
layers.4.self_attn.q_proj.weight
layers.4.self_attn.k_proj.weight
layers.4.self_attn.v_proj.weight
layers.4.self_attn.o_proj.weight
layers.4.mlp.gate_proj.weight
layers.4.mlp.up_proj.weight
layers.4.mlp.down_proj.weight
layers.4.input_layernorm.weight
layers.4.post_attention_layernorm.weight
layers.5.self_attn.q_proj.weight
layers.5.self_attn.k_proj.weight
layers.5.self_attn.v_proj.weight
layers.5.self_attn.o_proj.weight
layers.5.mlp.gate_proj.weight
layers.5.mlp.up_proj.weight
layers.5.mlp.down_proj.weight
layers.5.input_layernorm.weight
layers.5.post_attention_layernorm.weight
layers.6.self_attn.q_proj.weight
layers.6.self_attn.k_proj.weight
layers.6.self_attn.v_proj.weight
layers.6.self_attn.o_proj.weight
layers.6.mlp.gate_proj.weight
layers.6.mlp.up_proj.weight
layers.6.mlp.down_proj.weight
layers.6.input_layernorm.weight
layers.6.post_attention_layernorm.weight
layers.7.self_attn.q_proj.weight
layers.7.self_attn.k_proj.weight
layers.7.self_attn.v_proj.weight
layers.7.self_attn.o_proj.weight
layers.7.mlp.gate_proj.weight
layers.7.mlp.up_proj.weight
layers.7.mlp.down_proj.weight
layers.7.input_layernorm.weight
layers.7.post_attention_layernorm.weight
layers.8.self_attn.q_proj.weight
layers.8.self_attn.k_proj.weight
layers.8.self_attn.v_proj.weight
layers.8.self_attn.o_proj.weight
layers.8.mlp.gate_proj.weight
layers.8.mlp.up_proj.weight
layers.8.mlp.down_proj.weight
layers.8.input_layernorm.weight
layers.8.post_attention_layernorm.weight
layers.9.self_attn.q_proj.weight
layers.9.self_attn.k_proj.weight
layers.9.self_attn.v_proj.weight
layers.9.self_attn.o_proj.weight
layers.9.mlp.gate_proj.weight
layers.9.mlp.up_proj.weight
layers.9.mlp.down_proj.weight
layers.9.input_layernorm.weight
layers.9.post_attention_layernorm.weight
layers.10.self_attn.q_proj.weight
layers.10.self_attn.k_proj.weight
layers.10.self_attn.v_proj.weight
layers.10.self_attn.o_proj.weight
layers.10.mlp.gate_proj.weight
layers.10.mlp.up_proj.weight
layers.10.mlp.down_proj.weight
layers.10.input_layernorm.weight
layers.10.post_attention_layernorm.weight
layers.11.self_attn.q_proj.weight
layers.11.self_attn.k_proj.weight
layers.11.self_attn.v_proj.weight
layers.11.self_attn.o_proj.weight
layers.11.mlp.gate_proj.weight
layers.11.mlp.up_proj.weight
layers.11.mlp.down_proj.weight
layers.11.input_layernorm.weight
layers.11.post_attention_layernorm.weight
layers.12.self_attn.q_proj.weight
layers.12.self_attn.k_proj.weight
layers.12.self_attn.v_proj.weight
layers.12.self_attn.o_proj.weight
layers.12.mlp.gate_proj.weight
layers.12.mlp.up_proj.weight
layers.12.mlp.down_proj.weight
layers.12.input_layernorm.weight
layers.12.post_attention_layernorm.weight
layers.13.self_attn.q_proj.weight
layers.13.self_attn.k_proj.weight
layers.13.self_attn.v_proj.weight
layers.13.self_attn.o_proj.weight
layers.13.mlp.gate_proj.weight
layers.13.mlp.up_proj.weight
layers.13.mlp.down_proj.weight
layers.13.input_layernorm.weight
layers.13.post_attention_layernorm.weight
layers.14.self_attn.q_proj.weight
layers.14.self_attn.k_proj.weight
layers.14.self_attn.v_proj.weight
layers.14.self_attn.o_proj.weight
layers.14.mlp.gate_proj.weight
layers.14.mlp.up_proj.weight
layers.14.mlp.down_proj.weight
layers.14.input_layernorm.weight
layers.14.post_attention_layernorm.weight
layers.15.self_attn.q_proj.weight
layers.15.self_attn.k_proj.weight
layers.15.self_attn.v_proj.weight
layers.15.self_attn.o_proj.weight
layers.15.mlp.gate_proj.weight
layers.15.mlp.up_proj.weight
layers.15.mlp.down_proj.weight
layers.15.input_layernorm.weight
layers.15.post_attention_layernorm.weight
layers.16.self_attn.q_proj.weight
layers.16.self_attn.k_proj.weight
layers.16.self_attn.v_proj.weight
layers.16.self_attn.o_proj.weight
layers.16.mlp.gate_proj.weight
layers.16.mlp.up_proj.weight
layers.16.mlp.down_proj.weight
layers.16.input_layernorm.weight
layers.16.post_attention_layernorm.weight
layers.17.self_attn.q_proj.weight
layers.17.self_attn.k_proj.weight
layers.17.self_attn.v_proj.weight
layers.17.self_attn.o_proj.weight
layers.17.mlp.gate_proj.weight
layers.17.mlp.up_proj.weight
layers.17.mlp.down_proj.weight
layers.17.input_layernorm.weight
layers.17.post_attention_layernorm.weight
layers.18.self_attn.q_proj.weight
layers.18.self_attn.k_proj.weight
layers.18.self_attn.v_proj.weight
layers.18.self_attn.o_proj.weight
layers.18.mlp.gate_proj.weight
layers.18.mlp.up_proj.weight
layers.18.mlp.down_proj.weight
layers.18.input_layernorm.weight
layers.18.post_attention_layernorm.weight
layers.19.self_attn.q_proj.weight
layers.19.self_attn.k_proj.weight
layers.19.self_attn.v_proj.weight
layers.19.self_attn.o_proj.weight
layers.19.mlp.gate_proj.weight
layers.19.mlp.up_proj.weight
layers.19.mlp.down_proj.weight
layers.19.input_layernorm.weight
layers.19.post_attention_layernorm.weight
layers.20.self_attn.q_proj.weight
layers.20.self_attn.k_proj.weight
layers.20.self_attn.v_proj.weight
layers.20.self_attn.o_proj.weight
layers.20.mlp.gate_proj.weight
layers.20.mlp.up_proj.weight
layers.20.mlp.down_proj.weight
layers.20.input_layernorm.weight
layers.20.post_attention_layernorm.weight
layers.21.self_attn.q_proj.weight
layers.21.self_attn.k_proj.weight
layers.21.self_attn.v_proj.weight
layers.21.self_attn.o_proj.weight
layers.21.mlp.gate_proj.weight
layers.21.mlp.up_proj.weight
layers.21.mlp.down_proj.weight
layers.21.input_layernorm.weight
layers.21.post_attention_layernorm.weight
layers.22.self_attn.q_proj.weight
layers.22.self_attn.k_proj.weight
layers.22.self_attn.v_proj.weight
layers.22.self_attn.o_proj.weight
layers.22.mlp.gate_proj.weight
layers.22.mlp.up_proj.weight
layers.22.mlp.down_proj.weight
layers.22.input_layernorm.weight
layers.22.post_attention_layernorm.weight
layers.23.self_attn.q_proj.weight
layers.23.self_attn.k_proj.weight
layers.23.self_attn.v_proj.weight
layers.23.self_attn.o_proj.weight
layers.23.mlp.gate_proj.weight
layers.23.mlp.up_proj.weight
layers.23.mlp.down_proj.weight
layers.23.input_layernorm.weight
layers.23.post_attention_layernorm.weight
layers.24.self_attn.q_proj.weight
layers.24.self_attn.k_proj.weight
layers.24.self_attn.v_proj.weight
layers.24.self_attn.o_proj.weight
layers.24.mlp.gate_proj.weight
layers.24.mlp.up_proj.weight
layers.24.mlp.down_proj.weight
layers.24.input_layernorm.weight
layers.24.post_attention_layernorm.weight
layers.25.self_attn.q_proj.weight
layers.25.self_attn.k_proj.weight
layers.25.self_attn.v_proj.weight
layers.25.self_attn.o_proj.weight
layers.25.mlp.gate_proj.weight
layers.25.mlp.up_proj.weight
layers.25.mlp.down_proj.weight
layers.25.input_layernorm.weight
layers.25.post_attention_layernorm.weight
layers.26.self_attn.q_proj.weight
layers.26.self_attn.k_proj.weight
layers.26.self_attn.v_proj.weight
layers.26.self_attn.o_proj.weight
layers.26.mlp.gate_proj.weight
layers.26.mlp.up_proj.weight
layers.26.mlp.down_proj.weight
layers.26.input_layernorm.weight
layers.26.post_attention_layernorm.weight
layers.27.self_attn.q_proj.weight
layers.27.self_attn.k_proj.weight
layers.27.self_attn.v_proj.weight
layers.27.self_attn.o_proj.weight
layers.27.mlp.gate_proj.weight
layers.27.mlp.up_proj.weight
layers.27.mlp.down_proj.weight
layers.27.input_layernorm.weight
layers.27.post_attention_layernorm.weight
layers.28.self_attn.q_proj.weight
layers.28.self_attn.k_proj.weight
layers.28.self_attn.v_proj.weight
layers.28.self_attn.o_proj.weight
layers.28.mlp.gate_proj.weight
layers.28.mlp.up_proj.weight
layers.28.mlp.down_proj.weight
layers.28.input_layernorm.weight
layers.28.post_attention_layernorm.weight
layers.29.self_attn.q_proj.weight
layers.29.self_attn.k_proj.weight
layers.29.self_attn.v_proj.weight
layers.29.self_attn.o_proj.weight
layers.29.mlp.gate_proj.weight
layers.29.mlp.up_proj.weight
layers.29.mlp.down_proj.weight
layers.29.input_layernorm.weight
layers.29.post_attention_layernorm.weight
layers.30.self_attn.q_proj.weight
layers.30.self_attn.k_proj.weight
layers.30.self_attn.v_proj.weight
layers.30.self_attn.o_proj.weight
layers.30.mlp.gate_proj.weight
layers.30.mlp.up_proj.weight
layers.30.mlp.down_proj.weight
layers.30.input_layernorm.weight
layers.30.post_attention_layernorm.weight
layers.31.self_attn.q_proj.weight
layers.31.self_attn.k_proj.weight
layers.31.self_attn.v_proj.weight
layers.31.self_attn.o_proj.weight
layers.31.mlp.gate_proj.weight
layers.31.mlp.up_proj.weight
layers.31.mlp.down_proj.weight
layers.31.input_layernorm.weight
layers.31.post_attention_layernorm.weight
layers.32.self_attn.q_proj.weight
layers.32.self_attn.k_proj.weight
layers.32.self_attn.v_proj.weight
layers.32.self_attn.o_proj.weight
layers.32.mlp.gate_proj.weight
layers.32.mlp.up_proj.weight
layers.32.mlp.down_proj.weight
layers.32.input_layernorm.weight
layers.32.post_attention_layernorm.weight
layers.33.self_attn.q_proj.weight
layers.33.self_attn.k_proj.weight
layers.33.self_attn.v_proj.weight
layers.33.self_attn.o_proj.weight
layers.33.mlp.gate_proj.weight
layers.33.mlp.up_proj.weight
layers.33.mlp.down_proj.weight
layers.33.input_layernorm.weight
layers.33.post_attention_layernorm.weight
layers.34.self_attn.q_proj.weight
layers.34.self_attn.k_proj.weight
layers.34.self_attn.v_proj.weight
layers.34.self_attn.o_proj.weight
layers.34.mlp.gate_proj.weight
layers.34.mlp.up_proj.weight
layers.34.mlp.down_proj.weight
layers.34.input_layernorm.weight
layers.34.post_attention_layernorm.weight
layers.35.self_attn.q_proj.weight
layers.35.self_attn.k_proj.weight
layers.35.self_attn.v_proj.weight
layers.35.self_attn.o_proj.weight
layers.35.mlp.gate_proj.weight
layers.35.mlp.up_proj.weight
layers.35.mlp.down_proj.weight
layers.35.input_layernorm.weight
layers.35.post_attention_layernorm.weight
layers.36.self_attn.q_proj.weight
layers.36.self_attn.k_proj.weight
layers.36.self_attn.v_proj.weight
layers.36.self_attn.o_proj.weight
layers.36.mlp.gate_proj.weight
layers.36.mlp.up_proj.weight
layers.36.mlp.down_proj.weight
layers.36.input_layernorm.weight
layers.36.post_attention_layernorm.weight
layers.37.self_attn.q_proj.weight
layers.37.self_attn.k_proj.weight
layers.37.self_attn.v_proj.weight
layers.37.self_attn.o_proj.weight
layers.37.mlp.gate_proj.weight
layers.37.mlp.up_proj.weight
layers.37.mlp.down_proj.weight
layers.37.input_layernorm.weight
layers.37.post_attention_layernorm.weight
layers.38.self_attn.q_proj.weight
layers.38.self_attn.k_proj.weight
layers.38.self_attn.v_proj.weight
layers.38.self_attn.o_proj.weight
layers.38.mlp.gate_proj.weight
layers.38.mlp.up_proj.weight
layers.38.mlp.down_proj.weight
layers.38.input_layernorm.weight
layers.38.post_attention_layernorm.weight
layers.39.self_attn.q_proj.weight
layers.39.self_attn.k_proj.weight
layers.39.self_attn.v_proj.weight
layers.39.self_attn.o_proj.weight
layers.39.mlp.gate_proj.weight
layers.39.mlp.up_proj.weight
layers.39.mlp.down_proj.weight
layers.39.input_layernorm.weight
layers.39.post_attention_layernorm.weight
norm.weight
mm_projector.query
mm_projector.proj
mm_projector.kv_proj.weight
mm_projector.attn.in_proj_weight
mm_projector.attn.in_proj_bias
mm_projector.attn.out_proj.weight
mm_projector.attn.out_proj.bias
mm_projector.ln_q.weight
mm_projector.ln_q.bias
mm_projector.ln_kv.weight
mm_projector.ln_kv.bias
mm_projector.ln_post.weight
mm_projector.ln_post.bias
lm_head.weight
Formatting inputs...Skip in lazy mode
embed_tokens.weight
layers.0.self_attn.q_proj.weight
layers.0.self_attn.k_proj.weight
layers.0.self_attn.v_proj.weight
layers.0.self_attn.o_proj.weight
layers.0.mlp.gate_proj.weight
layers.0.mlp.up_proj.weight
layers.0.mlp.down_proj.weight
layers.0.input_layernorm.weight
layers.0.post_attention_layernorm.weight
layers.1.self_attn.q_proj.weight
layers.1.self_attn.k_proj.weight
layers.1.self_attn.v_proj.weight
layers.1.self_attn.o_proj.weight
layers.1.mlp.gate_proj.weight
layers.1.mlp.up_proj.weight
layers.1.mlp.down_proj.weight
layers.1.input_layernorm.weight
layers.1.post_attention_layernorm.weight
layers.2.self_attn.q_proj.weight
layers.2.self_attn.k_proj.weight
layers.2.self_attn.v_proj.weight
layers.2.self_attn.o_proj.weight
layers.2.mlp.gate_proj.weight
layers.2.mlp.up_proj.weight
layers.2.mlp.down_proj.weight
layers.2.input_layernorm.weight
layers.2.post_attention_layernorm.weight
layers.3.self_attn.q_proj.weight
layers.3.self_attn.k_proj.weight
layers.3.self_attn.v_proj.weight
layers.3.self_attn.o_proj.weight
layers.3.mlp.gate_proj.weight
layers.3.mlp.up_proj.weight
layers.3.mlp.down_proj.weight
layers.3.input_layernorm.weight
layers.3.post_attention_layernorm.weight
layers.4.self_attn.q_proj.weight
layers.4.self_attn.k_proj.weight
layers.4.self_attn.v_proj.weight
layers.4.self_attn.o_proj.weight
layers.4.mlp.gate_proj.weight
layers.4.mlp.up_proj.weight
layers.4.mlp.down_proj.weight
layers.4.input_layernorm.weight
layers.4.post_attention_layernorm.weight
layers.5.self_attn.q_proj.weight
layers.5.self_attn.k_proj.weight
layers.5.self_attn.v_proj.weight
layers.5.self_attn.o_proj.weight
layers.5.mlp.gate_proj.weight
layers.5.mlp.up_proj.weight
layers.5.mlp.down_proj.weight
layers.5.input_layernorm.weight
layers.5.post_attention_layernorm.weight
layers.6.self_attn.q_proj.weight
layers.6.self_attn.k_proj.weight
layers.6.self_attn.v_proj.weight
layers.6.self_attn.o_proj.weight
layers.6.mlp.gate_proj.weight
layers.6.mlp.up_proj.weight
layers.6.mlp.down_proj.weight
layers.6.input_layernorm.weight
layers.6.post_attention_layernorm.weight
layers.7.self_attn.q_proj.weight
layers.7.self_attn.k_proj.weight
layers.7.self_attn.v_proj.weight
layers.7.self_attn.o_proj.weight
layers.7.mlp.gate_proj.weight
layers.7.mlp.up_proj.weight
layers.7.mlp.down_proj.weight
layers.7.input_layernorm.weight
layers.7.post_attention_layernorm.weight
layers.8.self_attn.q_proj.weight
layers.8.self_attn.k_proj.weight
layers.8.self_attn.v_proj.weight
layers.8.self_attn.o_proj.weight
layers.8.mlp.gate_proj.weight
layers.8.mlp.up_proj.weight
layers.8.mlp.down_proj.weight
layers.8.input_layernorm.weight
layers.8.post_attention_layernorm.weight
layers.9.self_attn.q_proj.weight
layers.9.self_attn.k_proj.weight
layers.9.self_attn.v_proj.weight
layers.9.self_attn.o_proj.weight
layers.9.mlp.gate_proj.weight
layers.9.mlp.up_proj.weight
layers.9.mlp.down_proj.weight
layers.9.input_layernorm.weight
layers.9.post_attention_layernorm.weight
layers.10.self_attn.q_proj.weight
layers.10.self_attn.k_proj.weight
layers.10.self_attn.v_proj.weight
layers.10.self_attn.o_proj.weight
layers.10.mlp.gate_proj.weight
layers.10.mlp.up_proj.weight
layers.10.mlp.down_proj.weight
layers.10.input_layernorm.weight
layers.10.post_attention_layernorm.weight
layers.11.self_attn.q_proj.weight
layers.11.self_attn.k_proj.weight
layers.11.self_attn.v_proj.weight
layers.11.self_attn.o_proj.weight
layers.11.mlp.gate_proj.weight
layers.11.mlp.up_proj.weight
layers.11.mlp.down_proj.weight
layers.11.input_layernorm.weight
layers.11.post_attention_layernorm.weight
layers.12.self_attn.q_proj.weight
layers.12.self_attn.k_proj.weight
layers.12.self_attn.v_proj.weight
layers.12.self_attn.o_proj.weight
layers.12.mlp.gate_proj.weight
layers.12.mlp.up_proj.weight
layers.12.mlp.down_proj.weight
layers.12.input_layernorm.weight
layers.12.post_attention_layernorm.weight
layers.13.self_attn.q_proj.weight
layers.13.self_attn.k_proj.weight
layers.13.self_attn.v_proj.weight
layers.13.self_attn.o_proj.weight
layers.13.mlp.gate_proj.weight
layers.13.mlp.up_proj.weight
layers.13.mlp.down_proj.weight
layers.13.input_layernorm.weight
layers.13.post_attention_layernorm.weight
layers.14.self_attn.q_proj.weight
layers.14.self_attn.k_proj.weight
layers.14.self_attn.v_proj.weight
layers.14.self_attn.o_proj.weight
layers.14.mlp.gate_proj.weight
layers.14.mlp.up_proj.weight
layers.14.mlp.down_proj.weight
layers.14.input_layernorm.weight
layers.14.post_attention_layernorm.weight
layers.15.self_attn.q_proj.weight
layers.15.self_attn.k_proj.weight
layers.15.self_attn.v_proj.weight
layers.15.self_attn.o_proj.weight
layers.15.mlp.gate_proj.weight
layers.15.mlp.up_proj.weight
layers.15.mlp.down_proj.weight
layers.15.input_layernorm.weight
layers.15.post_attention_layernorm.weight
layers.16.self_attn.q_proj.weight
layers.16.self_attn.k_proj.weight
layers.16.self_attn.v_proj.weight
layers.16.self_attn.o_proj.weight
layers.16.mlp.gate_proj.weight
layers.16.mlp.up_proj.weight
layers.16.mlp.down_proj.weight
layers.16.input_layernorm.weight
layers.16.post_attention_layernorm.weight
layers.17.self_attn.q_proj.weight
layers.17.self_attn.k_proj.weight
layers.17.self_attn.v_proj.weight
layers.17.self_attn.o_proj.weight
layers.17.mlp.gate_proj.weight
layers.17.mlp.up_proj.weight
layers.17.mlp.down_proj.weight
layers.17.input_layernorm.weight
layers.17.post_attention_layernorm.weight
layers.18.self_attn.q_proj.weight
layers.18.self_attn.k_proj.weight
layers.18.self_attn.v_proj.weight
layers.18.self_attn.o_proj.weight
layers.18.mlp.gate_proj.weight
layers.18.mlp.up_proj.weight
layers.18.mlp.down_proj.weight
layers.18.input_layernorm.weight
layers.18.post_attention_layernorm.weight
layers.19.self_attn.q_proj.weight
layers.19.self_attn.k_proj.weight
layers.19.self_attn.v_proj.weight
layers.19.self_attn.o_proj.weight
layers.19.mlp.gate_proj.weight
layers.19.mlp.up_proj.weight
layers.19.mlp.down_proj.weight
layers.19.input_layernorm.weight
layers.19.post_attention_layernorm.weight
layers.20.self_attn.q_proj.weight
layers.20.self_attn.k_proj.weight
layers.20.self_attn.v_proj.weight
layers.20.self_attn.o_proj.weight
layers.20.mlp.gate_proj.weight
layers.20.mlp.up_proj.weight
layers.20.mlp.down_proj.weight
layers.20.input_layernorm.weight
layers.20.post_attention_layernorm.weight
layers.21.self_attn.q_proj.weight
layers.21.self_attn.k_proj.weight
layers.21.self_attn.v_proj.weight
layers.21.self_attn.o_proj.weight
layers.21.mlp.gate_proj.weight
layers.21.mlp.up_proj.weight
layers.21.mlp.down_proj.weight
layers.21.input_layernorm.weight
layers.21.post_attention_layernorm.weight
layers.22.self_attn.q_proj.weight
layers.22.self_attn.k_proj.weight
layers.22.self_attn.v_proj.weight
layers.22.self_attn.o_proj.weight
layers.22.mlp.gate_proj.weight
layers.22.mlp.up_proj.weight
layers.22.mlp.down_proj.weight
layers.22.input_layernorm.weight
layers.22.post_attention_layernorm.weight
layers.23.self_attn.q_proj.weight
layers.23.self_attn.k_proj.weight
layers.23.self_attn.v_proj.weight
layers.23.self_attn.o_proj.weight
layers.23.mlp.gate_proj.weight
layers.23.mlp.up_proj.weight
layers.23.mlp.down_proj.weight
layers.23.input_layernorm.weight
layers.23.post_attention_layernorm.weight
layers.24.self_attn.q_proj.weight
layers.24.self_attn.k_proj.weight
layers.24.self_attn.v_proj.weight
layers.24.self_attn.o_proj.weight
layers.24.mlp.gate_proj.weight
layers.24.mlp.up_proj.weight
layers.24.mlp.down_proj.weight
layers.24.input_layernorm.weight
layers.24.post_attention_layernorm.weight
layers.25.self_attn.q_proj.weight
layers.25.self_attn.k_proj.weight
layers.25.self_attn.v_proj.weight
layers.25.self_attn.o_proj.weight
layers.25.mlp.gate_proj.weight
layers.25.mlp.up_proj.weight
layers.25.mlp.down_proj.weight
layers.25.input_layernorm.weight
layers.25.post_attention_layernorm.weight
layers.26.self_attn.q_proj.weight
layers.26.self_attn.k_proj.weight
layers.26.self_attn.v_proj.weight
layers.26.self_attn.o_proj.weight
layers.26.mlp.gate_proj.weight
layers.26.mlp.up_proj.weight
layers.26.mlp.down_proj.weight
layers.26.input_layernorm.weight
layers.26.post_attention_layernorm.weight
layers.27.self_attn.q_proj.weight
layers.27.self_attn.k_proj.weight
layers.27.self_attn.v_proj.weight
layers.27.self_attn.o_proj.weight
layers.27.mlp.gate_proj.weight
layers.27.mlp.up_proj.weight
layers.27.mlp.down_proj.weight
layers.27.input_layernorm.weight
layers.27.post_attention_layernorm.weight
layers.28.self_attn.q_proj.weight
layers.28.self_attn.k_proj.weight
layers.28.self_attn.v_proj.weight
layers.28.self_attn.o_proj.weight
layers.28.mlp.gate_proj.weight
layers.28.mlp.up_proj.weight
layers.28.mlp.down_proj.weight
layers.28.input_layernorm.weight
layers.28.post_attention_layernorm.weight
layers.29.self_attn.q_proj.weight
layers.29.self_attn.k_proj.weight
layers.29.self_attn.v_proj.weight
layers.29.self_attn.o_proj.weight
layers.29.mlp.gate_proj.weight
layers.29.mlp.up_proj.weight
layers.29.mlp.down_proj.weight
layers.29.input_layernorm.weight
layers.29.post_attention_layernorm.weight
layers.30.self_attn.q_proj.weight
layers.30.self_attn.k_proj.weight
layers.30.self_attn.v_proj.weight
layers.30.self_attn.o_proj.weight
layers.30.mlp.gate_proj.weight
layers.30.mlp.up_proj.weight
layers.30.mlp.down_proj.weight
layers.30.input_layernorm.weight
layers.30.post_attention_layernorm.weight
layers.31.self_attn.q_proj.weight
layers.31.self_attn.k_proj.weight
layers.31.self_attn.v_proj.weight
layers.31.self_attn.o_proj.weight
layers.31.mlp.gate_proj.weight
layers.31.mlp.up_proj.weight
layers.31.mlp.down_proj.weight
layers.31.input_layernorm.weight
layers.31.post_attention_layernorm.weight
layers.32.self_attn.q_proj.weight
layers.32.self_attn.k_proj.weight
layers.32.self_attn.v_proj.weight
layers.32.self_attn.o_proj.weight
layers.32.mlp.gate_proj.weight
layers.32.mlp.up_proj.weight
layers.32.mlp.down_proj.weight
layers.32.input_layernorm.weight
layers.32.post_attention_layernorm.weight
layers.33.self_attn.q_proj.weight
layers.33.self_attn.k_proj.weight
layers.33.self_attn.v_proj.weight
layers.33.self_attn.o_proj.weight
layers.33.mlp.gate_proj.weight
layers.33.mlp.up_proj.weight
layers.33.mlp.down_proj.weight
layers.33.input_layernorm.weight
layers.33.post_attention_layernorm.weight
layers.34.self_attn.q_proj.weight
layers.34.self_attn.k_proj.weight
layers.34.self_attn.v_proj.weight
layers.34.self_attn.o_proj.weight
layers.34.mlp.gate_proj.weight
layers.34.mlp.up_proj.weight
layers.34.mlp.down_proj.weight
layers.34.input_layernorm.weight
layers.34.post_attention_layernorm.weight
layers.35.self_attn.q_proj.weight
layers.35.self_attn.k_proj.weight
layers.35.self_attn.v_proj.weight
layers.35.self_attn.o_proj.weight
layers.35.mlp.gate_proj.weight
layers.35.mlp.up_proj.weight
layers.35.mlp.down_proj.weight
layers.35.input_layernorm.weight
layers.35.post_attention_layernorm.weight
layers.36.self_attn.q_proj.weight
layers.36.self_attn.k_proj.weight
layers.36.self_attn.v_proj.weight
layers.36.self_attn.o_proj.weight
layers.36.mlp.gate_proj.weight
layers.36.mlp.up_proj.weight
layers.36.mlp.down_proj.weight
layers.36.input_layernorm.weight
layers.36.post_attention_layernorm.weight
layers.37.self_attn.q_proj.weight
layers.37.self_attn.k_proj.weight
layers.37.self_attn.v_proj.weight
layers.37.self_attn.o_proj.weight
layers.37.mlp.gate_proj.weight
layers.37.mlp.up_proj.weight
layers.37.mlp.down_proj.weight
layers.37.input_layernorm.weight
layers.37.post_attention_layernorm.weight
layers.38.self_attn.q_proj.weight
layers.38.self_attn.k_proj.weight
layers.38.self_attn.v_proj.weight
layers.38.self_attn.o_proj.weight
layers.38.mlp.gate_proj.weight
layers.38.mlp.up_proj.weight
layers.38.mlp.down_proj.weight
layers.38.input_layernorm.weight
layers.38.post_attention_layernorm.weight
layers.39.self_attn.q_proj.weight
layers.39.self_attn.k_proj.weight
layers.39.self_attn.v_proj.weight
layers.39.self_attn.o_proj.weight
layers.39.mlp.gate_proj.weight
layers.39.mlp.up_proj.weight
layers.39.mlp.down_proj.weight
layers.39.input_layernorm.weight
layers.39.post_attention_layernorm.weight
norm.weight
mm_projector.query
mm_projector.proj
mm_projector.kv_proj.weight
mm_projector.attn.in_proj_weight
mm_projector.attn.in_proj_bias
mm_projector.attn.out_proj.weight
mm_projector.attn.out_proj.bias
mm_projector.ln_q.weight
mm_projector.ln_q.bias
mm_projector.ln_kv.weight
mm_projector.ln_kv.bias
mm_projector.ln_post.weight
mm_projector.ln_post.bias
lm_head.weight
embed_tokens.weight
layers.0.self_attn.q_proj.weight
layers.0.self_attn.k_proj.weight
layers.0.self_attn.v_proj.weight
layers.0.self_attn.o_proj.weight
layers.0.mlp.gate_proj.weight
layers.0.mlp.up_proj.weight
layers.0.mlp.down_proj.weight
layers.0.input_layernorm.weight
layers.0.post_attention_layernorm.weight
layers.1.self_attn.q_proj.weight
layers.1.self_attn.k_proj.weight
layers.1.self_attn.v_proj.weight
layers.1.self_attn.o_proj.weight
layers.1.mlp.gate_proj.weight
layers.1.mlp.up_proj.weight
layers.1.mlp.down_proj.weight
layers.1.input_layernorm.weight
layers.1.post_attention_layernorm.weight
layers.2.self_attn.q_proj.weight
layers.2.self_attn.k_proj.weight
layers.2.self_attn.v_proj.weight
layers.2.self_attn.o_proj.weight
layers.2.mlp.gate_proj.weight
layers.2.mlp.up_proj.weight
layers.2.mlp.down_proj.weight
layers.2.input_layernorm.weight
layers.2.post_attention_layernorm.weight
layers.3.self_attn.q_proj.weight
layers.3.self_attn.k_proj.weight
layers.3.self_attn.v_proj.weight
layers.3.self_attn.o_proj.weight
layers.3.mlp.gate_proj.weight
layers.3.mlp.up_proj.weight
layers.3.mlp.down_proj.weight
layers.3.input_layernorm.weight
layers.3.post_attention_layernorm.weight
layers.4.self_attn.q_proj.weight
layers.4.self_attn.k_proj.weight
layers.4.self_attn.v_proj.weight
layers.4.self_attn.o_proj.weight
layers.4.mlp.gate_proj.weight
layers.4.mlp.up_proj.weight
layers.4.mlp.down_proj.weight
layers.4.input_layernorm.weight
layers.4.post_attention_layernorm.weight
layers.5.self_attn.q_proj.weight
layers.5.self_attn.k_proj.weight
layers.5.self_attn.v_proj.weight
layers.5.self_attn.o_proj.weight
layers.5.mlp.gate_proj.weight
layers.5.mlp.up_proj.weight
layers.5.mlp.down_proj.weight
layers.5.input_layernorm.weight
layers.5.post_attention_layernorm.weight
layers.6.self_attn.q_proj.weight
layers.6.self_attn.k_proj.weight
layers.6.self_attn.v_proj.weight
layers.6.self_attn.o_proj.weight
layers.6.mlp.gate_proj.weight
layers.6.mlp.up_proj.weight
layers.6.mlp.down_proj.weight
layers.6.input_layernorm.weight
layers.6.post_attention_layernorm.weight
layers.7.self_attn.q_proj.weight
layers.7.self_attn.k_proj.weight
layers.7.self_attn.v_proj.weight
layers.7.self_attn.o_proj.weight
layers.7.mlp.gate_proj.weight
layers.7.mlp.up_proj.weight
layers.7.mlp.down_proj.weight
layers.7.input_layernorm.weight
layers.7.post_attention_layernorm.weight
layers.8.self_attn.q_proj.weight
layers.8.self_attn.k_proj.weight
layers.8.self_attn.v_proj.weight
layers.8.self_attn.o_proj.weight
layers.8.mlp.gate_proj.weight
layers.8.mlp.up_proj.weight
layers.8.mlp.down_proj.weight
layers.8.input_layernorm.weight
layers.8.post_attention_layernorm.weight
layers.9.self_attn.q_proj.weight
layers.9.self_attn.k_proj.weight
layers.9.self_attn.v_proj.weight
layers.9.self_attn.o_proj.weight
layers.9.mlp.gate_proj.weight
layers.9.mlp.up_proj.weight
layers.9.mlp.down_proj.weight
layers.9.input_layernorm.weight
layers.9.post_attention_layernorm.weight
layers.10.self_attn.q_proj.weight
layers.10.self_attn.k_proj.weight
layers.10.self_attn.v_proj.weight
layers.10.self_attn.o_proj.weight
layers.10.mlp.gate_proj.weight
layers.10.mlp.up_proj.weight
layers.10.mlp.down_proj.weight
layers.10.input_layernorm.weight
layers.10.post_attention_layernorm.weight
layers.11.self_attn.q_proj.weight
layers.11.self_attn.k_proj.weight
layers.11.self_attn.v_proj.weight
layers.11.self_attn.o_proj.weight
layers.11.mlp.gate_proj.weight
layers.11.mlp.up_proj.weight
layers.11.mlp.down_proj.weight
layers.11.input_layernorm.weight
layers.11.post_attention_layernorm.weight
layers.12.self_attn.q_proj.weight
layers.12.self_attn.k_proj.weight
layers.12.self_attn.v_proj.weight
layers.12.self_attn.o_proj.weight
layers.12.mlp.gate_proj.weight
layers.12.mlp.up_proj.weight
layers.12.mlp.down_proj.weight
layers.12.input_layernorm.weight
layers.12.post_attention_layernorm.weight
layers.13.self_attn.q_proj.weight
layers.13.self_attn.k_proj.weight
layers.13.self_attn.v_proj.weight
layers.13.self_attn.o_proj.weight
layers.13.mlp.gate_proj.weight
layers.13.mlp.up_proj.weight
layers.13.mlp.down_proj.weight
layers.13.input_layernorm.weight
layers.13.post_attention_layernorm.weight
layers.14.self_attn.q_proj.weight
layers.14.self_attn.k_proj.weight
layers.14.self_attn.v_proj.weight
layers.14.self_attn.o_proj.weight
layers.14.mlp.gate_proj.weight
layers.14.mlp.up_proj.weight
layers.14.mlp.down_proj.weight
layers.14.input_layernorm.weight
layers.14.post_attention_layernorm.weight
layers.15.self_attn.q_proj.weight
layers.15.self_attn.k_proj.weight
layers.15.self_attn.v_proj.weight
layers.15.self_attn.o_proj.weight
layers.15.mlp.gate_proj.weight
layers.15.mlp.up_proj.weight
layers.15.mlp.down_proj.weight
layers.15.input_layernorm.weight
layers.15.post_attention_layernorm.weight
layers.16.self_attn.q_proj.weight
layers.16.self_attn.k_proj.weight
layers.16.self_attn.v_proj.weight
layers.16.self_attn.o_proj.weight
layers.16.mlp.gate_proj.weight
layers.16.mlp.up_proj.weight
layers.16.mlp.down_proj.weight
layers.16.input_layernorm.weight
layers.16.post_attention_layernorm.weight
layers.17.self_attn.q_proj.weight
layers.17.self_attn.k_proj.weight
layers.17.self_attn.v_proj.weight
layers.17.self_attn.o_proj.weight
layers.17.mlp.gate_proj.weight
layers.17.mlp.up_proj.weight
layers.17.mlp.down_proj.weight
layers.17.input_layernorm.weight
layers.17.post_attention_layernorm.weight
layers.18.self_attn.q_proj.weight
layers.18.self_attn.k_proj.weight
layers.18.self_attn.v_proj.weight
layers.18.self_attn.o_proj.weight
layers.18.mlp.gate_proj.weight
layers.18.mlp.up_proj.weight
layers.18.mlp.down_proj.weight
layers.18.input_layernorm.weight
layers.18.post_attention_layernorm.weight
layers.19.self_attn.q_proj.weight
layers.19.self_attn.k_proj.weight
layers.19.self_attn.v_proj.weight
layers.19.self_attn.o_proj.weight
layers.19.mlp.gate_proj.weight
layers.19.mlp.up_proj.weight
layers.19.mlp.down_proj.weight
layers.19.input_layernorm.weight
layers.19.post_attention_layernorm.weight
layers.20.self_attn.q_proj.weight
layers.20.self_attn.k_proj.weight
layers.20.self_attn.v_proj.weight
layers.20.self_attn.o_proj.weight
layers.20.mlp.gate_proj.weight
layers.20.mlp.up_proj.weight
layers.20.mlp.down_proj.weight
layers.20.input_layernorm.weight
layers.20.post_attention_layernorm.weight
layers.21.self_attn.q_proj.weight
layers.21.self_attn.k_proj.weight
layers.21.self_attn.v_proj.weight
layers.21.self_attn.o_proj.weight
layers.21.mlp.gate_proj.weight
layers.21.mlp.up_proj.weight
layers.21.mlp.down_proj.weight
layers.21.input_layernorm.weight
layers.21.post_attention_layernorm.weight
layers.22.self_attn.q_proj.weight
layers.22.self_attn.k_proj.weight
layers.22.self_attn.v_proj.weight
layers.22.self_attn.o_proj.weight
layers.22.mlp.gate_proj.weight
layers.22.mlp.up_proj.weight
layers.22.mlp.down_proj.weight
layers.22.input_layernorm.weight
layers.22.post_attention_layernorm.weight
layers.23.self_attn.q_proj.weight
layers.23.self_attn.k_proj.weight
layers.23.self_attn.v_proj.weight
layers.23.self_attn.o_proj.weight
layers.23.mlp.gate_proj.weight
layers.23.mlp.up_proj.weight
layers.23.mlp.down_proj.weight
layers.23.input_layernorm.weight
layers.23.post_attention_layernorm.weight
layers.24.self_attn.q_proj.weight
layers.24.self_attn.k_proj.weight
layers.24.self_attn.v_proj.weight
layers.24.self_attn.o_proj.weight
layers.24.mlp.gate_proj.weight
layers.24.mlp.up_proj.weight
layers.24.mlp.down_proj.weight
layers.24.input_layernorm.weight
layers.24.post_attention_layernorm.weight
layers.25.self_attn.q_proj.weight
layers.25.self_attn.k_proj.weight
layers.25.self_attn.v_proj.weight
layers.25.self_attn.o_proj.weight
layers.25.mlp.gate_proj.weight
layers.25.mlp.up_proj.weight
layers.25.mlp.down_proj.weight
layers.25.input_layernorm.weight
layers.25.post_attention_layernorm.weight
layers.26.self_attn.q_proj.weight
layers.26.self_attn.k_proj.weight
layers.26.self_attn.v_proj.weight
layers.26.self_attn.o_proj.weight
layers.26.mlp.gate_proj.weight
layers.26.mlp.up_proj.weight
layers.26.mlp.down_proj.weight
layers.26.input_layernorm.weight
layers.26.post_attention_layernorm.weight
layers.27.self_attn.q_proj.weight
layers.27.self_attn.k_proj.weight
layers.27.self_attn.v_proj.weight
layers.27.self_attn.o_proj.weight
layers.27.mlp.gate_proj.weight
layers.27.mlp.up_proj.weight
layers.27.mlp.down_proj.weight
layers.27.input_layernorm.weight
layers.27.post_attention_layernorm.weight
layers.28.self_attn.q_proj.weight
layers.28.self_attn.k_proj.weight
layers.28.self_attn.v_proj.weight
layers.28.self_attn.o_proj.weight
layers.28.mlp.gate_proj.weight
layers.28.mlp.up_proj.weight
layers.28.mlp.down_proj.weight
layers.28.input_layernorm.weight
layers.28.post_attention_layernorm.weight
layers.29.self_attn.q_proj.weight
layers.29.self_attn.k_proj.weight
layers.29.self_attn.v_proj.weight
layers.29.self_attn.o_proj.weight
layers.29.mlp.gate_proj.weight
layers.29.mlp.up_proj.weight
layers.29.mlp.down_proj.weight
layers.29.input_layernorm.weight
layers.29.post_attention_layernorm.weight
layers.30.self_attn.q_proj.weight
layers.30.self_attn.k_proj.weight
layers.30.self_attn.v_proj.weight
layers.30.self_attn.o_proj.weight
layers.30.mlp.gate_proj.weight
layers.30.mlp.up_proj.weight
layers.30.mlp.down_proj.weight
layers.30.input_layernorm.weight
layers.30.post_attention_layernorm.weight
layers.31.self_attn.q_proj.weight
layers.31.self_attn.k_proj.weight
layers.31.self_attn.v_proj.weight
layers.31.self_attn.o_proj.weight
layers.31.mlp.gate_proj.weight
layers.31.mlp.up_proj.weight
layers.31.mlp.down_proj.weight
layers.31.input_layernorm.weight
layers.31.post_attention_layernorm.weight
layers.32.self_attn.q_proj.weight
layers.32.self_attn.k_proj.weight
layers.32.self_attn.v_proj.weight
layers.32.self_attn.o_proj.weight
layers.32.mlp.gate_proj.weight
layers.32.mlp.up_proj.weight
layers.32.mlp.down_proj.weight
layers.32.input_layernorm.weight
layers.32.post_attention_layernorm.weight
layers.33.self_attn.q_proj.weight
layers.33.self_attn.k_proj.weight
layers.33.self_attn.v_proj.weight
layers.33.self_attn.o_proj.weight
layers.33.mlp.gate_proj.weight
layers.33.mlp.up_proj.weight
layers.33.mlp.down_proj.weight
layers.33.input_layernorm.weight
layers.33.post_attention_layernorm.weight
layers.34.self_attn.q_proj.weight
layers.34.self_attn.k_proj.weight
layers.34.self_attn.v_proj.weight
layers.34.self_attn.o_proj.weight
layers.34.mlp.gate_proj.weight
layers.34.mlp.up_proj.weight
layers.34.mlp.down_proj.weight
layers.34.input_layernorm.weight
layers.34.post_attention_layernorm.weight
layers.35.self_attn.q_proj.weight
layers.35.self_attn.k_proj.weight
layers.35.self_attn.v_proj.weight
layers.35.self_attn.o_proj.weight
layers.35.mlp.gate_proj.weight
layers.35.mlp.up_proj.weight
layers.35.mlp.down_proj.weight
layers.35.input_layernorm.weight
layers.35.post_attention_layernorm.weight
layers.36.self_attn.q_proj.weight
layers.36.self_attn.k_proj.weight
layers.36.self_attn.v_proj.weight
layers.36.self_attn.o_proj.weight
layers.36.mlp.gate_proj.weight
layers.36.mlp.up_proj.weight
layers.36.mlp.down_proj.weight
layers.36.input_layernorm.weight
layers.36.post_attention_layernorm.weight
layers.37.self_attn.q_proj.weight
layers.37.self_attn.k_proj.weight
layers.37.self_attn.v_proj.weight
layers.37.self_attn.o_proj.weight
layers.37.mlp.gate_proj.weight
layers.37.mlp.up_proj.weight
layers.37.mlp.down_proj.weight
layers.37.input_layernorm.weight
layers.37.post_attention_layernorm.weight
layers.38.self_attn.q_proj.weight
layers.38.self_attn.k_proj.weight
layers.38.self_attn.v_proj.weight
layers.38.self_attn.o_proj.weight
layers.38.mlp.gate_proj.weight
layers.38.mlp.up_proj.weight
layers.38.mlp.down_proj.weight
layers.38.input_layernorm.weight
layers.38.post_attention_layernorm.weight
layers.39.self_attn.q_proj.weight
layers.39.self_attn.k_proj.weight
layers.39.self_attn.v_proj.weight
layers.39.self_attn.o_proj.weight
layers.39.mlp.gate_proj.weight
layers.39.mlp.up_proj.weight
layers.39.mlp.down_proj.weight
layers.39.input_layernorm.weight
layers.39.post_attention_layernorm.weight
norm.weight
mm_projector.query
mm_projector.proj
mm_projector.kv_proj.weight
mm_projector.attn.in_proj_weight
mm_projector.attn.in_proj_bias
mm_projector.attn.out_proj.weight
mm_projector.attn.out_proj.bias
mm_projector.ln_q.weight
mm_projector.ln_q.bias
mm_projector.ln_kv.weight
mm_projector.ln_kv.bias
mm_projector.ln_post.weight
mm_projector.ln_post.bias
lm_head.weight
embed_tokens.weight
layers.0.self_attn.q_proj.weight
layers.0.self_attn.k_proj.weight
layers.0.self_attn.v_proj.weight
layers.0.self_attn.o_proj.weight
layers.0.mlp.gate_proj.weight
layers.0.mlp.up_proj.weight
layers.0.mlp.down_proj.weight
layers.0.input_layernorm.weight
layers.0.post_attention_layernorm.weight
layers.1.self_attn.q_proj.weight
layers.1.self_attn.k_proj.weight
layers.1.self_attn.v_proj.weight
layers.1.self_attn.o_proj.weight
layers.1.mlp.gate_proj.weight
layers.1.mlp.up_proj.weight
layers.1.mlp.down_proj.weight
layers.1.input_layernorm.weight
layers.1.post_attention_layernorm.weight
layers.2.self_attn.q_proj.weight
layers.2.self_attn.k_proj.weight
layers.2.self_attn.v_proj.weight
layers.2.self_attn.o_proj.weight
layers.2.mlp.gate_proj.weight
layers.2.mlp.up_proj.weight
layers.2.mlp.down_proj.weight
layers.2.input_layernorm.weight
layers.2.post_attention_layernorm.weight
layers.3.self_attn.q_proj.weight
layers.3.self_attn.k_proj.weight
layers.3.self_attn.v_proj.weight
layers.3.self_attn.o_proj.weight
layers.3.mlp.gate_proj.weight
layers.3.mlp.up_proj.weight
layers.3.mlp.down_proj.weight
layers.3.input_layernorm.weight
layers.3.post_attention_layernorm.weight
layers.4.self_attn.q_proj.weight
layers.4.self_attn.k_proj.weight
layers.4.self_attn.v_proj.weight
layers.4.self_attn.o_proj.weight
layers.4.mlp.gate_proj.weight
layers.4.mlp.up_proj.weight
layers.4.mlp.down_proj.weight
layers.4.input_layernorm.weight
layers.4.post_attention_layernorm.weight
layers.5.self_attn.q_proj.weight
layers.5.self_attn.k_proj.weight
layers.5.self_attn.v_proj.weight
layers.5.self_attn.o_proj.weight
layers.5.mlp.gate_proj.weight
layers.5.mlp.up_proj.weight
layers.5.mlp.down_proj.weight
layers.5.input_layernorm.weight
layers.5.post_attention_layernorm.weight
layers.6.self_attn.q_proj.weight
layers.6.self_attn.k_proj.weight
layers.6.self_attn.v_proj.weight
layers.6.self_attn.o_proj.weight
layers.6.mlp.gate_proj.weight
layers.6.mlp.up_proj.weight
layers.6.mlp.down_proj.weight
layers.6.input_layernorm.weight
layers.6.post_attention_layernorm.weight
layers.7.self_attn.q_proj.weight
layers.7.self_attn.k_proj.weight
layers.7.self_attn.v_proj.weight
layers.7.self_attn.o_proj.weight
layers.7.mlp.gate_proj.weight
layers.7.mlp.up_proj.weight
layers.7.mlp.down_proj.weight
layers.7.input_layernorm.weight
layers.7.post_attention_layernorm.weight
layers.8.self_attn.q_proj.weight
layers.8.self_attn.k_proj.weight
layers.8.self_attn.v_proj.weight
layers.8.self_attn.o_proj.weight
layers.8.mlp.gate_proj.weight
layers.8.mlp.up_proj.weight
layers.8.mlp.down_proj.weight
layers.8.input_layernorm.weight
layers.8.post_attention_layernorm.weight
layers.9.self_attn.q_proj.weight
layers.9.self_attn.k_proj.weight
layers.9.self_attn.v_proj.weight
layers.9.self_attn.o_proj.weight
layers.9.mlp.gate_proj.weight
layers.9.mlp.up_proj.weight
layers.9.mlp.down_proj.weight
layers.9.input_layernorm.weight
layers.9.post_attention_layernorm.weight
layers.10.self_attn.q_proj.weight
layers.10.self_attn.k_proj.weight
layers.10.self_attn.v_proj.weight
layers.10.self_attn.o_proj.weight
layers.10.mlp.gate_proj.weight
layers.10.mlp.up_proj.weight
layers.10.mlp.down_proj.weight
layers.10.input_layernorm.weight
layers.10.post_attention_layernorm.weight
layers.11.self_attn.q_proj.weight
layers.11.self_attn.k_proj.weight
layers.11.self_attn.v_proj.weight
layers.11.self_attn.o_proj.weight
layers.11.mlp.gate_proj.weight
layers.11.mlp.up_proj.weight
layers.11.mlp.down_proj.weight
layers.11.input_layernorm.weight
layers.11.post_attention_layernorm.weight
layers.12.self_attn.q_proj.weight
layers.12.self_attn.k_proj.weight
layers.12.self_attn.v_proj.weight
layers.12.self_attn.o_proj.weight
layers.12.mlp.gate_proj.weight
layers.12.mlp.up_proj.weight
layers.12.mlp.down_proj.weight
layers.12.input_layernorm.weight
layers.12.post_attention_layernorm.weight
layers.13.self_attn.q_proj.weight
layers.13.self_attn.k_proj.weight
layers.13.self_attn.v_proj.weight
layers.13.self_attn.o_proj.weight
layers.13.mlp.gate_proj.weight
layers.13.mlp.up_proj.weight
layers.13.mlp.down_proj.weight
layers.13.input_layernorm.weight
layers.13.post_attention_layernorm.weight
layers.14.self_attn.q_proj.weight
layers.14.self_attn.k_proj.weight
layers.14.self_attn.v_proj.weight
layers.14.self_attn.o_proj.weight
layers.14.mlp.gate_proj.weight
layers.14.mlp.up_proj.weight
layers.14.mlp.down_proj.weight
layers.14.input_layernorm.weight
layers.14.post_attention_layernorm.weight
layers.15.self_attn.q_proj.weight
layers.15.self_attn.k_proj.weight
layers.15.self_attn.v_proj.weight
layers.15.self_attn.o_proj.weight
layers.15.mlp.gate_proj.weight
layers.15.mlp.up_proj.weight
layers.15.mlp.down_proj.weight
layers.15.input_layernorm.weight
layers.15.post_attention_layernorm.weight
layers.16.self_attn.q_proj.weight
layers.16.self_attn.k_proj.weight
layers.16.self_attn.v_proj.weight
layers.16.self_attn.o_proj.weight
layers.16.mlp.gate_proj.weight
layers.16.mlp.up_proj.weight
layers.16.mlp.down_proj.weight
layers.16.input_layernorm.weight
layers.16.post_attention_layernorm.weight
layers.17.self_attn.q_proj.weight
layers.17.self_attn.k_proj.weight
layers.17.self_attn.v_proj.weight
layers.17.self_attn.o_proj.weight
layers.17.mlp.gate_proj.weight
layers.17.mlp.up_proj.weight
layers.17.mlp.down_proj.weight
layers.17.input_layernorm.weight
layers.17.post_attention_layernorm.weight
layers.18.self_attn.q_proj.weight
layers.18.self_attn.k_proj.weight
layers.18.self_attn.v_proj.weight
layers.18.self_attn.o_proj.weight
layers.18.mlp.gate_proj.weight
layers.18.mlp.up_proj.weight
layers.18.mlp.down_proj.weight
layers.18.input_layernorm.weight
layers.18.post_attention_layernorm.weight
layers.19.self_attn.q_proj.weight
layers.19.self_attn.k_proj.weight
layers.19.self_attn.v_proj.weight
layers.19.self_attn.o_proj.weight
layers.19.mlp.gate_proj.weight
layers.19.mlp.up_proj.weight
layers.19.mlp.down_proj.weight
layers.19.input_layernorm.weight
layers.19.post_attention_layernorm.weight
layers.20.self_attn.q_proj.weight
layers.20.self_attn.k_proj.weight
layers.20.self_attn.v_proj.weight
layers.20.self_attn.o_proj.weight
layers.20.mlp.gate_proj.weight
layers.20.mlp.up_proj.weight
layers.20.mlp.down_proj.weight
layers.20.input_layernorm.weight
layers.20.post_attention_layernorm.weight
layers.21.self_attn.q_proj.weight
layers.21.self_attn.k_proj.weight
layers.21.self_attn.v_proj.weight
layers.21.self_attn.o_proj.weight
layers.21.mlp.gate_proj.weight
layers.21.mlp.up_proj.weight
layers.21.mlp.down_proj.weight
layers.21.input_layernorm.weight
layers.21.post_attention_layernorm.weight
layers.22.self_attn.q_proj.weight
layers.22.self_attn.k_proj.weight
layers.22.self_attn.v_proj.weight
layers.22.self_attn.o_proj.weight
layers.22.mlp.gate_proj.weight
layers.22.mlp.up_proj.weight
layers.22.mlp.down_proj.weight
layers.22.input_layernorm.weight
layers.22.post_attention_layernorm.weight
layers.23.self_attn.q_proj.weight
layers.23.self_attn.k_proj.weight
layers.23.self_attn.v_proj.weight
layers.23.self_attn.o_proj.weight
layers.23.mlp.gate_proj.weight
layers.23.mlp.up_proj.weight
layers.23.mlp.down_proj.weight
layers.23.input_layernorm.weight
layers.23.post_attention_layernorm.weight
layers.24.self_attn.q_proj.weight
layers.24.self_attn.k_proj.weight
layers.24.self_attn.v_proj.weight
layers.24.self_attn.o_proj.weight
layers.24.mlp.gate_proj.weight
layers.24.mlp.up_proj.weight
layers.24.mlp.down_proj.weight
layers.24.input_layernorm.weight
layers.24.post_attention_layernorm.weight
layers.25.self_attn.q_proj.weight
layers.25.self_attn.k_proj.weight
layers.25.self_attn.v_proj.weight
layers.25.self_attn.o_proj.weight
layers.25.mlp.gate_proj.weight
layers.25.mlp.up_proj.weight
layers.25.mlp.down_proj.weight
layers.25.input_layernorm.weight
layers.25.post_attention_layernorm.weight
layers.26.self_attn.q_proj.weight
layers.26.self_attn.k_proj.weight
layers.26.self_attn.v_proj.weight
layers.26.self_attn.o_proj.weight
layers.26.mlp.gate_proj.weight
layers.26.mlp.up_proj.weight
layers.26.mlp.down_proj.weight
layers.26.input_layernorm.weight
layers.26.post_attention_layernorm.weight
layers.27.self_attn.q_proj.weight
layers.27.self_attn.k_proj.weight
layers.27.self_attn.v_proj.weight
layers.27.self_attn.o_proj.weight
layers.27.mlp.gate_proj.weight
layers.27.mlp.up_proj.weight
layers.27.mlp.down_proj.weight
layers.27.input_layernorm.weight
layers.27.post_attention_layernorm.weight
layers.28.self_attn.q_proj.weight
layers.28.self_attn.k_proj.weight
layers.28.self_attn.v_proj.weight
layers.28.self_attn.o_proj.weight
layers.28.mlp.gate_proj.weight
layers.28.mlp.up_proj.weight
layers.28.mlp.down_proj.weight
layers.28.input_layernorm.weight
layers.28.post_attention_layernorm.weight
layers.29.self_attn.q_proj.weight
layers.29.self_attn.k_proj.weight
layers.29.self_attn.v_proj.weight
layers.29.self_attn.o_proj.weight
layers.29.mlp.gate_proj.weight
layers.29.mlp.up_proj.weight
layers.29.mlp.down_proj.weight
layers.29.input_layernorm.weight
layers.29.post_attention_layernorm.weight
layers.30.self_attn.q_proj.weight
layers.30.self_attn.k_proj.weight
layers.30.self_attn.v_proj.weight
layers.30.self_attn.o_proj.weight
layers.30.mlp.gate_proj.weight
layers.30.mlp.up_proj.weight
layers.30.mlp.down_proj.weight
layers.30.input_layernorm.weight
layers.30.post_attention_layernorm.weight
layers.31.self_attn.q_proj.weight
layers.31.self_attn.k_proj.weight
layers.31.self_attn.v_proj.weight
layers.31.self_attn.o_proj.weight
layers.31.mlp.gate_proj.weight
layers.31.mlp.up_proj.weight
layers.31.mlp.down_proj.weight
layers.31.input_layernorm.weight
layers.31.post_attention_layernorm.weight
layers.32.self_attn.q_proj.weight
layers.32.self_attn.k_proj.weight
layers.32.self_attn.v_proj.weight
layers.32.self_attn.o_proj.weight
layers.32.mlp.gate_proj.weight
layers.32.mlp.up_proj.weight
layers.32.mlp.down_proj.weight
layers.32.input_layernorm.weight
layers.32.post_attention_layernorm.weight
layers.33.self_attn.q_proj.weight
layers.33.self_attn.k_proj.weight
layers.33.self_attn.v_proj.weight
layers.33.self_attn.o_proj.weight
layers.33.mlp.gate_proj.weight
layers.33.mlp.up_proj.weight
layers.33.mlp.down_proj.weight
layers.33.input_layernorm.weight
layers.33.post_attention_layernorm.weight
layers.34.self_attn.q_proj.weight
layers.34.self_attn.k_proj.weight
layers.34.self_attn.v_proj.weight
layers.34.self_attn.o_proj.weight
layers.34.mlp.gate_proj.weight
layers.34.mlp.up_proj.weight
layers.34.mlp.down_proj.weight
layers.34.input_layernorm.weight
layers.34.post_attention_layernorm.weight
layers.35.self_attn.q_proj.weight
layers.35.self_attn.k_proj.weight
layers.35.self_attn.v_proj.weight
layers.35.self_attn.o_proj.weight
layers.35.mlp.gate_proj.weight
layers.35.mlp.up_proj.weight
layers.35.mlp.down_proj.weight
layers.35.input_layernorm.weight
layers.35.post_attention_layernorm.weight
layers.36.self_attn.q_proj.weight
layers.36.self_attn.k_proj.weight
layers.36.self_attn.v_proj.weight
layers.36.self_attn.o_proj.weight
layers.36.mlp.gate_proj.weight
layers.36.mlp.up_proj.weight
layers.36.mlp.down_proj.weight
layers.36.input_layernorm.weight
layers.36.post_attention_layernorm.weight
layers.37.self_attn.q_proj.weight
layers.37.self_attn.k_proj.weight
layers.37.self_attn.v_proj.weight
layers.37.self_attn.o_proj.weight
layers.37.mlp.gate_proj.weight
layers.37.mlp.up_proj.weight
layers.37.mlp.down_proj.weight
layers.37.input_layernorm.weight
layers.37.post_attention_layernorm.weight
layers.38.self_attn.q_proj.weight
layers.38.self_attn.k_proj.weight
layers.38.self_attn.v_proj.weight
layers.38.self_attn.o_proj.weight
layers.38.mlp.gate_proj.weight
layers.38.mlp.up_proj.weight
layers.38.mlp.down_proj.weight
layers.38.input_layernorm.weight
layers.38.post_attention_layernorm.weight
layers.39.self_attn.q_proj.weight
layers.39.self_attn.k_proj.weight
layers.39.self_attn.v_proj.weight
layers.39.self_attn.o_proj.weight
layers.39.mlp.gate_proj.weight
layers.39.mlp.up_proj.weight
layers.39.mlp.down_proj.weight
layers.39.input_layernorm.weight
layers.39.post_attention_layernorm.weight
norm.weight
mm_projector.query
mm_projector.proj
mm_projector.kv_proj.weight
mm_projector.attn.in_proj_weight
mm_projector.attn.in_proj_bias
mm_projector.attn.out_proj.weight
mm_projector.attn.out_proj.bias
mm_projector.ln_q.weight
mm_projector.ln_q.bias
mm_projector.ln_kv.weight
mm_projector.ln_kv.bias
mm_projector.ln_post.weight
mm_projector.ln_post.bias
lm_head.weight
embed_tokens.weight
layers.0.self_attn.q_proj.weight
layers.0.self_attn.k_proj.weight
layers.0.self_attn.v_proj.weight
layers.0.self_attn.o_proj.weight
layers.0.mlp.gate_proj.weight
layers.0.mlp.up_proj.weight
layers.0.mlp.down_proj.weight
layers.0.input_layernorm.weight
layers.0.post_attention_layernorm.weight
layers.1.self_attn.q_proj.weight
layers.1.self_attn.k_proj.weight
layers.1.self_attn.v_proj.weight
layers.1.self_attn.o_proj.weight
layers.1.mlp.gate_proj.weight
layers.1.mlp.up_proj.weight
layers.1.mlp.down_proj.weight
layers.1.input_layernorm.weight
layers.1.post_attention_layernorm.weight
layers.2.self_attn.q_proj.weight
layers.2.self_attn.k_proj.weight
layers.2.self_attn.v_proj.weight
layers.2.self_attn.o_proj.weight
layers.2.mlp.gate_proj.weight
layers.2.mlp.up_proj.weight
layers.2.mlp.down_proj.weight
layers.2.input_layernorm.weight
layers.2.post_attention_layernorm.weight
layers.3.self_attn.q_proj.weight
layers.3.self_attn.k_proj.weight
layers.3.self_attn.v_proj.weight
layers.3.self_attn.o_proj.weight
layers.3.mlp.gate_proj.weight
layers.3.mlp.up_proj.weight
layers.3.mlp.down_proj.weight
layers.3.input_layernorm.weight
layers.3.post_attention_layernorm.weight
layers.4.self_attn.q_proj.weight
layers.4.self_attn.k_proj.weight
layers.4.self_attn.v_proj.weight
layers.4.self_attn.o_proj.weight
layers.4.mlp.gate_proj.weight
layers.4.mlp.up_proj.weight
layers.4.mlp.down_proj.weight
layers.4.input_layernorm.weight
layers.4.post_attention_layernorm.weight
layers.5.self_attn.q_proj.weight
layers.5.self_attn.k_proj.weight
layers.5.self_attn.v_proj.weight
layers.5.self_attn.o_proj.weight
layers.5.mlp.gate_proj.weight
layers.5.mlp.up_proj.weight
layers.5.mlp.down_proj.weight
layers.5.input_layernorm.weight
layers.5.post_attention_layernorm.weight
layers.6.self_attn.q_proj.weight
layers.6.self_attn.k_proj.weight
layers.6.self_attn.v_proj.weight
layers.6.self_attn.o_proj.weight
layers.6.mlp.gate_proj.weight
layers.6.mlp.up_proj.weight
layers.6.mlp.down_proj.weight
layers.6.input_layernorm.weight
layers.6.post_attention_layernorm.weight
layers.7.self_attn.q_proj.weight
layers.7.self_attn.k_proj.weight
layers.7.self_attn.v_proj.weight
layers.7.self_attn.o_proj.weight
layers.7.mlp.gate_proj.weight
layers.7.mlp.up_proj.weight
layers.7.mlp.down_proj.weight
layers.7.input_layernorm.weight
layers.7.post_attention_layernorm.weight
layers.8.self_attn.q_proj.weight
layers.8.self_attn.k_proj.weight
layers.8.self_attn.v_proj.weight
layers.8.self_attn.o_proj.weight
layers.8.mlp.gate_proj.weight
layers.8.mlp.up_proj.weight
layers.8.mlp.down_proj.weight
layers.8.input_layernorm.weight
layers.8.post_attention_layernorm.weight
layers.9.self_attn.q_proj.weight
layers.9.self_attn.k_proj.weight
layers.9.self_attn.v_proj.weight
layers.9.self_attn.o_proj.weight
layers.9.mlp.gate_proj.weight
layers.9.mlp.up_proj.weight
layers.9.mlp.down_proj.weight
layers.9.input_layernorm.weight
layers.9.post_attention_layernorm.weight
layers.10.self_attn.q_proj.weight
layers.10.self_attn.k_proj.weight
layers.10.self_attn.v_proj.weight
layers.10.self_attn.o_proj.weight
layers.10.mlp.gate_proj.weight
layers.10.mlp.up_proj.weight
layers.10.mlp.down_proj.weight
layers.10.input_layernorm.weight
layers.10.post_attention_layernorm.weight
layers.11.self_attn.q_proj.weight
layers.11.self_attn.k_proj.weight
layers.11.self_attn.v_proj.weight
layers.11.self_attn.o_proj.weight
layers.11.mlp.gate_proj.weight
layers.11.mlp.up_proj.weight
layers.11.mlp.down_proj.weight
layers.11.input_layernorm.weight
layers.11.post_attention_layernorm.weight
layers.12.self_attn.q_proj.weight
layers.12.self_attn.k_proj.weight
layers.12.self_attn.v_proj.weight
layers.12.self_attn.o_proj.weight
layers.12.mlp.gate_proj.weight
layers.12.mlp.up_proj.weight
layers.12.mlp.down_proj.weight
layers.12.input_layernorm.weight
layers.12.post_attention_layernorm.weight
layers.13.self_attn.q_proj.weight
layers.13.self_attn.k_proj.weight
layers.13.self_attn.v_proj.weight
layers.13.self_attn.o_proj.weight
layers.13.mlp.gate_proj.weight
layers.13.mlp.up_proj.weight
layers.13.mlp.down_proj.weight
layers.13.input_layernorm.weight
layers.13.post_attention_layernorm.weight
layers.14.self_attn.q_proj.weight
layers.14.self_attn.k_proj.weight
layers.14.self_attn.v_proj.weight
layers.14.self_attn.o_proj.weight
layers.14.mlp.gate_proj.weight
layers.14.mlp.up_proj.weight
layers.14.mlp.down_proj.weight
layers.14.input_layernorm.weight
layers.14.post_attention_layernorm.weight
layers.15.self_attn.q_proj.weight
layers.15.self_attn.k_proj.weight
layers.15.self_attn.v_proj.weight
layers.15.self_attn.o_proj.weight
layers.15.mlp.gate_proj.weight
layers.15.mlp.up_proj.weight
layers.15.mlp.down_proj.weight
layers.15.input_layernorm.weight
layers.15.post_attention_layernorm.weight
layers.16.self_attn.q_proj.weight
layers.16.self_attn.k_proj.weight
layers.16.self_attn.v_proj.weight
layers.16.self_attn.o_proj.weight
layers.16.mlp.gate_proj.weight
layers.16.mlp.up_proj.weight
layers.16.mlp.down_proj.weight
layers.16.input_layernorm.weight
layers.16.post_attention_layernorm.weight
layers.17.self_attn.q_proj.weight
layers.17.self_attn.k_proj.weight
layers.17.self_attn.v_proj.weight
layers.17.self_attn.o_proj.weight
layers.17.mlp.gate_proj.weight
layers.17.mlp.up_proj.weight
layers.17.mlp.down_proj.weight
layers.17.input_layernorm.weight
layers.17.post_attention_layernorm.weight
layers.18.self_attn.q_proj.weight
layers.18.self_attn.k_proj.weight
layers.18.self_attn.v_proj.weight
layers.18.self_attn.o_proj.weight
layers.18.mlp.gate_proj.weight
layers.18.mlp.up_proj.weight
layers.18.mlp.down_proj.weight
layers.18.input_layernorm.weight
layers.18.post_attention_layernorm.weight
layers.19.self_attn.q_proj.weight
layers.19.self_attn.k_proj.weight
layers.19.self_attn.v_proj.weight
layers.19.self_attn.o_proj.weight
layers.19.mlp.gate_proj.weight
layers.19.mlp.up_proj.weight
layers.19.mlp.down_proj.weight
layers.19.input_layernorm.weight
layers.19.post_attention_layernorm.weight
layers.20.self_attn.q_proj.weight
layers.20.self_attn.k_proj.weight
layers.20.self_attn.v_proj.weight
layers.20.self_attn.o_proj.weight
layers.20.mlp.gate_proj.weight
layers.20.mlp.up_proj.weight
layers.20.mlp.down_proj.weight
layers.20.input_layernorm.weight
layers.20.post_attention_layernorm.weight
layers.21.self_attn.q_proj.weight
layers.21.self_attn.k_proj.weight
layers.21.self_attn.v_proj.weight
layers.21.self_attn.o_proj.weight
layers.21.mlp.gate_proj.weight
layers.21.mlp.up_proj.weight
layers.21.mlp.down_proj.weight
layers.21.input_layernorm.weight
layers.21.post_attention_layernorm.weight
layers.22.self_attn.q_proj.weight
layers.22.self_attn.k_proj.weight
layers.22.self_attn.v_proj.weight
layers.22.self_attn.o_proj.weight
layers.22.mlp.gate_proj.weight
layers.22.mlp.up_proj.weight
layers.22.mlp.down_proj.weight
layers.22.input_layernorm.weight
layers.22.post_attention_layernorm.weight
layers.23.self_attn.q_proj.weight
layers.23.self_attn.k_proj.weight
layers.23.self_attn.v_proj.weight
layers.23.self_attn.o_proj.weight
layers.23.mlp.gate_proj.weight
layers.23.mlp.up_proj.weight
layers.23.mlp.down_proj.weight
layers.23.input_layernorm.weight
layers.23.post_attention_layernorm.weight
layers.24.self_attn.q_proj.weight
layers.24.self_attn.k_proj.weight
layers.24.self_attn.v_proj.weight
layers.24.self_attn.o_proj.weight
layers.24.mlp.gate_proj.weight
layers.24.mlp.up_proj.weight
layers.24.mlp.down_proj.weight
layers.24.input_layernorm.weight
layers.24.post_attention_layernorm.weight
layers.25.self_attn.q_proj.weight
layers.25.self_attn.k_proj.weight
layers.25.self_attn.v_proj.weight
layers.25.self_attn.o_proj.weight
layers.25.mlp.gate_proj.weight
layers.25.mlp.up_proj.weight
layers.25.mlp.down_proj.weight
layers.25.input_layernorm.weight
layers.25.post_attention_layernorm.weight
layers.26.self_attn.q_proj.weight
layers.26.self_attn.k_proj.weight
layers.26.self_attn.v_proj.weight
layers.26.self_attn.o_proj.weight
layers.26.mlp.gate_proj.weight
layers.26.mlp.up_proj.weight
layers.26.mlp.down_proj.weight
layers.26.input_layernorm.weight
layers.26.post_attention_layernorm.weight
layers.27.self_attn.q_proj.weight
layers.27.self_attn.k_proj.weight
layers.27.self_attn.v_proj.weight
layers.27.self_attn.o_proj.weight
layers.27.mlp.gate_proj.weight
layers.27.mlp.up_proj.weight
layers.27.mlp.down_proj.weight
layers.27.input_layernorm.weight
layers.27.post_attention_layernorm.weight
layers.28.self_attn.q_proj.weight
layers.28.self_attn.k_proj.weight
layers.28.self_attn.v_proj.weight
layers.28.self_attn.o_proj.weight
layers.28.mlp.gate_proj.weight
layers.28.mlp.up_proj.weight
layers.28.mlp.down_proj.weight
layers.28.input_layernorm.weight
layers.28.post_attention_layernorm.weight
layers.29.self_attn.q_proj.weight
layers.29.self_attn.k_proj.weight
layers.29.self_attn.v_proj.weight
layers.29.self_attn.o_proj.weight
layers.29.mlp.gate_proj.weight
layers.29.mlp.up_proj.weight
layers.29.mlp.down_proj.weight
layers.29.input_layernorm.weight
layers.29.post_attention_layernorm.weight
layers.30.self_attn.q_proj.weight
layers.30.self_attn.k_proj.weight
layers.30.self_attn.v_proj.weight
layers.30.self_attn.o_proj.weight
layers.30.mlp.gate_proj.weight
layers.30.mlp.up_proj.weight
layers.30.mlp.down_proj.weight
layers.30.input_layernorm.weight
layers.30.post_attention_layernorm.weight
layers.31.self_attn.q_proj.weight
layers.31.self_attn.k_proj.weight
layers.31.self_attn.v_proj.weight
layers.31.self_attn.o_proj.weight
layers.31.mlp.gate_proj.weight
layers.31.mlp.up_proj.weight
layers.31.mlp.down_proj.weight
layers.31.input_layernorm.weight
layers.31.post_attention_layernorm.weight
layers.32.self_attn.q_proj.weight
layers.32.self_attn.k_proj.weight
layers.32.self_attn.v_proj.weight
layers.32.self_attn.o_proj.weight
layers.32.mlp.gate_proj.weight
layers.32.mlp.up_proj.weight
layers.32.mlp.down_proj.weight
layers.32.input_layernorm.weight
layers.32.post_attention_layernorm.weight
layers.33.self_attn.q_proj.weight
layers.33.self_attn.k_proj.weight
layers.33.self_attn.v_proj.weight
layers.33.self_attn.o_proj.weight
layers.33.mlp.gate_proj.weight
layers.33.mlp.up_proj.weight
layers.33.mlp.down_proj.weight
layers.33.input_layernorm.weight
layers.33.post_attention_layernorm.weight
layers.34.self_attn.q_proj.weight
layers.34.self_attn.k_proj.weight
layers.34.self_attn.v_proj.weight
layers.34.self_attn.o_proj.weight
layers.34.mlp.gate_proj.weight
layers.34.mlp.up_proj.weight
layers.34.mlp.down_proj.weight
layers.34.input_layernorm.weight
layers.34.post_attention_layernorm.weight
layers.35.self_attn.q_proj.weight
layers.35.self_attn.k_proj.weight
layers.35.self_attn.v_proj.weight
layers.35.self_attn.o_proj.weight
layers.35.mlp.gate_proj.weight
layers.35.mlp.up_proj.weight
layers.35.mlp.down_proj.weight
layers.35.input_layernorm.weight
layers.35.post_attention_layernorm.weight
layers.36.self_attn.q_proj.weight
layers.36.self_attn.k_proj.weight
layers.36.self_attn.v_proj.weight
layers.36.self_attn.o_proj.weight
layers.36.mlp.gate_proj.weight
layers.36.mlp.up_proj.weight
layers.36.mlp.down_proj.weight
layers.36.input_layernorm.weight
layers.36.post_attention_layernorm.weight
layers.37.self_attn.q_proj.weight
layers.37.self_attn.k_proj.weight
layers.37.self_attn.v_proj.weight
layers.37.self_attn.o_proj.weight
layers.37.mlp.gate_proj.weight
layers.37.mlp.up_proj.weight
layers.37.mlp.down_proj.weight
layers.37.input_layernorm.weight
layers.37.post_attention_layernorm.weight
layers.38.self_attn.q_proj.weight
layers.38.self_attn.k_proj.weight
layers.38.self_attn.v_proj.weight
layers.38.self_attn.o_proj.weight
layers.38.mlp.gate_proj.weight
layers.38.mlp.up_proj.weight
layers.38.mlp.down_proj.weight
layers.38.input_layernorm.weight
layers.38.post_attention_layernorm.weight
layers.39.self_attn.q_proj.weight
layers.39.self_attn.k_proj.weight
layers.39.self_attn.v_proj.weight
layers.39.self_attn.o_proj.weight
layers.39.mlp.gate_proj.weight
layers.39.mlp.up_proj.weight
layers.39.mlp.down_proj.weight
layers.39.input_layernorm.weight
layers.39.post_attention_layernorm.weight
norm.weight
mm_projector.query
mm_projector.proj
mm_projector.kv_proj.weight
mm_projector.attn.in_proj_weight
mm_projector.attn.in_proj_bias
mm_projector.attn.out_proj.weight
mm_projector.attn.out_proj.bias
mm_projector.ln_q.weight
mm_projector.ln_q.bias
mm_projector.ln_kv.weight
mm_projector.ln_kv.bias
mm_projector.ln_post.weight
mm_projector.ln_post.bias
lm_head.weight
embed_tokens.weight
layers.0.self_attn.q_proj.weight
layers.0.self_attn.k_proj.weight
layers.0.self_attn.v_proj.weight
layers.0.self_attn.o_proj.weight
layers.0.mlp.gate_proj.weight
layers.0.mlp.up_proj.weight
layers.0.mlp.down_proj.weight
layers.0.input_layernorm.weight
layers.0.post_attention_layernorm.weight
layers.1.self_attn.q_proj.weight
layers.1.self_attn.k_proj.weight
layers.1.self_attn.v_proj.weight
layers.1.self_attn.o_proj.weight
layers.1.mlp.gate_proj.weight
layers.1.mlp.up_proj.weight
layers.1.mlp.down_proj.weight
layers.1.input_layernorm.weight
layers.1.post_attention_layernorm.weight
layers.2.self_attn.q_proj.weight
layers.2.self_attn.k_proj.weight
layers.2.self_attn.v_proj.weight
layers.2.self_attn.o_proj.weight
layers.2.mlp.gate_proj.weight
layers.2.mlp.up_proj.weight
layers.2.mlp.down_proj.weight
layers.2.input_layernorm.weight
layers.2.post_attention_layernorm.weight
layers.3.self_attn.q_proj.weight
layers.3.self_attn.k_proj.weight
layers.3.self_attn.v_proj.weight
layers.3.self_attn.o_proj.weight
layers.3.mlp.gate_proj.weight
layers.3.mlp.up_proj.weight
layers.3.mlp.down_proj.weight
layers.3.input_layernorm.weight
layers.3.post_attention_layernorm.weight
layers.4.self_attn.q_proj.weight
layers.4.self_attn.k_proj.weight
layers.4.self_attn.v_proj.weight
layers.4.self_attn.o_proj.weight
layers.4.mlp.gate_proj.weight
layers.4.mlp.up_proj.weight
layers.4.mlp.down_proj.weight
layers.4.input_layernorm.weight
layers.4.post_attention_layernorm.weight
layers.5.self_attn.q_proj.weight
layers.5.self_attn.k_proj.weight
layers.5.self_attn.v_proj.weight
layers.5.self_attn.o_proj.weight
layers.5.mlp.gate_proj.weight
layers.5.mlp.up_proj.weight
layers.5.mlp.down_proj.weight
layers.5.input_layernorm.weight
layers.5.post_attention_layernorm.weight
layers.6.self_attn.q_proj.weight
layers.6.self_attn.k_proj.weight
layers.6.self_attn.v_proj.weight
layers.6.self_attn.o_proj.weight
layers.6.mlp.gate_proj.weight
layers.6.mlp.up_proj.weight
layers.6.mlp.down_proj.weight
layers.6.input_layernorm.weight
layers.6.post_attention_layernorm.weight
layers.7.self_attn.q_proj.weight
layers.7.self_attn.k_proj.weight
layers.7.self_attn.v_proj.weight
layers.7.self_attn.o_proj.weight
layers.7.mlp.gate_proj.weight
layers.7.mlp.up_proj.weight
layers.7.mlp.down_proj.weight
layers.7.input_layernorm.weight
layers.7.post_attention_layernorm.weight
layers.8.self_attn.q_proj.weight
layers.8.self_attn.k_proj.weight
layers.8.self_attn.v_proj.weight
layers.8.self_attn.o_proj.weight
layers.8.mlp.gate_proj.weight
layers.8.mlp.up_proj.weight
layers.8.mlp.down_proj.weight
layers.8.input_layernorm.weight
layers.8.post_attention_layernorm.weight
layers.9.self_attn.q_proj.weight
layers.9.self_attn.k_proj.weight
layers.9.self_attn.v_proj.weight
layers.9.self_attn.o_proj.weight
layers.9.mlp.gate_proj.weight
layers.9.mlp.up_proj.weight
layers.9.mlp.down_proj.weight
layers.9.input_layernorm.weight
layers.9.post_attention_layernorm.weight
layers.10.self_attn.q_proj.weight
layers.10.self_attn.k_proj.weight
layers.10.self_attn.v_proj.weight
layers.10.self_attn.o_proj.weight
layers.10.mlp.gate_proj.weight
layers.10.mlp.up_proj.weight
layers.10.mlp.down_proj.weight
layers.10.input_layernorm.weight
layers.10.post_attention_layernorm.weight
layers.11.self_attn.q_proj.weight
layers.11.self_attn.k_proj.weight
layers.11.self_attn.v_proj.weight
layers.11.self_attn.o_proj.weight
layers.11.mlp.gate_proj.weight
layers.11.mlp.up_proj.weight
layers.11.mlp.down_proj.weight
layers.11.input_layernorm.weight
layers.11.post_attention_layernorm.weight
layers.12.self_attn.q_proj.weight
layers.12.self_attn.k_proj.weight
layers.12.self_attn.v_proj.weight
layers.12.self_attn.o_proj.weight
layers.12.mlp.gate_proj.weight
layers.12.mlp.up_proj.weight
layers.12.mlp.down_proj.weight
layers.12.input_layernorm.weight
layers.12.post_attention_layernorm.weight
layers.13.self_attn.q_proj.weight
layers.13.self_attn.k_proj.weight
layers.13.self_attn.v_proj.weight
layers.13.self_attn.o_proj.weight
layers.13.mlp.gate_proj.weight
layers.13.mlp.up_proj.weight
layers.13.mlp.down_proj.weight
layers.13.input_layernorm.weight
layers.13.post_attention_layernorm.weight
layers.14.self_attn.q_proj.weight
layers.14.self_attn.k_proj.weight
layers.14.self_attn.v_proj.weight
layers.14.self_attn.o_proj.weight
layers.14.mlp.gate_proj.weight
layers.14.mlp.up_proj.weight
layers.14.mlp.down_proj.weight
layers.14.input_layernorm.weight
layers.14.post_attention_layernorm.weight
layers.15.self_attn.q_proj.weight
layers.15.self_attn.k_proj.weight
layers.15.self_attn.v_proj.weight
layers.15.self_attn.o_proj.weight
layers.15.mlp.gate_proj.weight
layers.15.mlp.up_proj.weight
layers.15.mlp.down_proj.weight
layers.15.input_layernorm.weight
layers.15.post_attention_layernorm.weight
layers.16.self_attn.q_proj.weight
layers.16.self_attn.k_proj.weight
layers.16.self_attn.v_proj.weight
layers.16.self_attn.o_proj.weight
layers.16.mlp.gate_proj.weight
layers.16.mlp.up_proj.weight
layers.16.mlp.down_proj.weight
layers.16.input_layernorm.weight
layers.16.post_attention_layernorm.weight
layers.17.self_attn.q_proj.weight
layers.17.self_attn.k_proj.weight
layers.17.self_attn.v_proj.weight
layers.17.self_attn.o_proj.weight
layers.17.mlp.gate_proj.weight
layers.17.mlp.up_proj.weight
layers.17.mlp.down_proj.weight
layers.17.input_layernorm.weight
layers.17.post_attention_layernorm.weight
layers.18.self_attn.q_proj.weight
layers.18.self_attn.k_proj.weight
layers.18.self_attn.v_proj.weight
layers.18.self_attn.o_proj.weight
layers.18.mlp.gate_proj.weight
layers.18.mlp.up_proj.weight
layers.18.mlp.down_proj.weight
layers.18.input_layernorm.weight
layers.18.post_attention_layernorm.weight
layers.19.self_attn.q_proj.weight
layers.19.self_attn.k_proj.weight
layers.19.self_attn.v_proj.weight
layers.19.self_attn.o_proj.weight
layers.19.mlp.gate_proj.weight
layers.19.mlp.up_proj.weight
layers.19.mlp.down_proj.weight
layers.19.input_layernorm.weight
layers.19.post_attention_layernorm.weight
layers.20.self_attn.q_proj.weight
layers.20.self_attn.k_proj.weight
layers.20.self_attn.v_proj.weight
layers.20.self_attn.o_proj.weight
layers.20.mlp.gate_proj.weight
layers.20.mlp.up_proj.weight
layers.20.mlp.down_proj.weight
layers.20.input_layernorm.weight
layers.20.post_attention_layernorm.weight
layers.21.self_attn.q_proj.weight
layers.21.self_attn.k_proj.weight
layers.21.self_attn.v_proj.weight
layers.21.self_attn.o_proj.weight
layers.21.mlp.gate_proj.weight
layers.21.mlp.up_proj.weight
layers.21.mlp.down_proj.weight
layers.21.input_layernorm.weight
layers.21.post_attention_layernorm.weight
layers.22.self_attn.q_proj.weight
layers.22.self_attn.k_proj.weight
layers.22.self_attn.v_proj.weight
layers.22.self_attn.o_proj.weight
layers.22.mlp.gate_proj.weight
layers.22.mlp.up_proj.weight
layers.22.mlp.down_proj.weight
layers.22.input_layernorm.weight
layers.22.post_attention_layernorm.weight
layers.23.self_attn.q_proj.weight
layers.23.self_attn.k_proj.weight
layers.23.self_attn.v_proj.weight
layers.23.self_attn.o_proj.weight
layers.23.mlp.gate_proj.weight
layers.23.mlp.up_proj.weight
layers.23.mlp.down_proj.weight
layers.23.input_layernorm.weight
layers.23.post_attention_layernorm.weight
layers.24.self_attn.q_proj.weight
layers.24.self_attn.k_proj.weight
layers.24.self_attn.v_proj.weight
layers.24.self_attn.o_proj.weight
layers.24.mlp.gate_proj.weight
layers.24.mlp.up_proj.weight
layers.24.mlp.down_proj.weight
layers.24.input_layernorm.weight
layers.24.post_attention_layernorm.weight
layers.25.self_attn.q_proj.weight
layers.25.self_attn.k_proj.weight
layers.25.self_attn.v_proj.weight
layers.25.self_attn.o_proj.weight
layers.25.mlp.gate_proj.weight
layers.25.mlp.up_proj.weight
layers.25.mlp.down_proj.weight
layers.25.input_layernorm.weight
layers.25.post_attention_layernorm.weight
layers.26.self_attn.q_proj.weight
layers.26.self_attn.k_proj.weight
layers.26.self_attn.v_proj.weight
layers.26.self_attn.o_proj.weight
layers.26.mlp.gate_proj.weight
layers.26.mlp.up_proj.weight
layers.26.mlp.down_proj.weight
layers.26.input_layernorm.weight
layers.26.post_attention_layernorm.weight
layers.27.self_attn.q_proj.weight
layers.27.self_attn.k_proj.weight
layers.27.self_attn.v_proj.weight
layers.27.self_attn.o_proj.weight
layers.27.mlp.gate_proj.weight
layers.27.mlp.up_proj.weight
layers.27.mlp.down_proj.weight
layers.27.input_layernorm.weight
layers.27.post_attention_layernorm.weight
layers.28.self_attn.q_proj.weight
layers.28.self_attn.k_proj.weight
layers.28.self_attn.v_proj.weight
layers.28.self_attn.o_proj.weight
layers.28.mlp.gate_proj.weight
layers.28.mlp.up_proj.weight
layers.28.mlp.down_proj.weight
layers.28.input_layernorm.weight
layers.28.post_attention_layernorm.weight
layers.29.self_attn.q_proj.weight
layers.29.self_attn.k_proj.weight
layers.29.self_attn.v_proj.weight
layers.29.self_attn.o_proj.weight
layers.29.mlp.gate_proj.weight
layers.29.mlp.up_proj.weight
layers.29.mlp.down_proj.weight
layers.29.input_layernorm.weight
layers.29.post_attention_layernorm.weight
layers.30.self_attn.q_proj.weight
layers.30.self_attn.k_proj.weight
layers.30.self_attn.v_proj.weight
layers.30.self_attn.o_proj.weight
layers.30.mlp.gate_proj.weight
layers.30.mlp.up_proj.weight
layers.30.mlp.down_proj.weight
layers.30.input_layernorm.weight
layers.30.post_attention_layernorm.weight
layers.31.self_attn.q_proj.weight
layers.31.self_attn.k_proj.weight
layers.31.self_attn.v_proj.weight
layers.31.self_attn.o_proj.weight
layers.31.mlp.gate_proj.weight
layers.31.mlp.up_proj.weight
layers.31.mlp.down_proj.weight
layers.31.input_layernorm.weight
layers.31.post_attention_layernorm.weight
layers.32.self_attn.q_proj.weight
layers.32.self_attn.k_proj.weight
layers.32.self_attn.v_proj.weight
layers.32.self_attn.o_proj.weight
layers.32.mlp.gate_proj.weight
layers.32.mlp.up_proj.weight
layers.32.mlp.down_proj.weight
layers.32.input_layernorm.weight
layers.32.post_attention_layernorm.weight
layers.33.self_attn.q_proj.weight
layers.33.self_attn.k_proj.weight
layers.33.self_attn.v_proj.weight
layers.33.self_attn.o_proj.weight
layers.33.mlp.gate_proj.weight
layers.33.mlp.up_proj.weight
layers.33.mlp.down_proj.weight
layers.33.input_layernorm.weight
layers.33.post_attention_layernorm.weight
layers.34.self_attn.q_proj.weight
layers.34.self_attn.k_proj.weight
layers.34.self_attn.v_proj.weight
layers.34.self_attn.o_proj.weight
layers.34.mlp.gate_proj.weight
layers.34.mlp.up_proj.weight
layers.34.mlp.down_proj.weight
layers.34.input_layernorm.weight
layers.34.post_attention_layernorm.weight
layers.35.self_attn.q_proj.weight
layers.35.self_attn.k_proj.weight
layers.35.self_attn.v_proj.weight
layers.35.self_attn.o_proj.weight
layers.35.mlp.gate_proj.weight
layers.35.mlp.up_proj.weight
layers.35.mlp.down_proj.weight
layers.35.input_layernorm.weight
layers.35.post_attention_layernorm.weight
layers.36.self_attn.q_proj.weight
layers.36.self_attn.k_proj.weight
layers.36.self_attn.v_proj.weight
layers.36.self_attn.o_proj.weight
layers.36.mlp.gate_proj.weight
layers.36.mlp.up_proj.weight
layers.36.mlp.down_proj.weight
layers.36.input_layernorm.weight
layers.36.post_attention_layernorm.weight
layers.37.self_attn.q_proj.weight
layers.37.self_attn.k_proj.weight
layers.37.self_attn.v_proj.weight
layers.37.self_attn.o_proj.weight
layers.37.mlp.gate_proj.weight
layers.37.mlp.up_proj.weight
layers.37.mlp.down_proj.weight
layers.37.input_layernorm.weight
layers.37.post_attention_layernorm.weight
layers.38.self_attn.q_proj.weight
layers.38.self_attn.k_proj.weight
layers.38.self_attn.v_proj.weight
layers.38.self_attn.o_proj.weight
layers.38.mlp.gate_proj.weight
layers.38.mlp.up_proj.weight
layers.38.mlp.down_proj.weight
layers.38.input_layernorm.weight
layers.38.post_attention_layernorm.weight
layers.39.self_attn.q_proj.weight
layers.39.self_attn.k_proj.weight
layers.39.self_attn.v_proj.weight
layers.39.self_attn.o_proj.weight
layers.39.mlp.gate_proj.weight
layers.39.mlp.up_proj.weight
layers.39.mlp.down_proj.weight
layers.39.input_layernorm.weight
layers.39.post_attention_layernorm.weight
norm.weight
mm_projector.query
mm_projector.proj
mm_projector.kv_proj.weight
mm_projector.attn.in_proj_weight
mm_projector.attn.in_proj_bias
mm_projector.attn.out_proj.weight
mm_projector.attn.out_proj.bias
mm_projector.ln_q.weight
mm_projector.ln_q.bias
mm_projector.ln_kv.weight
mm_projector.ln_kv.bias
mm_projector.ln_post.weight
mm_projector.ln_post.bias
lm_head.weight
embed_tokens.weight
layers.0.self_attn.q_proj.weight
layers.0.self_attn.k_proj.weight
layers.0.self_attn.v_proj.weight
layers.0.self_attn.o_proj.weight
layers.0.mlp.gate_proj.weight
layers.0.mlp.up_proj.weight
layers.0.mlp.down_proj.weight
layers.0.input_layernorm.weight
layers.0.post_attention_layernorm.weight
layers.1.self_attn.q_proj.weight
layers.1.self_attn.k_proj.weight
layers.1.self_attn.v_proj.weight
layers.1.self_attn.o_proj.weight
layers.1.mlp.gate_proj.weight
layers.1.mlp.up_proj.weight
layers.1.mlp.down_proj.weight
layers.1.input_layernorm.weight
layers.1.post_attention_layernorm.weight
layers.2.self_attn.q_proj.weight
layers.2.self_attn.k_proj.weight
layers.2.self_attn.v_proj.weight
layers.2.self_attn.o_proj.weight
layers.2.mlp.gate_proj.weight
layers.2.mlp.up_proj.weight
layers.2.mlp.down_proj.weight
layers.2.input_layernorm.weight
layers.2.post_attention_layernorm.weight
layers.3.self_attn.q_proj.weight
layers.3.self_attn.k_proj.weight
layers.3.self_attn.v_proj.weight
layers.3.self_attn.o_proj.weight
layers.3.mlp.gate_proj.weight
layers.3.mlp.up_proj.weight
layers.3.mlp.down_proj.weight
layers.3.input_layernorm.weight
layers.3.post_attention_layernorm.weight
layers.4.self_attn.q_proj.weight
layers.4.self_attn.k_proj.weight
layers.4.self_attn.v_proj.weight
layers.4.self_attn.o_proj.weight
layers.4.mlp.gate_proj.weight
layers.4.mlp.up_proj.weight
layers.4.mlp.down_proj.weight
layers.4.input_layernorm.weight
layers.4.post_attention_layernorm.weight
layers.5.self_attn.q_proj.weight
layers.5.self_attn.k_proj.weight
layers.5.self_attn.v_proj.weight
layers.5.self_attn.o_proj.weight
layers.5.mlp.gate_proj.weight
layers.5.mlp.up_proj.weight
layers.5.mlp.down_proj.weight
layers.5.input_layernorm.weight
layers.5.post_attention_layernorm.weight
layers.6.self_attn.q_proj.weight
layers.6.self_attn.k_proj.weight
layers.6.self_attn.v_proj.weight
layers.6.self_attn.o_proj.weight
layers.6.mlp.gate_proj.weight
layers.6.mlp.up_proj.weight
layers.6.mlp.down_proj.weight
layers.6.input_layernorm.weight
layers.6.post_attention_layernorm.weight
layers.7.self_attn.q_proj.weight
layers.7.self_attn.k_proj.weight
layers.7.self_attn.v_proj.weight
layers.7.self_attn.o_proj.weight
layers.7.mlp.gate_proj.weight
layers.7.mlp.up_proj.weight
layers.7.mlp.down_proj.weight
layers.7.input_layernorm.weight
layers.7.post_attention_layernorm.weight
layers.8.self_attn.q_proj.weight
layers.8.self_attn.k_proj.weight
layers.8.self_attn.v_proj.weight
layers.8.self_attn.o_proj.weight
layers.8.mlp.gate_proj.weight
layers.8.mlp.up_proj.weight
layers.8.mlp.down_proj.weight
layers.8.input_layernorm.weight
layers.8.post_attention_layernorm.weight
layers.9.self_attn.q_proj.weight
layers.9.self_attn.k_proj.weight
layers.9.self_attn.v_proj.weight
layers.9.self_attn.o_proj.weight
layers.9.mlp.gate_proj.weight
layers.9.mlp.up_proj.weight
layers.9.mlp.down_proj.weight
layers.9.input_layernorm.weight
layers.9.post_attention_layernorm.weight
layers.10.self_attn.q_proj.weight
layers.10.self_attn.k_proj.weight
layers.10.self_attn.v_proj.weight
layers.10.self_attn.o_proj.weight
layers.10.mlp.gate_proj.weight
layers.10.mlp.up_proj.weight
layers.10.mlp.down_proj.weight
layers.10.input_layernorm.weight
layers.10.post_attention_layernorm.weight
layers.11.self_attn.q_proj.weight
layers.11.self_attn.k_proj.weight
layers.11.self_attn.v_proj.weight
layers.11.self_attn.o_proj.weight
layers.11.mlp.gate_proj.weight
layers.11.mlp.up_proj.weight
layers.11.mlp.down_proj.weight
layers.11.input_layernorm.weight
layers.11.post_attention_layernorm.weight
layers.12.self_attn.q_proj.weight
layers.12.self_attn.k_proj.weight
layers.12.self_attn.v_proj.weight
layers.12.self_attn.o_proj.weight
layers.12.mlp.gate_proj.weight
layers.12.mlp.up_proj.weight
layers.12.mlp.down_proj.weight
layers.12.input_layernorm.weight
layers.12.post_attention_layernorm.weight
layers.13.self_attn.q_proj.weight
layers.13.self_attn.k_proj.weight
layers.13.self_attn.v_proj.weight
layers.13.self_attn.o_proj.weight
layers.13.mlp.gate_proj.weight
layers.13.mlp.up_proj.weight
layers.13.mlp.down_proj.weight
layers.13.input_layernorm.weight
layers.13.post_attention_layernorm.weight
layers.14.self_attn.q_proj.weight
layers.14.self_attn.k_proj.weight
layers.14.self_attn.v_proj.weight
layers.14.self_attn.o_proj.weight
layers.14.mlp.gate_proj.weight
layers.14.mlp.up_proj.weight
layers.14.mlp.down_proj.weight
layers.14.input_layernorm.weight
layers.14.post_attention_layernorm.weight
layers.15.self_attn.q_proj.weight
layers.15.self_attn.k_proj.weight
layers.15.self_attn.v_proj.weight
layers.15.self_attn.o_proj.weight
layers.15.mlp.gate_proj.weight
layers.15.mlp.up_proj.weight
layers.15.mlp.down_proj.weight
layers.15.input_layernorm.weight
layers.15.post_attention_layernorm.weight
layers.16.self_attn.q_proj.weight
layers.16.self_attn.k_proj.weight
layers.16.self_attn.v_proj.weight
layers.16.self_attn.o_proj.weight
layers.16.mlp.gate_proj.weight
layers.16.mlp.up_proj.weight
layers.16.mlp.down_proj.weight
layers.16.input_layernorm.weight
layers.16.post_attention_layernorm.weight
layers.17.self_attn.q_proj.weight
layers.17.self_attn.k_proj.weight
layers.17.self_attn.v_proj.weight
layers.17.self_attn.o_proj.weight
layers.17.mlp.gate_proj.weight
layers.17.mlp.up_proj.weight
layers.17.mlp.down_proj.weight
layers.17.input_layernorm.weight
layers.17.post_attention_layernorm.weight
layers.18.self_attn.q_proj.weight
layers.18.self_attn.k_proj.weight
layers.18.self_attn.v_proj.weight
layers.18.self_attn.o_proj.weight
layers.18.mlp.gate_proj.weight
layers.18.mlp.up_proj.weight
layers.18.mlp.down_proj.weight
layers.18.input_layernorm.weight
layers.18.post_attention_layernorm.weight
layers.19.self_attn.q_proj.weight
layers.19.self_attn.k_proj.weight
layers.19.self_attn.v_proj.weight
layers.19.self_attn.o_proj.weight
layers.19.mlp.gate_proj.weight
layers.19.mlp.up_proj.weight
layers.19.mlp.down_proj.weight
layers.19.input_layernorm.weight
layers.19.post_attention_layernorm.weight
layers.20.self_attn.q_proj.weight
layers.20.self_attn.k_proj.weight
layers.20.self_attn.v_proj.weight
layers.20.self_attn.o_proj.weight
layers.20.mlp.gate_proj.weight
layers.20.mlp.up_proj.weight
layers.20.mlp.down_proj.weight
layers.20.input_layernorm.weight
layers.20.post_attention_layernorm.weight
layers.21.self_attn.q_proj.weight
layers.21.self_attn.k_proj.weight
layers.21.self_attn.v_proj.weight
layers.21.self_attn.o_proj.weight
layers.21.mlp.gate_proj.weight
layers.21.mlp.up_proj.weight
layers.21.mlp.down_proj.weight
layers.21.input_layernorm.weight
layers.21.post_attention_layernorm.weight
layers.22.self_attn.q_proj.weight
layers.22.self_attn.k_proj.weight
layers.22.self_attn.v_proj.weight
layers.22.self_attn.o_proj.weight
layers.22.mlp.gate_proj.weight
layers.22.mlp.up_proj.weight
layers.22.mlp.down_proj.weight
layers.22.input_layernorm.weight
layers.22.post_attention_layernorm.weight
layers.23.self_attn.q_proj.weight
layers.23.self_attn.k_proj.weight
layers.23.self_attn.v_proj.weight
layers.23.self_attn.o_proj.weight
layers.23.mlp.gate_proj.weight
layers.23.mlp.up_proj.weight
layers.23.mlp.down_proj.weight
layers.23.input_layernorm.weight
layers.23.post_attention_layernorm.weight
layers.24.self_attn.q_proj.weight
layers.24.self_attn.k_proj.weight
layers.24.self_attn.v_proj.weight
layers.24.self_attn.o_proj.weight
layers.24.mlp.gate_proj.weight
layers.24.mlp.up_proj.weight
layers.24.mlp.down_proj.weight
layers.24.input_layernorm.weight
layers.24.post_attention_layernorm.weight
layers.25.self_attn.q_proj.weight
layers.25.self_attn.k_proj.weight
layers.25.self_attn.v_proj.weight
layers.25.self_attn.o_proj.weight
layers.25.mlp.gate_proj.weight
layers.25.mlp.up_proj.weight
layers.25.mlp.down_proj.weight
layers.25.input_layernorm.weight
layers.25.post_attention_layernorm.weight
layers.26.self_attn.q_proj.weight
layers.26.self_attn.k_proj.weight
layers.26.self_attn.v_proj.weight
layers.26.self_attn.o_proj.weight
layers.26.mlp.gate_proj.weight
layers.26.mlp.up_proj.weight
layers.26.mlp.down_proj.weight
layers.26.input_layernorm.weight
layers.26.post_attention_layernorm.weight
layers.27.self_attn.q_proj.weight
layers.27.self_attn.k_proj.weight
layers.27.self_attn.v_proj.weight
layers.27.self_attn.o_proj.weight
layers.27.mlp.gate_proj.weight
layers.27.mlp.up_proj.weight
layers.27.mlp.down_proj.weight
layers.27.input_layernorm.weight
layers.27.post_attention_layernorm.weight
layers.28.self_attn.q_proj.weight
layers.28.self_attn.k_proj.weight
layers.28.self_attn.v_proj.weight
layers.28.self_attn.o_proj.weight
layers.28.mlp.gate_proj.weight
layers.28.mlp.up_proj.weight
layers.28.mlp.down_proj.weight
layers.28.input_layernorm.weight
layers.28.post_attention_layernorm.weight
layers.29.self_attn.q_proj.weight
layers.29.self_attn.k_proj.weight
layers.29.self_attn.v_proj.weight
layers.29.self_attn.o_proj.weight
layers.29.mlp.gate_proj.weight
layers.29.mlp.up_proj.weight
layers.29.mlp.down_proj.weight
layers.29.input_layernorm.weight
layers.29.post_attention_layernorm.weight
layers.30.self_attn.q_proj.weight
layers.30.self_attn.k_proj.weight
layers.30.self_attn.v_proj.weight
layers.30.self_attn.o_proj.weight
layers.30.mlp.gate_proj.weight
layers.30.mlp.up_proj.weight
layers.30.mlp.down_proj.weight
layers.30.input_layernorm.weight
layers.30.post_attention_layernorm.weight
layers.31.self_attn.q_proj.weight
layers.31.self_attn.k_proj.weight
layers.31.self_attn.v_proj.weight
layers.31.self_attn.o_proj.weight
layers.31.mlp.gate_proj.weight
layers.31.mlp.up_proj.weight
layers.31.mlp.down_proj.weight
layers.31.input_layernorm.weight
layers.31.post_attention_layernorm.weight
layers.32.self_attn.q_proj.weight
layers.32.self_attn.k_proj.weight
layers.32.self_attn.v_proj.weight
layers.32.self_attn.o_proj.weight
layers.32.mlp.gate_proj.weight
layers.32.mlp.up_proj.weight
layers.32.mlp.down_proj.weight
layers.32.input_layernorm.weight
layers.32.post_attention_layernorm.weight
layers.33.self_attn.q_proj.weight
layers.33.self_attn.k_proj.weight
layers.33.self_attn.v_proj.weight
layers.33.self_attn.o_proj.weight
layers.33.mlp.gate_proj.weight
layers.33.mlp.up_proj.weight
layers.33.mlp.down_proj.weight
layers.33.input_layernorm.weight
layers.33.post_attention_layernorm.weight
layers.34.self_attn.q_proj.weight
layers.34.self_attn.k_proj.weight
layers.34.self_attn.v_proj.weight
layers.34.self_attn.o_proj.weight
layers.34.mlp.gate_proj.weight
layers.34.mlp.up_proj.weight
layers.34.mlp.down_proj.weight
layers.34.input_layernorm.weight
layers.34.post_attention_layernorm.weight
layers.35.self_attn.q_proj.weight
layers.35.self_attn.k_proj.weight
layers.35.self_attn.v_proj.weight
layers.35.self_attn.o_proj.weight
layers.35.mlp.gate_proj.weight
layers.35.mlp.up_proj.weight
layers.35.mlp.down_proj.weight
layers.35.input_layernorm.weight
layers.35.post_attention_layernorm.weight
layers.36.self_attn.q_proj.weight
layers.36.self_attn.k_proj.weight
layers.36.self_attn.v_proj.weight
layers.36.self_attn.o_proj.weight
layers.36.mlp.gate_proj.weight
layers.36.mlp.up_proj.weight
layers.36.mlp.down_proj.weight
layers.36.input_layernorm.weight
layers.36.post_attention_layernorm.weight
layers.37.self_attn.q_proj.weight
layers.37.self_attn.k_proj.weight
layers.37.self_attn.v_proj.weight
layers.37.self_attn.o_proj.weight
layers.37.mlp.gate_proj.weight
layers.37.mlp.up_proj.weight
layers.37.mlp.down_proj.weight
layers.37.input_layernorm.weight
layers.37.post_attention_layernorm.weight
layers.38.self_attn.q_proj.weight
layers.38.self_attn.k_proj.weight
layers.38.self_attn.v_proj.weight
layers.38.self_attn.o_proj.weight
layers.38.mlp.gate_proj.weight
layers.38.mlp.up_proj.weight
layers.38.mlp.down_proj.weight
layers.38.input_layernorm.weight
layers.38.post_attention_layernorm.weight
layers.39.self_attn.q_proj.weight
layers.39.self_attn.k_proj.weight
layers.39.self_attn.v_proj.weight
layers.39.self_attn.o_proj.weight
layers.39.mlp.gate_proj.weight
layers.39.mlp.up_proj.weight
layers.39.mlp.down_proj.weight
layers.39.input_layernorm.weight
layers.39.post_attention_layernorm.weight
norm.weight
mm_projector.query
mm_projector.proj
mm_projector.kv_proj.weight
mm_projector.attn.in_proj_weight
mm_projector.attn.in_proj_bias
mm_projector.attn.out_proj.weight
mm_projector.attn.out_proj.bias
mm_projector.ln_q.weight
mm_projector.ln_q.bias
mm_projector.ln_kv.weight
mm_projector.ln_kv.bias
mm_projector.ln_post.weight
mm_projector.ln_post.bias
lm_head.weight
embed_tokens.weight
layers.0.self_attn.q_proj.weight
layers.0.self_attn.k_proj.weight
layers.0.self_attn.v_proj.weight
layers.0.self_attn.o_proj.weight
layers.0.mlp.gate_proj.weight
layers.0.mlp.up_proj.weight
layers.0.mlp.down_proj.weight
layers.0.input_layernorm.weight
layers.0.post_attention_layernorm.weight
layers.1.self_attn.q_proj.weight
layers.1.self_attn.k_proj.weight
layers.1.self_attn.v_proj.weight
layers.1.self_attn.o_proj.weight
layers.1.mlp.gate_proj.weight
layers.1.mlp.up_proj.weight
layers.1.mlp.down_proj.weight
layers.1.input_layernorm.weight
layers.1.post_attention_layernorm.weight
layers.2.self_attn.q_proj.weight
layers.2.self_attn.k_proj.weight
layers.2.self_attn.v_proj.weight
layers.2.self_attn.o_proj.weight
layers.2.mlp.gate_proj.weight
layers.2.mlp.up_proj.weight
layers.2.mlp.down_proj.weight
layers.2.input_layernorm.weight
layers.2.post_attention_layernorm.weight
layers.3.self_attn.q_proj.weight
layers.3.self_attn.k_proj.weight
layers.3.self_attn.v_proj.weight
layers.3.self_attn.o_proj.weight
layers.3.mlp.gate_proj.weight
layers.3.mlp.up_proj.weight
layers.3.mlp.down_proj.weight
layers.3.input_layernorm.weight
layers.3.post_attention_layernorm.weight
layers.4.self_attn.q_proj.weight
layers.4.self_attn.k_proj.weight
layers.4.self_attn.v_proj.weight
layers.4.self_attn.o_proj.weight
layers.4.mlp.gate_proj.weight
layers.4.mlp.up_proj.weight
layers.4.mlp.down_proj.weight
layers.4.input_layernorm.weight
layers.4.post_attention_layernorm.weight
layers.5.self_attn.q_proj.weight
layers.5.self_attn.k_proj.weight
layers.5.self_attn.v_proj.weight
layers.5.self_attn.o_proj.weight
layers.5.mlp.gate_proj.weight
layers.5.mlp.up_proj.weight
layers.5.mlp.down_proj.weight
layers.5.input_layernorm.weight
layers.5.post_attention_layernorm.weight
layers.6.self_attn.q_proj.weight
layers.6.self_attn.k_proj.weight
layers.6.self_attn.v_proj.weight
layers.6.self_attn.o_proj.weight
layers.6.mlp.gate_proj.weight
layers.6.mlp.up_proj.weight
layers.6.mlp.down_proj.weight
layers.6.input_layernorm.weight
layers.6.post_attention_layernorm.weight
layers.7.self_attn.q_proj.weight
layers.7.self_attn.k_proj.weight
layers.7.self_attn.v_proj.weight
layers.7.self_attn.o_proj.weight
layers.7.mlp.gate_proj.weight
layers.7.mlp.up_proj.weight
layers.7.mlp.down_proj.weight
layers.7.input_layernorm.weight
layers.7.post_attention_layernorm.weight
layers.8.self_attn.q_proj.weight
layers.8.self_attn.k_proj.weight
layers.8.self_attn.v_proj.weight
layers.8.self_attn.o_proj.weight
layers.8.mlp.gate_proj.weight
layers.8.mlp.up_proj.weight
layers.8.mlp.down_proj.weight
layers.8.input_layernorm.weight
layers.8.post_attention_layernorm.weight
layers.9.self_attn.q_proj.weight
layers.9.self_attn.k_proj.weight
layers.9.self_attn.v_proj.weight
layers.9.self_attn.o_proj.weight
layers.9.mlp.gate_proj.weight
layers.9.mlp.up_proj.weight
layers.9.mlp.down_proj.weight
layers.9.input_layernorm.weight
layers.9.post_attention_layernorm.weight
layers.10.self_attn.q_proj.weight
layers.10.self_attn.k_proj.weight
layers.10.self_attn.v_proj.weight
layers.10.self_attn.o_proj.weight
layers.10.mlp.gate_proj.weight
layers.10.mlp.up_proj.weight
layers.10.mlp.down_proj.weight
layers.10.input_layernorm.weight
layers.10.post_attention_layernorm.weight
layers.11.self_attn.q_proj.weight
layers.11.self_attn.k_proj.weight
layers.11.self_attn.v_proj.weight
layers.11.self_attn.o_proj.weight
layers.11.mlp.gate_proj.weight
layers.11.mlp.up_proj.weight
layers.11.mlp.down_proj.weight
layers.11.input_layernorm.weight
layers.11.post_attention_layernorm.weight
layers.12.self_attn.q_proj.weight
layers.12.self_attn.k_proj.weight
layers.12.self_attn.v_proj.weight
layers.12.self_attn.o_proj.weight
layers.12.mlp.gate_proj.weight
layers.12.mlp.up_proj.weight
layers.12.mlp.down_proj.weight
layers.12.input_layernorm.weight
layers.12.post_attention_layernorm.weight
layers.13.self_attn.q_proj.weight
layers.13.self_attn.k_proj.weight
layers.13.self_attn.v_proj.weight
layers.13.self_attn.o_proj.weight
layers.13.mlp.gate_proj.weight
layers.13.mlp.up_proj.weight
layers.13.mlp.down_proj.weight
layers.13.input_layernorm.weight
layers.13.post_attention_layernorm.weight
layers.14.self_attn.q_proj.weight
layers.14.self_attn.k_proj.weight
layers.14.self_attn.v_proj.weight
layers.14.self_attn.o_proj.weight
layers.14.mlp.gate_proj.weight
layers.14.mlp.up_proj.weight
layers.14.mlp.down_proj.weight
layers.14.input_layernorm.weight
layers.14.post_attention_layernorm.weight
layers.15.self_attn.q_proj.weight
layers.15.self_attn.k_proj.weight
layers.15.self_attn.v_proj.weight
layers.15.self_attn.o_proj.weight
layers.15.mlp.gate_proj.weight
layers.15.mlp.up_proj.weight
layers.15.mlp.down_proj.weight
layers.15.input_layernorm.weight
layers.15.post_attention_layernorm.weight
layers.16.self_attn.q_proj.weight
layers.16.self_attn.k_proj.weight
layers.16.self_attn.v_proj.weight
layers.16.self_attn.o_proj.weight
layers.16.mlp.gate_proj.weight
layers.16.mlp.up_proj.weight
layers.16.mlp.down_proj.weight
layers.16.input_layernorm.weight
layers.16.post_attention_layernorm.weight
layers.17.self_attn.q_proj.weight
layers.17.self_attn.k_proj.weight
layers.17.self_attn.v_proj.weight
layers.17.self_attn.o_proj.weight
layers.17.mlp.gate_proj.weight
layers.17.mlp.up_proj.weight
layers.17.mlp.down_proj.weight
layers.17.input_layernorm.weight
layers.17.post_attention_layernorm.weight
layers.18.self_attn.q_proj.weight
layers.18.self_attn.k_proj.weight
layers.18.self_attn.v_proj.weight
layers.18.self_attn.o_proj.weight
layers.18.mlp.gate_proj.weight
layers.18.mlp.up_proj.weight
layers.18.mlp.down_proj.weight
layers.18.input_layernorm.weight
layers.18.post_attention_layernorm.weight
layers.19.self_attn.q_proj.weight
layers.19.self_attn.k_proj.weight
layers.19.self_attn.v_proj.weight
layers.19.self_attn.o_proj.weight
layers.19.mlp.gate_proj.weight
layers.19.mlp.up_proj.weight
layers.19.mlp.down_proj.weight
layers.19.input_layernorm.weight
layers.19.post_attention_layernorm.weight
layers.20.self_attn.q_proj.weight
layers.20.self_attn.k_proj.weight
layers.20.self_attn.v_proj.weight
layers.20.self_attn.o_proj.weight
layers.20.mlp.gate_proj.weight
layers.20.mlp.up_proj.weight
layers.20.mlp.down_proj.weight
layers.20.input_layernorm.weight
layers.20.post_attention_layernorm.weight
layers.21.self_attn.q_proj.weight
layers.21.self_attn.k_proj.weight
layers.21.self_attn.v_proj.weight
layers.21.self_attn.o_proj.weight
layers.21.mlp.gate_proj.weight
layers.21.mlp.up_proj.weight
layers.21.mlp.down_proj.weight
layers.21.input_layernorm.weight
layers.21.post_attention_layernorm.weight
layers.22.self_attn.q_proj.weight
layers.22.self_attn.k_proj.weight
layers.22.self_attn.v_proj.weight
layers.22.self_attn.o_proj.weight
layers.22.mlp.gate_proj.weight
layers.22.mlp.up_proj.weight
layers.22.mlp.down_proj.weight
layers.22.input_layernorm.weight
layers.22.post_attention_layernorm.weight
layers.23.self_attn.q_proj.weight
layers.23.self_attn.k_proj.weight
layers.23.self_attn.v_proj.weight
layers.23.self_attn.o_proj.weight
layers.23.mlp.gate_proj.weight
layers.23.mlp.up_proj.weight
layers.23.mlp.down_proj.weight
layers.23.input_layernorm.weight
layers.23.post_attention_layernorm.weight
layers.24.self_attn.q_proj.weight
layers.24.self_attn.k_proj.weight
layers.24.self_attn.v_proj.weight
layers.24.self_attn.o_proj.weight
layers.24.mlp.gate_proj.weight
layers.24.mlp.up_proj.weight
layers.24.mlp.down_proj.weight
layers.24.input_layernorm.weight
layers.24.post_attention_layernorm.weight
layers.25.self_attn.q_proj.weight
layers.25.self_attn.k_proj.weight
layers.25.self_attn.v_proj.weight
layers.25.self_attn.o_proj.weight
layers.25.mlp.gate_proj.weight
layers.25.mlp.up_proj.weight
layers.25.mlp.down_proj.weight
layers.25.input_layernorm.weight
layers.25.post_attention_layernorm.weight
layers.26.self_attn.q_proj.weight
layers.26.self_attn.k_proj.weight
layers.26.self_attn.v_proj.weight
layers.26.self_attn.o_proj.weight
layers.26.mlp.gate_proj.weight
layers.26.mlp.up_proj.weight
layers.26.mlp.down_proj.weight
layers.26.input_layernorm.weight
layers.26.post_attention_layernorm.weight
layers.27.self_attn.q_proj.weight
layers.27.self_attn.k_proj.weight
layers.27.self_attn.v_proj.weight
layers.27.self_attn.o_proj.weight
layers.27.mlp.gate_proj.weight
layers.27.mlp.up_proj.weight
layers.27.mlp.down_proj.weight
layers.27.input_layernorm.weight
layers.27.post_attention_layernorm.weight
layers.28.self_attn.q_proj.weight
layers.28.self_attn.k_proj.weight
layers.28.self_attn.v_proj.weight
layers.28.self_attn.o_proj.weight
layers.28.mlp.gate_proj.weight
layers.28.mlp.up_proj.weight
layers.28.mlp.down_proj.weight
layers.28.input_layernorm.weight
layers.28.post_attention_layernorm.weight
layers.29.self_attn.q_proj.weight
layers.29.self_attn.k_proj.weight
layers.29.self_attn.v_proj.weight
layers.29.self_attn.o_proj.weight
layers.29.mlp.gate_proj.weight
layers.29.mlp.up_proj.weight
layers.29.mlp.down_proj.weight
layers.29.input_layernorm.weight
layers.29.post_attention_layernorm.weight
layers.30.self_attn.q_proj.weight
layers.30.self_attn.k_proj.weight
layers.30.self_attn.v_proj.weight
layers.30.self_attn.o_proj.weight
layers.30.mlp.gate_proj.weight
layers.30.mlp.up_proj.weight
layers.30.mlp.down_proj.weight
layers.30.input_layernorm.weight
layers.30.post_attention_layernorm.weight
layers.31.self_attn.q_proj.weight
layers.31.self_attn.k_proj.weight
layers.31.self_attn.v_proj.weight
layers.31.self_attn.o_proj.weight
layers.31.mlp.gate_proj.weight
layers.31.mlp.up_proj.weight
layers.31.mlp.down_proj.weight
layers.31.input_layernorm.weight
layers.31.post_attention_layernorm.weight
layers.32.self_attn.q_proj.weight
layers.32.self_attn.k_proj.weight
layers.32.self_attn.v_proj.weight
layers.32.self_attn.o_proj.weight
layers.32.mlp.gate_proj.weight
layers.32.mlp.up_proj.weight
layers.32.mlp.down_proj.weight
layers.32.input_layernorm.weight
layers.32.post_attention_layernorm.weight
layers.33.self_attn.q_proj.weight
layers.33.self_attn.k_proj.weight
layers.33.self_attn.v_proj.weight
layers.33.self_attn.o_proj.weight
layers.33.mlp.gate_proj.weight
layers.33.mlp.up_proj.weight
layers.33.mlp.down_proj.weight
layers.33.input_layernorm.weight
layers.33.post_attention_layernorm.weight
layers.34.self_attn.q_proj.weight
layers.34.self_attn.k_proj.weight
layers.34.self_attn.v_proj.weight
layers.34.self_attn.o_proj.weight
layers.34.mlp.gate_proj.weight
layers.34.mlp.up_proj.weight
layers.34.mlp.down_proj.weight
layers.34.input_layernorm.weight
layers.34.post_attention_layernorm.weight
layers.35.self_attn.q_proj.weight
layers.35.self_attn.k_proj.weight
layers.35.self_attn.v_proj.weight
layers.35.self_attn.o_proj.weight
layers.35.mlp.gate_proj.weight
layers.35.mlp.up_proj.weight
layers.35.mlp.down_proj.weight
layers.35.input_layernorm.weight
layers.35.post_attention_layernorm.weight
layers.36.self_attn.q_proj.weight
layers.36.self_attn.k_proj.weight
layers.36.self_attn.v_proj.weight
layers.36.self_attn.o_proj.weight
layers.36.mlp.gate_proj.weight
layers.36.mlp.up_proj.weight
layers.36.mlp.down_proj.weight
layers.36.input_layernorm.weight
layers.36.post_attention_layernorm.weight
layers.37.self_attn.q_proj.weight
layers.37.self_attn.k_proj.weight
layers.37.self_attn.v_proj.weight
layers.37.self_attn.o_proj.weight
layers.37.mlp.gate_proj.weight
layers.37.mlp.up_proj.weight
layers.37.mlp.down_proj.weight
layers.37.input_layernorm.weight
layers.37.post_attention_layernorm.weight
layers.38.self_attn.q_proj.weight
layers.38.self_attn.k_proj.weight
layers.38.self_attn.v_proj.weight
layers.38.self_attn.o_proj.weight
layers.38.mlp.gate_proj.weight
layers.38.mlp.up_proj.weight
layers.38.mlp.down_proj.weight
layers.38.input_layernorm.weight
layers.38.post_attention_layernorm.weight
layers.39.self_attn.q_proj.weight
layers.39.self_attn.k_proj.weight
layers.39.self_attn.v_proj.weight
layers.39.self_attn.o_proj.weight
layers.39.mlp.gate_proj.weight
layers.39.mlp.up_proj.weight
layers.39.mlp.down_proj.weight
layers.39.input_layernorm.weight
layers.39.post_attention_layernorm.weight
norm.weight
mm_projector.query
mm_projector.proj
mm_projector.kv_proj.weight
mm_projector.attn.in_proj_weight
mm_projector.attn.in_proj_bias
mm_projector.attn.out_proj.weight
mm_projector.attn.out_proj.bias
mm_projector.ln_q.weight
mm_projector.ln_q.bias
mm_projector.ln_kv.weight
mm_projector.ln_kv.bias
mm_projector.ln_post.weight
mm_projector.ln_post.bias
lm_head.weight
wandb: Tracking run with wandb version 0.17.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
  0%|          | 0/2496 [00:00<?, ?it/s]/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
this iter is wrong in something... skip...
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1652: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1652: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1652: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1652: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1652: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1652: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1652: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
/home/test/test08/anaconda3/envs/llava_uhd/lib/python3.9/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1652: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
  0%|          | 1/2496 [00:50<34:59:32, 50.49s/it]                                                   {'loss': 1.2121, 'learning_rate': 2.666666666666667e-07, 'epoch': 0.0}
  0%|          | 1/2496 [00:50<34:59:32, 50.49s/it]  0%|          | 2/2496 [01:16<24:48:28, 35.81s/it]                                                   {'loss': 1.258, 'learning_rate': 5.333333333333335e-07, 'epoch': 0.0}
  0%|          | 2/2496 [01:16<24:48:28, 35.81s/it]  0%|          | 3/2496 [01:43<22:01:23, 31.80s/it]                                                   {'loss': 1.2347, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.0}
  0%|          | 3/2496 [01:43<22:01:23, 31.80s/it]  0%|          | 4/2496 [02:06<19:50:39, 28.67s/it]                                                   {'loss': 1.2153, 'learning_rate': 1.066666666666667e-06, 'epoch': 0.0}
  0%|          | 4/2496 [02:06<19:50:39, 28.67s/it]  0%|          | 5/2496 [02:31<18:54:02, 27.32s/it]                                                   {'loss': 1.2444, 'learning_rate': 1.3333333333333334e-06, 'epoch': 0.0}
  0%|          | 5/2496 [02:31<18:54:02, 27.32s/it]  0%|          | 6/2496 [02:55<18:05:06, 26.15s/it]                                                   {'loss': 1.1926, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.0}
  0%|          | 6/2496 [02:55<18:05:06, 26.15s/it]  0%|          | 7/2496 [03:19<17:28:42, 25.28s/it]                                                   {'loss': 1.2225, 'learning_rate': 1.8666666666666669e-06, 'epoch': 0.0}
  0%|          | 7/2496 [03:19<17:28:42, 25.28s/it]  0%|          | 8/2496 [03:43<17:16:18, 24.99s/it]                                                   {'loss': 1.1771, 'learning_rate': 2.133333333333334e-06, 'epoch': 0.0}
  0%|          | 8/2496 [03:43<17:16:18, 24.99s/it]  0%|          | 9/2496 [04:09<17:30:20, 25.34s/it]                                                   {'loss': 1.1444, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.0}
  0%|          | 9/2496 [04:09<17:30:20, 25.34s/it]  0%|          | 10/2496 [04:35<17:32:21, 25.40s/it]                                                    {'loss': 1.0668, 'learning_rate': 2.666666666666667e-06, 'epoch': 0.0}
  0%|          | 10/2496 [04:35<17:32:21, 25.40s/it]  0%|          | 11/2496 [05:00<17:34:38, 25.46s/it]                                                    {'loss': 1.051, 'learning_rate': 2.9333333333333338e-06, 'epoch': 0.0}
  0%|          | 11/2496 [05:00<17:34:38, 25.46s/it]  0%|          | 12/2496 [05:26<17:41:44, 25.65s/it]                                                    {'loss': 1.0461, 'learning_rate': 3.2000000000000003e-06, 'epoch': 0.0}
  0%|          | 12/2496 [05:26<17:41:44, 25.65s/it]  1%|          | 13/2496 [05:54<18:10:33, 26.35s/it]                                                    {'loss': 1.0784, 'learning_rate': 3.4666666666666672e-06, 'epoch': 0.01}
  1%|          | 13/2496 [05:54<18:10:33, 26.35s/it]  1%|          | 14/2496 [06:21<18:17:50, 26.54s/it]                                                    {'loss': 1.0296, 'learning_rate': 3.7333333333333337e-06, 'epoch': 0.01}
  1%|          | 14/2496 [06:21<18:17:50, 26.54s/it]  1%|          | 15/2496 [06:49<18:37:18, 27.02s/it]                                                    {'loss': 1.0142, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.01}
  1%|          | 15/2496 [06:49<18:37:18, 27.02s/it]  1%|          | 16/2496 [07:13<17:54:51, 26.00s/it]                                                    {'loss': 1.0416, 'learning_rate': 4.266666666666668e-06, 'epoch': 0.01}
  1%|          | 16/2496 [07:13<17:54:51, 26.00s/it]  1%|          | 17/2496 [07:37<17:22:47, 25.24s/it]                                                    {'loss': 0.9986, 'learning_rate': 4.533333333333334e-06, 'epoch': 0.01}
  1%|          | 17/2496 [07:37<17:22:47, 25.24s/it]  1%|          | 18/2496 [08:04<17:43:42, 25.76s/it]                                                    {'loss': 0.993, 'learning_rate': 4.800000000000001e-06, 'epoch': 0.01}
  1%|          | 18/2496 [08:04<17:43:42, 25.76s/it]  1%|          | 19/2496 [08:26<17:01:45, 24.75s/it]                                                    {'loss': 1.0005, 'learning_rate': 5.0666666666666676e-06, 'epoch': 0.01}
  1%|          | 19/2496 [08:26<17:01:45, 24.75s/it]  1%|          | 20/2496 [08:53<17:26:53, 25.37s/it]                                                    {'loss': 0.9515, 'learning_rate': 5.333333333333334e-06, 'epoch': 0.01}
  1%|          | 20/2496 [08:53<17:26:53, 25.37s/it]  1%|          | 21/2496 [09:18<17:30:44, 25.47s/it]                                                    {'loss': 0.9941, 'learning_rate': 5.600000000000001e-06, 'epoch': 0.01}
  1%|          | 21/2496 [09:18<17:30:44, 25.47s/it]  1%|          | 22/2496 [09:43<17:19:06, 25.20s/it]                                                    {'loss': 0.9548, 'learning_rate': 5.8666666666666675e-06, 'epoch': 0.01}
  1%|          | 22/2496 [09:43<17:19:06, 25.20s/it]this iter is wrong in something... skip...
  1%|          | 23/2496 [10:08<17:10:48, 25.01s/it]                                                    {'loss': 0.9097, 'learning_rate': 6.133333333333334e-06, 'epoch': 0.01}
  1%|          | 23/2496 [10:08<17:10:48, 25.01s/it]  1%|          | 24/2496 [10:33<17:11:39, 25.04s/it]                                                    {'loss': 0.8902, 'learning_rate': 6.4000000000000006e-06, 'epoch': 0.01}
  1%|          | 24/2496 [10:33<17:11:39, 25.04s/it]  1%|          | 25/2496 [10:58<17:09:17, 24.99s/it]                                                    {'loss': 0.2689, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.01}
  1%|          | 25/2496 [10:58<17:09:17, 24.99s/it]  1%|          | 26/2496 [11:22<16:58:24, 24.74s/it]                                                    {'loss': 0.9153, 'learning_rate': 6.9333333333333344e-06, 'epoch': 0.01}
  1%|          | 26/2496 [11:22<16:58:24, 24.74s/it]  1%|          | 27/2496 [11:48<17:22:12, 25.33s/it]                                                    {'loss': 0.8846, 'learning_rate': 7.2000000000000005e-06, 'epoch': 0.01}
  1%|          | 27/2496 [11:48<17:22:12, 25.33s/it]  1%|          | 28/2496 [12:14<17:21:34, 25.32s/it]                                                    {'loss': 0.9269, 'learning_rate': 7.4666666666666675e-06, 'epoch': 0.01}
  1%|          | 28/2496 [12:14<17:21:34, 25.32s/it]  1%|          | 29/2496 [12:38<17:02:45, 24.87s/it]                                                    {'loss': 0.907, 'learning_rate': 7.733333333333334e-06, 'epoch': 0.01}
  1%|          | 29/2496 [12:38<17:02:45, 24.87s/it]  1%|          | 30/2496 [13:05<17:29:30, 25.54s/it]                                                    {'loss': 0.9095, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.01}
  1%|          | 30/2496 [13:05<17:29:30, 25.54s/it]  1%|          | 31/2496 [13:31<17:34:39, 25.67s/it]                                                    {'loss': 0.8932, 'learning_rate': 8.266666666666667e-06, 'epoch': 0.01}
  1%|          | 31/2496 [13:31<17:34:39, 25.67s/it]  1%|▏         | 32/2496 [13:57<17:40:04, 25.81s/it]                                                    {'loss': 0.8847, 'learning_rate': 8.533333333333335e-06, 'epoch': 0.01}
  1%|▏         | 32/2496 [13:57<17:40:04, 25.81s/it]  1%|▏         | 33/2496 [14:22<17:30:18, 25.59s/it]                                                    {'loss': 0.8105, 'learning_rate': 8.8e-06, 'epoch': 0.01}
  1%|▏         | 33/2496 [14:22<17:30:18, 25.59s/it]  1%|▏         | 34/2496 [14:48<17:36:57, 25.76s/it]                                                    {'loss': 0.8678, 'learning_rate': 9.066666666666667e-06, 'epoch': 0.01}
  1%|▏         | 34/2496 [14:48<17:36:57, 25.76s/it]  1%|▏         | 35/2496 [15:11<17:03:01, 24.94s/it]                                                    {'loss': 0.8333, 'learning_rate': 9.333333333333334e-06, 'epoch': 0.01}
  1%|▏         | 35/2496 [15:11<17:03:01, 24.94s/it]  1%|▏         | 36/2496 [15:36<17:01:03, 24.90s/it]                                                    {'loss': 0.2549, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.01}
  1%|▏         | 36/2496 [15:36<17:01:03, 24.90s/it]  1%|▏         | 37/2496 [15:59<16:34:26, 24.26s/it]                                                    {'loss': 0.8514, 'learning_rate': 9.866666666666668e-06, 'epoch': 0.01}
  1%|▏         | 37/2496 [15:59<16:34:26, 24.26s/it]  2%|▏         | 38/2496 [16:23<16:37:07, 24.34s/it]                                                    {'loss': 0.8813, 'learning_rate': 1.0133333333333335e-05, 'epoch': 0.02}
  2%|▏         | 38/2496 [16:23<16:37:07, 24.34s/it]  2%|▏         | 39/2496 [16:49<16:51:16, 24.70s/it]                                                    {'loss': 0.8449, 'learning_rate': 1.04e-05, 'epoch': 0.02}
  2%|▏         | 39/2496 [16:49<16:51:16, 24.70s/it]  2%|▏         | 40/2496 [17:14<16:55:11, 24.80s/it]                                                    {'loss': 0.8352, 'learning_rate': 1.0666666666666667e-05, 'epoch': 0.02}
  2%|▏         | 40/2496 [17:14<16:55:11, 24.80s/it]  2%|▏         | 41/2496 [17:40<17:10:47, 25.19s/it]                                                    {'loss': 0.8401, 'learning_rate': 1.0933333333333334e-05, 'epoch': 0.02}
  2%|▏         | 41/2496 [17:40<17:10:47, 25.19s/it]  2%|▏         | 42/2496 [18:05<17:05:46, 25.08s/it]                                                    {'loss': 0.8283, 'learning_rate': 1.1200000000000001e-05, 'epoch': 0.02}
  2%|▏         | 42/2496 [18:05<17:05:46, 25.08s/it]  2%|▏         | 43/2496 [18:31<17:15:48, 25.34s/it]                                                    {'loss': 0.8566, 'learning_rate': 1.1466666666666668e-05, 'epoch': 0.02}
  2%|▏         | 43/2496 [18:31<17:15:48, 25.34s/it]  2%|▏         | 44/2496 [18:56<17:17:53, 25.40s/it]                                                    {'loss': 0.8576, 'learning_rate': 1.1733333333333335e-05, 'epoch': 0.02}
  2%|▏         | 44/2496 [18:56<17:17:53, 25.40s/it]  2%|▏         | 45/2496 [19:22<17:21:44, 25.50s/it]                                                    {'loss': 0.8545, 'learning_rate': 1.2e-05, 'epoch': 0.02}
  2%|▏         | 45/2496 [19:22<17:21:44, 25.50s/it]this iter is wrong in something... skip...
  2%|▏         | 46/2496 [19:49<17:42:48, 26.03s/it]                                                    {'loss': 0.8288, 'learning_rate': 1.2266666666666667e-05, 'epoch': 0.02}
  2%|▏         | 46/2496 [19:49<17:42:48, 26.03s/it]  2%|▏         | 47/2496 [20:17<18:02:59, 26.53s/it]                                                    {'loss': 0.8555, 'learning_rate': 1.2533333333333336e-05, 'epoch': 0.02}
  2%|▏         | 47/2496 [20:17<18:02:59, 26.53s/it]  2%|▏         | 48/2496 [20:42<17:43:20, 26.06s/it]                                                    {'loss': 0.7889, 'learning_rate': 1.2800000000000001e-05, 'epoch': 0.02}
  2%|▏         | 48/2496 [20:42<17:43:20, 26.06s/it]  2%|▏         | 49/2496 [21:09<17:59:59, 26.48s/it]                                                    {'loss': 0.8291, 'learning_rate': 1.3066666666666668e-05, 'epoch': 0.02}
  2%|▏         | 49/2496 [21:09<17:59:59, 26.48s/it]  2%|▏         | 50/2496 [21:36<18:04:34, 26.60s/it]                                                    {'loss': 0.8401, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.02}
  2%|▏         | 50/2496 [21:36<18:04:34, 26.60s/it]  2%|▏         | 51/2496 [22:02<17:54:19, 26.36s/it]                                                    {'loss': 0.7958, 'learning_rate': 1.3600000000000002e-05, 'epoch': 0.02}
  2%|▏         | 51/2496 [22:02<17:54:19, 26.36s/it]  2%|▏         | 52/2496 [22:25<17:15:06, 25.41s/it]                                                    {'loss': 0.8484, 'learning_rate': 1.3866666666666669e-05, 'epoch': 0.02}
  2%|▏         | 52/2496 [22:25<17:15:06, 25.41s/it]  2%|▏         | 53/2496 [22:53<17:41:15, 26.06s/it]                                                    {'loss': 0.8186, 'learning_rate': 1.4133333333333334e-05, 'epoch': 0.02}
  2%|▏         | 53/2496 [22:53<17:41:15, 26.06s/it]  2%|▏         | 54/2496 [23:18<17:32:20, 25.86s/it]                                                    {'loss': 0.8293, 'learning_rate': 1.4400000000000001e-05, 'epoch': 0.02}
  2%|▏         | 54/2496 [23:18<17:32:20, 25.86s/it]  2%|▏         | 55/2496 [23:45<17:39:49, 26.05s/it]                                                    {'loss': 0.8221, 'learning_rate': 1.4666666666666666e-05, 'epoch': 0.02}
  2%|▏         | 55/2496 [23:45<17:39:49, 26.05s/it]  2%|▏         | 56/2496 [24:10<17:31:04, 25.85s/it]                                                    {'loss': 0.254, 'learning_rate': 1.4933333333333335e-05, 'epoch': 0.02}
  2%|▏         | 56/2496 [24:10<17:31:04, 25.85s/it]  2%|▏         | 57/2496 [24:34<17:13:21, 25.42s/it]                                                    {'loss': 0.8039, 'learning_rate': 1.5200000000000002e-05, 'epoch': 0.02}
  2%|▏         | 57/2496 [24:34<17:13:21, 25.42s/it]  2%|▏         | 58/2496 [24:59<17:05:44, 25.24s/it]                                                    {'loss': 0.8067, 'learning_rate': 1.546666666666667e-05, 'epoch': 0.02}
  2%|▏         | 58/2496 [24:59<17:05:44, 25.24s/it]  2%|▏         | 59/2496 [25:25<17:09:50, 25.36s/it]                                                    {'loss': 0.8236, 'learning_rate': 1.5733333333333334e-05, 'epoch': 0.02}
  2%|▏         | 59/2496 [25:25<17:09:50, 25.36s/it]  2%|▏         | 60/2496 [25:50<17:03:50, 25.22s/it]                                                    {'loss': 0.2545, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.02}
  2%|▏         | 60/2496 [25:50<17:03:50, 25.22s/it]this iter is wrong in something... skip...
  2%|▏         | 61/2496 [26:15<17:06:57, 25.30s/it]                                                    {'loss': 0.822, 'learning_rate': 1.6266666666666668e-05, 'epoch': 0.02}
  2%|▏         | 61/2496 [26:15<17:06:57, 25.30s/it]  2%|▏         | 62/2496 [26:40<17:04:13, 25.25s/it]                                                    {'loss': 0.8008, 'learning_rate': 1.6533333333333333e-05, 'epoch': 0.02}
  2%|▏         | 62/2496 [26:40<17:04:13, 25.25s/it]  3%|▎         | 63/2496 [27:06<17:05:44, 25.30s/it]                                                    {'loss': 0.841, 'learning_rate': 1.6800000000000002e-05, 'epoch': 0.03}
  3%|▎         | 63/2496 [27:06<17:05:44, 25.30s/it]  3%|▎         | 64/2496 [27:28<16:32:58, 24.50s/it]                                                    {'loss': 0.8613, 'learning_rate': 1.706666666666667e-05, 'epoch': 0.03}
  3%|▎         | 64/2496 [27:28<16:32:58, 24.50s/it]  3%|▎         | 65/2496 [27:54<16:51:33, 24.97s/it]                                                    {'loss': 0.781, 'learning_rate': 1.7333333333333336e-05, 'epoch': 0.03}
  3%|▎         | 65/2496 [27:54<16:51:33, 24.97s/it]  3%|▎         | 66/2496 [28:20<17:00:26, 25.20s/it]                                                    {'loss': 0.8161, 'learning_rate': 1.76e-05, 'epoch': 0.03}
  3%|▎         | 66/2496 [28:20<17:00:26, 25.20s/it]  3%|▎         | 67/2496 [28:46<17:11:28, 25.48s/it]                                                    {'loss': 0.7888, 'learning_rate': 1.7866666666666666e-05, 'epoch': 0.03}
  3%|▎         | 67/2496 [28:46<17:11:28, 25.48s/it]  3%|▎         | 68/2496 [29:12<17:16:19, 25.61s/it]                                                    {'loss': 0.8228, 'learning_rate': 1.8133333333333335e-05, 'epoch': 0.03}
  3%|▎         | 68/2496 [29:12<17:16:19, 25.61s/it]  3%|▎         | 69/2496 [29:37<17:07:34, 25.40s/it]                                                    {'loss': 0.2535, 'learning_rate': 1.8400000000000003e-05, 'epoch': 0.03}
  3%|▎         | 69/2496 [29:37<17:07:34, 25.40s/it]WARNING: tokenization mismatch: 1 vs. 1419. (ignored)
  3%|▎         | 70/2496 [30:02<16:59:45, 25.22s/it]                                                    {'loss': 0.765, 'learning_rate': 1.866666666666667e-05, 'epoch': 0.03}
  3%|▎         | 70/2496 [30:02<16:59:45, 25.22s/it]  3%|▎         | 71/2496 [30:27<16:55:12, 25.12s/it]                                                    {'loss': 0.7753, 'learning_rate': 1.8933333333333334e-05, 'epoch': 0.03}
  3%|▎         | 71/2496 [30:27<16:55:12, 25.12s/it]this iter is wrong in something... skip...
  3%|▎         | 72/2496 [30:53<17:10:12, 25.50s/it]                                                    {'loss': 0.8046, 'learning_rate': 1.9200000000000003e-05, 'epoch': 0.03}
  3%|▎         | 72/2496 [30:53<17:10:12, 25.50s/it]  3%|▎         | 73/2496 [31:18<17:06:40, 25.42s/it]                                                    {'loss': 0.7931, 'learning_rate': 1.9466666666666668e-05, 'epoch': 0.03}
  3%|▎         | 73/2496 [31:18<17:06:40, 25.42s/it]  3%|▎         | 74/2496 [31:43<16:54:20, 25.13s/it]                                                    {'loss': 0.8178, 'learning_rate': 1.9733333333333336e-05, 'epoch': 0.03}
  3%|▎         | 74/2496 [31:43<16:54:20, 25.13s/it]  3%|▎         | 75/2496 [32:08<16:52:24, 25.09s/it]                                                    {'loss': 0.2447, 'learning_rate': 2e-05, 'epoch': 0.03}
  3%|▎         | 75/2496 [32:08<16:52:24, 25.09s/it]  3%|▎         | 76/2496 [32:34<16:58:28, 25.25s/it]                                                    {'loss': 0.7833, 'learning_rate': 1.9999991580620032e-05, 'epoch': 0.03}
  3%|▎         | 76/2496 [32:34<16:58:28, 25.25s/it]  3%|▎         | 77/2496 [32:58<16:45:11, 24.93s/it]                                                    {'loss': 0.7691, 'learning_rate': 1.999996632249429e-05, 'epoch': 0.03}
  3%|▎         | 77/2496 [32:58<16:45:11, 24.93s/it]  3%|▎         | 78/2496 [33:21<16:27:33, 24.51s/it]                                                    {'loss': 0.8232, 'learning_rate': 1.9999924225665326e-05, 'epoch': 0.03}
  3%|▎         | 78/2496 [33:21<16:27:33, 24.51s/it]  3%|▎         | 79/2496 [33:47<16:37:29, 24.76s/it]                                                    {'loss': 0.8098, 'learning_rate': 1.9999865290204007e-05, 'epoch': 0.03}
  3%|▎         | 79/2496 [33:47<16:37:29, 24.76s/it]  3%|▎         | 80/2496 [34:12<16:46:39, 25.00s/it]                                                    {'loss': 0.7723, 'learning_rate': 1.9999789516209584e-05, 'epoch': 0.03}
  3%|▎         | 80/2496 [34:12<16:46:39, 25.00s/it]  3%|▎         | 81/2496 [34:37<16:39:29, 24.83s/it]                                                    {'loss': 0.7857, 'learning_rate': 1.9999696903809647e-05, 'epoch': 0.03}
  3%|▎         | 81/2496 [34:37<16:39:29, 24.83s/it]  3%|▎         | 82/2496 [34:59<16:11:36, 24.15s/it]                                                    {'loss': 0.7998, 'learning_rate': 1.9999587453160142e-05, 'epoch': 0.03}
  3%|▎         | 82/2496 [34:59<16:11:36, 24.15s/it]  3%|▎         | 83/2496 [35:23<16:11:55, 24.17s/it]                                                    {'loss': 0.7656, 'learning_rate': 1.9999461164445376e-05, 'epoch': 0.03}
  3%|▎         | 83/2496 [35:23<16:11:55, 24.17s/it]  3%|▎         | 84/2496 [35:49<16:34:01, 24.73s/it]                                                    {'loss': 0.8112, 'learning_rate': 1.9999318037877998e-05, 'epoch': 0.03}
  3%|▎         | 84/2496 [35:49<16:34:01, 24.73s/it]  3%|▎         | 85/2496 [36:13<16:22:32, 24.45s/it]                                                    {'loss': 0.8519, 'learning_rate': 1.9999158073699017e-05, 'epoch': 0.03}
  3%|▎         | 85/2496 [36:13<16:22:32, 24.45s/it]  3%|▎         | 86/2496 [36:39<16:34:28, 24.76s/it]                                                    {'loss': 0.8217, 'learning_rate': 1.9998981272177796e-05, 'epoch': 0.03}
  3%|▎         | 86/2496 [36:39<16:34:28, 24.76s/it]  3%|▎         | 87/2496 [37:07<17:11:48, 25.70s/it]                                                    {'loss': 0.7981, 'learning_rate': 1.9998787633612046e-05, 'epoch': 0.03}
  3%|▎         | 87/2496 [37:07<17:11:48, 25.70s/it]  4%|▎         | 88/2496 [37:30<16:42:05, 24.97s/it]                                                    {'loss': 0.811, 'learning_rate': 1.999857715832782e-05, 'epoch': 0.04}
  4%|▎         | 88/2496 [37:30<16:42:05, 24.97s/it]  4%|▎         | 89/2496 [37:56<16:51:53, 25.22s/it]                                                    {'loss': 0.7612, 'learning_rate': 1.9998349846679547e-05, 'epoch': 0.04}
  4%|▎         | 89/2496 [37:56<16:51:53, 25.22s/it]  4%|▎         | 90/2496 [38:19<16:30:24, 24.70s/it]                                                    {'loss': 0.7684, 'learning_rate': 1.9998105699049984e-05, 'epoch': 0.04}
  4%|▎         | 90/2496 [38:19<16:30:24, 24.70s/it]this iter is wrong in something... skip...
  4%|▎         | 91/2496 [38:42<16:06:50, 24.12s/it]                                                    {'loss': 0.8104, 'learning_rate': 1.9997844715850248e-05, 'epoch': 0.04}
  4%|▎         | 91/2496 [38:42<16:06:50, 24.12s/it]  4%|▎         | 92/2496 [39:05<15:59:16, 23.94s/it]                                                    {'loss': 0.7936, 'learning_rate': 1.99975668975198e-05, 'epoch': 0.04}
  4%|▎         | 92/2496 [39:05<15:59:16, 23.94s/it]  4%|▎         | 93/2496 [39:29<15:59:50, 23.97s/it]                                                    {'loss': 0.7673, 'learning_rate': 1.9997272244526454e-05, 'epoch': 0.04}
  4%|▎         | 93/2496 [39:29<15:59:50, 23.97s/it]  4%|▍         | 94/2496 [39:53<15:59:15, 23.96s/it]                                                    {'loss': 0.7937, 'learning_rate': 1.999696075736637e-05, 'epoch': 0.04}
  4%|▍         | 94/2496 [39:53<15:59:15, 23.96s/it]  4%|▍         | 95/2496 [40:17<15:55:53, 23.89s/it]                                                    {'loss': 0.7765, 'learning_rate': 1.999663243656405e-05, 'epoch': 0.04}
  4%|▍         | 95/2496 [40:17<15:55:53, 23.89s/it]  4%|▍         | 96/2496 [40:44<16:29:56, 24.75s/it]                                                    {'loss': 0.7703, 'learning_rate': 1.9996287282672345e-05, 'epoch': 0.04}
  4%|▍         | 96/2496 [40:44<16:29:56, 24.75s/it]  4%|▍         | 97/2496 [41:12<17:08:04, 25.71s/it]                                                    {'loss': 0.7777, 'learning_rate': 1.9995925296272455e-05, 'epoch': 0.04}
  4%|▍         | 97/2496 [41:12<17:08:04, 25.71s/it]  4%|▍         | 98/2496 [41:37<17:05:58, 25.67s/it]                                                    {'loss': 0.7872, 'learning_rate': 1.999554647797392e-05, 'epoch': 0.04}
  4%|▍         | 98/2496 [41:37<17:05:58, 25.67s/it]this iter is wrong in something... skip...
  4%|▍         | 99/2496 [42:01<16:42:39, 25.10s/it]                                                    {'loss': 0.7982, 'learning_rate': 1.999515082841462e-05, 'epoch': 0.04}
  4%|▍         | 99/2496 [42:01<16:42:39, 25.10s/it]  4%|▍         | 100/2496 [42:26<16:39:10, 25.02s/it]                                                     {'loss': 0.7834, 'learning_rate': 1.9994738348260782e-05, 'epoch': 0.04}
  4%|▍         | 100/2496 [42:26<16:39:10, 25.02s/it]this iter is wrong in something... skip...
  4%|▍         | 101/2496 [42:52<16:46:59, 25.23s/it]                                                     {'loss': 0.7668, 'learning_rate': 1.999430903820697e-05, 'epoch': 0.04}
  4%|▍         | 101/2496 [42:52<16:46:59, 25.23s/it]this iter is wrong in something... skip...
  4%|▍         | 102/2496 [43:19<17:05:14, 25.70s/it]                                                     {'loss': 0.8047, 'learning_rate': 1.9993862898976092e-05, 'epoch': 0.04}
  4%|▍         | 102/2496 [43:19<17:05:14, 25.70s/it]  4%|▍         | 103/2496 [43:42<16:34:20, 24.93s/it]                                                     {'loss': 0.8463, 'learning_rate': 1.9993399931319385e-05, 'epoch': 0.04}
  4%|▍         | 103/2496 [43:42<16:34:20, 24.93s/it]  4%|▍         | 104/2496 [44:07<16:43:23, 25.17s/it]                                                     {'loss': 0.7412, 'learning_rate': 1.999292013601644e-05, 'epoch': 0.04}
  4%|▍         | 104/2496 [44:07<16:43:23, 25.17s/it]  4%|▍         | 105/2496 [44:32<16:31:18, 24.88s/it]                                                     {'loss': 0.7748, 'learning_rate': 1.9992423513875158e-05, 'epoch': 0.04}
  4%|▍         | 105/2496 [44:32<16:31:18, 24.88s/it]  4%|▍         | 106/2496 [44:56<16:23:18, 24.69s/it]                                                     {'loss': 0.7779, 'learning_rate': 1.9991910065731805e-05, 'epoch': 0.04}
  4%|▍         | 106/2496 [44:56<16:23:18, 24.69s/it]  4%|▍         | 107/2496 [45:20<16:20:00, 24.61s/it]                                                     {'loss': 0.7992, 'learning_rate': 1.9991379792450953e-05, 'epoch': 0.04}
  4%|▍         | 107/2496 [45:20<16:20:00, 24.61s/it]  4%|▍         | 108/2496 [45:47<16:46:07, 25.28s/it]                                                     {'loss': 0.7423, 'learning_rate': 1.9990832694925514e-05, 'epoch': 0.04}
  4%|▍         | 108/2496 [45:47<16:46:07, 25.28s/it]  4%|▍         | 109/2496 [46:13<16:52:49, 25.46s/it]                                                     {'loss': 0.8227, 'learning_rate': 1.9990268774076746e-05, 'epoch': 0.04}
  4%|▍         | 109/2496 [46:13<16:52:49, 25.46s/it]  4%|▍         | 110/2496 [46:39<16:59:16, 25.63s/it]                                                     {'loss': 0.7705, 'learning_rate': 1.9989688030854205e-05, 'epoch': 0.04}
  4%|▍         | 110/2496 [46:39<16:59:16, 25.63s/it]  4%|▍         | 111/2496 [47:07<17:29:01, 26.39s/it]                                                     {'loss': 0.7798, 'learning_rate': 1.998909046623581e-05, 'epoch': 0.04}
  4%|▍         | 111/2496 [47:07<17:29:01, 26.39s/it]  4%|▍         | 112/2496 [47:33<17:26:45, 26.34s/it]                                                     {'loss': 0.7948, 'learning_rate': 1.9988476081227767e-05, 'epoch': 0.04}
  4%|▍         | 112/2496 [47:33<17:26:45, 26.34s/it]  5%|▍         | 113/2496 [47:55<16:33:30, 25.01s/it]                                                     {'loss': 0.7791, 'learning_rate': 1.9987844876864633e-05, 'epoch': 0.05}
  5%|▍         | 113/2496 [47:55<16:33:30, 25.01s/it]  5%|▍         | 114/2496 [48:18<16:01:45, 24.23s/it]                                                     {'loss': 0.8053, 'learning_rate': 1.9987196854209278e-05, 'epoch': 0.05}
  5%|▍         | 114/2496 [48:18<16:01:45, 24.23s/it]  5%|▍         | 115/2496 [48:43<16:08:39, 24.41s/it]                                                     {'loss': 0.2356, 'learning_rate': 1.9986532014352892e-05, 'epoch': 0.05}
  5%|▍         | 115/2496 [48:43<16:08:39, 24.41s/it]  5%|▍         | 116/2496 [49:09<16:29:44, 24.95s/it]                                                     {'loss': 0.7481, 'learning_rate': 1.9985850358414983e-05, 'epoch': 0.05}
  5%|▍         | 116/2496 [49:09<16:29:44, 24.95s/it]  5%|▍         | 117/2496 [49:33<16:21:45, 24.76s/it]                                                     {'loss': 0.8025, 'learning_rate': 1.998515188754337e-05, 'epoch': 0.05}
  5%|▍         | 117/2496 [49:33<16:21:45, 24.76s/it]  5%|▍         | 118/2496 [49:57<16:14:05, 24.58s/it]                                                     {'loss': 0.819, 'learning_rate': 1.9984436602914196e-05, 'epoch': 0.05}
  5%|▍         | 118/2496 [49:57<16:14:05, 24.58s/it]  5%|▍         | 119/2496 [50:23<16:28:30, 24.95s/it]                                                     {'loss': 0.772, 'learning_rate': 1.998370450573191e-05, 'epoch': 0.05}
  5%|▍         | 119/2496 [50:23<16:28:30, 24.95s/it]  5%|▍         | 120/2496 [50:48<16:22:21, 24.81s/it]                                                     {'loss': 0.7753, 'learning_rate': 1.9982955597229275e-05, 'epoch': 0.05}
  5%|▍         | 120/2496 [50:48<16:22:21, 24.81s/it]  5%|▍         | 121/2496 [51:14<16:40:27, 25.27s/it]                                                     {'loss': 0.7968, 'learning_rate': 1.998218987866736e-05, 'epoch': 0.05}
  5%|▍         | 121/2496 [51:14<16:40:27, 25.27s/it]  5%|▍         | 122/2496 [51:37<16:19:45, 24.76s/it]                                                     {'loss': 0.7566, 'learning_rate': 1.9981407351335535e-05, 'epoch': 0.05}
  5%|▍         | 122/2496 [51:37<16:19:45, 24.76s/it]  5%|▍         | 123/2496 [52:02<16:17:41, 24.72s/it]                                                     {'loss': 0.7474, 'learning_rate': 1.998060801655149e-05, 'epoch': 0.05}
  5%|▍         | 123/2496 [52:02<16:17:41, 24.72s/it]  5%|▍         | 124/2496 [52:31<17:12:10, 26.11s/it]                                                     {'loss': 0.7496, 'learning_rate': 1.997979187566119e-05, 'epoch': 0.05}
  5%|▍         | 124/2496 [52:31<17:12:10, 26.11s/it]  5%|▌         | 125/2496 [52:59<17:31:55, 26.62s/it]                                                     {'loss': 0.7904, 'learning_rate': 1.9978958930038925e-05, 'epoch': 0.05}
  5%|▌         | 125/2496 [52:59<17:31:55, 26.62s/it]  5%|▌         | 126/2496 [53:27<17:39:41, 26.83s/it]                                                     {'loss': 0.7649, 'learning_rate': 1.9978109181087274e-05, 'epoch': 0.05}
  5%|▌         | 126/2496 [53:27<17:39:41, 26.83s/it]  5%|▌         | 127/2496 [53:53<17:37:22, 26.78s/it]                                                     {'loss': 0.7716, 'learning_rate': 1.9977242630237105e-05, 'epoch': 0.05}
  5%|▌         | 127/2496 [53:53<17:37:22, 26.78s/it]  5%|▌         | 128/2496 [54:18<17:13:23, 26.18s/it]                                                     {'loss': 0.7728, 'learning_rate': 1.997635927894758e-05, 'epoch': 0.05}
  5%|▌         | 128/2496 [54:18<17:13:23, 26.18s/it]  5%|▌         | 129/2496 [54:43<16:53:28, 25.69s/it]                                                     {'loss': 0.7843, 'learning_rate': 1.9975459128706155e-05, 'epoch': 0.05}
  5%|▌         | 129/2496 [54:43<16:53:28, 25.69s/it]  5%|▌         | 130/2496 [55:07<16:35:56, 25.26s/it]                                                     {'loss': 0.8141, 'learning_rate': 1.9974542181028574e-05, 'epoch': 0.05}
  5%|▌         | 130/2496 [55:07<16:35:56, 25.26s/it]  5%|▌         | 131/2496 [55:32<16:38:20, 25.33s/it]                                                     {'loss': 0.7355, 'learning_rate': 1.9973608437458863e-05, 'epoch': 0.05}
  5%|▌         | 131/2496 [55:32<16:38:20, 25.33s/it]  5%|▌         | 132/2496 [55:57<16:28:39, 25.09s/it]                                                     {'loss': 0.7831, 'learning_rate': 1.9972657899569324e-05, 'epoch': 0.05}
  5%|▌         | 132/2496 [55:57<16:28:39, 25.09s/it]  5%|▌         | 133/2496 [56:25<17:03:30, 25.99s/it]                                                     {'loss': 0.7841, 'learning_rate': 1.997169056896055e-05, 'epoch': 0.05}
  5%|▌         | 133/2496 [56:25<17:03:30, 25.99s/it]  5%|▌         | 134/2496 [56:50<16:56:08, 25.81s/it]                                                     {'loss': 0.7764, 'learning_rate': 1.997070644726141e-05, 'epoch': 0.05}
  5%|▌         | 134/2496 [56:50<16:56:08, 25.81s/it]  5%|▌         | 135/2496 [57:17<17:04:10, 26.03s/it]                                                     {'loss': 0.7496, 'learning_rate': 1.9969705536129033e-05, 'epoch': 0.05}
  5%|▌         | 135/2496 [57:17<17:04:10, 26.03s/it]  5%|▌         | 136/2496 [57:43<17:05:52, 26.08s/it]                                                     {'loss': 0.73, 'learning_rate': 1.9968687837248838e-05, 'epoch': 0.05}
  5%|▌         | 136/2496 [57:43<17:05:52, 26.08s/it]  5%|▌         | 137/2496 [58:07<16:41:38, 25.48s/it]                                                     {'loss': 0.7967, 'learning_rate': 1.9967653352334498e-05, 'epoch': 0.05}
  5%|▌         | 137/2496 [58:07<16:41:38, 25.48s/it]  6%|▌         | 138/2496 [58:34<17:02:16, 26.01s/it]                                                     {'loss': 0.7692, 'learning_rate': 1.996660208312796e-05, 'epoch': 0.06}
  6%|▌         | 138/2496 [58:34<17:02:16, 26.01s/it]  6%|▌         | 139/2496 [58:59<16:46:22, 25.62s/it]                                                     {'loss': 0.802, 'learning_rate': 1.9965534031399434e-05, 'epoch': 0.06}
  6%|▌         | 139/2496 [58:59<16:46:22, 25.62s/it]  6%|▌         | 140/2496 [59:25<16:52:12, 25.78s/it]                                                     {'loss': 0.772, 'learning_rate': 1.9964449198947377e-05, 'epoch': 0.06}
  6%|▌         | 140/2496 [59:25<16:52:12, 25.78s/it]  6%|▌         | 141/2496 [59:51<16:52:39, 25.80s/it]                                                     {'loss': 0.7725, 'learning_rate': 1.9963347587598524e-05, 'epoch': 0.06}
  6%|▌         | 141/2496 [59:51<16:52:39, 25.80s/it]  6%|▌         | 142/2496 [1:00:16<16:37:11, 25.42s/it]                                                       {'loss': 0.8046, 'learning_rate': 1.996222919920784e-05, 'epoch': 0.06}
  6%|▌         | 142/2496 [1:00:16<16:37:11, 25.42s/it]  6%|▌         | 143/2496 [1:00:45<17:27:23, 26.71s/it]                                                       {'loss': 0.7358, 'learning_rate': 1.9961094035658567e-05, 'epoch': 0.06}
  6%|▌         | 143/2496 [1:00:45<17:27:23, 26.71s/it]  6%|▌         | 144/2496 [1:01:10<17:00:28, 26.03s/it]                                                       {'loss': 0.7244, 'learning_rate': 1.9959942098862165e-05, 'epoch': 0.06}
  6%|▌         | 144/2496 [1:01:10<17:00:28, 26.03s/it]  6%|▌         | 145/2496 [1:01:35<16:45:51, 25.67s/it]                                                       {'loss': 0.8031, 'learning_rate': 1.9958773390758358e-05, 'epoch': 0.06}
  6%|▌         | 145/2496 [1:01:35<16:45:51, 25.67s/it]  6%|▌         | 146/2496 [1:02:00<16:39:59, 25.53s/it]                                                       {'loss': 0.7882, 'learning_rate': 1.995758791331511e-05, 'epoch': 0.06}
  6%|▌         | 146/2496 [1:02:00<16:39:59, 25.53s/it]  6%|▌         | 147/2496 [1:02:26<16:43:53, 25.64s/it]                                                       {'loss': 0.7693, 'learning_rate': 1.9956385668528614e-05, 'epoch': 0.06}
  6%|▌         | 147/2496 [1:02:26<16:43:53, 25.64s/it]  6%|▌         | 148/2496 [1:02:51<16:36:16, 25.46s/it]                                                       {'loss': 0.7685, 'learning_rate': 1.9955166658423303e-05, 'epoch': 0.06}
  6%|▌         | 148/2496 [1:02:51<16:36:16, 25.46s/it]  6%|▌         | 149/2496 [1:03:18<16:54:12, 25.93s/it]                                                       {'loss': 0.7711, 'learning_rate': 1.9953930885051832e-05, 'epoch': 0.06}
  6%|▌         | 149/2496 [1:03:18<16:54:12, 25.93s/it]  6%|▌         | 150/2496 [1:03:42<16:33:47, 25.42s/it]                                                       {'loss': 0.776, 'learning_rate': 1.9952678350495104e-05, 'epoch': 0.06}
  6%|▌         | 150/2496 [1:03:42<16:33:47, 25.42s/it]  6%|▌         | 151/2496 [1:04:05<16:05:53, 24.71s/it]                                                       {'loss': 0.7454, 'learning_rate': 1.9951409056862218e-05, 'epoch': 0.06}
  6%|▌         | 151/2496 [1:04:05<16:05:53, 24.71s/it]  6%|▌         | 152/2496 [1:04:31<16:24:38, 25.20s/it]                                                       {'loss': 0.7228, 'learning_rate': 1.995012300629051e-05, 'epoch': 0.06}
  6%|▌         | 152/2496 [1:04:31<16:24:38, 25.20s/it]  6%|▌         | 153/2496 [1:04:56<16:22:05, 25.15s/it]                                                       {'loss': 0.7608, 'learning_rate': 1.994882020094554e-05, 'epoch': 0.06}
  6%|▌         | 153/2496 [1:04:56<16:22:05, 25.15s/it]  6%|▌         | 154/2496 [1:05:23<16:35:33, 25.51s/it]                                                       {'loss': 0.7875, 'learning_rate': 1.994750064302106e-05, 'epoch': 0.06}
  6%|▌         | 154/2496 [1:05:23<16:35:33, 25.51s/it]  6%|▌         | 155/2496 [1:05:51<17:10:00, 26.40s/it]                                                       {'loss': 0.7344, 'learning_rate': 1.9946164334739042e-05, 'epoch': 0.06}
  6%|▌         | 155/2496 [1:05:51<17:10:00, 26.40s/it]  6%|▋         | 156/2496 [1:06:16<16:49:24, 25.88s/it]                                                       {'loss': 0.2555, 'learning_rate': 1.9944811278349666e-05, 'epoch': 0.06}
  6%|▋         | 156/2496 [1:06:16<16:49:24, 25.88s/it]  6%|▋         | 157/2496 [1:08:34<38:40:24, 59.52s/it]                                                       {'loss': 0.7959, 'learning_rate': 1.9943441476131316e-05, 'epoch': 0.06}
  6%|▋         | 157/2496 [1:08:34<38:40:24, 59.52s/it]  6%|▋         | 158/2496 [1:08:59<32:01:02, 49.30s/it]                                                       {'loss': 0.7829, 'learning_rate': 1.9942054930390565e-05, 'epoch': 0.06}
  6%|▋         | 158/2496 [1:08:59<32:01:02, 49.30s/it]  6%|▋         | 159/2496 [1:09:23<27:03:14, 41.67s/it]                                                       {'loss': 0.7511, 'learning_rate': 1.9940651643462178e-05, 'epoch': 0.06}
  6%|▋         | 159/2496 [1:09:23<27:03:14, 41.67s/it]  6%|▋         | 160/2496 [1:09:49<23:53:01, 36.81s/it]                                                       {'loss': 0.7451, 'learning_rate': 1.9939231617709126e-05, 'epoch': 0.06}
  6%|▋         | 160/2496 [1:09:49<23:53:01, 36.81s/it]  6%|▋         | 161/2496 [1:10:16<22:03:16, 34.00s/it]                                                       {'loss': 0.7712, 'learning_rate': 1.993779485552255e-05, 'epoch': 0.06}
  6%|▋         | 161/2496 [1:10:16<22:03:16, 34.00s/it]  6%|▋         | 162/2496 [1:10:40<20:04:29, 30.96s/it]                                                       {'loss': 0.7894, 'learning_rate': 1.993634135932178e-05, 'epoch': 0.06}
  6%|▋         | 162/2496 [1:10:40<20:04:29, 30.96s/it]  7%|▋         | 163/2496 [1:11:05<18:54:43, 29.18s/it]                                                       {'loss': 0.7741, 'learning_rate': 1.993487113155433e-05, 'epoch': 0.07}
  7%|▋         | 163/2496 [1:11:05<18:54:43, 29.18s/it]  7%|▋         | 164/2496 [1:11:34<18:49:58, 29.07s/it]                                                       {'loss': 0.7411, 'learning_rate': 1.993338417469587e-05, 'epoch': 0.07}
  7%|▋         | 164/2496 [1:11:34<18:49:58, 29.07s/it]  7%|▋         | 165/2496 [1:12:00<18:09:25, 28.04s/it]                                                       {'loss': 0.7543, 'learning_rate': 1.9931880491250263e-05, 'epoch': 0.07}
  7%|▋         | 165/2496 [1:12:00<18:09:25, 28.04s/it]this iter is wrong in something... skip...
  7%|▋         | 166/2496 [1:12:26<17:51:36, 27.59s/it]                                                       {'loss': 0.7795, 'learning_rate': 1.9930360083749517e-05, 'epoch': 0.07}
  7%|▋         | 166/2496 [1:12:26<17:51:36, 27.59s/it]  7%|▋         | 167/2496 [1:12:53<17:43:43, 27.40s/it]                                                       {'loss': 0.7743, 'learning_rate': 1.992882295475381e-05, 'epoch': 0.07}
  7%|▋         | 167/2496 [1:12:53<17:43:43, 27.40s/it]  7%|▋         | 168/2496 [1:13:21<17:46:08, 27.48s/it]                                                       {'loss': 0.7216, 'learning_rate': 1.9927269106851482e-05, 'epoch': 0.07}
  7%|▋         | 168/2496 [1:13:21<17:46:08, 27.48s/it]  7%|▋         | 169/2496 [1:13:44<16:52:02, 26.09s/it]                                                       {'loss': 0.7686, 'learning_rate': 1.9925698542659012e-05, 'epoch': 0.07}
  7%|▋         | 169/2496 [1:13:44<16:52:02, 26.09s/it]  7%|▋         | 170/2496 [1:14:07<16:25:42, 25.43s/it]                                                       {'loss': 0.7541, 'learning_rate': 1.9924111264821047e-05, 'epoch': 0.07}
  7%|▋         | 170/2496 [1:14:07<16:25:42, 25.43s/it]  7%|▋         | 171/2496 [1:14:31<16:06:25, 24.94s/it]                                                       {'loss': 0.7688, 'learning_rate': 1.9922507276010355e-05, 'epoch': 0.07}
  7%|▋         | 171/2496 [1:14:31<16:06:25, 24.94s/it]  7%|▋         | 172/2496 [1:14:55<15:49:39, 24.52s/it]                                                       {'loss': 0.7569, 'learning_rate': 1.992088657892786e-05, 'epoch': 0.07}
  7%|▋         | 172/2496 [1:14:55<15:49:39, 24.52s/it]  7%|▋         | 173/2496 [1:15:18<15:35:48, 24.17s/it]                                                       {'loss': 0.7795, 'learning_rate': 1.9919249176302615e-05, 'epoch': 0.07}
  7%|▋         | 173/2496 [1:15:18<15:35:48, 24.17s/it]  7%|▋         | 174/2496 [1:15:40<15:13:36, 23.61s/it]                                                       {'loss': 0.8057, 'learning_rate': 1.9917595070891796e-05, 'epoch': 0.07}
  7%|▋         | 174/2496 [1:15:40<15:13:36, 23.61s/it]  7%|▋         | 175/2496 [1:16:05<15:23:02, 23.86s/it]                                                       {'loss': 0.7842, 'learning_rate': 1.991592426548072e-05, 'epoch': 0.07}
  7%|▋         | 175/2496 [1:16:05<15:23:02, 23.86s/it]  7%|▋         | 176/2496 [1:16:29<15:27:53, 24.00s/it]                                                       {'loss': 0.76, 'learning_rate': 1.9914236762882818e-05, 'epoch': 0.07}
  7%|▋         | 176/2496 [1:16:29<15:27:53, 24.00s/it]  7%|▋         | 177/2496 [1:16:53<15:27:11, 23.99s/it]                                                       {'loss': 0.7795, 'learning_rate': 1.9912532565939623e-05, 'epoch': 0.07}
  7%|▋         | 177/2496 [1:16:53<15:27:11, 23.99s/it]  7%|▋         | 178/2496 [1:17:18<15:30:51, 24.09s/it]                                                       {'loss': 0.8005, 'learning_rate': 1.9910811677520803e-05, 'epoch': 0.07}
  7%|▋         | 178/2496 [1:17:18<15:30:51, 24.09s/it]  7%|▋         | 179/2496 [1:17:41<15:26:46, 24.00s/it]                                                       {'loss': 0.7514, 'learning_rate': 1.9909074100524113e-05, 'epoch': 0.07}
  7%|▋         | 179/2496 [1:17:41<15:26:46, 24.00s/it]  7%|▋         | 180/2496 [1:18:10<16:17:50, 25.33s/it]                                                       {'loss': 0.7919, 'learning_rate': 1.990731983787542e-05, 'epoch': 0.07}
  7%|▋         | 180/2496 [1:18:10<16:17:50, 25.33s/it]  7%|▋         | 181/2496 [1:18:34<16:04:03, 24.99s/it]                                                       {'loss': 0.8029, 'learning_rate': 1.990554889252869e-05, 'epoch': 0.07}
  7%|▋         | 181/2496 [1:18:34<16:04:03, 24.99s/it]  7%|▋         | 182/2496 [1:19:00<16:18:54, 25.38s/it]                                                       {'loss': 0.7964, 'learning_rate': 1.9903761267465965e-05, 'epoch': 0.07}
  7%|▋         | 182/2496 [1:19:00<16:18:54, 25.38s/it]  7%|▋         | 183/2496 [1:19:26<16:23:28, 25.51s/it]                                                       {'loss': 0.7913, 'learning_rate': 1.9901956965697387e-05, 'epoch': 0.07}
  7%|▋         | 183/2496 [1:19:26<16:23:28, 25.51s/it]  7%|▋         | 184/2496 [1:19:52<16:27:42, 25.63s/it]                                                       {'loss': 0.7752, 'learning_rate': 1.9900135990261186e-05, 'epoch': 0.07}
  7%|▋         | 184/2496 [1:19:52<16:27:42, 25.63s/it]  7%|▋         | 185/2496 [1:20:17<16:17:22, 25.38s/it]                                                       {'loss': 0.7922, 'learning_rate': 1.989829834422365e-05, 'epoch': 0.07}
  7%|▋         | 185/2496 [1:20:17<16:17:22, 25.38s/it]  7%|▋         | 186/2496 [1:20:41<16:05:31, 25.08s/it]                                                       {'loss': 0.7429, 'learning_rate': 1.9896444030679146e-05, 'epoch': 0.07}
  7%|▋         | 186/2496 [1:20:41<16:05:31, 25.08s/it]  7%|▋         | 187/2496 [1:21:04<15:44:18, 24.54s/it]                                                       {'loss': 0.7605, 'learning_rate': 1.9894573052750112e-05, 'epoch': 0.07}
  7%|▋         | 187/2496 [1:21:04<15:44:18, 24.54s/it]  8%|▊         | 188/2496 [1:21:29<15:45:04, 24.57s/it]                                                       {'loss': 0.7552, 'learning_rate': 1.9892685413587044e-05, 'epoch': 0.08}
  8%|▊         | 188/2496 [1:21:29<15:45:04, 24.57s/it]  8%|▊         | 189/2496 [1:21:55<16:02:17, 25.03s/it]                                                       {'loss': 0.7476, 'learning_rate': 1.9890781116368484e-05, 'epoch': 0.08}
  8%|▊         | 189/2496 [1:21:55<16:02:17, 25.03s/it]  8%|▊         | 190/2496 [1:22:19<15:43:28, 24.55s/it]                                                       {'loss': 0.779, 'learning_rate': 1.9888860164301043e-05, 'epoch': 0.08}
  8%|▊         | 190/2496 [1:22:19<15:43:28, 24.55s/it]this iter is wrong in something... skip...
  8%|▊         | 191/2496 [1:22:44<15:50:47, 24.75s/it]                                                       {'loss': 0.7468, 'learning_rate': 1.9886922560619362e-05, 'epoch': 0.08}
  8%|▊         | 191/2496 [1:22:44<15:50:47, 24.75s/it]  8%|▊         | 192/2496 [1:23:09<15:54:29, 24.86s/it]                                                       {'loss': 0.7579, 'learning_rate': 1.988496830858612e-05, 'epoch': 0.08}
  8%|▊         | 192/2496 [1:23:09<15:54:29, 24.86s/it]this iter is wrong in something... skip...
  8%|▊         | 193/2496 [1:23:36<16:21:00, 25.56s/it]                                                       {'loss': 0.7787, 'learning_rate': 1.9882997411492046e-05, 'epoch': 0.08}
  8%|▊         | 193/2496 [1:23:36<16:21:00, 25.56s/it]  8%|▊         | 194/2496 [1:24:01<16:16:04, 25.44s/it]                                                       {'loss': 0.7365, 'learning_rate': 1.9881009872655873e-05, 'epoch': 0.08}
  8%|▊         | 194/2496 [1:24:01<16:16:04, 25.44s/it]  8%|▊         | 195/2496 [1:24:27<16:17:54, 25.50s/it]                                                       {'loss': 0.773, 'learning_rate': 1.987900569542438e-05, 'epoch': 0.08}
  8%|▊         | 195/2496 [1:24:27<16:17:54, 25.50s/it]  8%|▊         | 196/2496 [1:24:53<16:24:42, 25.69s/it]                                                       {'loss': 0.7686, 'learning_rate': 1.9876984883172352e-05, 'epoch': 0.08}
  8%|▊         | 196/2496 [1:24:53<16:24:42, 25.69s/it]this iter is wrong in something... skip...
  8%|▊         | 197/2496 [1:25:18<16:20:09, 25.58s/it]                                                       {'loss': 0.7506, 'learning_rate': 1.987494743930258e-05, 'epoch': 0.08}
  8%|▊         | 197/2496 [1:25:18<16:20:09, 25.58s/it]  8%|▊         | 198/2496 [1:25:44<16:20:25, 25.60s/it]                                                       {'loss': 0.7729, 'learning_rate': 1.9872893367245874e-05, 'epoch': 0.08}
  8%|▊         | 198/2496 [1:25:44<16:20:25, 25.60s/it]  8%|▊         | 199/2496 [1:26:07<15:49:48, 24.81s/it]                                                       {'loss': 0.7297, 'learning_rate': 1.987082267046103e-05, 'epoch': 0.08}
  8%|▊         | 199/2496 [1:26:07<15:49:48, 24.81s/it]  8%|▊         | 200/2496 [1:26:33<16:05:51, 25.24s/it]                                                       {'loss': 0.7509, 'learning_rate': 1.9868735352434855e-05, 'epoch': 0.08}
  8%|▊         | 200/2496 [1:26:33<16:05:51, 25.24s/it]  8%|▊         | 201/2496 [1:26:59<16:08:19, 25.32s/it]                                                       {'loss': 0.7302, 'learning_rate': 1.986663141668212e-05, 'epoch': 0.08}
  8%|▊         | 201/2496 [1:26:59<16:08:19, 25.32s/it]  8%|▊         | 202/2496 [1:27:24<16:07:38, 25.31s/it]                                                       {'loss': 0.7823, 'learning_rate': 1.9864510866745603e-05, 'epoch': 0.08}
  8%|▊         | 202/2496 [1:27:24<16:07:38, 25.31s/it]  8%|▊         | 203/2496 [1:27:50<16:18:53, 25.61s/it]                                                       {'loss': 0.7635, 'learning_rate': 1.986237370619604e-05, 'epoch': 0.08}
  8%|▊         | 203/2496 [1:27:50<16:18:53, 25.61s/it]  8%|▊         | 204/2496 [1:28:24<17:51:51, 28.06s/it]                                                       {'loss': 0.7878, 'learning_rate': 1.986021993863215e-05, 'epoch': 0.08}
  8%|▊         | 204/2496 [1:28:24<17:51:51, 28.06s/it]  8%|▊         | 205/2496 [1:28:52<17:30:26, 27.51s/it]                                                       {'loss': 0.7101, 'learning_rate': 1.9858049567680603e-05, 'epoch': 0.08}
  8%|▊         | 205/2496 [1:28:52<17:30:26, 27.51s/it]  8%|▊         | 206/2496 [1:29:16<17:10:34, 27.00s/it]                                                       {'loss': 0.7457, 'learning_rate': 1.9855862596996045e-05, 'epoch': 0.08}
  8%|▊         | 206/2496 [1:29:16<17:10:34, 27.00s/it]  8%|▊         | 207/2496 [1:29:40<16:32:31, 26.02s/it]                                                       {'loss': 0.7384, 'learning_rate': 1.9853659030261056e-05, 'epoch': 0.08}
  8%|▊         | 207/2496 [1:29:40<16:32:31, 26.02s/it]  8%|▊         | 208/2496 [1:30:03<16:04:36, 25.30s/it]                                                       {'loss': 0.7934, 'learning_rate': 1.9851438871186168e-05, 'epoch': 0.08}
  8%|▊         | 208/2496 [1:30:03<16:04:36, 25.30s/it]  8%|▊         | 209/2496 [1:30:27<15:46:46, 24.84s/it]                                                       {'loss': 0.7191, 'learning_rate': 1.984920212350986e-05, 'epoch': 0.08}
  8%|▊         | 209/2496 [1:30:27<15:46:46, 24.84s/it]  8%|▊         | 210/2496 [1:30:53<15:54:08, 25.04s/it]                                                       {'loss': 0.756, 'learning_rate': 1.9846948790998532e-05, 'epoch': 0.08}
  8%|▊         | 210/2496 [1:30:53<15:54:08, 25.04s/it]  8%|▊         | 211/2496 [1:31:18<16:01:25, 25.25s/it]                                                       {'loss': 0.7399, 'learning_rate': 1.9844678877446522e-05, 'epoch': 0.08}
  8%|▊         | 211/2496 [1:31:18<16:01:25, 25.25s/it]  8%|▊         | 212/2496 [1:31:43<15:52:51, 25.03s/it]                                                       {'loss': 0.7819, 'learning_rate': 1.9842392386676076e-05, 'epoch': 0.08}
  8%|▊         | 212/2496 [1:31:43<15:52:51, 25.03s/it]  9%|▊         | 213/2496 [1:32:07<15:40:14, 24.71s/it]                                                       {'loss': 0.7908, 'learning_rate': 1.9840089322537363e-05, 'epoch': 0.09}
  9%|▊         | 213/2496 [1:32:07<15:40:14, 24.71s/it]  9%|▊         | 214/2496 [1:32:35<16:17:55, 25.71s/it]                                                       {'loss': 0.7662, 'learning_rate': 1.983776968890846e-05, 'epoch': 0.09}
  9%|▊         | 214/2496 [1:32:35<16:17:55, 25.71s/it]  9%|▊         | 215/2496 [1:32:58<15:43:20, 24.81s/it]                                                       {'loss': 0.7585, 'learning_rate': 1.9835433489695348e-05, 'epoch': 0.09}
  9%|▊         | 215/2496 [1:32:58<15:43:20, 24.81s/it]  9%|▊         | 216/2496 [1:33:22<15:37:58, 24.68s/it]                                                       {'loss': 0.7668, 'learning_rate': 1.983308072883188e-05, 'epoch': 0.09}
  9%|▊         | 216/2496 [1:33:22<15:37:58, 24.68s/it]  9%|▊         | 217/2496 [1:33:47<15:42:33, 24.82s/it]                                                       {'loss': 0.2942, 'learning_rate': 1.9830711410279832e-05, 'epoch': 0.09}
  9%|▊         | 217/2496 [1:33:47<15:42:33, 24.82s/it]this iter is wrong in something... skip...
  9%|▊         | 218/2496 [1:34:13<15:57:27, 25.22s/it]                                                       {'loss': 0.8026, 'learning_rate': 1.982832553802883e-05, 'epoch': 0.09}
  9%|▊         | 218/2496 [1:34:13<15:57:27, 25.22s/it]  9%|▉         | 219/2496 [1:34:37<15:37:39, 24.71s/it]                                                       {'loss': 0.7412, 'learning_rate': 1.982592311609639e-05, 'epoch': 0.09}
  9%|▉         | 219/2496 [1:34:37<15:37:39, 24.71s/it]  9%|▉         | 220/2496 [1:35:00<15:18:22, 24.21s/it]                                                       {'loss': 0.7479, 'learning_rate': 1.9823504148527897e-05, 'epoch': 0.09}
  9%|▉         | 220/2496 [1:35:00<15:18:22, 24.21s/it]  9%|▉         | 221/2496 [1:35:27<15:53:02, 25.14s/it]                                                       {'loss': 0.761, 'learning_rate': 1.9821068639396588e-05, 'epoch': 0.09}
  9%|▉         | 221/2496 [1:35:27<15:53:02, 25.14s/it]  9%|▉         | 222/2496 [1:35:52<15:53:06, 25.15s/it]                                                       {'loss': 0.7705, 'learning_rate': 1.981861659280356e-05, 'epoch': 0.09}
  9%|▉         | 222/2496 [1:35:52<15:53:06, 25.15s/it]  9%|▉         | 223/2496 [1:36:18<15:57:28, 25.27s/it]                                                       {'loss': 0.7452, 'learning_rate': 1.9816148012877753e-05, 'epoch': 0.09}
  9%|▉         | 223/2496 [1:36:18<15:57:28, 25.27s/it]  9%|▉         | 224/2496 [1:36:42<15:46:22, 24.99s/it]                                                       {'loss': 0.7699, 'learning_rate': 1.9813662903775955e-05, 'epoch': 0.09}
  9%|▉         | 224/2496 [1:36:42<15:46:22, 24.99s/it]  9%|▉         | 225/2496 [1:37:08<15:57:22, 25.29s/it]                                                       {'loss': 0.7451, 'learning_rate': 1.9811161269682776e-05, 'epoch': 0.09}
  9%|▉         | 225/2496 [1:37:08<15:57:22, 25.29s/it]  9%|▉         | 226/2496 [1:37:32<15:42:23, 24.91s/it]                                                       {'loss': 0.7489, 'learning_rate': 1.980864311481066e-05, 'epoch': 0.09}
  9%|▉         | 226/2496 [1:37:32<15:42:23, 24.91s/it]  9%|▉         | 227/2496 [1:37:57<15:40:59, 24.88s/it]                                                       {'loss': 0.778, 'learning_rate': 1.980610844339987e-05, 'epoch': 0.09}
  9%|▉         | 227/2496 [1:37:57<15:40:59, 24.88s/it]  9%|▉         | 228/2496 [1:38:23<15:51:40, 25.18s/it]                                                       {'loss': 0.7513, 'learning_rate': 1.9803557259718472e-05, 'epoch': 0.09}
  9%|▉         | 228/2496 [1:38:23<15:51:40, 25.18s/it]  9%|▉         | 229/2496 [1:38:48<15:44:53, 25.01s/it]                                                       {'loss': 0.7653, 'learning_rate': 1.9800989568062347e-05, 'epoch': 0.09}
  9%|▉         | 229/2496 [1:38:48<15:44:53, 25.01s/it]  9%|▉         | 230/2496 [1:39:15<16:09:05, 25.66s/it]                                                       {'loss': 0.7492, 'learning_rate': 1.979840537275517e-05, 'epoch': 0.09}
  9%|▉         | 230/2496 [1:39:15<16:09:05, 25.66s/it]  9%|▉         | 231/2496 [1:39:42<16:22:00, 26.01s/it]                                                       {'loss': 0.7673, 'learning_rate': 1.9795804678148403e-05, 'epoch': 0.09}
  9%|▉         | 231/2496 [1:39:42<16:22:00, 26.01s/it]  9%|▉         | 232/2496 [1:40:07<16:10:16, 25.71s/it]                                                       {'loss': 0.7638, 'learning_rate': 1.9793187488621296e-05, 'epoch': 0.09}
  9%|▉         | 232/2496 [1:40:07<16:10:16, 25.71s/it]  9%|▉         | 233/2496 [1:40:32<16:00:50, 25.48s/it]                                                       {'loss': 0.7484, 'learning_rate': 1.9790553808580868e-05, 'epoch': 0.09}
  9%|▉         | 233/2496 [1:40:32<16:00:50, 25.48s/it]  9%|▉         | 234/2496 [1:40:56<15:51:30, 25.24s/it]                                                       {'loss': 0.7652, 'learning_rate': 1.9787903642461913e-05, 'epoch': 0.09}
  9%|▉         | 234/2496 [1:40:56<15:51:30, 25.24s/it]  9%|▉         | 235/2496 [1:41:20<15:38:32, 24.91s/it]                                                       {'loss': 0.7643, 'learning_rate': 1.9785236994726982e-05, 'epoch': 0.09}
  9%|▉         | 235/2496 [1:41:20<15:38:32, 24.91s/it]  9%|▉         | 236/2496 [1:41:45<15:35:40, 24.84s/it]                                                       {'loss': 0.7767, 'learning_rate': 1.9782553869866378e-05, 'epoch': 0.09}
  9%|▉         | 236/2496 [1:41:45<15:35:40, 24.84s/it]  9%|▉         | 237/2496 [1:42:12<15:55:19, 25.37s/it]                                                       {'loss': 0.7346, 'learning_rate': 1.977985427239815e-05, 'epoch': 0.09}
  9%|▉         | 237/2496 [1:42:12<15:55:19, 25.37s/it] 10%|▉         | 238/2496 [1:42:36<15:46:20, 25.15s/it]                                                       {'loss': 0.7119, 'learning_rate': 1.9777138206868087e-05, 'epoch': 0.1}
 10%|▉         | 238/2496 [1:42:36<15:46:20, 25.15s/it] 10%|▉         | 239/2496 [1:43:02<15:50:15, 25.26s/it]                                                       {'loss': 0.7538, 'learning_rate': 1.97744056778497e-05, 'epoch': 0.1}
 10%|▉         | 239/2496 [1:43:02<15:50:15, 25.26s/it] 10%|▉         | 240/2496 [1:43:25<15:21:27, 24.51s/it]                                                       {'loss': 0.7712, 'learning_rate': 1.9771656689944238e-05, 'epoch': 0.1}
 10%|▉         | 240/2496 [1:43:25<15:21:27, 24.51s/it] 10%|▉         | 241/2496 [1:43:49<15:24:36, 24.60s/it]                                                       {'loss': 0.7589, 'learning_rate': 1.9768891247780653e-05, 'epoch': 0.1}
 10%|▉         | 241/2496 [1:43:49<15:24:36, 24.60s/it] 10%|▉         | 242/2496 [1:44:16<15:42:48, 25.10s/it]                                                       {'loss': 0.7391, 'learning_rate': 1.9766109356015607e-05, 'epoch': 0.1}
 10%|▉         | 242/2496 [1:44:16<15:42:48, 25.10s/it] 10%|▉         | 243/2496 [1:44:44<16:18:45, 26.07s/it]                                                       {'loss': 0.7594, 'learning_rate': 1.9763311019333457e-05, 'epoch': 0.1}
 10%|▉         | 243/2496 [1:44:44<16:18:45, 26.07s/it] 10%|▉         | 244/2496 [1:45:10<16:19:22, 26.09s/it]                                                       {'loss': 0.7481, 'learning_rate': 1.9760496242446258e-05, 'epoch': 0.1}
 10%|▉         | 244/2496 [1:45:10<16:19:22, 26.09s/it] 10%|▉         | 245/2496 [1:45:35<16:06:16, 25.76s/it]                                                       {'loss': 0.7933, 'learning_rate': 1.9757665030093746e-05, 'epoch': 0.1}
 10%|▉         | 245/2496 [1:45:35<16:06:16, 25.76s/it] 10%|▉         | 246/2496 [1:46:01<16:06:34, 25.78s/it]                                                       {'loss': 0.7631, 'learning_rate': 1.975481738704333e-05, 'epoch': 0.1}
 10%|▉         | 246/2496 [1:46:01<16:06:34, 25.78s/it] 10%|▉         | 247/2496 [1:46:25<15:45:16, 25.22s/it]                                                       {'loss': 0.7722, 'learning_rate': 1.9751953318090086e-05, 'epoch': 0.1}
 10%|▉         | 247/2496 [1:46:25<15:45:16, 25.22s/it] 10%|▉         | 248/2496 [1:46:48<15:25:32, 24.70s/it]                                                       {'loss': 0.8125, 'learning_rate': 1.9749072828056753e-05, 'epoch': 0.1}
 10%|▉         | 248/2496 [1:46:48<15:25:32, 24.70s/it] 10%|▉         | 249/2496 [1:47:14<15:40:17, 25.11s/it]                                                       {'loss': 0.778, 'learning_rate': 1.974617592179372e-05, 'epoch': 0.1}
 10%|▉         | 249/2496 [1:47:14<15:40:17, 25.11s/it] 10%|█         | 250/2496 [1:47:39<15:34:00, 24.95s/it]                                                       {'loss': 0.3284, 'learning_rate': 1.974326260417902e-05, 'epoch': 0.1}
 10%|█         | 250/2496 [1:47:39<15:34:00, 24.95s/it] 10%|█         | 251/2496 [1:48:07<16:02:51, 25.73s/it]                                                       {'loss': 0.747, 'learning_rate': 1.9740332880118314e-05, 'epoch': 0.1}
 10%|█         | 251/2496 [1:48:07<16:02:51, 25.73s/it] 10%|█         | 252/2496 [1:48:34<16:22:17, 26.26s/it]                                                       {'loss': 0.7653, 'learning_rate': 1.9737386754544895e-05, 'epoch': 0.1}
 10%|█         | 252/2496 [1:48:34<16:22:17, 26.26s/it] 10%|█         | 253/2496 [1:48:59<16:01:35, 25.72s/it]                                                       {'loss': 0.7547, 'learning_rate': 1.9734424232419672e-05, 'epoch': 0.1}
 10%|█         | 253/2496 [1:48:59<16:01:35, 25.72s/it] 10%|█         | 254/2496 [1:49:25<16:12:07, 26.02s/it]                                                       {'loss': 0.7311, 'learning_rate': 1.973144531873117e-05, 'epoch': 0.1}
 10%|█         | 254/2496 [1:49:25<16:12:07, 26.02s/it] 10%|█         | 255/2496 [1:49:49<15:47:37, 25.37s/it]                                                       {'loss': 0.7905, 'learning_rate': 1.9728450018495506e-05, 'epoch': 0.1}
 10%|█         | 255/2496 [1:49:49<15:47:37, 25.37s/it] 10%|█         | 256/2496 [1:50:15<15:57:32, 25.65s/it]                                                       {'loss': 0.7095, 'learning_rate': 1.9725438336756393e-05, 'epoch': 0.1}
 10%|█         | 256/2496 [1:50:15<15:57:32, 25.65s/it] 10%|█         | 257/2496 [1:50:41<16:00:39, 25.74s/it]                                                       {'loss': 0.7328, 'learning_rate': 1.9722410278585135e-05, 'epoch': 0.1}
 10%|█         | 257/2496 [1:50:41<16:00:39, 25.74s/it] 10%|█         | 258/2496 [1:51:09<16:24:06, 26.38s/it]                                                       {'loss': 0.7917, 'learning_rate': 1.97193658490806e-05, 'epoch': 0.1}
 10%|█         | 258/2496 [1:51:09<16:24:06, 26.38s/it]this iter is wrong in something... skip...
 10%|█         | 259/2496 [1:51:35<16:22:01, 26.34s/it]                                                       {'loss': 0.7649, 'learning_rate': 1.9716305053369232e-05, 'epoch': 0.1}
 10%|█         | 259/2496 [1:51:35<16:22:01, 26.34s/it] 10%|█         | 260/2496 [1:52:02<16:24:51, 26.43s/it]                                                       {'loss': 0.7397, 'learning_rate': 1.9713227896605036e-05, 'epoch': 0.1}
 10%|█         | 260/2496 [1:52:02<16:24:51, 26.43s/it] 10%|█         | 261/2496 [1:52:29<16:34:05, 26.69s/it]                                                       {'loss': 0.7636, 'learning_rate': 1.9710134383969555e-05, 'epoch': 0.1}
 10%|█         | 261/2496 [1:52:29<16:34:05, 26.69s/it] 10%|█         | 262/2496 [1:52:53<16:04:49, 25.91s/it]                                                       {'loss': 0.7849, 'learning_rate': 1.9707024520671886e-05, 'epoch': 0.1}
 10%|█         | 262/2496 [1:52:53<16:04:49, 25.91s/it] 11%|█         | 263/2496 [1:53:19<15:57:08, 25.72s/it]                                                       {'loss': 0.7661, 'learning_rate': 1.970389831194865e-05, 'epoch': 0.11}
 11%|█         | 263/2496 [1:53:19<15:57:08, 25.72s/it] 11%|█         | 264/2496 [1:53:51<17:06:20, 27.59s/it]                                                       {'loss': 0.7662, 'learning_rate': 1.9700755763064e-05, 'epoch': 0.11}
 11%|█         | 264/2496 [1:53:51<17:06:20, 27.59s/it] 11%|█         | 265/2496 [1:54:15<16:31:57, 26.68s/it]                                                       {'loss': 0.7626, 'learning_rate': 1.9697596879309593e-05, 'epoch': 0.11}
 11%|█         | 265/2496 [1:54:15<16:31:57, 26.68s/it] 11%|█         | 266/2496 [1:54:44<16:51:33, 27.22s/it]                                                       {'loss': 0.77, 'learning_rate': 1.9694421666004598e-05, 'epoch': 0.11}
 11%|█         | 266/2496 [1:54:44<16:51:33, 27.22s/it] 11%|█         | 267/2496 [1:55:09<16:26:54, 26.57s/it]                                                       {'loss': 0.7318, 'learning_rate': 1.9691230128495685e-05, 'epoch': 0.11}
 11%|█         | 267/2496 [1:55:09<16:26:54, 26.57s/it] 11%|█         | 268/2496 [1:55:34<16:08:06, 26.07s/it]                                                       {'loss': 0.7567, 'learning_rate': 1.9688022272157e-05, 'epoch': 0.11}
 11%|█         | 268/2496 [1:55:34<16:08:06, 26.07s/it]this iter is wrong in something... skip...
 11%|█         | 269/2496 [1:55:59<15:54:51, 25.73s/it]                                                       {'loss': 0.7427, 'learning_rate': 1.9684798102390182e-05, 'epoch': 0.11}
 11%|█         | 269/2496 [1:55:59<15:54:51, 25.73s/it] 11%|█         | 270/2496 [1:56:25<16:03:49, 25.98s/it]                                                       {'loss': 0.768, 'learning_rate': 1.968155762462433e-05, 'epoch': 0.11}
 11%|█         | 270/2496 [1:56:25<16:03:49, 25.98s/it] 11%|█         | 271/2496 [1:56:50<15:50:22, 25.63s/it]                                                       {'loss': 0.7712, 'learning_rate': 1.967830084431601e-05, 'epoch': 0.11}
 11%|█         | 271/2496 [1:56:50<15:50:22, 25.63s/it] 11%|█         | 272/2496 [1:57:15<15:37:55, 25.30s/it]                                                       {'loss': 0.7431, 'learning_rate': 1.967502776694923e-05, 'epoch': 0.11}
 11%|█         | 272/2496 [1:57:15<15:37:55, 25.30s/it] 11%|█         | 273/2496 [1:57:38<15:21:21, 24.87s/it]                                                       {'loss': 0.748, 'learning_rate': 1.967173839803545e-05, 'epoch': 0.11}
 11%|█         | 273/2496 [1:57:38<15:21:21, 24.87s/it] 11%|█         | 274/2496 [1:58:04<15:24:55, 24.98s/it]                                                       {'loss': 0.7531, 'learning_rate': 1.9668432743113562e-05, 'epoch': 0.11}
 11%|█         | 274/2496 [1:58:04<15:24:55, 24.98s/it] 11%|█         | 275/2496 [1:58:28<15:15:54, 24.74s/it]                                                       {'loss': 0.7605, 'learning_rate': 1.9665110807749873e-05, 'epoch': 0.11}
 11%|█         | 275/2496 [1:58:28<15:15:54, 24.74s/it] 11%|█         | 276/2496 [1:58:52<15:07:05, 24.52s/it]                                                       {'loss': 0.7628, 'learning_rate': 1.9661772597538114e-05, 'epoch': 0.11}
 11%|█         | 276/2496 [1:58:52<15:07:05, 24.52s/it] 11%|█         | 277/2496 [1:59:18<15:30:19, 25.16s/it]                                                       {'loss': 0.7287, 'learning_rate': 1.965841811809942e-05, 'epoch': 0.11}
 11%|█         | 277/2496 [1:59:18<15:30:19, 25.16s/it] 11%|█         | 278/2496 [1:59:42<15:09:48, 24.61s/it]                                                       {'loss': 0.7119, 'learning_rate': 1.9655047375082312e-05, 'epoch': 0.11}
 11%|█         | 278/2496 [1:59:42<15:09:48, 24.61s/it] 11%|█         | 279/2496 [2:00:08<15:31:45, 25.22s/it]                                                       {'loss': 0.7557, 'learning_rate': 1.9651660374162707e-05, 'epoch': 0.11}
 11%|█         | 279/2496 [2:00:08<15:31:45, 25.22s/it] 11%|█         | 280/2496 [2:00:35<15:48:39, 25.69s/it]                                                       {'loss': 0.7378, 'learning_rate': 1.9648257121043897e-05, 'epoch': 0.11}
 11%|█         | 280/2496 [2:00:35<15:48:39, 25.69s/it] 11%|█▏        | 281/2496 [2:01:00<15:39:56, 25.46s/it]                                                       {'loss': 0.2757, 'learning_rate': 1.964483762145653e-05, 'epoch': 0.11}
 11%|█▏        | 281/2496 [2:01:00<15:39:56, 25.46s/it] 11%|█▏        | 282/2496 [2:01:27<15:53:54, 25.85s/it]                                                       {'loss': 0.7186, 'learning_rate': 1.9641401881158625e-05, 'epoch': 0.11}
 11%|█▏        | 282/2496 [2:01:27<15:53:54, 25.85s/it] 11%|█▏        | 283/2496 [2:01:51<15:37:50, 25.43s/it]                                                       {'loss': 0.7668, 'learning_rate': 1.9637949905935545e-05, 'epoch': 0.11}
 11%|█▏        | 283/2496 [2:01:51<15:37:50, 25.43s/it] 11%|█▏        | 284/2496 [2:02:16<15:27:22, 25.15s/it]                                                       {'loss': 0.7507, 'learning_rate': 1.963448170159998e-05, 'epoch': 0.11}
 11%|█▏        | 284/2496 [2:02:16<15:27:22, 25.15s/it]this iter is wrong in something... skip...
 11%|█▏        | 285/2496 [2:02:40<15:18:39, 24.93s/it]                                                       {'loss': 0.7476, 'learning_rate': 1.9630997273991964e-05, 'epoch': 0.11}
 11%|█▏        | 285/2496 [2:02:40<15:18:39, 24.93s/it] 11%|█▏        | 286/2496 [2:03:05<15:21:15, 25.01s/it]                                                       {'loss': 0.7585, 'learning_rate': 1.962749662897884e-05, 'epoch': 0.11}
 11%|█▏        | 286/2496 [2:03:05<15:21:15, 25.01s/it]this iter is wrong in something... skip...
 11%|█▏        | 287/2496 [2:03:36<16:27:06, 26.81s/it]                                                       {'loss': 0.7634, 'learning_rate': 1.9623979772455253e-05, 'epoch': 0.11}
 11%|█▏        | 287/2496 [2:03:36<16:27:06, 26.81s/it] 12%|█▏        | 288/2496 [2:04:00<15:52:55, 25.89s/it]                                                       {'loss': 0.7464, 'learning_rate': 1.9620446710343163e-05, 'epoch': 0.12}
 12%|█▏        | 288/2496 [2:04:00<15:52:55, 25.89s/it] 12%|█▏        | 289/2496 [2:04:26<15:52:06, 25.88s/it]                                                       {'loss': 0.8004, 'learning_rate': 1.9616897448591804e-05, 'epoch': 0.12}
 12%|█▏        | 289/2496 [2:04:26<15:52:06, 25.88s/it] 12%|█▏        | 290/2496 [2:04:50<15:27:05, 25.22s/it]                                                       {'loss': 0.7892, 'learning_rate': 1.961333199317769e-05, 'epoch': 0.12}
 12%|█▏        | 290/2496 [2:04:50<15:27:05, 25.22s/it]this iter is wrong in something... skip...
 12%|█▏        | 291/2496 [2:05:16<15:37:34, 25.51s/it]                                                       {'loss': 0.7741, 'learning_rate': 1.960975035010461e-05, 'epoch': 0.12}
 12%|█▏        | 291/2496 [2:05:16<15:37:34, 25.51s/it] 12%|█▏        | 292/2496 [2:05:41<15:27:18, 25.24s/it]                                                       {'loss': 0.7744, 'learning_rate': 1.9606152525403604e-05, 'epoch': 0.12}
 12%|█▏        | 292/2496 [2:05:41<15:27:18, 25.24s/it] 12%|█▏        | 293/2496 [2:06:07<15:45:12, 25.74s/it]                                                       {'loss': 0.7334, 'learning_rate': 1.9602538525132965e-05, 'epoch': 0.12}
 12%|█▏        | 293/2496 [2:06:07<15:45:12, 25.74s/it] 12%|█▏        | 294/2496 [2:06:35<16:00:03, 26.16s/it]                                                       {'loss': 0.7132, 'learning_rate': 1.9598908355378218e-05, 'epoch': 0.12}
 12%|█▏        | 294/2496 [2:06:35<16:00:03, 26.16s/it] 12%|█▏        | 295/2496 [2:07:03<16:26:44, 26.90s/it]                                                       {'loss': 0.732, 'learning_rate': 1.9595262022252123e-05, 'epoch': 0.12}
 12%|█▏        | 295/2496 [2:07:03<16:26:44, 26.90s/it] 12%|█▏        | 296/2496 [2:07:27<15:50:40, 25.93s/it]                                                       {'loss': 0.7875, 'learning_rate': 1.959159953189465e-05, 'epoch': 0.12}
 12%|█▏        | 296/2496 [2:07:27<15:50:40, 25.93s/it] 12%|█▏        | 297/2496 [2:07:53<15:55:09, 26.06s/it]                                                       {'loss': 0.7273, 'learning_rate': 1.958792089047298e-05, 'epoch': 0.12}
 12%|█▏        | 297/2496 [2:07:53<15:55:09, 26.06s/it] 12%|█▏        | 298/2496 [2:08:18<15:36:39, 25.57s/it]                                                       {'loss': 0.7639, 'learning_rate': 1.9584226104181484e-05, 'epoch': 0.12}
 12%|█▏        | 298/2496 [2:08:18<15:36:39, 25.57s/it] 12%|█▏        | 299/2496 [2:08:44<15:48:44, 25.91s/it]                                                       {'loss': 0.7437, 'learning_rate': 1.9580515179241734e-05, 'epoch': 0.12}
 12%|█▏        | 299/2496 [2:08:44<15:48:44, 25.91s/it] 12%|█▏        | 300/2496 [2:09:09<15:38:45, 25.65s/it]                                                       {'loss': 0.7605, 'learning_rate': 1.9576788121902457e-05, 'epoch': 0.12}
 12%|█▏        | 300/2496 [2:09:09<15:38:45, 25.65s/it]this iter is wrong in something... skip...
 12%|█▏        | 301/2496 [2:09:33<15:12:01, 24.93s/it]                                                       {'loss': 0.7363, 'learning_rate': 1.9573044938439563e-05, 'epoch': 0.12}
 12%|█▏        | 301/2496 [2:09:33<15:12:01, 24.93s/it] 12%|█▏        | 302/2496 [2:09:56<14:48:38, 24.30s/it]                                                       {'loss': 0.7618, 'learning_rate': 1.9569285635156104e-05, 'epoch': 0.12}
 12%|█▏        | 302/2496 [2:09:56<14:48:38, 24.30s/it] 12%|█▏        | 303/2496 [2:10:19<14:44:18, 24.19s/it]                                                       {'loss': 0.7188, 'learning_rate': 1.9565510218382283e-05, 'epoch': 0.12}
 12%|█▏        | 303/2496 [2:10:19<14:44:18, 24.19s/it] 12%|█▏        | 304/2496 [2:10:43<14:33:12, 23.90s/it]                                                       {'loss': 0.7462, 'learning_rate': 1.956171869447543e-05, 'epoch': 0.12}
 12%|█▏        | 304/2496 [2:10:43<14:33:12, 23.90s/it] 12%|█▏        | 305/2496 [2:11:06<14:30:36, 23.84s/it]                                                       {'loss': 0.7492, 'learning_rate': 1.955791106982001e-05, 'epoch': 0.12}
 12%|█▏        | 305/2496 [2:11:06<14:30:36, 23.84s/it] 12%|█▏        | 306/2496 [2:11:29<14:21:49, 23.61s/it]                                                       {'loss': 0.7538, 'learning_rate': 1.955408735082758e-05, 'epoch': 0.12}
 12%|█▏        | 306/2496 [2:11:29<14:21:49, 23.61s/it] 12%|█▏        | 307/2496 [2:12:56<25:48:59, 42.46s/it]                                                       {'loss': 0.7186, 'learning_rate': 1.9550247543936813e-05, 'epoch': 0.12}
 12%|█▏        | 307/2496 [2:12:56<25:48:59, 42.46s/it] 12%|█▏        | 308/2496 [2:13:22<22:50:38, 37.59s/it]                                                       {'loss': 0.7709, 'learning_rate': 1.954639165561347e-05, 'epoch': 0.12}
 12%|█▏        | 308/2496 [2:13:22<22:50:38, 37.59s/it] 12%|█▏        | 309/2496 [2:13:45<20:08:15, 33.15s/it]                                                       {'loss': 0.7605, 'learning_rate': 1.954251969235039e-05, 'epoch': 0.12}
 12%|█▏        | 309/2496 [2:13:45<20:08:15, 33.15s/it] 12%|█▏        | 310/2496 [2:14:08<18:22:49, 30.27s/it]                                                       {'loss': 0.7116, 'learning_rate': 1.9538631660667472e-05, 'epoch': 0.12}
 12%|█▏        | 310/2496 [2:14:08<18:22:49, 30.27s/it] 12%|█▏        | 311/2496 [2:14:34<17:27:23, 28.76s/it]                                                       {'loss': 0.7428, 'learning_rate': 1.953472756711168e-05, 'epoch': 0.12}
 12%|█▏        | 311/2496 [2:14:34<17:27:23, 28.76s/it] 12%|█▎        | 312/2496 [2:15:00<16:59:03, 28.00s/it]                                                       {'loss': 0.7477, 'learning_rate': 1.953080741825703e-05, 'epoch': 0.12}
 12%|█▎        | 312/2496 [2:15:00<16:59:03, 28.00s/it]this iter is wrong in something... skip...
 13%|█▎        | 313/2496 [2:15:25<16:23:20, 27.03s/it]                                                       {'loss': 0.7332, 'learning_rate': 1.9526871220704567e-05, 'epoch': 0.13}
 13%|█▎        | 313/2496 [2:15:25<16:23:20, 27.03s/it] 13%|█▎        | 314/2496 [2:15:47<15:33:41, 25.67s/it]                                                       {'loss': 0.7599, 'learning_rate': 1.9522918981082347e-05, 'epoch': 0.13}
 13%|█▎        | 314/2496 [2:15:47<15:33:41, 25.67s/it]this iter is wrong in something... skip...
 13%|█▎        | 315/2496 [2:16:11<15:17:27, 25.24s/it]                                                       {'loss': 0.7752, 'learning_rate': 1.951895070604547e-05, 'epoch': 0.13}
 13%|█▎        | 315/2496 [2:16:11<15:17:27, 25.24s/it] 13%|█▎        | 316/2496 [2:16:44<16:31:50, 27.30s/it]                                                       {'loss': 0.713, 'learning_rate': 1.9514966402276e-05, 'epoch': 0.13}
 13%|█▎        | 316/2496 [2:16:44<16:31:50, 27.30s/it] 13%|█▎        | 317/2496 [2:17:09<16:16:24, 26.89s/it]                                                       {'loss': 0.7315, 'learning_rate': 1.9510966076483023e-05, 'epoch': 0.13}
 13%|█▎        | 317/2496 [2:17:09<16:16:24, 26.89s/it] 13%|█▎        | 318/2496 [2:17:35<15:59:12, 26.42s/it]                                                       {'loss': 0.7372, 'learning_rate': 1.950694973540259e-05, 'epoch': 0.13}
 13%|█▎        | 318/2496 [2:17:35<15:59:12, 26.42s/it] 13%|█▎        | 319/2496 [2:18:00<15:43:00, 25.99s/it]                                                       {'loss': 0.7287, 'learning_rate': 1.9502917385797716e-05, 'epoch': 0.13}
 13%|█▎        | 319/2496 [2:18:00<15:43:00, 25.99s/it] 13%|█▎        | 320/2496 [2:18:23<15:15:10, 25.23s/it]                                                       {'loss': 0.7593, 'learning_rate': 1.9498869034458384e-05, 'epoch': 0.13}
 13%|█▎        | 320/2496 [2:18:23<15:15:10, 25.23s/it] 13%|█▎        | 321/2496 [2:18:50<15:26:50, 25.57s/it]                                                       {'loss': 0.759, 'learning_rate': 1.9494804688201513e-05, 'epoch': 0.13}
 13%|█▎        | 321/2496 [2:18:50<15:26:50, 25.57s/it] 13%|█▎        | 322/2496 [2:19:15<15:26:48, 25.58s/it]                                                       {'loss': 0.7697, 'learning_rate': 1.9490724353870957e-05, 'epoch': 0.13}
 13%|█▎        | 322/2496 [2:19:15<15:26:48, 25.58s/it] 13%|█▎        | 323/2496 [2:19:40<15:17:23, 25.33s/it]                                                       {'loss': 0.7573, 'learning_rate': 1.948662803833749e-05, 'epoch': 0.13}
 13%|█▎        | 323/2496 [2:19:40<15:17:23, 25.33s/it] 13%|█▎        | 324/2496 [2:20:05<15:12:00, 25.19s/it]                                                       {'loss': 0.7444, 'learning_rate': 1.9482515748498807e-05, 'epoch': 0.13}
 13%|█▎        | 324/2496 [2:20:05<15:12:00, 25.19s/it] 13%|█▎        | 325/2496 [2:20:29<14:58:16, 24.83s/it]                                                       {'loss': 0.706, 'learning_rate': 1.947838749127949e-05, 'epoch': 0.13}
 13%|█▎        | 325/2496 [2:20:29<14:58:16, 24.83s/it] 13%|█▎        | 326/2496 [2:20:54<15:04:00, 25.00s/it]                                                       {'loss': 0.7484, 'learning_rate': 1.9474243273631014e-05, 'epoch': 0.13}
 13%|█▎        | 326/2496 [2:20:54<15:04:00, 25.00s/it] 13%|█▎        | 327/2496 [2:21:22<15:37:42, 25.94s/it]                                                       {'loss': 0.729, 'learning_rate': 1.9470083102531724e-05, 'epoch': 0.13}
 13%|█▎        | 327/2496 [2:21:22<15:37:42, 25.94s/it] 13%|█▎        | 328/2496 [2:21:44<14:53:30, 24.73s/it]                                                       {'loss': 0.7686, 'learning_rate': 1.9465906984986834e-05, 'epoch': 0.13}
 13%|█▎        | 328/2496 [2:21:44<14:53:30, 24.73s/it]this iter is wrong in something... skip...
 13%|█▎        | 329/2496 [2:22:09<14:54:34, 24.77s/it]                                                       {'loss': 0.7305, 'learning_rate': 1.946171492802841e-05, 'epoch': 0.13}
 13%|█▎        | 329/2496 [2:22:09<14:54:34, 24.77s/it] 13%|█▎        | 330/2496 [2:22:35<15:03:22, 25.02s/it]                                                       {'loss': 0.746, 'learning_rate': 1.9457506938715357e-05, 'epoch': 0.13}
 13%|█▎        | 330/2496 [2:22:35<15:03:22, 25.02s/it] 13%|█▎        | 331/2496 [2:23:00<15:10:34, 25.24s/it]                                                       {'loss': 0.7313, 'learning_rate': 1.94532830241334e-05, 'epoch': 0.13}
 13%|█▎        | 331/2496 [2:23:00<15:10:34, 25.24s/it] 13%|█▎        | 332/2496 [2:23:27<15:23:32, 25.61s/it]                                                       {'loss': 0.7722, 'learning_rate': 1.9449043191395098e-05, 'epoch': 0.13}
 13%|█▎        | 332/2496 [2:23:27<15:23:32, 25.61s/it] 13%|█▎        | 333/2496 [2:23:54<15:36:43, 25.98s/it]                                                       {'loss': 0.7541, 'learning_rate': 1.9444787447639794e-05, 'epoch': 0.13}
 13%|█▎        | 333/2496 [2:23:54<15:36:43, 25.98s/it] 13%|█▎        | 334/2496 [2:24:20<15:41:13, 26.12s/it]                                                       {'loss': 0.72, 'learning_rate': 1.9440515800033636e-05, 'epoch': 0.13}
 13%|█▎        | 334/2496 [2:24:20<15:41:13, 26.12s/it] 13%|█▎        | 335/2496 [2:24:44<15:19:23, 25.53s/it]                                                       {'loss': 0.746, 'learning_rate': 1.943622825576955e-05, 'epoch': 0.13}
 13%|█▎        | 335/2496 [2:24:44<15:19:23, 25.53s/it] 13%|█▎        | 336/2496 [2:25:10<15:22:13, 25.62s/it]                                                       {'loss': 0.7603, 'learning_rate': 1.943192482206723e-05, 'epoch': 0.13}
 13%|█▎        | 336/2496 [2:25:10<15:22:13, 25.62s/it] 14%|█▎        | 337/2496 [2:25:35<15:16:25, 25.47s/it]                                                       {'loss': 0.7484, 'learning_rate': 1.942760550617312e-05, 'epoch': 0.13}
 14%|█▎        | 337/2496 [2:25:35<15:16:25, 25.47s/it] 14%|█▎        | 338/2496 [2:26:03<15:40:41, 26.15s/it]                                                       {'loss': 0.7086, 'learning_rate': 1.9423270315360418e-05, 'epoch': 0.14}
 14%|█▎        | 338/2496 [2:26:03<15:40:41, 26.15s/it] 14%|█▎        | 339/2496 [2:26:26<15:03:56, 25.14s/it]                                                       {'loss': 0.7542, 'learning_rate': 1.9418919256929044e-05, 'epoch': 0.14}
 14%|█▎        | 339/2496 [2:26:26<15:03:56, 25.14s/it] 14%|█▎        | 340/2496 [2:26:54<15:40:47, 26.18s/it]                                                       {'loss': 0.7233, 'learning_rate': 1.941455233820564e-05, 'epoch': 0.14}
 14%|█▎        | 340/2496 [2:26:54<15:40:47, 26.18s/it] 14%|█▎        | 341/2496 [2:27:17<15:02:43, 25.13s/it]                                                       {'loss': 0.7547, 'learning_rate': 1.941016956654356e-05, 'epoch': 0.14}
 14%|█▎        | 341/2496 [2:27:17<15:02:43, 25.13s/it] 14%|█▎        | 342/2496 [2:27:42<14:57:51, 25.01s/it]                                                       {'loss': 0.76, 'learning_rate': 1.9405770949322846e-05, 'epoch': 0.14}
 14%|█▎        | 342/2496 [2:27:42<14:57:51, 25.01s/it] 14%|█▎        | 343/2496 [2:28:05<14:39:11, 24.50s/it]                                                       {'loss': 0.7456, 'learning_rate': 1.940135649395022e-05, 'epoch': 0.14}
 14%|█▎        | 343/2496 [2:28:05<14:39:11, 24.50s/it] 14%|█▍        | 344/2496 [2:28:28<14:25:08, 24.12s/it]                                                       {'loss': 0.7489, 'learning_rate': 1.9396926207859085e-05, 'epoch': 0.14}
 14%|█▍        | 344/2496 [2:28:28<14:25:08, 24.12s/it] 14%|█▍        | 345/2496 [2:28:54<14:45:27, 24.70s/it]                                                       {'loss': 0.7386, 'learning_rate': 1.9392480098509488e-05, 'epoch': 0.14}
 14%|█▍        | 345/2496 [2:28:54<14:45:27, 24.70s/it] 14%|█▍        | 346/2496 [2:29:19<14:44:25, 24.68s/it]                                                       {'loss': 0.7002, 'learning_rate': 1.9388018173388126e-05, 'epoch': 0.14}
 14%|█▍        | 346/2496 [2:29:19<14:44:25, 24.68s/it] 14%|█▍        | 347/2496 [2:29:43<14:40:52, 24.59s/it]                                                       {'loss': 0.727, 'learning_rate': 1.9383540440008328e-05, 'epoch': 0.14}
 14%|█▍        | 347/2496 [2:29:43<14:40:52, 24.59s/it] 14%|█▍        | 348/2496 [2:30:09<14:48:25, 24.82s/it]                                                       {'loss': 0.7356, 'learning_rate': 1.9379046905910046e-05, 'epoch': 0.14}
 14%|█▍        | 348/2496 [2:30:09<14:48:25, 24.82s/it]this iter is wrong in something... skip...
 14%|█▍        | 349/2496 [2:30:32<14:32:25, 24.38s/it]                                                       {'loss': 0.7433, 'learning_rate': 1.9374537578659828e-05, 'epoch': 0.14}
 14%|█▍        | 349/2496 [2:30:32<14:32:25, 24.38s/it] 14%|█▍        | 350/2496 [2:30:56<14:26:29, 24.23s/it]                                                       {'loss': 0.7492, 'learning_rate': 1.9370012465850823e-05, 'epoch': 0.14}
 14%|█▍        | 350/2496 [2:30:56<14:26:29, 24.23s/it] 14%|█▍        | 351/2496 [2:31:21<14:30:29, 24.35s/it]                                                       {'loss': 0.6935, 'learning_rate': 1.9365471575102764e-05, 'epoch': 0.14}
 14%|█▍        | 351/2496 [2:31:21<14:30:29, 24.35s/it]this iter is wrong in something... skip...
 14%|█▍        | 352/2496 [2:31:44<14:22:30, 24.14s/it]                                                       {'loss': 0.7577, 'learning_rate': 1.9360914914061942e-05, 'epoch': 0.14}
 14%|█▍        | 352/2496 [2:31:44<14:22:30, 24.14s/it] 14%|█▍        | 353/2496 [2:32:11<14:49:00, 24.89s/it]                                                       {'loss': 0.7386, 'learning_rate': 1.935634249040122e-05, 'epoch': 0.14}
 14%|█▍        | 353/2496 [2:32:11<14:49:00, 24.89s/it]this iter is wrong in something... skip...
 14%|█▍        | 354/2496 [2:32:38<15:09:38, 25.48s/it]                                                       {'loss': 0.7212, 'learning_rate': 1.9351754311819978e-05, 'epoch': 0.14}
 14%|█▍        | 354/2496 [2:32:38<15:09:38, 25.48s/it] 14%|█▍        | 355/2496 [2:33:02<14:51:07, 24.97s/it]                                                       {'loss': 0.7553, 'learning_rate': 1.9347150386044146e-05, 'epoch': 0.14}
 14%|█▍        | 355/2496 [2:33:02<14:51:07, 24.97s/it] 14%|█▍        | 356/2496 [2:33:27<14:53:56, 25.06s/it]                                                       {'loss': 0.7978, 'learning_rate': 1.934253072082617e-05, 'epoch': 0.14}
 14%|█▍        | 356/2496 [2:33:27<14:53:56, 25.06s/it] 14%|█▍        | 357/2496 [2:33:53<15:05:59, 25.41s/it]                                                       {'loss': 0.7575, 'learning_rate': 1.9337895323944986e-05, 'epoch': 0.14}
 14%|█▍        | 357/2496 [2:33:53<15:05:59, 25.41s/it] 14%|█▍        | 358/2496 [2:34:20<15:26:00, 25.99s/it]                                                       {'loss': 0.7726, 'learning_rate': 1.9333244203206027e-05, 'epoch': 0.14}
 14%|█▍        | 358/2496 [2:34:20<15:26:00, 25.99s/it] 14%|█▍        | 359/2496 [2:34:45<15:05:05, 25.41s/it]                                                       {'loss': 0.7149, 'learning_rate': 1.932857736644121e-05, 'epoch': 0.14}
 14%|█▍        | 359/2496 [2:34:45<15:05:05, 25.41s/it] 14%|█▍        | 360/2496 [2:35:12<15:22:07, 25.90s/it]                                                       {'loss': 0.7082, 'learning_rate': 1.93238948215089e-05, 'epoch': 0.14}
 14%|█▍        | 360/2496 [2:35:12<15:22:07, 25.90s/it] 14%|█▍        | 361/2496 [2:35:37<15:11:56, 25.63s/it]                                                       {'loss': 0.7436, 'learning_rate': 1.931919657629393e-05, 'epoch': 0.14}
 14%|█▍        | 361/2496 [2:35:37<15:11:56, 25.63s/it] 15%|█▍        | 362/2496 [2:36:02<15:05:09, 25.45s/it]                                                       {'loss': 0.743, 'learning_rate': 1.9314482638707562e-05, 'epoch': 0.15}
 15%|█▍        | 362/2496 [2:36:02<15:05:09, 25.45s/it] 15%|█▍        | 363/2496 [2:36:26<14:49:27, 25.02s/it]                                                       {'loss': 0.7329, 'learning_rate': 1.9309753016687478e-05, 'epoch': 0.15}
 15%|█▍        | 363/2496 [2:36:26<14:49:27, 25.02s/it] 15%|█▍        | 364/2496 [2:36:52<15:03:54, 25.44s/it]                                                       {'loss': 0.7365, 'learning_rate': 1.930500771819778e-05, 'epoch': 0.15}
 15%|█▍        | 364/2496 [2:36:52<15:03:54, 25.44s/it]this iter is wrong in something... skip...
 15%|█▍        | 365/2496 [2:37:18<15:04:14, 25.46s/it]                                                       {'loss': 0.7542, 'learning_rate': 1.9300246751228955e-05, 'epoch': 0.15}
 15%|█▍        | 365/2496 [2:37:18<15:04:14, 25.46s/it] 15%|█▍        | 366/2496 [2:37:43<15:08:28, 25.59s/it]                                                       {'loss': 0.7738, 'learning_rate': 1.9295470123797887e-05, 'epoch': 0.15}
 15%|█▍        | 366/2496 [2:37:43<15:08:28, 25.59s/it] 15%|█▍        | 367/2496 [2:38:07<14:48:01, 25.03s/it]                                                       {'loss': 0.7267, 'learning_rate': 1.9290677843947825e-05, 'epoch': 0.15}
 15%|█▍        | 367/2496 [2:38:07<14:48:01, 25.03s/it] 15%|█▍        | 368/2496 [2:38:31<14:38:41, 24.78s/it]                                                       {'loss': 0.7414, 'learning_rate': 1.928586991974837e-05, 'epoch': 0.15}
 15%|█▍        | 368/2496 [2:38:31<14:38:41, 24.78s/it] 15%|█▍        | 369/2496 [2:38:56<14:34:49, 24.68s/it]                                                       {'loss': 0.7505, 'learning_rate': 1.9281046359295472e-05, 'epoch': 0.15}
 15%|█▍        | 369/2496 [2:38:56<14:34:49, 24.68s/it] 15%|█▍        | 370/2496 [2:39:22<14:52:24, 25.19s/it]                                                       {'loss': 0.7671, 'learning_rate': 1.927620717071141e-05, 'epoch': 0.15}
 15%|█▍        | 370/2496 [2:39:22<14:52:24, 25.19s/it] 15%|█▍        | 371/2496 [2:39:46<14:41:29, 24.89s/it]                                                       {'loss': 0.7494, 'learning_rate': 1.9271352362144774e-05, 'epoch': 0.15}
 15%|█▍        | 371/2496 [2:39:46<14:41:29, 24.89s/it] 15%|█▍        | 372/2496 [2:40:11<14:43:48, 24.97s/it]                                                       {'loss': 0.7618, 'learning_rate': 1.9266481941770463e-05, 'epoch': 0.15}
 15%|█▍        | 372/2496 [2:40:11<14:43:48, 24.97s/it] 15%|█▍        | 373/2496 [2:40:38<14:55:55, 25.32s/it]                                                       {'loss': 0.7253, 'learning_rate': 1.9261595917789656e-05, 'epoch': 0.15}
 15%|█▍        | 373/2496 [2:40:38<14:55:55, 25.32s/it] 15%|█▍        | 374/2496 [2:41:02<14:47:27, 25.09s/it]                                                       {'loss': 0.7266, 'learning_rate': 1.9256694298429818e-05, 'epoch': 0.15}
 15%|█▍        | 374/2496 [2:41:02<14:47:27, 25.09s/it] 15%|█▌        | 375/2496 [2:41:35<16:04:57, 27.30s/it]                                                       {'loss': 0.7536, 'learning_rate': 1.9251777091944665e-05, 'epoch': 0.15}
 15%|█▌        | 375/2496 [2:41:35<16:04:57, 27.30s/it] 15%|█▌        | 376/2496 [2:42:00<15:45:28, 26.76s/it]                                                       {'loss': 0.7971, 'learning_rate': 1.9246844306614164e-05, 'epoch': 0.15}
 15%|█▌        | 376/2496 [2:42:00<15:45:28, 26.76s/it] 15%|█▌        | 377/2496 [2:42:25<15:26:23, 26.23s/it]                                                       {'loss': 0.7348, 'learning_rate': 1.9241895950744514e-05, 'epoch': 0.15}
 15%|█▌        | 377/2496 [2:42:25<15:26:23, 26.23s/it] 15%|█▌        | 378/2496 [2:42:49<14:59:52, 25.49s/it]                                                       {'loss': 0.7559, 'learning_rate': 1.923693203266813e-05, 'epoch': 0.15}
 15%|█▌        | 378/2496 [2:42:49<14:59:52, 25.49s/it] 15%|█▌        | 379/2496 [2:43:13<14:41:10, 24.97s/it]                                                       {'loss': 0.7588, 'learning_rate': 1.9231952560743634e-05, 'epoch': 0.15}
 15%|█▌        | 379/2496 [2:43:13<14:41:10, 24.97s/it] 15%|█▌        | 380/2496 [2:43:37<14:37:13, 24.87s/it]                                                       {'loss': 0.7197, 'learning_rate': 1.9226957543355843e-05, 'epoch': 0.15}
 15%|█▌        | 380/2496 [2:43:37<14:37:13, 24.87s/it] 15%|█▌        | 381/2496 [2:44:02<14:33:33, 24.78s/it]                                                       {'loss': 0.7397, 'learning_rate': 1.9221946988915745e-05, 'epoch': 0.15}
 15%|█▌        | 381/2496 [2:44:02<14:33:33, 24.78s/it]this iter is wrong in something... skip...
 15%|█▌        | 382/2496 [2:44:29<14:57:03, 25.46s/it]                                                       {'loss': 0.6981, 'learning_rate': 1.9216920905860494e-05, 'epoch': 0.15}
 15%|█▌        | 382/2496 [2:44:29<14:57:03, 25.46s/it] 15%|█▌        | 383/2496 [2:44:54<14:50:53, 25.30s/it]                                                       {'loss': 0.7082, 'learning_rate': 1.9211879302653387e-05, 'epoch': 0.15}
 15%|█▌        | 383/2496 [2:44:54<14:50:53, 25.30s/it] 15%|█▌        | 384/2496 [2:45:19<14:46:44, 25.19s/it]                                                       {'loss': 0.7692, 'learning_rate': 1.920682218778386e-05, 'epoch': 0.15}
 15%|█▌        | 384/2496 [2:45:19<14:46:44, 25.19s/it] 15%|█▌        | 385/2496 [2:45:44<14:49:45, 25.29s/it]                                                       {'loss': 0.7176, 'learning_rate': 1.9201749569767473e-05, 'epoch': 0.15}
 15%|█▌        | 385/2496 [2:45:44<14:49:45, 25.29s/it] 15%|█▌        | 386/2496 [2:46:10<14:54:14, 25.43s/it]                                                       {'loss': 0.7237, 'learning_rate': 1.9196661457145876e-05, 'epoch': 0.15}
 15%|█▌        | 386/2496 [2:46:10<14:54:14, 25.43s/it] 16%|█▌        | 387/2496 [2:46:35<14:50:18, 25.33s/it]                                                       {'loss': 0.737, 'learning_rate': 1.9191557858486825e-05, 'epoch': 0.16}
 16%|█▌        | 387/2496 [2:46:35<14:50:18, 25.33s/it] 16%|█▌        | 388/2496 [2:47:00<14:42:23, 25.12s/it]                                                       {'loss': 0.7332, 'learning_rate': 1.9186438782384147e-05, 'epoch': 0.16}
 16%|█▌        | 388/2496 [2:47:00<14:42:23, 25.12s/it] 16%|█▌        | 389/2496 [2:47:23<14:17:06, 24.41s/it]                                                       {'loss': 0.7443, 'learning_rate': 1.918130423745773e-05, 'epoch': 0.16}
 16%|█▌        | 389/2496 [2:47:23<14:17:06, 24.41s/it] 16%|█▌        | 390/2496 [2:47:46<14:11:24, 24.26s/it]                                                       {'loss': 0.7405, 'learning_rate': 1.9176154232353513e-05, 'epoch': 0.16}
 16%|█▌        | 390/2496 [2:47:46<14:11:24, 24.26s/it] 16%|█▌        | 391/2496 [2:48:11<14:18:21, 24.47s/it]                                                       {'loss': 0.7386, 'learning_rate': 1.917098877574347e-05, 'epoch': 0.16}
 16%|█▌        | 391/2496 [2:48:11<14:18:21, 24.47s/it] 16%|█▌        | 392/2496 [2:48:37<14:26:57, 24.72s/it]                                                       {'loss': 0.733, 'learning_rate': 1.9165807876325577e-05, 'epoch': 0.16}
 16%|█▌        | 392/2496 [2:48:37<14:26:57, 24.72s/it] 16%|█▌        | 393/2496 [2:49:03<14:38:43, 25.07s/it]                                                       {'loss': 0.7439, 'learning_rate': 1.916061154282384e-05, 'epoch': 0.16}
 16%|█▌        | 393/2496 [2:49:03<14:38:43, 25.07s/it] 16%|█▌        | 394/2496 [2:49:28<14:39:51, 25.12s/it]                                                       {'loss': 0.7558, 'learning_rate': 1.9155399783988228e-05, 'epoch': 0.16}
 16%|█▌        | 394/2496 [2:49:28<14:39:51, 25.12s/it] 16%|█▌        | 395/2496 [2:49:51<14:22:02, 24.62s/it]                                                       {'loss': 0.7855, 'learning_rate': 1.9150172608594702e-05, 'epoch': 0.16}
 16%|█▌        | 395/2496 [2:49:51<14:22:02, 24.62s/it] 16%|█▌        | 396/2496 [2:50:18<14:45:15, 25.29s/it]                                                       {'loss': 0.7583, 'learning_rate': 1.9144930025445184e-05, 'epoch': 0.16}
 16%|█▌        | 396/2496 [2:50:18<14:45:15, 25.29s/it]this iter is wrong in something... skip...
 16%|█▌        | 397/2496 [2:50:42<14:28:19, 24.82s/it]                                                       {'loss': 0.7542, 'learning_rate': 1.913967204336752e-05, 'epoch': 0.16}
 16%|█▌        | 397/2496 [2:50:42<14:28:19, 24.82s/it] 16%|█▌        | 398/2496 [2:51:07<14:35:26, 25.04s/it]                                                       {'loss': 0.7506, 'learning_rate': 1.9134398671215517e-05, 'epoch': 0.16}
 16%|█▌        | 398/2496 [2:51:07<14:35:26, 25.04s/it] 16%|█▌        | 399/2496 [2:51:32<14:31:20, 24.93s/it]                                                       {'loss': 0.7406, 'learning_rate': 1.9129109917868863e-05, 'epoch': 0.16}
 16%|█▌        | 399/2496 [2:51:32<14:31:20, 24.93s/it] 16%|█▌        | 400/2496 [2:51:59<14:51:11, 25.51s/it]                                                       {'loss': 0.7682, 'learning_rate': 1.9123805792233167e-05, 'epoch': 0.16}
 16%|█▌        | 400/2496 [2:51:59<14:51:11, 25.51s/it] 16%|█▌        | 401/2496 [2:52:24<14:50:33, 25.51s/it]                                                       {'loss': 0.7179, 'learning_rate': 1.9118486303239928e-05, 'epoch': 0.16}
 16%|█▌        | 401/2496 [2:52:24<14:50:33, 25.51s/it] 16%|█▌        | 402/2496 [2:52:50<14:53:50, 25.61s/it]                                                       {'loss': 0.7305, 'learning_rate': 1.9113151459846494e-05, 'epoch': 0.16}
 16%|█▌        | 402/2496 [2:52:50<14:53:50, 25.61s/it] 16%|█▌        | 403/2496 [2:53:17<15:01:22, 25.84s/it]                                                       {'loss': 0.7214, 'learning_rate': 1.910780127103609e-05, 'epoch': 0.16}
 16%|█▌        | 403/2496 [2:53:17<15:01:22, 25.84s/it] 16%|█▌        | 404/2496 [2:53:44<15:18:00, 26.33s/it]                                                       {'loss': 0.7248, 'learning_rate': 1.9102435745817766e-05, 'epoch': 0.16}
 16%|█▌        | 404/2496 [2:53:44<15:18:00, 26.33s/it] 16%|█▌        | 405/2496 [2:54:09<15:02:31, 25.90s/it]                                                       {'loss': 0.7178, 'learning_rate': 1.9097054893226395e-05, 'epoch': 0.16}
 16%|█▌        | 405/2496 [2:54:09<15:02:31, 25.90s/it] 16%|█▋        | 406/2496 [2:54:34<14:52:23, 25.62s/it]                                                       {'loss': 0.7457, 'learning_rate': 1.9091658722322678e-05, 'epoch': 0.16}
 16%|█▋        | 406/2496 [2:54:34<14:52:23, 25.62s/it] 16%|█▋        | 407/2496 [2:54:58<14:37:37, 25.21s/it]                                                       {'loss': 0.7748, 'learning_rate': 1.908624724219309e-05, 'epoch': 0.16}
 16%|█▋        | 407/2496 [2:54:58<14:37:37, 25.21s/it] 16%|█▋        | 408/2496 [2:55:23<14:34:39, 25.13s/it]                                                       {'loss': 0.756, 'learning_rate': 1.9080820461949886e-05, 'epoch': 0.16}
 16%|█▋        | 408/2496 [2:55:23<14:34:39, 25.13s/it] 16%|█▋        | 409/2496 [2:55:49<14:43:08, 25.39s/it]                                                       {'loss': 0.7562, 'learning_rate': 1.9075378390731108e-05, 'epoch': 0.16}
 16%|█▋        | 409/2496 [2:55:49<14:43:08, 25.39s/it] 16%|█▋        | 410/2496 [2:56:11<14:08:54, 24.42s/it]                                                       {'loss': 0.7628, 'learning_rate': 1.9069921037700514e-05, 'epoch': 0.16}
 16%|█▋        | 410/2496 [2:56:11<14:08:54, 24.42s/it] 16%|█▋        | 411/2496 [2:56:38<14:29:54, 25.03s/it]                                                       {'loss': 0.7342, 'learning_rate': 1.9064448412047615e-05, 'epoch': 0.16}
 16%|█▋        | 411/2496 [2:56:38<14:29:54, 25.03s/it] 17%|█▋        | 412/2496 [2:57:02<14:18:06, 24.71s/it]                                                       {'loss': 0.7566, 'learning_rate': 1.9058960522987638e-05, 'epoch': 0.17}
 17%|█▋        | 412/2496 [2:57:02<14:18:06, 24.71s/it] 17%|█▋        | 413/2496 [2:57:28<14:30:15, 25.07s/it]                                                       {'loss': 0.7432, 'learning_rate': 1.90534573797615e-05, 'epoch': 0.17}
 17%|█▋        | 413/2496 [2:57:28<14:30:15, 25.07s/it] 17%|█▋        | 414/2496 [2:57:52<14:23:19, 24.88s/it]                                                       {'loss': 0.7391, 'learning_rate': 1.904793899163582e-05, 'epoch': 0.17}
 17%|█▋        | 414/2496 [2:57:52<14:23:19, 24.88s/it] 17%|█▋        | 415/2496 [2:58:20<14:53:30, 25.76s/it]                                                       {'loss': 0.7264, 'learning_rate': 1.904240536790287e-05, 'epoch': 0.17}
 17%|█▋        | 415/2496 [2:58:20<14:53:30, 25.76s/it] 17%|█▋        | 416/2496 [2:58:45<14:47:39, 25.61s/it]                                                       {'loss': 0.7575, 'learning_rate': 1.9036856517880596e-05, 'epoch': 0.17}
 17%|█▋        | 416/2496 [2:58:45<14:47:39, 25.61s/it] 17%|█▋        | 417/2496 [2:59:11<14:45:52, 25.57s/it]                                                       {'loss': 0.7234, 'learning_rate': 1.9031292450912565e-05, 'epoch': 0.17}
 17%|█▋        | 417/2496 [2:59:11<14:45:52, 25.57s/it] 17%|█▋        | 418/2496 [2:59:33<14:14:05, 24.66s/it]                                                       {'loss': 0.7404, 'learning_rate': 1.902571317636798e-05, 'epoch': 0.17}
 17%|█▋        | 418/2496 [2:59:33<14:14:05, 24.66s/it] 17%|█▋        | 419/2496 [2:59:56<13:49:47, 23.97s/it]                                                       {'loss': 0.728, 'learning_rate': 1.9020118703641647e-05, 'epoch': 0.17}
 17%|█▋        | 419/2496 [2:59:56<13:49:47, 23.97s/it] 17%|█▋        | 420/2496 [3:00:20<13:59:03, 24.25s/it]                                                       {'loss': 0.7553, 'learning_rate': 1.9014509042153964e-05, 'epoch': 0.17}
 17%|█▋        | 420/2496 [3:00:20<13:59:03, 24.25s/it] 17%|█▋        | 421/2496 [3:00:45<14:01:16, 24.33s/it]                                                       {'loss': 0.7321, 'learning_rate': 1.9008884201350905e-05, 'epoch': 0.17}
 17%|█▋        | 421/2496 [3:00:45<14:01:16, 24.33s/it] 17%|█▋        | 422/2496 [3:01:12<14:29:30, 25.15s/it]                                                       {'loss': 0.7664, 'learning_rate': 1.9003244190704008e-05, 'epoch': 0.17}
 17%|█▋        | 422/2496 [3:01:12<14:29:30, 25.15s/it] 17%|█▋        | 423/2496 [3:01:36<14:17:22, 24.82s/it]                                                       {'loss': 0.7408, 'learning_rate': 1.8997589019710344e-05, 'epoch': 0.17}
 17%|█▋        | 423/2496 [3:01:36<14:17:22, 24.82s/it]this iter is wrong in something... skip...
 17%|█▋        | 424/2496 [3:02:00<14:11:18, 24.65s/it]                                                       {'loss': 0.7462, 'learning_rate': 1.8991918697892525e-05, 'epoch': 0.17}
 17%|█▋        | 424/2496 [3:02:00<14:11:18, 24.65s/it] 17%|█▋        | 425/2496 [3:02:27<14:30:27, 25.22s/it]                                                       {'loss': 0.7407, 'learning_rate': 1.8986233234798666e-05, 'epoch': 0.17}
 17%|█▋        | 425/2496 [3:02:27<14:30:27, 25.22s/it] 17%|█▋        | 426/2496 [3:02:53<14:40:32, 25.52s/it]                                                       {'loss': 0.7544, 'learning_rate': 1.898053264000239e-05, 'epoch': 0.17}
 17%|█▋        | 426/2496 [3:02:53<14:40:32, 25.52s/it] 17%|█▋        | 427/2496 [3:03:17<14:22:29, 25.01s/it]                                                       {'loss': 0.7255, 'learning_rate': 1.8974816923102785e-05, 'epoch': 0.17}
 17%|█▋        | 427/2496 [3:03:17<14:22:29, 25.01s/it] 17%|█▋        | 428/2496 [3:03:42<14:22:32, 25.03s/it]                                                       {'loss': 0.7536, 'learning_rate': 1.896908609372441e-05, 'epoch': 0.17}
 17%|█▋        | 428/2496 [3:03:42<14:22:32, 25.03s/it] 17%|█▋        | 429/2496 [3:04:06<14:13:20, 24.77s/it]                                                       {'loss': 0.7538, 'learning_rate': 1.896334016151727e-05, 'epoch': 0.17}
 17%|█▋        | 429/2496 [3:04:06<14:13:20, 24.77s/it] 17%|█▋        | 430/2496 [3:04:32<14:22:31, 25.05s/it]                                                       {'loss': 0.6905, 'learning_rate': 1.8957579136156808e-05, 'epoch': 0.17}
 17%|█▋        | 430/2496 [3:04:32<14:22:31, 25.05s/it]this iter is wrong in something... skip...
 17%|█▋        | 431/2496 [3:04:57<14:21:10, 25.02s/it]                                                       {'loss': 0.2815, 'learning_rate': 1.895180302734387e-05, 'epoch': 0.17}
 17%|█▋        | 431/2496 [3:04:57<14:21:10, 25.02s/it] 17%|█▋        | 432/2496 [3:05:20<14:04:56, 24.56s/it]                                                       {'loss': 0.7441, 'learning_rate': 1.8946011844804706e-05, 'epoch': 0.17}
 17%|█▋        | 432/2496 [3:05:20<14:04:56, 24.56s/it] 17%|█▋        | 433/2496 [3:05:47<14:29:03, 25.28s/it]                                                       {'loss': 0.7349, 'learning_rate': 1.894020559829096e-05, 'epoch': 0.17}
 17%|█▋        | 433/2496 [3:05:47<14:29:03, 25.28s/it] 17%|█▋        | 434/2496 [3:06:12<14:18:29, 24.98s/it]                                                       {'loss': 0.7309, 'learning_rate': 1.8934384297579617e-05, 'epoch': 0.17}
 17%|█▋        | 434/2496 [3:06:12<14:18:29, 24.98s/it] 17%|█▋        | 435/2496 [3:06:38<14:31:43, 25.38s/it]                                                       {'loss': 0.6952, 'learning_rate': 1.8928547952473037e-05, 'epoch': 0.17}
 17%|█▋        | 435/2496 [3:06:38<14:31:43, 25.38s/it] 17%|█▋        | 436/2496 [3:07:01<14:12:38, 24.83s/it]                                                       {'loss': 0.721, 'learning_rate': 1.8922696572798895e-05, 'epoch': 0.17}
 17%|█▋        | 436/2496 [3:07:01<14:12:38, 24.83s/it] 18%|█▊        | 437/2496 [3:07:27<14:18:44, 25.02s/it]                                                       {'loss': 0.7279, 'learning_rate': 1.891683016841019e-05, 'epoch': 0.18}
 18%|█▊        | 437/2496 [3:07:27<14:18:44, 25.02s/it] 18%|█▊        | 438/2496 [3:07:55<14:51:29, 25.99s/it]                                                       {'loss': 0.7374, 'learning_rate': 1.891094874918522e-05, 'epoch': 0.18}
 18%|█▊        | 438/2496 [3:07:55<14:51:29, 25.99s/it] 18%|█▊        | 439/2496 [3:08:21<14:45:47, 25.84s/it]                                                       {'loss': 0.7354, 'learning_rate': 1.8905052325027567e-05, 'epoch': 0.18}
 18%|█▊        | 439/2496 [3:08:21<14:45:47, 25.84s/it] 18%|█▊        | 440/2496 [3:08:45<14:26:33, 25.29s/it]                                                       {'loss': 0.7654, 'learning_rate': 1.8899140905866076e-05, 'epoch': 0.18}
 18%|█▊        | 440/2496 [3:08:45<14:26:33, 25.29s/it] 18%|█▊        | 441/2496 [3:09:13<14:59:05, 26.25s/it]                                                       {'loss': 0.7448, 'learning_rate': 1.8893214501654845e-05, 'epoch': 0.18}
 18%|█▊        | 441/2496 [3:09:13<14:59:05, 26.25s/it] 18%|█▊        | 442/2496 [3:09:39<14:51:38, 26.05s/it]                                                       {'loss': 0.7206, 'learning_rate': 1.8887273122373202e-05, 'epoch': 0.18}
 18%|█▊        | 442/2496 [3:09:39<14:51:38, 26.05s/it]this iter is wrong in something... skip...
 18%|█▊        | 443/2496 [3:10:02<14:24:00, 25.25s/it]                                                       {'loss': 0.7198, 'learning_rate': 1.8881316778025694e-05, 'epoch': 0.18}
 18%|█▊        | 443/2496 [3:10:02<14:24:00, 25.25s/it] 18%|█▊        | 444/2496 [3:10:27<14:21:30, 25.19s/it]                                                       {'loss': 0.2932, 'learning_rate': 1.8875345478642067e-05, 'epoch': 0.18}
 18%|█▊        | 444/2496 [3:10:27<14:21:30, 25.19s/it] 18%|█▊        | 445/2496 [3:10:52<14:17:19, 25.08s/it]                                                       {'loss': 0.741, 'learning_rate': 1.886935923427725e-05, 'epoch': 0.18}
 18%|█▊        | 445/2496 [3:10:52<14:17:19, 25.08s/it] 18%|█▊        | 446/2496 [3:11:16<14:09:13, 24.86s/it]                                                       {'loss': 0.7239, 'learning_rate': 1.8863358055011332e-05, 'epoch': 0.18}
 18%|█▊        | 446/2496 [3:11:16<14:09:13, 24.86s/it] 18%|█▊        | 447/2496 [3:11:41<14:08:18, 24.84s/it]                                                       {'loss': 0.726, 'learning_rate': 1.885734195094956e-05, 'epoch': 0.18}
 18%|█▊        | 447/2496 [3:11:41<14:08:18, 24.84s/it] 18%|█▊        | 448/2496 [3:12:05<14:03:02, 24.70s/it]                                                       {'loss': 0.7459, 'learning_rate': 1.88513109322223e-05, 'epoch': 0.18}
 18%|█▊        | 448/2496 [3:12:05<14:03:02, 24.70s/it] 18%|█▊        | 449/2496 [3:12:31<14:16:10, 25.10s/it]                                                       {'loss': 0.7249, 'learning_rate': 1.8845265008985046e-05, 'epoch': 0.18}
 18%|█▊        | 449/2496 [3:12:31<14:16:10, 25.10s/it] 18%|█▊        | 450/2496 [3:12:56<14:11:44, 24.98s/it]                                                       {'loss': 0.7114, 'learning_rate': 1.8839204191418386e-05, 'epoch': 0.18}
 18%|█▊        | 450/2496 [3:12:56<14:11:44, 24.98s/it] 18%|█▊        | 451/2496 [3:13:22<14:15:43, 25.11s/it]                                                       {'loss': 0.7196, 'learning_rate': 1.8833128489727973e-05, 'epoch': 0.18}
 18%|█▊        | 451/2496 [3:13:22<14:15:43, 25.11s/it] 18%|█▊        | 452/2496 [3:13:46<14:06:08, 24.84s/it]                                                       {'loss': 0.7494, 'learning_rate': 1.882703791414455e-05, 'epoch': 0.18}
 18%|█▊        | 452/2496 [3:13:46<14:06:08, 24.84s/it] 18%|█▊        | 453/2496 [3:14:12<14:22:53, 25.34s/it]                                                       {'loss': 0.7759, 'learning_rate': 1.8820932474923874e-05, 'epoch': 0.18}
 18%|█▊        | 453/2496 [3:14:12<14:22:53, 25.34s/it] 18%|█▊        | 454/2496 [3:14:37<14:19:53, 25.27s/it]                                                       {'loss': 0.7677, 'learning_rate': 1.8814812182346764e-05, 'epoch': 0.18}
 18%|█▊        | 454/2496 [3:14:37<14:19:53, 25.27s/it] 18%|█▊        | 455/2496 [3:15:05<14:44:55, 26.01s/it]                                                       {'loss': 0.7237, 'learning_rate': 1.8808677046719023e-05, 'epoch': 0.18}
 18%|█▊        | 455/2496 [3:15:05<14:44:55, 26.01s/it] 18%|█▊        | 456/2496 [3:15:30<14:35:39, 25.75s/it]                                                       {'loss': 0.7067, 'learning_rate': 1.8802527078371465e-05, 'epoch': 0.18}
 18%|█▊        | 456/2496 [3:15:30<14:35:39, 25.75s/it] 18%|█▊        | 457/2496 [3:15:54<14:13:33, 25.12s/it]                                                       {'loss': 0.7283, 'learning_rate': 1.8796362287659868e-05, 'epoch': 0.18}
 18%|█▊        | 457/2496 [3:15:54<14:13:33, 25.12s/it] 18%|█▊        | 458/2496 [3:16:19<14:11:51, 25.08s/it]                                                       {'loss': 0.7357, 'learning_rate': 1.8790182684964983e-05, 'epoch': 0.18}
 18%|█▊        | 458/2496 [3:16:19<14:11:51, 25.08s/it] 18%|█▊        | 459/2496 [3:16:45<14:16:35, 25.23s/it]                                                       {'loss': 0.7006, 'learning_rate': 1.8783988280692487e-05, 'epoch': 0.18}
 18%|█▊        | 459/2496 [3:16:45<14:16:35, 25.23s/it]this iter is wrong in something... skip...
 18%|█▊        | 460/2496 [3:17:08<13:57:06, 24.67s/it]                                                       {'loss': 0.7552, 'learning_rate': 1.877777908527299e-05, 'epoch': 0.18}
 18%|█▊        | 460/2496 [3:17:08<13:57:06, 24.67s/it] 18%|█▊        | 461/2496 [3:17:35<14:22:03, 25.42s/it]                                                       {'loss': 0.7472, 'learning_rate': 1.8771555109162013e-05, 'epoch': 0.18}
 18%|█▊        | 461/2496 [3:17:35<14:22:03, 25.42s/it] 19%|█▊        | 462/2496 [3:18:01<14:27:30, 25.59s/it]                                                       {'loss': 0.7213, 'learning_rate': 1.8765316362839955e-05, 'epoch': 0.19}
 19%|█▊        | 462/2496 [3:18:01<14:27:30, 25.59s/it] 19%|█▊        | 463/2496 [3:18:28<14:36:19, 25.86s/it]                                                       {'loss': 0.7547, 'learning_rate': 1.875906285681209e-05, 'epoch': 0.19}
 19%|█▊        | 463/2496 [3:18:28<14:36:19, 25.86s/it] 19%|█▊        | 464/2496 [3:18:52<14:19:13, 25.37s/it]                                                       {'loss': 0.7466, 'learning_rate': 1.8752794601608547e-05, 'epoch': 0.19}
 19%|█▊        | 464/2496 [3:18:52<14:19:13, 25.37s/it] 19%|█▊        | 465/2496 [3:19:15<14:01:00, 24.85s/it]                                                       {'loss': 0.7858, 'learning_rate': 1.8746511607784298e-05, 'epoch': 0.19}
 19%|█▊        | 465/2496 [3:19:15<14:01:00, 24.85s/it] 19%|█▊        | 466/2496 [3:19:43<14:26:51, 25.62s/it]                                                       {'loss': 0.7246, 'learning_rate': 1.8740213885919115e-05, 'epoch': 0.19}
 19%|█▊        | 466/2496 [3:19:43<14:26:51, 25.62s/it] 19%|█▊        | 467/2496 [3:20:09<14:31:43, 25.78s/it]                                                       {'loss': 0.7173, 'learning_rate': 1.8733901446617586e-05, 'epoch': 0.19}
 19%|█▊        | 467/2496 [3:20:09<14:31:43, 25.78s/it] 19%|█▉        | 468/2496 [3:20:36<14:41:10, 26.07s/it]                                                       {'loss': 0.7073, 'learning_rate': 1.8727574300509077e-05, 'epoch': 0.19}
 19%|█▉        | 468/2496 [3:20:36<14:41:10, 26.07s/it] 19%|█▉        | 469/2496 [3:21:04<14:59:49, 26.64s/it]                                                       {'loss': 0.7595, 'learning_rate': 1.8721232458247715e-05, 'epoch': 0.19}
 19%|█▉        | 469/2496 [3:21:04<14:59:49, 26.64s/it] 19%|█▉        | 470/2496 [3:21:27<14:28:07, 25.71s/it]                                                       {'loss': 0.7476, 'learning_rate': 1.871487593051238e-05, 'epoch': 0.19}
 19%|█▉        | 470/2496 [3:21:27<14:28:07, 25.71s/it] 19%|█▉        | 471/2496 [3:21:54<14:39:40, 26.06s/it]                                                       {'loss': 0.7331, 'learning_rate': 1.8708504728006668e-05, 'epoch': 0.19}
 19%|█▉        | 471/2496 [3:21:54<14:39:40, 26.06s/it] 19%|█▉        | 472/2496 [3:22:19<14:32:03, 25.85s/it]                                                       {'loss': 0.7079, 'learning_rate': 1.87021188614589e-05, 'epoch': 0.19}
 19%|█▉        | 472/2496 [3:22:19<14:32:03, 25.85s/it] 19%|█▉        | 473/2496 [3:22:48<14:56:52, 26.60s/it]                                                       {'loss': 0.7332, 'learning_rate': 1.869571834162208e-05, 'epoch': 0.19}
 19%|█▉        | 473/2496 [3:22:48<14:56:52, 26.60s/it] 19%|█▉        | 474/2496 [3:23:13<14:41:46, 26.17s/it]                                                       {'loss': 0.7168, 'learning_rate': 1.8689303179273895e-05, 'epoch': 0.19}
 19%|█▉        | 474/2496 [3:23:13<14:41:46, 26.17s/it] 19%|█▉        | 475/2496 [3:23:39<14:35:20, 25.99s/it]                                                       {'loss': 0.7543, 'learning_rate': 1.8682873385216683e-05, 'epoch': 0.19}
 19%|█▉        | 475/2496 [3:23:39<14:35:20, 25.99s/it] 19%|█▉        | 476/2496 [3:24:02<14:14:26, 25.38s/it]                                                       {'loss': 0.6996, 'learning_rate': 1.8676428970277413e-05, 'epoch': 0.19}
 19%|█▉        | 476/2496 [3:24:02<14:14:26, 25.38s/it] 19%|█▉        | 477/2496 [3:24:27<14:09:52, 25.26s/it]                                                       {'loss': 0.272, 'learning_rate': 1.8669969945307683e-05, 'epoch': 0.19}
 19%|█▉        | 477/2496 [3:24:27<14:09:52, 25.26s/it] 19%|█▉        | 478/2496 [3:24:53<14:13:09, 25.37s/it]                                                       {'loss': 0.721, 'learning_rate': 1.8663496321183697e-05, 'epoch': 0.19}
 19%|█▉        | 478/2496 [3:24:53<14:13:09, 25.37s/it] 19%|█▉        | 479/2496 [3:25:17<13:57:12, 24.90s/it]                                                       {'loss': 0.7172, 'learning_rate': 1.8657008108806227e-05, 'epoch': 0.19}
 19%|█▉        | 479/2496 [3:25:17<13:57:12, 24.90s/it] 19%|█▉        | 480/2496 [3:25:45<14:24:42, 25.74s/it]                                                       {'loss': 0.7352, 'learning_rate': 1.865050531910062e-05, 'epoch': 0.19}
 19%|█▉        | 480/2496 [3:25:45<14:24:42, 25.74s/it] 19%|█▉        | 481/2496 [3:26:15<15:16:02, 27.28s/it]                                                       {'loss': 0.7122, 'learning_rate': 1.8643987963016773e-05, 'epoch': 0.19}
 19%|█▉        | 481/2496 [3:26:15<15:16:02, 27.28s/it] 19%|█▉        | 482/2496 [3:26:40<14:52:34, 26.59s/it]                                                       {'loss': 0.7664, 'learning_rate': 1.8637456051529096e-05, 'epoch': 0.19}
 19%|█▉        | 482/2496 [3:26:40<14:52:34, 26.59s/it] 19%|█▉        | 483/2496 [3:27:05<14:30:29, 25.95s/it]                                                       {'loss': 0.7269, 'learning_rate': 1.8630909595636522e-05, 'epoch': 0.19}
 19%|█▉        | 483/2496 [3:27:05<14:30:29, 25.95s/it] 19%|█▉        | 484/2496 [3:27:34<15:05:32, 27.00s/it]                                                       {'loss': 0.7207, 'learning_rate': 1.8624348606362476e-05, 'epoch': 0.19}
 19%|█▉        | 484/2496 [3:27:34<15:05:32, 27.00s/it] 19%|█▉        | 485/2496 [3:27:59<14:43:30, 26.36s/it]                                                       {'loss': 0.7186, 'learning_rate': 1.861777309475484e-05, 'epoch': 0.19}
 19%|█▉        | 485/2496 [3:27:59<14:43:30, 26.36s/it] 19%|█▉        | 486/2496 [3:28:26<14:49:19, 26.55s/it]                                                       {'loss': 0.7519, 'learning_rate': 1.861118307188597e-05, 'epoch': 0.19}
 19%|█▉        | 486/2496 [3:28:26<14:49:19, 26.55s/it] 20%|█▉        | 487/2496 [3:28:52<14:43:32, 26.39s/it]                                                       {'loss': 0.7262, 'learning_rate': 1.8604578548852648e-05, 'epoch': 0.2}
 20%|█▉        | 487/2496 [3:28:52<14:43:32, 26.39s/it] 20%|█▉        | 488/2496 [3:29:16<14:17:03, 25.61s/it]                                                       {'loss': 0.7576, 'learning_rate': 1.859795953677606e-05, 'epoch': 0.2}
 20%|█▉        | 488/2496 [3:29:16<14:17:03, 25.61s/it] 20%|█▉        | 489/2496 [3:29:43<14:34:37, 26.15s/it]                                                       {'loss': 0.702, 'learning_rate': 1.8591326046801813e-05, 'epoch': 0.2}
 20%|█▉        | 489/2496 [3:29:43<14:34:37, 26.15s/it] 20%|█▉        | 490/2496 [3:30:07<14:10:04, 25.43s/it]                                                       {'loss': 0.7347, 'learning_rate': 1.8584678090099875e-05, 'epoch': 0.2}
 20%|█▉        | 490/2496 [3:30:07<14:10:04, 25.43s/it] 20%|█▉        | 491/2496 [3:30:35<14:34:22, 26.17s/it]                                                       {'loss': 0.6981, 'learning_rate': 1.8578015677864586e-05, 'epoch': 0.2}
 20%|█▉        | 491/2496 [3:30:35<14:34:22, 26.17s/it] 20%|█▉        | 492/2496 [3:31:02<14:42:09, 26.41s/it]                                                       {'loss': 0.7445, 'learning_rate': 1.8571338821314618e-05, 'epoch': 0.2}
 20%|█▉        | 492/2496 [3:31:02<14:42:09, 26.41s/it] 20%|█▉        | 493/2496 [3:31:28<14:38:38, 26.32s/it]                                                       {'loss': 0.7326, 'learning_rate': 1.856464753169297e-05, 'epoch': 0.2}
 20%|█▉        | 493/2496 [3:31:28<14:38:38, 26.32s/it] 20%|█▉        | 494/2496 [3:31:54<14:36:56, 26.28s/it]                                                       {'loss': 0.7617, 'learning_rate': 1.8557941820266946e-05, 'epoch': 0.2}
 20%|█▉        | 494/2496 [3:31:54<14:36:56, 26.28s/it] 20%|█▉        | 495/2496 [3:32:20<14:25:29, 25.95s/it]                                                       {'loss': 0.743, 'learning_rate': 1.855122169832813e-05, 'epoch': 0.2}
 20%|█▉        | 495/2496 [3:32:20<14:25:29, 25.95s/it] 20%|█▉        | 496/2496 [3:32:44<14:11:59, 25.56s/it]                                                       {'loss': 0.2581, 'learning_rate': 1.854448717719237e-05, 'epoch': 0.2}
 20%|█▉        | 496/2496 [3:32:44<14:11:59, 25.56s/it] 20%|█▉        | 497/2496 [3:33:09<14:08:16, 25.46s/it]                                                       {'loss': 0.7345, 'learning_rate': 1.853773826819978e-05, 'epoch': 0.2}
 20%|█▉        | 497/2496 [3:33:09<14:08:16, 25.46s/it] 20%|█▉        | 498/2496 [3:33:35<14:08:40, 25.49s/it]                                                       {'loss': 0.7115, 'learning_rate': 1.8530974982714667e-05, 'epoch': 0.2}
 20%|█▉        | 498/2496 [3:33:35<14:08:40, 25.49s/it] 20%|█▉        | 499/2496 [3:33:59<13:57:59, 25.18s/it]                                                       {'loss': 0.2746, 'learning_rate': 1.852419733212558e-05, 'epoch': 0.2}
 20%|█▉        | 499/2496 [3:33:59<13:57:59, 25.18s/it] 20%|██        | 500/2496 [3:34:25<14:03:20, 25.35s/it]                                                       {'loss': 0.7319, 'learning_rate': 1.8517405327845227e-05, 'epoch': 0.2}
 20%|██        | 500/2496 [3:34:25<14:03:20, 25.35s/it] 20%|██        | 501/2496 [3:34:51<14:05:44, 25.44s/it]                                                       {'loss': 0.7368, 'learning_rate': 1.8510598981310515e-05, 'epoch': 0.2}
 20%|██        | 501/2496 [3:34:51<14:05:44, 25.44s/it] 20%|██        | 502/2496 [3:35:17<14:12:29, 25.65s/it]                                                       {'loss': 0.7372, 'learning_rate': 1.850377830398248e-05, 'epoch': 0.2}
 20%|██        | 502/2496 [3:35:17<14:12:29, 25.65s/it] 20%|██        | 503/2496 [3:35:41<13:59:30, 25.27s/it]                                                       {'loss': 0.742, 'learning_rate': 1.84969433073463e-05, 'epoch': 0.2}
 20%|██        | 503/2496 [3:35:41<13:59:30, 25.27s/it] 20%|██        | 504/2496 [3:36:08<14:13:05, 25.70s/it]                                                       {'loss': 0.7235, 'learning_rate': 1.8490094002911264e-05, 'epoch': 0.2}
 20%|██        | 504/2496 [3:36:08<14:13:05, 25.70s/it] 20%|██        | 505/2496 [3:36:34<14:15:01, 25.77s/it]                                                       {'loss': 0.7626, 'learning_rate': 1.8483230402210744e-05, 'epoch': 0.2}
 20%|██        | 505/2496 [3:36:34<14:15:01, 25.77s/it]this iter is wrong in something... skip...
 20%|██        | 506/2496 [3:37:00<14:20:48, 25.95s/it]                                                       {'loss': 0.7531, 'learning_rate': 1.8476352516802198e-05, 'epoch': 0.2}
 20%|██        | 506/2496 [3:37:00<14:20:48, 25.95s/it] 20%|██        | 507/2496 [3:37:27<14:25:21, 26.10s/it]                                                       {'loss': 0.7224, 'learning_rate': 1.8469460358267127e-05, 'epoch': 0.2}
 20%|██        | 507/2496 [3:37:27<14:25:21, 26.10s/it] 20%|██        | 508/2496 [3:37:52<14:11:44, 25.71s/it]                                                       {'loss': 0.7362, 'learning_rate': 1.8462553938211077e-05, 'epoch': 0.2}
 20%|██        | 508/2496 [3:37:52<14:11:44, 25.71s/it] 20%|██        | 509/2496 [3:38:19<14:30:50, 26.30s/it]                                                       {'loss': 0.7309, 'learning_rate': 1.84556332682636e-05, 'epoch': 0.2}
 20%|██        | 509/2496 [3:38:19<14:30:50, 26.30s/it] 20%|██        | 510/2496 [3:38:45<14:25:23, 26.14s/it]                                                       {'loss': 0.7002, 'learning_rate': 1.844869836007825e-05, 'epoch': 0.2}
 20%|██        | 510/2496 [3:38:45<14:25:23, 26.14s/it] 20%|██        | 511/2496 [3:39:09<13:59:15, 25.37s/it]                                                       {'loss': 0.6728, 'learning_rate': 1.8441749225332547e-05, 'epoch': 0.2}
 20%|██        | 511/2496 [3:39:09<13:59:15, 25.37s/it]this iter is wrong in something... skip...
 21%|██        | 512/2496 [3:39:32<13:42:23, 24.87s/it]                                                       {'loss': 0.7095, 'learning_rate': 1.8434785875727975e-05, 'epoch': 0.21}
 21%|██        | 512/2496 [3:39:32<13:42:23, 24.87s/it] 21%|██        | 513/2496 [3:39:55<13:16:03, 24.09s/it]                                                       {'loss': 0.7639, 'learning_rate': 1.842780832298995e-05, 'epoch': 0.21}
 21%|██        | 513/2496 [3:39:55<13:16:03, 24.09s/it] 21%|██        | 514/2496 [3:40:22<13:47:17, 25.04s/it]                                                       {'loss': 0.7285, 'learning_rate': 1.8420816578867807e-05, 'epoch': 0.21}
 21%|██        | 514/2496 [3:40:22<13:47:17, 25.04s/it] 21%|██        | 515/2496 [3:40:46<13:38:43, 24.80s/it]                                                       {'loss': 0.7627, 'learning_rate': 1.841381065513477e-05, 'epoch': 0.21}
 21%|██        | 515/2496 [3:40:46<13:38:43, 24.80s/it]this iter is wrong in something... skip...
 21%|██        | 516/2496 [3:41:12<13:49:29, 25.14s/it]                                                       {'loss': 0.7283, 'learning_rate': 1.8406790563587958e-05, 'epoch': 0.21}
 21%|██        | 516/2496 [3:41:12<13:49:29, 25.14s/it] 21%|██        | 517/2496 [3:41:37<13:51:41, 25.22s/it]                                                       {'loss': 0.7172, 'learning_rate': 1.8399756316048324e-05, 'epoch': 0.21}
 21%|██        | 517/2496 [3:41:37<13:51:41, 25.22s/it] 21%|██        | 518/2496 [3:42:03<13:54:52, 25.32s/it]                                                       {'loss': 0.7507, 'learning_rate': 1.8392707924360676e-05, 'epoch': 0.21}
 21%|██        | 518/2496 [3:42:03<13:54:52, 25.32s/it] 21%|██        | 519/2496 [3:42:27<13:43:36, 25.00s/it]                                                       {'loss': 0.7476, 'learning_rate': 1.8385645400393625e-05, 'epoch': 0.21}
 21%|██        | 519/2496 [3:42:27<13:43:36, 25.00s/it] 21%|██        | 520/2496 [3:42:54<14:02:19, 25.58s/it]                                                       {'loss': 0.7257, 'learning_rate': 1.837856875603959e-05, 'epoch': 0.21}
 21%|██        | 520/2496 [3:42:54<14:02:19, 25.58s/it] 21%|██        | 521/2496 [3:43:19<13:58:48, 25.48s/it]                                                       {'loss': 0.6952, 'learning_rate': 1.837147800321476e-05, 'epoch': 0.21}
 21%|██        | 521/2496 [3:43:19<13:58:48, 25.48s/it] 21%|██        | 522/2496 [3:43:45<13:57:26, 25.45s/it]                                                       {'loss': 0.7717, 'learning_rate': 1.8364373153859082e-05, 'epoch': 0.21}
 21%|██        | 522/2496 [3:43:45<13:57:26, 25.45s/it] 21%|██        | 523/2496 [3:44:11<14:02:07, 25.61s/it]                                                       {'loss': 0.7347, 'learning_rate': 1.8357254219936244e-05, 'epoch': 0.21}
 21%|██        | 523/2496 [3:44:11<14:02:07, 25.61s/it] 21%|██        | 524/2496 [3:44:39<14:23:39, 26.28s/it]                                                       {'loss': 0.7155, 'learning_rate': 1.835012121343365e-05, 'epoch': 0.21}
 21%|██        | 524/2496 [3:44:39<14:23:39, 26.28s/it] 21%|██        | 525/2496 [3:45:04<14:12:08, 25.94s/it]                                                       {'loss': 0.7037, 'learning_rate': 1.8342974146362397e-05, 'epoch': 0.21}
 21%|██        | 525/2496 [3:45:04<14:12:08, 25.94s/it] 21%|██        | 526/2496 [3:45:29<14:07:28, 25.81s/it]                                                       {'loss': 0.6859, 'learning_rate': 1.833581303075725e-05, 'epoch': 0.21}
 21%|██        | 526/2496 [3:45:29<14:07:28, 25.81s/it] 21%|██        | 527/2496 [3:45:55<14:02:51, 25.68s/it]                                                       {'loss': 0.7112, 'learning_rate': 1.832863787867666e-05, 'epoch': 0.21}
 21%|██        | 527/2496 [3:45:55<14:02:51, 25.68s/it] 21%|██        | 528/2496 [3:46:19<13:48:40, 25.26s/it]                                                       {'loss': 0.731, 'learning_rate': 1.8321448702202675e-05, 'epoch': 0.21}
 21%|██        | 528/2496 [3:46:19<13:48:40, 25.26s/it] 21%|██        | 529/2496 [3:46:45<13:52:22, 25.39s/it]                                                       {'loss': 0.7325, 'learning_rate': 1.8314245513440986e-05, 'epoch': 0.21}
 21%|██        | 529/2496 [3:46:45<13:52:22, 25.39s/it] 21%|██        | 530/2496 [3:47:10<13:56:44, 25.54s/it]                                                       {'loss': 0.7661, 'learning_rate': 1.8307028324520866e-05, 'epoch': 0.21}
 21%|██        | 530/2496 [3:47:10<13:56:44, 25.54s/it] 21%|██▏       | 531/2496 [3:47:34<13:38:37, 25.00s/it]                                                       {'loss': 0.7334, 'learning_rate': 1.8299797147595165e-05, 'epoch': 0.21}
 21%|██▏       | 531/2496 [3:47:34<13:38:37, 25.00s/it] 21%|██▏       | 532/2496 [3:48:01<13:52:52, 25.44s/it]                                                       {'loss': 0.7049, 'learning_rate': 1.8292551994840292e-05, 'epoch': 0.21}
 21%|██▏       | 532/2496 [3:48:01<13:52:52, 25.44s/it] 21%|██▏       | 533/2496 [3:48:27<14:01:42, 25.73s/it]                                                       {'loss': 0.7725, 'learning_rate': 1.8285292878456186e-05, 'epoch': 0.21}
 21%|██▏       | 533/2496 [3:48:27<14:01:42, 25.73s/it] 21%|██▏       | 534/2496 [3:48:53<14:03:48, 25.80s/it]                                                       {'loss': 0.7282, 'learning_rate': 1.8278019810666295e-05, 'epoch': 0.21}
 21%|██▏       | 534/2496 [3:48:53<14:03:48, 25.80s/it] 21%|██▏       | 535/2496 [3:49:18<13:59:07, 25.67s/it]                                                       {'loss': 0.7384, 'learning_rate': 1.8270732803717565e-05, 'epoch': 0.21}
 21%|██▏       | 535/2496 [3:49:18<13:59:07, 25.67s/it] 21%|██▏       | 536/2496 [3:49:43<13:44:47, 25.25s/it]                                                       {'loss': 0.6937, 'learning_rate': 1.8263431869880414e-05, 'epoch': 0.21}
 21%|██▏       | 536/2496 [3:49:43<13:44:47, 25.25s/it] 22%|██▏       | 537/2496 [3:50:08<13:46:48, 25.32s/it]                                                       {'loss': 0.6856, 'learning_rate': 1.8256117021448707e-05, 'epoch': 0.22}
 22%|██▏       | 537/2496 [3:50:08<13:46:48, 25.32s/it] 22%|██▏       | 538/2496 [3:50:31<13:17:44, 24.45s/it]                                                       {'loss': 0.7152, 'learning_rate': 1.8248788270739744e-05, 'epoch': 0.22}
 22%|██▏       | 538/2496 [3:50:31<13:17:44, 24.45s/it] 22%|██▏       | 539/2496 [3:50:58<13:46:43, 25.35s/it]                                                       {'loss': 0.7064, 'learning_rate': 1.8241445630094227e-05, 'epoch': 0.22}
 22%|██▏       | 539/2496 [3:50:58<13:46:43, 25.35s/it] 22%|██▏       | 540/2496 [3:51:21<13:27:32, 24.77s/it]                                                       {'loss': 0.7525, 'learning_rate': 1.8234089111876256e-05, 'epoch': 0.22}
 22%|██▏       | 540/2496 [3:51:21<13:27:32, 24.77s/it] 22%|██▏       | 541/2496 [3:51:50<13:59:49, 25.77s/it]                                                       {'loss': 0.7128, 'learning_rate': 1.8226718728473297e-05, 'epoch': 0.22}
 22%|██▏       | 541/2496 [3:51:50<13:59:49, 25.77s/it] 22%|██▏       | 542/2496 [3:52:14<13:48:52, 25.45s/it]                                                       {'loss': 0.7372, 'learning_rate': 1.8219334492296162e-05, 'epoch': 0.22}
 22%|██▏       | 542/2496 [3:52:14<13:48:52, 25.45s/it] 22%|██▏       | 543/2496 [3:52:41<14:02:10, 25.87s/it]                                                       {'loss': 0.7509, 'learning_rate': 1.8211936415778986e-05, 'epoch': 0.22}
 22%|██▏       | 543/2496 [3:52:41<14:02:10, 25.87s/it] 22%|██▏       | 544/2496 [3:53:07<14:04:12, 25.95s/it]                                                       {'loss': 0.7366, 'learning_rate': 1.8204524511379212e-05, 'epoch': 0.22}
 22%|██▏       | 544/2496 [3:53:07<14:04:12, 25.95s/it] 22%|██▏       | 545/2496 [3:53:32<13:56:15, 25.72s/it]                                                       {'loss': 0.2591, 'learning_rate': 1.8197098791577568e-05, 'epoch': 0.22}
 22%|██▏       | 545/2496 [3:53:32<13:56:15, 25.72s/it] 22%|██▏       | 546/2496 [3:53:59<14:05:37, 26.02s/it]                                                       {'loss': 0.7387, 'learning_rate': 1.8189659268878047e-05, 'epoch': 0.22}
 22%|██▏       | 546/2496 [3:53:59<14:05:37, 26.02s/it] 22%|██▏       | 547/2496 [3:54:29<14:41:56, 27.15s/it]                                                       {'loss': 0.7146, 'learning_rate': 1.8182205955807885e-05, 'epoch': 0.22}
 22%|██▏       | 547/2496 [3:54:29<14:41:56, 27.15s/it] 22%|██▏       | 548/2496 [3:54:58<15:01:32, 27.77s/it]                                                       {'loss': 0.7511, 'learning_rate': 1.8174738864917538e-05, 'epoch': 0.22}
 22%|██▏       | 548/2496 [3:54:58<15:01:32, 27.77s/it] 22%|██▏       | 549/2496 [3:55:23<14:27:45, 26.74s/it]                                                       {'loss': 0.7002, 'learning_rate': 1.816725800878065e-05, 'epoch': 0.22}
 22%|██▏       | 549/2496 [3:55:23<14:27:45, 26.74s/it] 22%|██▏       | 550/2496 [3:55:48<14:10:39, 26.23s/it]                                                       {'loss': 0.663, 'learning_rate': 1.8159763399994064e-05, 'epoch': 0.22}
 22%|██▏       | 550/2496 [3:55:48<14:10:39, 26.23s/it] 22%|██▏       | 551/2496 [3:56:15<14:22:29, 26.61s/it]                                                       {'loss': 0.7077, 'learning_rate': 1.8152255051177774e-05, 'epoch': 0.22}
 22%|██▏       | 551/2496 [3:56:15<14:22:29, 26.61s/it] 22%|██▏       | 552/2496 [3:56:39<13:57:01, 25.83s/it]                                                       {'loss': 0.6886, 'learning_rate': 1.8144732974974902e-05, 'epoch': 0.22}
 22%|██▏       | 552/2496 [3:56:39<13:57:01, 25.83s/it] 22%|██▏       | 553/2496 [3:57:05<14:02:17, 26.01s/it]                                                       {'loss': 0.7492, 'learning_rate': 1.8137197184051696e-05, 'epoch': 0.22}
 22%|██▏       | 553/2496 [3:57:05<14:02:17, 26.01s/it] 22%|██▏       | 554/2496 [3:57:32<14:11:11, 26.30s/it]                                                       {'loss': 0.7353, 'learning_rate': 1.812964769109749e-05, 'epoch': 0.22}
 22%|██▏       | 554/2496 [3:57:32<14:11:11, 26.30s/it] 22%|██▏       | 555/2496 [3:57:59<14:10:03, 26.28s/it]                                                       {'loss': 0.7254, 'learning_rate': 1.8122084508824692e-05, 'epoch': 0.22}
 22%|██▏       | 555/2496 [3:57:59<14:10:03, 26.28s/it] 22%|██▏       | 556/2496 [3:58:26<14:20:27, 26.61s/it]                                                       {'loss': 0.7135, 'learning_rate': 1.8114507649968774e-05, 'epoch': 0.22}
 22%|██▏       | 556/2496 [3:58:26<14:20:27, 26.61s/it] 22%|██▏       | 557/2496 [3:58:53<14:26:36, 26.82s/it]                                                       {'loss': 0.742, 'learning_rate': 1.8106917127288216e-05, 'epoch': 0.22}
 22%|██▏       | 557/2496 [3:58:53<14:26:36, 26.82s/it] 22%|██▏       | 558/2496 [3:59:19<14:18:24, 26.58s/it]                                                       {'loss': 0.7585, 'learning_rate': 1.809931295356452e-05, 'epoch': 0.22}
 22%|██▏       | 558/2496 [3:59:19<14:18:24, 26.58s/it] 22%|██▏       | 559/2496 [3:59:48<14:34:41, 27.09s/it]                                                       {'loss': 0.7105, 'learning_rate': 1.8091695141602172e-05, 'epoch': 0.22}
 22%|██▏       | 559/2496 [3:59:48<14:34:41, 27.09s/it] 22%|██▏       | 560/2496 [4:00:15<14:33:03, 27.06s/it]                                                       {'loss': 0.6892, 'learning_rate': 1.8084063704228624e-05, 'epoch': 0.22}
 22%|██▏       | 560/2496 [4:00:15<14:33:03, 27.06s/it] 22%|██▏       | 561/2496 [4:00:44<14:53:15, 27.70s/it]                                                       {'loss': 0.7267, 'learning_rate': 1.8076418654294267e-05, 'epoch': 0.22}
 22%|██▏       | 561/2496 [4:00:44<14:53:15, 27.70s/it] 23%|██▎       | 562/2496 [4:01:11<14:51:12, 27.65s/it]                                                       {'loss': 0.7301, 'learning_rate': 1.806876000467242e-05, 'epoch': 0.23}
 23%|██▎       | 562/2496 [4:01:11<14:51:12, 27.65s/it]this iter is wrong in something... skip...
 23%|██▎       | 563/2496 [4:01:37<14:30:19, 27.01s/it]                                                       {'loss': 0.7187, 'learning_rate': 1.8061087768259297e-05, 'epoch': 0.23}
 23%|██▎       | 563/2496 [4:01:37<14:30:19, 27.01s/it] 23%|██▎       | 564/2496 [4:02:01<14:05:44, 26.27s/it]                                                       {'loss': 0.6984, 'learning_rate': 1.8053401957973994e-05, 'epoch': 0.23}
 23%|██▎       | 564/2496 [4:02:01<14:05:44, 26.27s/it] 23%|██▎       | 565/2496 [4:02:30<14:29:07, 27.01s/it]                                                       {'loss': 0.7226, 'learning_rate': 1.8045702586758464e-05, 'epoch': 0.23}
 23%|██▎       | 565/2496 [4:02:30<14:29:07, 27.01s/it] 23%|██▎       | 566/2496 [4:02:55<14:08:56, 26.39s/it]                                                       {'loss': 0.7064, 'learning_rate': 1.803798966757749e-05, 'epoch': 0.23}
 23%|██▎       | 566/2496 [4:02:55<14:08:56, 26.39s/it] 23%|██▎       | 567/2496 [4:03:23<14:25:04, 26.91s/it]                                                       {'loss': 0.7346, 'learning_rate': 1.8030263213418673e-05, 'epoch': 0.23}
 23%|██▎       | 567/2496 [4:03:23<14:25:04, 26.91s/it] 23%|██▎       | 568/2496 [4:03:49<14:15:37, 26.63s/it]                                                       {'loss': 0.7412, 'learning_rate': 1.8022523237292403e-05, 'epoch': 0.23}
 23%|██▎       | 568/2496 [4:03:49<14:15:37, 26.63s/it] 23%|██▎       | 569/2496 [4:04:16<14:19:59, 26.78s/it]                                                       {'loss': 0.7362, 'learning_rate': 1.8014769752231845e-05, 'epoch': 0.23}
 23%|██▎       | 569/2496 [4:04:16<14:19:59, 26.78s/it] 23%|██▎       | 570/2496 [4:04:46<14:47:01, 27.63s/it]                                                       {'loss': 0.7566, 'learning_rate': 1.80070027712929e-05, 'epoch': 0.23}
 23%|██▎       | 570/2496 [4:04:46<14:47:01, 27.63s/it] 23%|██▎       | 571/2496 [4:05:11<14:16:52, 26.71s/it]                                                       {'loss': 0.7314, 'learning_rate': 1.79992223075542e-05, 'epoch': 0.23}
 23%|██▎       | 571/2496 [4:05:11<14:16:52, 26.71s/it] 23%|██▎       | 572/2496 [4:05:38<14:22:01, 26.88s/it]                                                       {'loss': 0.7345, 'learning_rate': 1.7991428374117087e-05, 'epoch': 0.23}
 23%|██▎       | 572/2496 [4:05:38<14:22:01, 26.88s/it] 23%|██▎       | 573/2496 [4:06:03<14:02:26, 26.29s/it]                                                       {'loss': 0.7315, 'learning_rate': 1.798362098410557e-05, 'epoch': 0.23}
 23%|██▎       | 573/2496 [4:06:03<14:02:26, 26.29s/it] 23%|██▎       | 574/2496 [4:06:27<13:46:54, 25.81s/it]                                                       {'loss': 0.7108, 'learning_rate': 1.797580015066634e-05, 'epoch': 0.23}
 23%|██▎       | 574/2496 [4:06:27<13:46:54, 25.81s/it] 23%|██▎       | 575/2496 [4:06:57<14:21:43, 26.92s/it]                                                       {'loss': 0.723, 'learning_rate': 1.7967965886968696e-05, 'epoch': 0.23}
 23%|██▎       | 575/2496 [4:06:57<14:21:43, 26.92s/it] 23%|██▎       | 576/2496 [4:07:22<14:05:44, 26.43s/it]                                                       {'loss': 0.6961, 'learning_rate': 1.7960118206204574e-05, 'epoch': 0.23}
 23%|██▎       | 576/2496 [4:07:22<14:05:44, 26.43s/it] 23%|██▎       | 577/2496 [4:07:48<14:01:01, 26.30s/it]                                                       {'loss': 0.7258, 'learning_rate': 1.7952257121588493e-05, 'epoch': 0.23}
 23%|██▎       | 577/2496 [4:07:48<14:01:01, 26.30s/it] 23%|██▎       | 578/2496 [4:08:15<14:06:37, 26.48s/it]                                                       {'loss': 0.6937, 'learning_rate': 1.7944382646357545e-05, 'epoch': 0.23}
 23%|██▎       | 578/2496 [4:08:15<14:06:37, 26.48s/it] 23%|██▎       | 579/2496 [4:08:42<14:11:19, 26.65s/it]                                                       {'loss': 0.7196, 'learning_rate': 1.793649479377137e-05, 'epoch': 0.23}
 23%|██▎       | 579/2496 [4:08:42<14:11:19, 26.65s/it] 23%|██▎       | 580/2496 [4:09:06<13:43:14, 25.78s/it]                                                       {'loss': 0.7432, 'learning_rate': 1.7928593577112133e-05, 'epoch': 0.23}
 23%|██▎       | 580/2496 [4:09:06<13:43:14, 25.78s/it] 23%|██▎       | 581/2496 [4:09:33<13:52:35, 26.09s/it]                                                       {'loss': 0.7176, 'learning_rate': 1.7920679009684506e-05, 'epoch': 0.23}
 23%|██▎       | 581/2496 [4:09:33<13:52:35, 26.09s/it] 23%|██▎       | 582/2496 [4:10:02<14:21:02, 26.99s/it]                                                       {'loss': 0.759, 'learning_rate': 1.7912751104815636e-05, 'epoch': 0.23}
 23%|██▎       | 582/2496 [4:10:02<14:21:02, 26.99s/it] 23%|██▎       | 583/2496 [4:10:31<14:40:27, 27.62s/it]                                                       {'loss': 0.7434, 'learning_rate': 1.790480987585513e-05, 'epoch': 0.23}
 23%|██▎       | 583/2496 [4:10:31<14:40:27, 27.62s/it] 23%|██▎       | 584/2496 [4:10:56<14:15:08, 26.84s/it]                                                       {'loss': 0.2761, 'learning_rate': 1.7896855336175035e-05, 'epoch': 0.23}
 23%|██▎       | 584/2496 [4:10:56<14:15:08, 26.84s/it] 23%|██▎       | 585/2496 [4:11:22<14:06:28, 26.58s/it]                                                       {'loss': 0.729, 'learning_rate': 1.7888887499169816e-05, 'epoch': 0.23}
 23%|██▎       | 585/2496 [4:11:22<14:06:28, 26.58s/it] 23%|██▎       | 586/2496 [4:11:48<14:03:17, 26.49s/it]                                                       {'loss': 0.7455, 'learning_rate': 1.788090637825631e-05, 'epoch': 0.23}
 23%|██▎       | 586/2496 [4:11:48<14:03:17, 26.49s/it] 24%|██▎       | 587/2496 [4:12:14<13:54:06, 26.22s/it]                                                       {'loss': 0.7144, 'learning_rate': 1.7872911986873743e-05, 'epoch': 0.24}
 24%|██▎       | 587/2496 [4:12:14<13:54:06, 26.22s/it] 24%|██▎       | 588/2496 [4:12:38<13:36:16, 25.67s/it]                                                       {'loss': 0.6581, 'learning_rate': 1.7864904338483676e-05, 'epoch': 0.24}
 24%|██▎       | 588/2496 [4:12:38<13:36:16, 25.67s/it] 24%|██▎       | 589/2496 [4:13:03<13:24:55, 25.33s/it]                                                       {'loss': 0.7642, 'learning_rate': 1.785688344657e-05, 'epoch': 0.24}
 24%|██▎       | 589/2496 [4:13:03<13:24:55, 25.33s/it] 24%|██▎       | 590/2496 [4:13:28<13:29:00, 25.47s/it]                                                       {'loss': 0.6947, 'learning_rate': 1.7848849324638897e-05, 'epoch': 0.24}
 24%|██▎       | 590/2496 [4:13:28<13:29:00, 25.47s/it]this iter is wrong in something... skip...
 24%|██▎       | 591/2496 [4:13:55<13:37:10, 25.74s/it]                                                       {'loss': 0.6753, 'learning_rate': 1.7840801986218834e-05, 'epoch': 0.24}
 24%|██▎       | 591/2496 [4:13:55<13:37:10, 25.74s/it] 24%|██▎       | 592/2496 [4:14:21<13:44:14, 25.97s/it]                                                       {'loss': 0.7381, 'learning_rate': 1.783274144486053e-05, 'epoch': 0.24}
 24%|██▎       | 592/2496 [4:14:21<13:44:14, 25.97s/it] 24%|██▍       | 593/2496 [4:14:47<13:44:44, 26.00s/it]                                                       {'loss': 0.7199, 'learning_rate': 1.782466771413694e-05, 'epoch': 0.24}
 24%|██▍       | 593/2496 [4:14:47<13:44:44, 26.00s/it]this iter is wrong in something... skip...
 24%|██▍       | 594/2496 [4:15:13<13:40:08, 25.87s/it]                                                       {'loss': 0.7381, 'learning_rate': 1.7816580807643222e-05, 'epoch': 0.24}
 24%|██▍       | 594/2496 [4:15:13<13:40:08, 25.87s/it] 24%|██▍       | 595/2496 [4:15:37<13:26:06, 25.44s/it]                                                       {'loss': 0.7325, 'learning_rate': 1.7808480738996727e-05, 'epoch': 0.24}
 24%|██▍       | 595/2496 [4:15:37<13:26:06, 25.44s/it]this iter is wrong in something... skip...
 24%|██▍       | 596/2496 [4:16:02<13:22:06, 25.33s/it]                                                       {'loss': 0.7147, 'learning_rate': 1.7800367521836958e-05, 'epoch': 0.24}
 24%|██▍       | 596/2496 [4:16:02<13:22:06, 25.33s/it] 24%|██▍       | 597/2496 [4:16:30<13:40:22, 25.92s/it]                                                       {'loss': 0.6839, 'learning_rate': 1.779224116982558e-05, 'epoch': 0.24}
 24%|██▍       | 597/2496 [4:16:30<13:40:22, 25.92s/it] 24%|██▍       | 598/2496 [4:16:54<13:23:05, 25.39s/it]                                                       {'loss': 0.6972, 'learning_rate': 1.7784101696646355e-05, 'epoch': 0.24}
 24%|██▍       | 598/2496 [4:16:54<13:23:05, 25.39s/it] 24%|██▍       | 599/2496 [4:17:19<13:22:48, 25.39s/it]                                                       {'loss': 0.7367, 'learning_rate': 1.7775949116005144e-05, 'epoch': 0.24}
 24%|██▍       | 599/2496 [4:17:19<13:22:48, 25.39s/it] 24%|██▍       | 600/2496 [4:17:44<13:11:38, 25.05s/it]                                                       {'loss': 0.7593, 'learning_rate': 1.7767783441629883e-05, 'epoch': 0.24}
 24%|██▍       | 600/2496 [4:17:44<13:11:38, 25.05s/it] 24%|██▍       | 601/2496 [4:18:09<13:14:20, 25.15s/it]                                                       {'loss': 0.7424, 'learning_rate': 1.775960468727056e-05, 'epoch': 0.24}
 24%|██▍       | 601/2496 [4:18:09<13:14:20, 25.15s/it] 24%|██▍       | 602/2496 [4:18:33<13:01:05, 24.74s/it]                                                       {'loss': 0.719, 'learning_rate': 1.775141286669918e-05, 'epoch': 0.24}
 24%|██▍       | 602/2496 [4:18:33<13:01:05, 24.74s/it] 24%|██▍       | 603/2496 [4:18:58<13:03:31, 24.83s/it]                                                       {'loss': 0.7308, 'learning_rate': 1.774320799370975e-05, 'epoch': 0.24}
 24%|██▍       | 603/2496 [4:18:58<13:03:31, 24.83s/it] 24%|██▍       | 604/2496 [4:19:22<13:00:17, 24.74s/it]                                                       {'loss': 0.7424, 'learning_rate': 1.7734990082118263e-05, 'epoch': 0.24}
 24%|██▍       | 604/2496 [4:19:22<13:00:17, 24.74s/it] 24%|██▍       | 605/2496 [4:19:49<13:15:11, 25.23s/it]                                                       {'loss': 0.7527, 'learning_rate': 1.7726759145762656e-05, 'epoch': 0.24}
 24%|██▍       | 605/2496 [4:19:49<13:15:11, 25.23s/it] 24%|██▍       | 606/2496 [4:20:14<13:17:16, 25.31s/it]                                                       {'loss': 0.7289, 'learning_rate': 1.7718515198502816e-05, 'epoch': 0.24}
 24%|██▍       | 606/2496 [4:20:14<13:17:16, 25.31s/it] 24%|██▍       | 607/2496 [4:20:40<13:20:53, 25.44s/it]                                                       {'loss': 0.726, 'learning_rate': 1.771025825422052e-05, 'epoch': 0.24}
 24%|██▍       | 607/2496 [4:20:40<13:20:53, 25.44s/it] 24%|██▍       | 608/2496 [4:21:05<13:19:07, 25.40s/it]                                                       {'loss': 0.7387, 'learning_rate': 1.770198832681944e-05, 'epoch': 0.24}
 24%|██▍       | 608/2496 [4:21:05<13:19:07, 25.40s/it] 24%|██▍       | 609/2496 [4:21:31<13:22:27, 25.52s/it]                                                       {'loss': 0.7181, 'learning_rate': 1.7693705430225114e-05, 'epoch': 0.24}
 24%|██▍       | 609/2496 [4:21:31<13:22:27, 25.52s/it] 24%|██▍       | 610/2496 [4:21:56<13:18:57, 25.42s/it]                                                       {'loss': 0.7461, 'learning_rate': 1.76854095783849e-05, 'epoch': 0.24}
 24%|██▍       | 610/2496 [4:21:56<13:18:57, 25.42s/it] 24%|██▍       | 611/2496 [4:22:20<13:05:57, 25.02s/it]                                                       {'loss': 0.7254, 'learning_rate': 1.7677100785268e-05, 'epoch': 0.24}
 24%|██▍       | 611/2496 [4:22:20<13:05:57, 25.02s/it] 25%|██▍       | 612/2496 [4:22:46<13:10:24, 25.17s/it]                                                       {'loss': 0.7401, 'learning_rate': 1.7668779064865375e-05, 'epoch': 0.25}
 25%|██▍       | 612/2496 [4:22:46<13:10:24, 25.17s/it] 25%|██▍       | 613/2496 [4:23:11<13:11:51, 25.23s/it]                                                       {'loss': 0.736, 'learning_rate': 1.766044443118978e-05, 'epoch': 0.25}
 25%|██▍       | 613/2496 [4:23:11<13:11:51, 25.23s/it] 25%|██▍       | 614/2496 [4:23:36<13:03:09, 24.97s/it]                                                       {'loss': 0.7341, 'learning_rate': 1.7652096898275702e-05, 'epoch': 0.25}
 25%|██▍       | 614/2496 [4:23:36<13:03:09, 24.97s/it] 25%|██▍       | 615/2496 [4:24:00<13:01:53, 24.94s/it]                                                       {'loss': 0.7273, 'learning_rate': 1.7643736480179353e-05, 'epoch': 0.25}
 25%|██▍       | 615/2496 [4:24:00<13:01:53, 24.94s/it] 25%|██▍       | 616/2496 [4:24:26<13:05:06, 25.06s/it]                                                       {'loss': 0.7632, 'learning_rate': 1.763536319097864e-05, 'epoch': 0.25}
 25%|██▍       | 616/2496 [4:24:26<13:05:06, 25.06s/it] 25%|██▍       | 617/2496 [4:24:50<12:53:18, 24.69s/it]                                                       {'loss': 0.7063, 'learning_rate': 1.762697704477314e-05, 'epoch': 0.25}
 25%|██▍       | 617/2496 [4:24:50<12:53:18, 24.69s/it] 25%|██▍       | 618/2496 [4:25:14<12:48:12, 24.54s/it]                                                       {'loss': 0.7258, 'learning_rate': 1.761857805568409e-05, 'epoch': 0.25}
 25%|██▍       | 618/2496 [4:25:14<12:48:12, 24.54s/it] 25%|██▍       | 619/2496 [4:25:41<13:08:54, 25.22s/it]                                                       {'loss': 0.6801, 'learning_rate': 1.761016623785434e-05, 'epoch': 0.25}
 25%|██▍       | 619/2496 [4:25:41<13:08:54, 25.22s/it] 25%|██▍       | 620/2496 [4:26:06<13:14:38, 25.41s/it]                                                       {'loss': 0.6833, 'learning_rate': 1.760174160544835e-05, 'epoch': 0.25}
 25%|██▍       | 620/2496 [4:26:06<13:14:38, 25.41s/it] 25%|██▍       | 621/2496 [4:26:33<13:23:40, 25.72s/it]                                                       {'loss': 0.7629, 'learning_rate': 1.7593304172652156e-05, 'epoch': 0.25}
 25%|██▍       | 621/2496 [4:26:33<13:23:40, 25.72s/it] 25%|██▍       | 622/2496 [4:26:55<12:53:09, 24.75s/it]                                                       {'loss': 0.7554, 'learning_rate': 1.7584853953673348e-05, 'epoch': 0.25}
 25%|██▍       | 622/2496 [4:26:55<12:53:09, 24.75s/it] 25%|██▍       | 623/2496 [4:27:20<12:54:40, 24.82s/it]                                                       {'loss': 0.2765, 'learning_rate': 1.757639096274105e-05, 'epoch': 0.25}
 25%|██▍       | 623/2496 [4:27:20<12:54:40, 24.82s/it] 25%|██▌       | 624/2496 [4:27:45<12:54:33, 24.83s/it]                                                       {'loss': 0.7602, 'learning_rate': 1.7567915214105883e-05, 'epoch': 0.25}
 25%|██▌       | 624/2496 [4:27:45<12:54:33, 24.83s/it] 25%|██▌       | 625/2496 [4:28:12<13:14:47, 25.49s/it]                                                       {'loss': 0.7009, 'learning_rate': 1.7559426722039966e-05, 'epoch': 0.25}
 25%|██▌       | 625/2496 [4:28:12<13:14:47, 25.49s/it] 25%|██▌       | 626/2496 [4:28:36<12:56:56, 24.93s/it]                                                       {'loss': 0.6811, 'learning_rate': 1.7550925500836856e-05, 'epoch': 0.25}
 25%|██▌       | 626/2496 [4:28:36<12:56:56, 24.93s/it] 25%|██▌       | 627/2496 [4:29:01<12:55:07, 24.88s/it]                                                       {'loss': 0.2631, 'learning_rate': 1.7542411564811564e-05, 'epoch': 0.25}
 25%|██▌       | 627/2496 [4:29:01<12:55:07, 24.88s/it] 25%|██▌       | 628/2496 [4:29:29<13:25:16, 25.87s/it]                                                       {'loss': 0.7292, 'learning_rate': 1.7533884928300505e-05, 'epoch': 0.25}
 25%|██▌       | 628/2496 [4:29:29<13:25:16, 25.87s/it] 25%|██▌       | 629/2496 [4:29:54<13:19:54, 25.71s/it]                                                       {'loss': 0.7165, 'learning_rate': 1.7525345605661466e-05, 'epoch': 0.25}
 25%|██▌       | 629/2496 [4:29:54<13:19:54, 25.71s/it] 25%|██▌       | 630/2496 [4:30:17<12:54:30, 24.90s/it]                                                       {'loss': 0.7336, 'learning_rate': 1.7516793611273614e-05, 'epoch': 0.25}
 25%|██▌       | 630/2496 [4:30:17<12:54:30, 24.90s/it] 25%|██▌       | 631/2496 [4:30:43<12:59:01, 25.06s/it]                                                       {'loss': 0.7142, 'learning_rate': 1.7508228959537445e-05, 'epoch': 0.25}
 25%|██▌       | 631/2496 [4:30:43<12:59:01, 25.06s/it] 25%|██▌       | 632/2496 [4:31:08<12:57:51, 25.04s/it]                                                       {'loss': 0.7265, 'learning_rate': 1.749965166487478e-05, 'epoch': 0.25}
 25%|██▌       | 632/2496 [4:31:08<12:57:51, 25.04s/it] 25%|██▌       | 633/2496 [4:31:34<13:05:49, 25.31s/it]                                                       {'loss': 0.694, 'learning_rate': 1.7491061741728703e-05, 'epoch': 0.25}
 25%|██▌       | 633/2496 [4:31:34<13:05:49, 25.31s/it] 25%|██▌       | 634/2496 [4:31:58<12:56:51, 25.03s/it]                                                       {'loss': 0.7385, 'learning_rate': 1.7482459204563592e-05, 'epoch': 0.25}
 25%|██▌       | 634/2496 [4:31:58<12:56:51, 25.03s/it] 25%|██▌       | 635/2496 [4:32:22<12:45:19, 24.67s/it]                                                       {'loss': 0.6765, 'learning_rate': 1.7473844067865044e-05, 'epoch': 0.25}
 25%|██▌       | 635/2496 [4:32:22<12:45:19, 24.67s/it] 25%|██▌       | 636/2496 [4:32:45<12:34:25, 24.34s/it]                                                       {'loss': 0.7161, 'learning_rate': 1.746521634613989e-05, 'epoch': 0.25}
 25%|██▌       | 636/2496 [4:32:45<12:34:25, 24.34s/it] 26%|██▌       | 637/2496 [4:33:10<12:40:03, 24.53s/it]                                                       {'loss': 0.2486, 'learning_rate': 1.745657605391614e-05, 'epoch': 0.26}
 26%|██▌       | 637/2496 [4:33:10<12:40:03, 24.53s/it] 26%|██▌       | 638/2496 [4:33:34<12:32:48, 24.31s/it]                                                       {'loss': 0.7098, 'learning_rate': 1.7447923205742974e-05, 'epoch': 0.26}
 26%|██▌       | 638/2496 [4:33:34<12:32:48, 24.31s/it] 26%|██▌       | 639/2496 [4:34:01<12:55:50, 25.07s/it]                                                       {'loss': 0.7541, 'learning_rate': 1.7439257816190712e-05, 'epoch': 0.26}
 26%|██▌       | 639/2496 [4:34:01<12:55:50, 25.07s/it] 26%|██▌       | 640/2496 [4:34:27<13:02:41, 25.30s/it]                                                       {'loss': 0.7072, 'learning_rate': 1.7430579899850803e-05, 'epoch': 0.26}
 26%|██▌       | 640/2496 [4:34:27<13:02:41, 25.30s/it] 26%|██▌       | 641/2496 [4:34:53<13:10:23, 25.57s/it]                                                       {'loss': 0.726, 'learning_rate': 1.7421889471335773e-05, 'epoch': 0.26}
 26%|██▌       | 641/2496 [4:34:53<13:10:23, 25.57s/it] 26%|██▌       | 642/2496 [4:35:19<13:14:33, 25.71s/it]                                                       {'loss': 0.7057, 'learning_rate': 1.741318654527923e-05, 'epoch': 0.26}
 26%|██▌       | 642/2496 [4:35:19<13:14:33, 25.71s/it] 26%|██▌       | 643/2496 [4:35:46<13:26:22, 26.11s/it]                                                       {'loss': 0.7357, 'learning_rate': 1.7404471136335828e-05, 'epoch': 0.26}
 26%|██▌       | 643/2496 [4:35:46<13:26:22, 26.11s/it] 26%|██▌       | 644/2496 [4:36:10<13:10:44, 25.62s/it]                                                       {'loss': 0.2478, 'learning_rate': 1.7395743259181227e-05, 'epoch': 0.26}
 26%|██▌       | 644/2496 [4:36:10<13:10:44, 25.62s/it] 26%|██▌       | 645/2496 [4:36:35<13:01:54, 25.35s/it]                                                       {'loss': 0.7383, 'learning_rate': 1.7387002928512093e-05, 'epoch': 0.26}
 26%|██▌       | 645/2496 [4:36:35<13:01:54, 25.35s/it] 26%|██▌       | 646/2496 [4:36:59<12:50:29, 24.99s/it]                                                       {'loss': 0.7156, 'learning_rate': 1.7378250159046058e-05, 'epoch': 0.26}
 26%|██▌       | 646/2496 [4:36:59<12:50:29, 24.99s/it] 26%|██▌       | 647/2496 [4:37:26<13:03:52, 25.44s/it]                                                       {'loss': 0.6785, 'learning_rate': 1.73694849655217e-05, 'epoch': 0.26}
 26%|██▌       | 647/2496 [4:37:26<13:03:52, 25.44s/it] 26%|██▌       | 648/2496 [4:37:53<13:15:00, 25.81s/it]                                                       {'loss': 0.7501, 'learning_rate': 1.736070736269852e-05, 'epoch': 0.26}
 26%|██▌       | 648/2496 [4:37:53<13:15:00, 25.81s/it] 26%|██▌       | 649/2496 [4:38:18<13:15:02, 25.83s/it]                                                       {'loss': 0.7056, 'learning_rate': 1.735191736535691e-05, 'epoch': 0.26}
 26%|██▌       | 649/2496 [4:38:18<13:15:02, 25.83s/it] 26%|██▌       | 650/2496 [4:38:44<13:15:20, 25.85s/it]                                                       {'loss': 0.7113, 'learning_rate': 1.734311498829814e-05, 'epoch': 0.26}
 26%|██▌       | 650/2496 [4:38:44<13:15:20, 25.85s/it] 26%|██▌       | 651/2496 [4:39:11<13:25:02, 26.18s/it]                                                       {'loss': 0.737, 'learning_rate': 1.7334300246344318e-05, 'epoch': 0.26}
 26%|██▌       | 651/2496 [4:39:11<13:25:02, 26.18s/it] 26%|██▌       | 652/2496 [4:39:35<12:58:19, 25.33s/it]                                                       {'loss': 0.721, 'learning_rate': 1.7325473154338376e-05, 'epoch': 0.26}
 26%|██▌       | 652/2496 [4:39:35<12:58:19, 25.33s/it] 26%|██▌       | 653/2496 [4:39:59<12:51:11, 25.11s/it]                                                       {'loss': 0.7227, 'learning_rate': 1.7316633727144043e-05, 'epoch': 0.26}
 26%|██▌       | 653/2496 [4:39:59<12:51:11, 25.11s/it] 26%|██▌       | 654/2496 [4:40:22<12:34:01, 24.56s/it]                                                       {'loss': 0.7253, 'learning_rate': 1.7307781979645817e-05, 'epoch': 0.26}
 26%|██▌       | 654/2496 [4:40:22<12:34:01, 24.56s/it] 26%|██▌       | 655/2496 [4:40:49<12:54:58, 25.26s/it]                                                       {'loss': 0.7119, 'learning_rate': 1.7298917926748947e-05, 'epoch': 0.26}
 26%|██▌       | 655/2496 [4:40:49<12:54:58, 25.26s/it] 26%|██▋       | 656/2496 [4:41:14<12:49:26, 25.09s/it]                                                       {'loss': 0.2431, 'learning_rate': 1.7290041583379395e-05, 'epoch': 0.26}
 26%|██▋       | 656/2496 [4:41:14<12:49:26, 25.09s/it] 26%|██▋       | 657/2496 [4:41:40<12:55:01, 25.29s/it]                                                       {'loss': 0.7244, 'learning_rate': 1.7281152964483825e-05, 'epoch': 0.26}
 26%|██▋       | 657/2496 [4:41:40<12:55:01, 25.29s/it] 26%|██▋       | 658/2496 [4:42:04<12:43:30, 24.92s/it]                                                       {'loss': 0.7813, 'learning_rate': 1.7272252085029568e-05, 'epoch': 0.26}
 26%|██▋       | 658/2496 [4:42:04<12:43:30, 24.92s/it] 26%|██▋       | 659/2496 [4:42:28<12:32:54, 24.59s/it]                                                       {'loss': 0.7303, 'learning_rate': 1.72633389600046e-05, 'epoch': 0.26}
 26%|██▋       | 659/2496 [4:42:28<12:32:54, 24.59s/it] 26%|██▋       | 660/2496 [4:42:53<12:40:48, 24.86s/it]                                                       {'loss': 0.7583, 'learning_rate': 1.725441360441752e-05, 'epoch': 0.26}
 26%|██▋       | 660/2496 [4:42:53<12:40:48, 24.86s/it] 26%|██▋       | 661/2496 [4:43:18<12:43:29, 24.96s/it]                                                       {'loss': 0.2394, 'learning_rate': 1.724547603329752e-05, 'epoch': 0.26}
 26%|██▋       | 661/2496 [4:43:18<12:43:29, 24.96s/it] 27%|██▋       | 662/2496 [4:43:43<12:38:19, 24.81s/it]                                                       {'loss': 0.6956, 'learning_rate': 1.723652626169436e-05, 'epoch': 0.27}
 27%|██▋       | 662/2496 [4:43:43<12:38:19, 24.81s/it] 27%|██▋       | 663/2496 [4:44:12<13:13:43, 25.98s/it]                                                       {'loss': 0.7175, 'learning_rate': 1.7227564304678346e-05, 'epoch': 0.27}
 27%|██▋       | 663/2496 [4:44:12<13:13:43, 25.98s/it] 27%|██▋       | 664/2496 [4:44:36<12:55:29, 25.40s/it]                                                       {'loss': 0.7622, 'learning_rate': 1.7218590177340307e-05, 'epoch': 0.27}
 27%|██▋       | 664/2496 [4:44:36<12:55:29, 25.40s/it] 27%|██▋       | 665/2496 [4:45:04<13:26:41, 26.43s/it]                                                       {'loss': 0.7084, 'learning_rate': 1.7209603894791552e-05, 'epoch': 0.27}
 27%|██▋       | 665/2496 [4:45:04<13:26:41, 26.43s/it] 27%|██▋       | 666/2496 [4:45:30<13:14:01, 26.03s/it]                                                       {'loss': 0.7272, 'learning_rate': 1.7200605472163873e-05, 'epoch': 0.27}
 27%|██▋       | 666/2496 [4:45:30<13:14:01, 26.03s/it] 27%|██▋       | 667/2496 [4:45:53<12:54:00, 25.39s/it]                                                       {'loss': 0.7302, 'learning_rate': 1.7191594924609493e-05, 'epoch': 0.27}
 27%|██▋       | 667/2496 [4:45:53<12:54:00, 25.39s/it] 27%|██▋       | 668/2496 [4:46:19<12:52:03, 25.34s/it]                                                       {'loss': 0.7373, 'learning_rate': 1.7182572267301064e-05, 'epoch': 0.27}
 27%|██▋       | 668/2496 [4:46:19<12:52:03, 25.34s/it] 27%|██▋       | 669/2496 [4:46:45<12:59:46, 25.61s/it]                                                       {'loss': 0.7202, 'learning_rate': 1.7173537515431612e-05, 'epoch': 0.27}
 27%|██▋       | 669/2496 [4:46:45<12:59:46, 25.61s/it] 27%|██▋       | 670/2496 [4:47:07<12:31:49, 24.70s/it]                                                       {'loss': 0.7137, 'learning_rate': 1.7164490684214547e-05, 'epoch': 0.27}
 27%|██▋       | 670/2496 [4:47:07<12:31:49, 24.70s/it] 27%|██▋       | 671/2496 [4:47:33<12:36:20, 24.87s/it]                                                       {'loss': 0.6875, 'learning_rate': 1.715543178888361e-05, 'epoch': 0.27}
 27%|██▋       | 671/2496 [4:47:33<12:36:20, 24.87s/it] 27%|██▋       | 672/2496 [4:47:56<12:25:46, 24.53s/it]                                                       {'loss': 0.7339, 'learning_rate': 1.7146360844692852e-05, 'epoch': 0.27}
 27%|██▋       | 672/2496 [4:47:56<12:25:46, 24.53s/it] 27%|██▋       | 673/2496 [4:48:21<12:26:34, 24.57s/it]                                                       {'loss': 0.2304, 'learning_rate': 1.7137277866916625e-05, 'epoch': 0.27}
 27%|██▋       | 673/2496 [4:48:21<12:26:34, 24.57s/it] 27%|██▋       | 674/2496 [4:48:46<12:31:12, 24.74s/it]                                                       {'loss': 0.7112, 'learning_rate': 1.7128182870849532e-05, 'epoch': 0.27}
 27%|██▋       | 674/2496 [4:48:46<12:31:12, 24.74s/it] 27%|██▋       | 675/2496 [4:49:12<12:44:13, 25.18s/it]                                                       {'loss': 0.6839, 'learning_rate': 1.711907587180642e-05, 'epoch': 0.27}
 27%|██▋       | 675/2496 [4:49:12<12:44:13, 25.18s/it] 27%|██▋       | 676/2496 [4:49:36<12:32:47, 24.82s/it]                                                       {'loss': 0.723, 'learning_rate': 1.710995688512235e-05, 'epoch': 0.27}
 27%|██▋       | 676/2496 [4:49:36<12:32:47, 24.82s/it] 27%|██▋       | 677/2496 [4:50:04<12:58:25, 25.68s/it]                                                       {'loss': 0.7141, 'learning_rate': 1.7100825926152556e-05, 'epoch': 0.27}
 27%|██▋       | 677/2496 [4:50:04<12:58:25, 25.68s/it] 27%|██▋       | 678/2496 [4:50:31<13:13:20, 26.18s/it]                                                       {'loss': 0.6912, 'learning_rate': 1.7091683010272447e-05, 'epoch': 0.27}
 27%|██▋       | 678/2496 [4:50:31<13:13:20, 26.18s/it] 27%|██▋       | 679/2496 [4:50:57<13:05:45, 25.95s/it]                                                       {'loss': 0.73, 'learning_rate': 1.708252815287756e-05, 'epoch': 0.27}
 27%|██▋       | 679/2496 [4:50:57<13:05:45, 25.95s/it] 27%|██▋       | 680/2496 [4:51:23<13:11:12, 26.14s/it]                                                       {'loss': 0.6924, 'learning_rate': 1.7073361369383538e-05, 'epoch': 0.27}
 27%|██▋       | 680/2496 [4:51:23<13:11:12, 26.14s/it] 27%|██▋       | 681/2496 [4:51:51<13:19:38, 26.43s/it]                                                       {'loss': 0.7558, 'learning_rate': 1.706418267522611e-05, 'epoch': 0.27}
 27%|██▋       | 681/2496 [4:51:51<13:19:38, 26.43s/it] 27%|██▋       | 682/2496 [4:52:18<13:32:16, 26.87s/it]                                                       {'loss': 0.6968, 'learning_rate': 1.7054992085861053e-05, 'epoch': 0.27}
 27%|██▋       | 682/2496 [4:52:18<13:32:16, 26.87s/it] 27%|██▋       | 683/2496 [4:52:43<13:08:56, 26.11s/it]                                                       {'loss': 0.743, 'learning_rate': 1.7045789616764183e-05, 'epoch': 0.27}
 27%|██▋       | 683/2496 [4:52:43<13:08:56, 26.11s/it] 27%|██▋       | 684/2496 [4:53:06<12:44:40, 25.32s/it]                                                       {'loss': 0.698, 'learning_rate': 1.703657528343132e-05, 'epoch': 0.27}
 27%|██▋       | 684/2496 [4:53:06<12:44:40, 25.32s/it] 27%|██▋       | 685/2496 [4:53:33<12:56:01, 25.71s/it]                                                       {'loss': 0.7404, 'learning_rate': 1.7027349101378256e-05, 'epoch': 0.27}
 27%|██▋       | 685/2496 [4:53:33<12:56:01, 25.71s/it] 27%|██▋       | 686/2496 [4:53:56<12:31:40, 24.92s/it]                                                       {'loss': 0.7243, 'learning_rate': 1.7018111086140732e-05, 'epoch': 0.27}
 27%|██▋       | 686/2496 [4:53:56<12:31:40, 24.92s/it] 28%|██▊       | 687/2496 [4:54:23<12:51:26, 25.59s/it]                                                       {'loss': 0.7297, 'learning_rate': 1.700886125327443e-05, 'epoch': 0.28}
 28%|██▊       | 687/2496 [4:54:23<12:51:26, 25.59s/it] 28%|██▊       | 688/2496 [4:54:47<12:38:25, 25.17s/it]                                                       {'loss': 0.7034, 'learning_rate': 1.6999599618354915e-05, 'epoch': 0.28}
 28%|██▊       | 688/2496 [4:54:47<12:38:25, 25.17s/it] 28%|██▊       | 689/2496 [4:55:13<12:40:49, 25.26s/it]                                                       {'loss': 0.741, 'learning_rate': 1.6990326196977637e-05, 'epoch': 0.28}
 28%|██▊       | 689/2496 [4:55:13<12:40:49, 25.26s/it] 28%|██▊       | 690/2496 [4:55:37<12:28:06, 24.85s/it]                                                       {'loss': 0.7155, 'learning_rate': 1.698104100475788e-05, 'epoch': 0.28}
 28%|██▊       | 690/2496 [4:55:37<12:28:06, 24.85s/it] 28%|██▊       | 691/2496 [4:56:03<12:44:03, 25.40s/it]                                                       {'loss': 0.712, 'learning_rate': 1.6971744057330764e-05, 'epoch': 0.28}
 28%|██▊       | 691/2496 [4:56:03<12:44:03, 25.40s/it] 28%|██▊       | 692/2496 [4:56:30<12:56:06, 25.81s/it]                                                       {'loss': 0.7122, 'learning_rate': 1.696243537035119e-05, 'epoch': 0.28}
 28%|██▊       | 692/2496 [4:56:30<12:56:06, 25.81s/it]this iter is wrong in something... skip...
 28%|██▊       | 693/2496 [4:56:55<12:47:58, 25.56s/it]                                                       {'loss': 0.7375, 'learning_rate': 1.6953114959493834e-05, 'epoch': 0.28}
 28%|██▊       | 693/2496 [4:56:55<12:47:58, 25.56s/it] 28%|██▊       | 694/2496 [4:57:20<12:38:56, 25.27s/it]                                                       {'loss': 0.2542, 'learning_rate': 1.6943782840453117e-05, 'epoch': 0.28}
 28%|██▊       | 694/2496 [4:57:20<12:38:56, 25.27s/it] 28%|██▊       | 695/2496 [4:57:43<12:20:46, 24.68s/it]                                                       {'loss': 0.7086, 'learning_rate': 1.693443902894316e-05, 'epoch': 0.28}
 28%|██▊       | 695/2496 [4:57:43<12:20:46, 24.68s/it] 28%|██▊       | 696/2496 [4:58:07<12:15:22, 24.51s/it]                                                       {'loss': 0.7058, 'learning_rate': 1.692508354069779e-05, 'epoch': 0.28}
 28%|██▊       | 696/2496 [4:58:07<12:15:22, 24.51s/it] 28%|██▊       | 697/2496 [4:58:34<12:33:05, 25.12s/it]                                                       {'loss': 0.6857, 'learning_rate': 1.691571639147049e-05, 'epoch': 0.28}
 28%|██▊       | 697/2496 [4:58:34<12:33:05, 25.12s/it] 28%|██▊       | 698/2496 [4:59:02<12:58:00, 25.96s/it]                                                       {'loss': 0.731, 'learning_rate': 1.6906337597034377e-05, 'epoch': 0.28}
 28%|██▊       | 698/2496 [4:59:02<12:58:00, 25.96s/it] 28%|██▊       | 699/2496 [4:59:26<12:45:17, 25.55s/it]                                                       {'loss': 0.7416, 'learning_rate': 1.6896947173182177e-05, 'epoch': 0.28}
 28%|██▊       | 699/2496 [4:59:26<12:45:17, 25.55s/it]this iter is wrong in something... skip...
 28%|██▊       | 700/2496 [4:59:52<12:47:24, 25.64s/it]                                                       {'loss': 0.6872, 'learning_rate': 1.6887545135726195e-05, 'epoch': 0.28}
 28%|██▊       | 700/2496 [4:59:52<12:47:24, 25.64s/it] 28%|██▊       | 701/2496 [5:00:17<12:39:20, 25.38s/it]                                                       {'loss': 0.7118, 'learning_rate': 1.6878131500498302e-05, 'epoch': 0.28}
 28%|██▊       | 701/2496 [5:00:17<12:39:20, 25.38s/it] 28%|██▊       | 702/2496 [5:00:40<12:22:18, 24.83s/it]                                                       {'loss': 0.7365, 'learning_rate': 1.6868706283349888e-05, 'epoch': 0.28}
 28%|██▊       | 702/2496 [5:00:40<12:22:18, 24.83s/it] 28%|██▊       | 703/2496 [5:01:04<12:15:32, 24.61s/it]                                                       {'loss': 0.7436, 'learning_rate': 1.6859269500151856e-05, 'epoch': 0.28}
 28%|██▊       | 703/2496 [5:01:04<12:15:32, 24.61s/it] 28%|██▊       | 704/2496 [5:01:29<12:10:47, 24.47s/it]                                                       {'loss': 0.7087, 'learning_rate': 1.684982116679457e-05, 'epoch': 0.28}
 28%|██▊       | 704/2496 [5:01:29<12:10:47, 24.47s/it] 28%|██▊       | 705/2496 [5:01:52<11:59:37, 24.11s/it]                                                       {'loss': 0.6879, 'learning_rate': 1.684036129918786e-05, 'epoch': 0.28}
 28%|██▊       | 705/2496 [5:01:52<11:59:37, 24.11s/it] 28%|██▊       | 706/2496 [5:02:18<12:17:05, 24.71s/it]                                                       {'loss': 0.737, 'learning_rate': 1.6830889913260968e-05, 'epoch': 0.28}
 28%|██▊       | 706/2496 [5:02:18<12:17:05, 24.71s/it]this iter is wrong in something... skip...
 28%|██▊       | 707/2496 [5:02:43<12:21:24, 24.87s/it]                                                       {'loss': 0.7325, 'learning_rate': 1.682140702496253e-05, 'epoch': 0.28}
 28%|██▊       | 707/2496 [5:02:43<12:21:24, 24.87s/it] 28%|██▊       | 708/2496 [5:03:10<12:37:31, 25.42s/it]                                                       {'loss': 0.7015, 'learning_rate': 1.6811912650260557e-05, 'epoch': 0.28}
 28%|██▊       | 708/2496 [5:03:10<12:37:31, 25.42s/it] 28%|██▊       | 709/2496 [5:03:35<12:34:02, 25.32s/it]                                                       {'loss': 0.7316, 'learning_rate': 1.6802406805142394e-05, 'epoch': 0.28}
 28%|██▊       | 709/2496 [5:03:35<12:34:02, 25.32s/it] 28%|██▊       | 710/2496 [5:04:03<12:58:24, 26.15s/it]                                                       {'loss': 0.709, 'learning_rate': 1.6792889505614715e-05, 'epoch': 0.28}
 28%|██▊       | 710/2496 [5:04:03<12:58:24, 26.15s/it] 28%|██▊       | 711/2496 [5:04:27<12:41:39, 25.60s/it]                                                       {'loss': 0.7117, 'learning_rate': 1.678336076770346e-05, 'epoch': 0.28}
 28%|██▊       | 711/2496 [5:04:27<12:41:39, 25.60s/it] 29%|██▊       | 712/2496 [5:04:51<12:26:08, 25.09s/it]                                                       {'loss': 0.6836, 'learning_rate': 1.6773820607453852e-05, 'epoch': 0.29}
 29%|██▊       | 712/2496 [5:04:51<12:26:08, 25.09s/it] 29%|██▊       | 713/2496 [5:05:16<12:26:13, 25.11s/it]                                                       {'loss': 0.7567, 'learning_rate': 1.6764269040930333e-05, 'epoch': 0.29}
 29%|██▊       | 713/2496 [5:05:16<12:26:13, 25.11s/it] 29%|██▊       | 714/2496 [5:05:44<12:45:47, 25.78s/it]                                                       {'loss': 0.7273, 'learning_rate': 1.6754706084216556e-05, 'epoch': 0.29}
 29%|██▊       | 714/2496 [5:05:44<12:45:47, 25.78s/it] 29%|██▊       | 715/2496 [5:06:08<12:34:27, 25.42s/it]                                                       {'loss': 0.7442, 'learning_rate': 1.674513175341536e-05, 'epoch': 0.29}
 29%|██▊       | 715/2496 [5:06:08<12:34:27, 25.42s/it] 29%|██▊       | 716/2496 [5:06:31<12:11:39, 24.66s/it]                                                       {'loss': 0.725, 'learning_rate': 1.6735546064648724e-05, 'epoch': 0.29}
 29%|██▊       | 716/2496 [5:06:31<12:11:39, 24.66s/it] 29%|██▊       | 717/2496 [5:06:56<12:08:11, 24.56s/it]                                                       {'loss': 0.7275, 'learning_rate': 1.672594903405776e-05, 'epoch': 0.29}
 29%|██▊       | 717/2496 [5:06:56<12:08:11, 24.56s/it] 29%|██▉       | 718/2496 [5:07:22<12:26:39, 25.20s/it]                                                       {'loss': 0.7378, 'learning_rate': 1.6716340677802684e-05, 'epoch': 0.29}
 29%|██▉       | 718/2496 [5:07:22<12:26:39, 25.20s/it] 29%|██▉       | 719/2496 [5:07:50<12:46:51, 25.89s/it]                                                       {'loss': 0.7155, 'learning_rate': 1.670672101206277e-05, 'epoch': 0.29}
 29%|██▉       | 719/2496 [5:07:50<12:46:51, 25.89s/it] 29%|██▉       | 720/2496 [5:08:14<12:34:53, 25.50s/it]                                                       {'loss': 0.7273, 'learning_rate': 1.6697090053036344e-05, 'epoch': 0.29}
 29%|██▉       | 720/2496 [5:08:14<12:34:53, 25.50s/it] 29%|██▉       | 721/2496 [5:08:41<12:41:21, 25.74s/it]                                                       {'loss': 0.7028, 'learning_rate': 1.6687447816940744e-05, 'epoch': 0.29}
 29%|██▉       | 721/2496 [5:08:41<12:41:21, 25.74s/it] 29%|██▉       | 722/2496 [5:09:05<12:28:12, 25.31s/it]                                                       {'loss': 0.7135, 'learning_rate': 1.6677794320012305e-05, 'epoch': 0.29}
 29%|██▉       | 722/2496 [5:09:05<12:28:12, 25.31s/it] 29%|██▉       | 723/2496 [5:09:30<12:26:54, 25.28s/it]                                                       {'loss': 0.6648, 'learning_rate': 1.6668129578506315e-05, 'epoch': 0.29}
 29%|██▉       | 723/2496 [5:09:30<12:26:54, 25.28s/it] 29%|██▉       | 724/2496 [5:09:53<12:08:25, 24.66s/it]                                                       {'loss': 0.7305, 'learning_rate': 1.6658453608697e-05, 'epoch': 0.29}
 29%|██▉       | 724/2496 [5:09:53<12:08:25, 24.66s/it] 29%|██▉       | 725/2496 [5:10:18<12:11:13, 24.77s/it]                                                       {'loss': 0.6832, 'learning_rate': 1.66487664268775e-05, 'epoch': 0.29}
 29%|██▉       | 725/2496 [5:10:18<12:11:13, 24.77s/it] 29%|██▉       | 726/2496 [5:10:45<12:24:39, 25.24s/it]                                                       {'loss': 0.7074, 'learning_rate': 1.663906804935982e-05, 'epoch': 0.29}
 29%|██▉       | 726/2496 [5:10:45<12:24:39, 25.24s/it] 29%|██▉       | 727/2496 [5:11:10<12:21:25, 25.15s/it]                                                       {'loss': 0.2558, 'learning_rate': 1.6629358492474827e-05, 'epoch': 0.29}
 29%|██▉       | 727/2496 [5:11:10<12:21:25, 25.15s/it] 29%|██▉       | 728/2496 [5:11:34<12:16:17, 24.99s/it]                                                       {'loss': 0.2388, 'learning_rate': 1.661963777257221e-05, 'epoch': 0.29}
 29%|██▉       | 728/2496 [5:11:34<12:16:17, 24.99s/it] 29%|██▉       | 729/2496 [5:12:02<12:35:45, 25.66s/it]                                                       {'loss': 0.698, 'learning_rate': 1.660990590602046e-05, 'epoch': 0.29}
 29%|██▉       | 729/2496 [5:12:02<12:35:45, 25.66s/it] 29%|██▉       | 730/2496 [5:12:29<12:51:49, 26.22s/it]                                                       {'loss': 0.6779, 'learning_rate': 1.6600162909206833e-05, 'epoch': 0.29}
 29%|██▉       | 730/2496 [5:12:29<12:51:49, 26.22s/it] 29%|██▉       | 731/2496 [5:13:00<13:28:33, 27.49s/it]                                                       {'loss': 0.6723, 'learning_rate': 1.6590408798537317e-05, 'epoch': 0.29}
 29%|██▉       | 731/2496 [5:13:00<13:28:33, 27.49s/it] 29%|██▉       | 732/2496 [5:13:27<13:28:40, 27.51s/it]                                                       {'loss': 0.7108, 'learning_rate': 1.658064359043664e-05, 'epoch': 0.29}
 29%|██▉       | 732/2496 [5:13:27<13:28:40, 27.51s/it] 29%|██▉       | 733/2496 [5:13:51<12:55:52, 26.41s/it]                                                       {'loss': 0.7377, 'learning_rate': 1.6570867301348194e-05, 'epoch': 0.29}
 29%|██▉       | 733/2496 [5:13:51<12:55:52, 26.41s/it] 29%|██▉       | 734/2496 [5:14:18<13:03:29, 26.68s/it]                                                       {'loss': 0.7173, 'learning_rate': 1.6561079947734037e-05, 'epoch': 0.29}
 29%|██▉       | 734/2496 [5:14:18<13:03:29, 26.68s/it] 29%|██▉       | 735/2496 [5:14:43<12:50:16, 26.24s/it]                                                       {'loss': 0.7249, 'learning_rate': 1.6551281546074863e-05, 'epoch': 0.29}
 29%|██▉       | 735/2496 [5:14:43<12:50:16, 26.24s/it] 29%|██▉       | 736/2496 [5:15:10<12:49:47, 26.24s/it]                                                       {'loss': 0.7294, 'learning_rate': 1.654147211286996e-05, 'epoch': 0.29}
 29%|██▉       | 736/2496 [5:15:10<12:49:47, 26.24s/it] 30%|██▉       | 737/2496 [5:15:38<13:09:02, 26.91s/it]                                                       {'loss': 0.712, 'learning_rate': 1.6531651664637198e-05, 'epoch': 0.3}
 30%|██▉       | 737/2496 [5:15:38<13:09:02, 26.91s/it] 30%|██▉       | 738/2496 [5:16:04<13:01:29, 26.67s/it]                                                       {'loss': 0.7044, 'learning_rate': 1.6521820217912998e-05, 'epoch': 0.3}
 30%|██▉       | 738/2496 [5:16:04<13:01:29, 26.67s/it] 30%|██▉       | 739/2496 [5:16:30<12:52:42, 26.39s/it]                                                       {'loss': 0.7068, 'learning_rate': 1.651197778925229e-05, 'epoch': 0.3}
 30%|██▉       | 739/2496 [5:16:30<12:52:42, 26.39s/it] 30%|██▉       | 740/2496 [5:16:56<12:52:49, 26.41s/it]                                                       {'loss': 0.726, 'learning_rate': 1.6502124395228512e-05, 'epoch': 0.3}
 30%|██▉       | 740/2496 [5:16:56<12:52:49, 26.41s/it] 30%|██▉       | 741/2496 [5:17:22<12:45:35, 26.17s/it]                                                       {'loss': 0.7033, 'learning_rate': 1.6492260052433554e-05, 'epoch': 0.3}
 30%|██▉       | 741/2496 [5:17:22<12:45:35, 26.17s/it] 30%|██▉       | 742/2496 [5:17:45<12:19:16, 25.29s/it]                                                       {'loss': 0.714, 'learning_rate': 1.6482384777477745e-05, 'epoch': 0.3}
 30%|██▉       | 742/2496 [5:17:45<12:19:16, 25.29s/it] 30%|██▉       | 743/2496 [5:18:10<12:15:16, 25.17s/it]                                                       {'loss': 0.6938, 'learning_rate': 1.6472498586989824e-05, 'epoch': 0.3}
 30%|██▉       | 743/2496 [5:18:10<12:15:16, 25.17s/it] 30%|██▉       | 744/2496 [5:18:33<11:56:25, 24.54s/it]                                                       {'loss': 0.7534, 'learning_rate': 1.6462601497616905e-05, 'epoch': 0.3}
 30%|██▉       | 744/2496 [5:18:33<11:56:25, 24.54s/it] 30%|██▉       | 745/2496 [5:19:00<12:10:59, 25.05s/it]                                                       {'loss': 0.6863, 'learning_rate': 1.645269352602447e-05, 'epoch': 0.3}
 30%|██▉       | 745/2496 [5:19:00<12:10:59, 25.05s/it] 30%|██▉       | 746/2496 [5:19:23<11:52:37, 24.43s/it]                                                       {'loss': 0.7177, 'learning_rate': 1.6442774688896307e-05, 'epoch': 0.3}
 30%|██▉       | 746/2496 [5:19:23<11:52:37, 24.43s/it] 30%|██▉       | 747/2496 [5:19:47<11:54:02, 24.50s/it]                                                       {'loss': 0.7293, 'learning_rate': 1.6432845002934508e-05, 'epoch': 0.3}
 30%|██▉       | 747/2496 [5:19:47<11:54:02, 24.50s/it] 30%|██▉       | 748/2496 [5:20:14<12:16:13, 25.27s/it]                                                       {'loss': 0.7438, 'learning_rate': 1.6422904484859436e-05, 'epoch': 0.3}
 30%|██▉       | 748/2496 [5:20:14<12:16:13, 25.27s/it] 30%|███       | 749/2496 [5:20:40<12:18:28, 25.36s/it]                                                       {'loss': 0.7219, 'learning_rate': 1.641295315140969e-05, 'epoch': 0.3}
 30%|███       | 749/2496 [5:20:40<12:18:28, 25.36s/it] 30%|███       | 750/2496 [5:21:04<12:06:07, 24.95s/it]                                                       {'loss': 0.7323, 'learning_rate': 1.6402991019342073e-05, 'epoch': 0.3}
 30%|███       | 750/2496 [5:21:04<12:06:07, 24.95s/it] 30%|███       | 751/2496 [5:21:27<11:50:10, 24.42s/it]                                                       {'loss': 0.7081, 'learning_rate': 1.6393018105431597e-05, 'epoch': 0.3}
 30%|███       | 751/2496 [5:21:27<11:50:10, 24.42s/it] 30%|███       | 752/2496 [5:21:53<12:00:28, 24.79s/it]                                                       {'loss': 0.6902, 'learning_rate': 1.6383034426471394e-05, 'epoch': 0.3}
 30%|███       | 752/2496 [5:21:53<12:00:28, 24.79s/it] 30%|███       | 753/2496 [5:22:17<11:59:42, 24.78s/it]                                                       {'loss': 0.7113, 'learning_rate': 1.6373039999272754e-05, 'epoch': 0.3}
 30%|███       | 753/2496 [5:22:17<11:59:42, 24.78s/it] 30%|███       | 754/2496 [5:22:43<12:07:17, 25.05s/it]                                                       {'loss': 0.6891, 'learning_rate': 1.636303484066505e-05, 'epoch': 0.3}
 30%|███       | 754/2496 [5:22:43<12:07:17, 25.05s/it] 30%|███       | 755/2496 [5:23:08<12:06:30, 25.04s/it]                                                       {'loss': 0.7168, 'learning_rate': 1.6353018967495727e-05, 'epoch': 0.3}
 30%|███       | 755/2496 [5:23:08<12:06:30, 25.04s/it] 30%|███       | 756/2496 [5:23:31<11:48:07, 24.42s/it]                                                       {'loss': 0.7073, 'learning_rate': 1.6342992396630276e-05, 'epoch': 0.3}
 30%|███       | 756/2496 [5:23:31<11:48:07, 24.42s/it] 30%|███       | 757/2496 [5:23:56<11:56:36, 24.72s/it]                                                       {'loss': 0.6851, 'learning_rate': 1.6332955144952194e-05, 'epoch': 0.3}
 30%|███       | 757/2496 [5:23:56<11:56:36, 24.72s/it] 30%|███       | 758/2496 [5:24:20<11:45:22, 24.35s/it]                                                       {'loss': 0.7477, 'learning_rate': 1.632290722936297e-05, 'epoch': 0.3}
 30%|███       | 758/2496 [5:24:20<11:45:22, 24.35s/it] 30%|███       | 759/2496 [5:24:47<12:04:20, 25.02s/it]                                                       {'loss': 0.7468, 'learning_rate': 1.631284866678205e-05, 'epoch': 0.3}
 30%|███       | 759/2496 [5:24:47<12:04:20, 25.02s/it]this iter is wrong in something... skip...
 30%|███       | 760/2496 [5:25:11<11:56:51, 24.78s/it]                                                       {'loss': 0.6922, 'learning_rate': 1.6302779474146806e-05, 'epoch': 0.3}
 30%|███       | 760/2496 [5:25:11<11:56:51, 24.78s/it] 30%|███       | 761/2496 [5:25:34<11:47:12, 24.46s/it]                                                       {'loss': 0.7282, 'learning_rate': 1.629269966841251e-05, 'epoch': 0.3}
 30%|███       | 761/2496 [5:25:34<11:47:12, 24.46s/it] 31%|███       | 762/2496 [5:26:01<12:02:24, 25.00s/it]                                                       {'loss': 0.7141, 'learning_rate': 1.62826092665523e-05, 'epoch': 0.31}
 31%|███       | 762/2496 [5:26:01<12:02:24, 25.00s/it] 31%|███       | 763/2496 [5:26:26<12:05:53, 25.13s/it]                                                       {'loss': 0.7138, 'learning_rate': 1.6272508285557167e-05, 'epoch': 0.31}
 31%|███       | 763/2496 [5:26:26<12:05:53, 25.13s/it] 31%|███       | 764/2496 [5:26:54<12:27:28, 25.89s/it]                                                       {'loss': 0.7123, 'learning_rate': 1.626239674243591e-05, 'epoch': 0.31}
 31%|███       | 764/2496 [5:26:54<12:27:28, 25.89s/it]this iter is wrong in something... skip...
 31%|███       | 765/2496 [5:27:18<12:15:03, 25.48s/it]                                                       {'loss': 0.7624, 'learning_rate': 1.625227465421511e-05, 'epoch': 0.31}
 31%|███       | 765/2496 [5:27:18<12:15:03, 25.48s/it] 31%|███       | 766/2496 [5:27:44<12:13:53, 25.45s/it]                                                       {'loss': 0.7464, 'learning_rate': 1.624214203793911e-05, 'epoch': 0.31}
 31%|███       | 766/2496 [5:27:44<12:13:53, 25.45s/it] 31%|███       | 767/2496 [5:28:10<12:21:11, 25.72s/it]                                                       {'loss': 0.7069, 'learning_rate': 1.623199891066998e-05, 'epoch': 0.31}
 31%|███       | 767/2496 [5:28:10<12:21:11, 25.72s/it] 31%|███       | 768/2496 [5:28:35<12:10:25, 25.36s/it]                                                       {'loss': 0.711, 'learning_rate': 1.6221845289487493e-05, 'epoch': 0.31}
 31%|███       | 768/2496 [5:28:35<12:10:25, 25.36s/it] 31%|███       | 769/2496 [5:28:58<11:52:21, 24.75s/it]                                                       {'loss': 0.7176, 'learning_rate': 1.6211681191489078e-05, 'epoch': 0.31}
 31%|███       | 769/2496 [5:28:58<11:52:21, 24.75s/it] 31%|███       | 770/2496 [5:29:22<11:46:51, 24.57s/it]                                                       {'loss': 0.7177, 'learning_rate': 1.6201506633789825e-05, 'epoch': 0.31}
 31%|███       | 770/2496 [5:29:22<11:46:51, 24.57s/it] 31%|███       | 771/2496 [5:29:46<11:41:47, 24.41s/it]                                                       {'loss': 0.7144, 'learning_rate': 1.6191321633522422e-05, 'epoch': 0.31}
 31%|███       | 771/2496 [5:29:46<11:41:47, 24.41s/it] 31%|███       | 772/2496 [5:30:13<12:04:33, 25.22s/it]                                                       {'loss': 0.6715, 'learning_rate': 1.6181126207837146e-05, 'epoch': 0.31}
 31%|███       | 772/2496 [5:30:13<12:04:33, 25.22s/it]this iter is wrong in something... skip...
 31%|███       | 773/2496 [5:30:39<12:08:23, 25.36s/it]                                                       {'loss': 0.6787, 'learning_rate': 1.617092037390183e-05, 'epoch': 0.31}
 31%|███       | 773/2496 [5:30:39<12:08:23, 25.36s/it] 31%|███       | 774/2496 [5:31:05<12:12:18, 25.52s/it]                                                       {'loss': 0.7197, 'learning_rate': 1.6160704148901836e-05, 'epoch': 0.31}
 31%|███       | 774/2496 [5:31:05<12:12:18, 25.52s/it] 31%|███       | 775/2496 [5:31:29<11:58:16, 25.04s/it]                                                       {'loss': 0.6921, 'learning_rate': 1.6150477550040022e-05, 'epoch': 0.31}
 31%|███       | 775/2496 [5:31:29<11:58:16, 25.04s/it] 31%|███       | 776/2496 [5:31:54<12:01:34, 25.17s/it]                                                       {'loss': 0.7338, 'learning_rate': 1.6140240594536706e-05, 'epoch': 0.31}
 31%|███       | 776/2496 [5:31:54<12:01:34, 25.17s/it] 31%|███       | 777/2496 [5:32:21<12:13:31, 25.60s/it]                                                       {'loss': 0.7233, 'learning_rate': 1.6129993299629652e-05, 'epoch': 0.31}
 31%|███       | 777/2496 [5:32:21<12:13:31, 25.60s/it] 31%|███       | 778/2496 [5:32:47<12:17:29, 25.76s/it]                                                       {'loss': 0.7034, 'learning_rate': 1.611973568257404e-05, 'epoch': 0.31}
 31%|███       | 778/2496 [5:32:47<12:17:29, 25.76s/it] 31%|███       | 779/2496 [5:33:12<12:11:22, 25.56s/it]                                                       {'loss': 0.732, 'learning_rate': 1.6109467760642422e-05, 'epoch': 0.31}
 31%|███       | 779/2496 [5:33:12<12:11:22, 25.56s/it] 31%|███▏      | 780/2496 [5:33:37<12:08:18, 25.47s/it]                                                       {'loss': 0.6989, 'learning_rate': 1.60991895511247e-05, 'epoch': 0.31}
 31%|███▏      | 780/2496 [5:33:37<12:08:18, 25.47s/it] 31%|███▏      | 781/2496 [5:34:02<12:05:02, 25.37s/it]                                                       {'loss': 0.6865, 'learning_rate': 1.608890107132811e-05, 'epoch': 0.31}
 31%|███▏      | 781/2496 [5:34:02<12:05:02, 25.37s/it] 31%|███▏      | 782/2496 [5:34:28<12:03:10, 25.32s/it]                                                       {'loss': 0.7328, 'learning_rate': 1.6078602338577176e-05, 'epoch': 0.31}
 31%|███▏      | 782/2496 [5:34:28<12:03:10, 25.32s/it] 31%|███▏      | 783/2496 [5:34:51<11:50:28, 24.89s/it]                                                       {'loss': 0.7033, 'learning_rate': 1.6068293370213687e-05, 'epoch': 0.31}
 31%|███▏      | 783/2496 [5:34:51<11:50:28, 24.89s/it] 31%|███▏      | 784/2496 [5:35:17<11:56:19, 25.10s/it]                                                       {'loss': 0.7116, 'learning_rate': 1.605797418359666e-05, 'epoch': 0.31}
 31%|███▏      | 784/2496 [5:35:17<11:56:19, 25.10s/it] 31%|███▏      | 785/2496 [5:35:43<12:04:12, 25.40s/it]                                                       {'loss': 0.6877, 'learning_rate': 1.6047644796102336e-05, 'epoch': 0.31}
 31%|███▏      | 785/2496 [5:35:43<12:04:12, 25.40s/it] 31%|███▏      | 786/2496 [5:36:09<12:06:07, 25.48s/it]                                                       {'loss': 0.6897, 'learning_rate': 1.6037305225124122e-05, 'epoch': 0.31}
 31%|███▏      | 786/2496 [5:36:09<12:06:07, 25.48s/it] 32%|███▏      | 787/2496 [5:36:37<12:28:50, 26.29s/it]                                                       {'loss': 0.6897, 'learning_rate': 1.6026955488072566e-05, 'epoch': 0.32}
 32%|███▏      | 787/2496 [5:36:37<12:28:50, 26.29s/it] 32%|███▏      | 788/2496 [5:37:04<12:32:09, 26.42s/it]                                                       {'loss': 0.7098, 'learning_rate': 1.6016595602375346e-05, 'epoch': 0.32}
 32%|███▏      | 788/2496 [5:37:04<12:32:09, 26.42s/it] 32%|███▏      | 789/2496 [5:37:29<12:25:24, 26.20s/it]                                                       {'loss': 0.7287, 'learning_rate': 1.6006225585477224e-05, 'epoch': 0.32}
 32%|███▏      | 789/2496 [5:37:29<12:25:24, 26.20s/it] 32%|███▏      | 790/2496 [5:37:54<12:13:15, 25.79s/it]                                                       {'loss': 0.3144, 'learning_rate': 1.5995845454840023e-05, 'epoch': 0.32}
 32%|███▏      | 790/2496 [5:37:54<12:13:15, 25.79s/it] 32%|███▏      | 791/2496 [5:38:18<11:54:30, 25.14s/it]                                                       {'loss': 0.7309, 'learning_rate': 1.5985455227942592e-05, 'epoch': 0.32}
 32%|███▏      | 791/2496 [5:38:18<11:54:30, 25.14s/it] 32%|███▏      | 792/2496 [5:38:43<11:56:11, 25.22s/it]                                                       {'loss': 0.6943, 'learning_rate': 1.5975054922280793e-05, 'epoch': 0.32}
 32%|███▏      | 792/2496 [5:38:43<11:56:11, 25.22s/it]this iter is wrong in something... skip...
 32%|███▏      | 793/2496 [5:39:09<11:56:01, 25.23s/it]                                                       {'loss': 0.7105, 'learning_rate': 1.5964644555367445e-05, 'epoch': 0.32}
 32%|███▏      | 793/2496 [5:39:09<11:56:01, 25.23s/it] 32%|███▏      | 794/2496 [5:39:34<11:54:34, 25.19s/it]                                                       {'loss': 0.7199, 'learning_rate': 1.5954224144732316e-05, 'epoch': 0.32}
 32%|███▏      | 794/2496 [5:39:34<11:54:34, 25.19s/it] 32%|███▏      | 795/2496 [5:39:57<11:38:16, 24.63s/it]                                                       {'loss': 0.7813, 'learning_rate': 1.5943793707922086e-05, 'epoch': 0.32}
 32%|███▏      | 795/2496 [5:39:57<11:38:16, 24.63s/it] 32%|███▏      | 796/2496 [5:40:21<11:33:15, 24.47s/it]                                                       {'loss': 0.7196, 'learning_rate': 1.593335326250032e-05, 'epoch': 0.32}
 32%|███▏      | 796/2496 [5:40:21<11:33:15, 24.47s/it] 32%|███▏      | 797/2496 [5:40:45<11:25:22, 24.20s/it]                                                       {'loss': 0.7479, 'learning_rate': 1.5922902826047423e-05, 'epoch': 0.32}
 32%|███▏      | 797/2496 [5:40:45<11:25:22, 24.20s/it] 32%|███▏      | 798/2496 [5:41:10<11:36:19, 24.61s/it]                                                       {'loss': 0.7102, 'learning_rate': 1.5912442416160645e-05, 'epoch': 0.32}
 32%|███▏      | 798/2496 [5:41:10<11:36:19, 24.61s/it] 32%|███▏      | 799/2496 [5:41:37<11:53:05, 25.21s/it]                                                       {'loss': 0.7076, 'learning_rate': 1.5901972050454017e-05, 'epoch': 0.32}
 32%|███▏      | 799/2496 [5:41:37<11:53:05, 25.21s/it] 32%|███▏      | 800/2496 [5:42:02<11:56:18, 25.34s/it]                                                       {'loss': 0.6794, 'learning_rate': 1.589149174655833e-05, 'epoch': 0.32}
 32%|███▏      | 800/2496 [5:42:02<11:56:18, 25.34s/it] 32%|███▏      | 801/2496 [5:42:28<11:53:23, 25.25s/it]                                                       {'loss': 0.6978, 'learning_rate': 1.5881001522121126e-05, 'epoch': 0.32}
 32%|███▏      | 801/2496 [5:42:28<11:53:23, 25.25s/it] 32%|███▏      | 802/2496 [5:42:52<11:42:32, 24.88s/it]                                                       {'loss': 0.6829, 'learning_rate': 1.5870501394806633e-05, 'epoch': 0.32}
 32%|███▏      | 802/2496 [5:42:52<11:42:32, 24.88s/it] 32%|███▏      | 803/2496 [5:43:17<11:47:17, 25.07s/it]                                                       {'loss': 0.6555, 'learning_rate': 1.585999138229577e-05, 'epoch': 0.32}
 32%|███▏      | 803/2496 [5:43:17<11:47:17, 25.07s/it] 32%|███▏      | 804/2496 [5:43:44<12:01:54, 25.60s/it]                                                       {'loss': 0.7487, 'learning_rate': 1.5849471502286088e-05, 'epoch': 0.32}
 32%|███▏      | 804/2496 [5:43:44<12:01:54, 25.60s/it] 32%|███▏      | 805/2496 [5:44:09<12:00:54, 25.58s/it]                                                       {'loss': 0.7538, 'learning_rate': 1.583894177249177e-05, 'epoch': 0.32}
 32%|███▏      | 805/2496 [5:44:09<12:00:54, 25.58s/it] 32%|███▏      | 806/2496 [5:44:35<12:03:35, 25.69s/it]                                                       {'loss': 0.7239, 'learning_rate': 1.5828402210643566e-05, 'epoch': 0.32}
 32%|███▏      | 806/2496 [5:44:35<12:03:35, 25.69s/it] 32%|███▏      | 807/2496 [5:44:59<11:44:10, 25.02s/it]                                                       {'loss': 0.751, 'learning_rate': 1.5817852834488798e-05, 'epoch': 0.32}
 32%|███▏      | 807/2496 [5:44:59<11:44:10, 25.02s/it] 32%|███▏      | 808/2496 [5:45:23<11:39:33, 24.87s/it]                                                       {'loss': 0.6866, 'learning_rate': 1.58072936617913e-05, 'epoch': 0.32}
 32%|███▏      | 808/2496 [5:45:23<11:39:33, 24.87s/it] 32%|███▏      | 809/2496 [5:45:48<11:35:01, 24.72s/it]                                                       {'loss': 0.7444, 'learning_rate': 1.5796724710331418e-05, 'epoch': 0.32}
 32%|███▏      | 809/2496 [5:45:48<11:35:01, 24.72s/it] 32%|███▏      | 810/2496 [5:46:14<11:43:45, 25.04s/it]                                                       {'loss': 0.7062, 'learning_rate': 1.5786145997905952e-05, 'epoch': 0.32}
 32%|███▏      | 810/2496 [5:46:14<11:43:45, 25.04s/it] 32%|███▏      | 811/2496 [5:46:39<11:42:57, 25.03s/it]                                                       {'loss': 0.7219, 'learning_rate': 1.577555754232814e-05, 'epoch': 0.32}
 32%|███▏      | 811/2496 [5:46:39<11:42:57, 25.03s/it] 33%|███▎      | 812/2496 [5:47:04<11:44:15, 25.09s/it]                                                       {'loss': 0.7101, 'learning_rate': 1.5764959361427624e-05, 'epoch': 0.33}
 33%|███▎      | 812/2496 [5:47:04<11:44:15, 25.09s/it] 33%|███▎      | 813/2496 [5:47:30<11:50:36, 25.33s/it]                                                       {'loss': 0.6827, 'learning_rate': 1.5754351473050434e-05, 'epoch': 0.33}
 33%|███▎      | 813/2496 [5:47:30<11:50:36, 25.33s/it] 33%|███▎      | 814/2496 [5:47:53<11:34:46, 24.78s/it]                                                       {'loss': 0.7309, 'learning_rate': 1.574373389505894e-05, 'epoch': 0.33}
 33%|███▎      | 814/2496 [5:47:53<11:34:46, 24.78s/it]this iter is wrong in something... skip...
 33%|███▎      | 815/2496 [5:48:18<11:37:45, 24.90s/it]                                                       {'loss': 0.7236, 'learning_rate': 1.573310664533182e-05, 'epoch': 0.33}
 33%|███▎      | 815/2496 [5:48:18<11:37:45, 24.90s/it] 33%|███▎      | 816/2496 [5:48:43<11:39:34, 24.98s/it]                                                       {'loss': 0.6852, 'learning_rate': 1.5722469741764047e-05, 'epoch': 0.33}
 33%|███▎      | 816/2496 [5:48:43<11:39:34, 24.98s/it] 33%|███▎      | 817/2496 [5:49:07<11:27:43, 24.58s/it]                                                       {'loss': 0.7226, 'learning_rate': 1.5711823202266854e-05, 'epoch': 0.33}
 33%|███▎      | 817/2496 [5:49:07<11:27:43, 24.58s/it] 33%|███▎      | 818/2496 [5:49:32<11:26:57, 24.56s/it]                                                       {'loss': 0.7065, 'learning_rate': 1.570116704476768e-05, 'epoch': 0.33}
 33%|███▎      | 818/2496 [5:49:32<11:26:57, 24.56s/it] 33%|███▎      | 819/2496 [5:49:55<11:20:14, 24.34s/it]                                                       {'loss': 0.7283, 'learning_rate': 1.5690501287210188e-05, 'epoch': 0.33}
 33%|███▎      | 819/2496 [5:49:55<11:20:14, 24.34s/it] 33%|███▎      | 820/2496 [5:50:18<11:08:33, 23.93s/it]                                                       {'loss': 0.7583, 'learning_rate': 1.5679825947554176e-05, 'epoch': 0.33}
 33%|███▎      | 820/2496 [5:50:18<11:08:33, 23.93s/it] 33%|███▎      | 821/2496 [5:50:41<10:57:21, 23.55s/it]                                                       {'loss': 0.7506, 'learning_rate': 1.5669141043775606e-05, 'epoch': 0.33}
 33%|███▎      | 821/2496 [5:50:41<10:57:21, 23.55s/it] 33%|███▎      | 822/2496 [5:51:07<11:15:45, 24.22s/it]                                                       {'loss': 0.7227, 'learning_rate': 1.5658446593866517e-05, 'epoch': 0.33}
 33%|███▎      | 822/2496 [5:51:07<11:15:45, 24.22s/it] 33%|███▎      | 823/2496 [5:51:32<11:22:28, 24.48s/it]                                                       {'loss': 0.7046, 'learning_rate': 1.564774261583505e-05, 'epoch': 0.33}
 33%|███▎      | 823/2496 [5:51:32<11:22:28, 24.48s/it] 33%|███▎      | 824/2496 [5:51:58<11:33:26, 24.88s/it]                                                       {'loss': 0.694, 'learning_rate': 1.563702912770537e-05, 'epoch': 0.33}
 33%|███▎      | 824/2496 [5:51:58<11:33:26, 24.88s/it] 33%|███▎      | 825/2496 [5:52:22<11:27:57, 24.70s/it]                                                       {'loss': 0.6856, 'learning_rate': 1.5626306147517665e-05, 'epoch': 0.33}
 33%|███▎      | 825/2496 [5:52:22<11:27:57, 24.70s/it] 33%|███▎      | 826/2496 [5:52:48<11:39:30, 25.13s/it]                                                       {'loss': 0.69, 'learning_rate': 1.56155736933281e-05, 'epoch': 0.33}
 33%|███▎      | 826/2496 [5:52:48<11:39:30, 25.13s/it] 33%|███▎      | 827/2496 [5:53:14<11:44:28, 25.33s/it]                                                       {'loss': 0.7008, 'learning_rate': 1.5604831783208796e-05, 'epoch': 0.33}
 33%|███▎      | 827/2496 [5:53:14<11:44:28, 25.33s/it] 33%|███▎      | 828/2496 [5:53:40<11:46:34, 25.42s/it]                                                       {'loss': 0.7267, 'learning_rate': 1.55940804352478e-05, 'epoch': 0.33}
 33%|███▎      | 828/2496 [5:53:40<11:46:34, 25.42s/it] 33%|███▎      | 829/2496 [5:54:04<11:37:55, 25.12s/it]                                                       {'loss': 0.737, 'learning_rate': 1.5583319667549057e-05, 'epoch': 0.33}
 33%|███▎      | 829/2496 [5:54:04<11:37:55, 25.12s/it] 33%|███▎      | 830/2496 [5:54:28<11:26:17, 24.72s/it]                                                       {'loss': 0.7026, 'learning_rate': 1.5572549498232353e-05, 'epoch': 0.33}
 33%|███▎      | 830/2496 [5:54:28<11:26:17, 24.72s/it] 33%|███▎      | 831/2496 [5:54:53<11:31:38, 24.92s/it]                                                       {'loss': 0.7341, 'learning_rate': 1.5561769945433326e-05, 'epoch': 0.33}
 33%|███▎      | 831/2496 [5:54:53<11:31:38, 24.92s/it] 33%|███▎      | 832/2496 [5:55:18<11:33:06, 24.99s/it]                                                       {'loss': 0.3633, 'learning_rate': 1.55509810273034e-05, 'epoch': 0.33}
 33%|███▎      | 832/2496 [5:55:18<11:33:06, 24.99s/it] 33%|███▎      | 833/2496 [5:55:43<11:29:03, 24.86s/it]                                                       {'loss': 0.7277, 'learning_rate': 1.5540182762009774e-05, 'epoch': 0.33}
 33%|███▎      | 833/2496 [5:55:43<11:29:03, 24.86s/it] 33%|███▎      | 834/2496 [5:56:09<11:36:06, 25.13s/it]                                                       {'loss': 0.6739, 'learning_rate': 1.5529375167735396e-05, 'epoch': 0.33}
 33%|███▎      | 834/2496 [5:56:09<11:36:06, 25.13s/it] 33%|███▎      | 835/2496 [5:56:34<11:36:24, 25.16s/it]                                                       {'loss': 0.7371, 'learning_rate': 1.551855826267891e-05, 'epoch': 0.33}
 33%|███▎      | 835/2496 [5:56:34<11:36:24, 25.16s/it] 33%|███▎      | 836/2496 [5:56:56<11:11:44, 24.28s/it]                                                       {'loss': 0.7469, 'learning_rate': 1.5507732065054642e-05, 'epoch': 0.33}
 33%|███▎      | 836/2496 [5:56:56<11:11:44, 24.28s/it] 34%|███▎      | 837/2496 [5:57:20<11:06:33, 24.11s/it]                                                       {'loss': 0.7248, 'learning_rate': 1.549689659309257e-05, 'epoch': 0.34}
 34%|███▎      | 837/2496 [5:57:20<11:06:33, 24.11s/it] 34%|███▎      | 838/2496 [5:57:44<11:08:57, 24.21s/it]                                                       {'loss': 0.7065, 'learning_rate': 1.5486051865038276e-05, 'epoch': 0.34}
 34%|███▎      | 838/2496 [5:57:44<11:08:57, 24.21s/it] 34%|███▎      | 839/2496 [5:58:08<11:06:11, 24.12s/it]                                                       {'loss': 0.7281, 'learning_rate': 1.5475197899152947e-05, 'epoch': 0.34}
 34%|███▎      | 839/2496 [5:58:08<11:06:11, 24.12s/it] 34%|███▎      | 840/2496 [5:58:32<11:02:03, 23.99s/it]                                                       {'loss': 0.6999, 'learning_rate': 1.5464334713713312e-05, 'epoch': 0.34}
 34%|███▎      | 840/2496 [5:58:32<11:02:03, 23.99s/it] 34%|███▎      | 841/2496 [5:58:58<11:16:33, 24.53s/it]                                                       {'loss': 0.6946, 'learning_rate': 1.5453462327011628e-05, 'epoch': 0.34}
 34%|███▎      | 841/2496 [5:58:58<11:16:33, 24.53s/it] 34%|███▎      | 842/2496 [5:59:23<11:19:45, 24.66s/it]                                                       {'loss': 0.2972, 'learning_rate': 1.5442580757355647e-05, 'epoch': 0.34}
 34%|███▎      | 842/2496 [5:59:23<11:19:45, 24.66s/it] 34%|███▍      | 843/2496 [5:59:49<11:30:48, 25.07s/it]                                                       {'loss': 0.706, 'learning_rate': 1.5431690023068582e-05, 'epoch': 0.34}
 34%|███▍      | 843/2496 [5:59:49<11:30:48, 25.07s/it] 34%|███▍      | 844/2496 [6:00:14<11:33:44, 25.20s/it]                                                       {'loss': 0.6999, 'learning_rate': 1.542079014248908e-05, 'epoch': 0.34}
 34%|███▍      | 844/2496 [6:00:14<11:33:44, 25.20s/it] 34%|███▍      | 845/2496 [6:00:39<11:26:29, 24.95s/it]                                                       {'loss': 0.7109, 'learning_rate': 1.5409881133971184e-05, 'epoch': 0.34}
 34%|███▍      | 845/2496 [6:00:39<11:26:29, 24.95s/it] 34%|███▍      | 846/2496 [6:01:05<11:38:04, 25.38s/it]                                                       {'loss': 0.6866, 'learning_rate': 1.539896301588432e-05, 'epoch': 0.34}
 34%|███▍      | 846/2496 [6:01:05<11:38:04, 25.38s/it] 34%|███▍      | 847/2496 [6:01:32<11:49:08, 25.80s/it]                                                       {'loss': 0.6729, 'learning_rate': 1.5388035806613238e-05, 'epoch': 0.34}
 34%|███▍      | 847/2496 [6:01:32<11:49:08, 25.80s/it] 34%|███▍      | 848/2496 [6:01:59<12:04:29, 26.38s/it]                                                       {'loss': 0.7058, 'learning_rate': 1.5377099524558e-05, 'epoch': 0.34}
 34%|███▍      | 848/2496 [6:01:59<12:04:29, 26.38s/it] 34%|███▍      | 849/2496 [6:02:25<11:59:03, 26.20s/it]                                                       {'loss': 0.6946, 'learning_rate': 1.5366154188133962e-05, 'epoch': 0.34}
 34%|███▍      | 849/2496 [6:02:25<11:59:03, 26.20s/it] 34%|███▍      | 850/2496 [6:02:51<11:51:32, 25.94s/it]                                                       {'loss': 0.7131, 'learning_rate': 1.53551998157717e-05, 'epoch': 0.34}
 34%|███▍      | 850/2496 [6:02:51<11:51:32, 25.94s/it] 34%|███▍      | 851/2496 [6:03:14<11:32:35, 25.26s/it]                                                       {'loss': 0.7074, 'learning_rate': 1.5344236425917026e-05, 'epoch': 0.34}
 34%|███▍      | 851/2496 [6:03:14<11:32:35, 25.26s/it] 34%|███▍      | 852/2496 [6:03:40<11:34:23, 25.34s/it]                                                       {'loss': 0.7049, 'learning_rate': 1.533326403703093e-05, 'epoch': 0.34}
 34%|███▍      | 852/2496 [6:03:40<11:34:23, 25.34s/it] 34%|███▍      | 853/2496 [6:04:04<11:26:42, 25.08s/it]                                                       {'loss': 0.7633, 'learning_rate': 1.5322282667589547e-05, 'epoch': 0.34}
 34%|███▍      | 853/2496 [6:04:04<11:26:42, 25.08s/it] 34%|███▍      | 854/2496 [6:04:31<11:37:13, 25.48s/it]                                                       {'loss': 0.6944, 'learning_rate': 1.5311292336084146e-05, 'epoch': 0.34}
 34%|███▍      | 854/2496 [6:04:31<11:37:13, 25.48s/it] 34%|███▍      | 855/2496 [6:04:55<11:28:59, 25.19s/it]                                                       {'loss': 0.7006, 'learning_rate': 1.5300293061021084e-05, 'epoch': 0.34}
 34%|███▍      | 855/2496 [6:04:55<11:28:59, 25.19s/it] 34%|███▍      | 856/2496 [6:05:20<11:29:23, 25.22s/it]                                                       {'loss': 0.7067, 'learning_rate': 1.5289284860921773e-05, 'epoch': 0.34}
 34%|███▍      | 856/2496 [6:05:20<11:29:23, 25.22s/it] 34%|███▍      | 857/2496 [6:05:49<11:56:15, 26.22s/it]                                                       {'loss': 0.7118, 'learning_rate': 1.5278267754322662e-05, 'epoch': 0.34}
 34%|███▍      | 857/2496 [6:05:49<11:56:15, 26.22s/it] 34%|███▍      | 858/2496 [6:06:13<11:41:46, 25.71s/it]                                                       {'loss': 0.6799, 'learning_rate': 1.526724175977518e-05, 'epoch': 0.34}
 34%|███▍      | 858/2496 [6:06:13<11:41:46, 25.71s/it]this iter is wrong in something... skip...
 34%|███▍      | 859/2496 [6:06:40<11:45:46, 25.87s/it]                                                       {'loss': 0.7123, 'learning_rate': 1.525620689584575e-05, 'epoch': 0.34}
 34%|███▍      | 859/2496 [6:06:40<11:45:46, 25.87s/it] 34%|███▍      | 860/2496 [6:07:03<11:24:53, 25.12s/it]                                                       {'loss': 0.7033, 'learning_rate': 1.5245163181115707e-05, 'epoch': 0.34}
 34%|███▍      | 860/2496 [6:07:03<11:24:53, 25.12s/it] 34%|███▍      | 861/2496 [6:07:27<11:15:09, 24.78s/it]                                                       {'loss': 0.6978, 'learning_rate': 1.5234110634181294e-05, 'epoch': 0.34}
 34%|███▍      | 861/2496 [6:07:27<11:15:09, 24.78s/it] 35%|███▍      | 862/2496 [6:07:52<11:18:50, 24.93s/it]                                                       {'loss': 0.6894, 'learning_rate': 1.5223049273653638e-05, 'epoch': 0.35}
 35%|███▍      | 862/2496 [6:07:52<11:18:50, 24.93s/it] 35%|███▍      | 863/2496 [6:08:19<11:29:39, 25.34s/it]                                                       {'loss': 0.6903, 'learning_rate': 1.521197911815869e-05, 'epoch': 0.35}
 35%|███▍      | 863/2496 [6:08:19<11:29:39, 25.34s/it] 35%|███▍      | 864/2496 [6:08:42<11:16:10, 24.86s/it]                                                       {'loss': 0.7061, 'learning_rate': 1.5200900186337223e-05, 'epoch': 0.35}
 35%|███▍      | 864/2496 [6:08:42<11:16:10, 24.86s/it] 35%|███▍      | 865/2496 [6:09:11<11:42:22, 25.84s/it]                                                       {'loss': 0.7257, 'learning_rate': 1.5189812496844784e-05, 'epoch': 0.35}
 35%|███▍      | 865/2496 [6:09:11<11:42:22, 25.84s/it] 35%|███▍      | 866/2496 [6:09:35<11:32:13, 25.48s/it]                                                       {'loss': 0.2677, 'learning_rate': 1.5178716068351669e-05, 'epoch': 0.35}
 35%|███▍      | 866/2496 [6:09:35<11:32:13, 25.48s/it] 35%|███▍      | 867/2496 [6:10:01<11:31:34, 25.47s/it]                                                       {'loss': 0.7209, 'learning_rate': 1.5167610919542885e-05, 'epoch': 0.35}
 35%|███▍      | 867/2496 [6:10:01<11:31:34, 25.47s/it] 35%|███▍      | 868/2496 [6:10:26<11:32:45, 25.53s/it]                                                       {'loss': 0.7179, 'learning_rate': 1.5156497069118125e-05, 'epoch': 0.35}
 35%|███▍      | 868/2496 [6:10:26<11:32:45, 25.53s/it] 35%|███▍      | 869/2496 [6:10:51<11:24:53, 25.26s/it]                                                       {'loss': 0.682, 'learning_rate': 1.5145374535791737e-05, 'epoch': 0.35}
 35%|███▍      | 869/2496 [6:10:51<11:24:53, 25.26s/it] 35%|███▍      | 870/2496 [6:11:15<11:18:07, 25.02s/it]                                                       {'loss': 0.7034, 'learning_rate': 1.5134243338292686e-05, 'epoch': 0.35}
 35%|███▍      | 870/2496 [6:11:15<11:18:07, 25.02s/it] 35%|███▍      | 871/2496 [6:11:40<11:15:20, 24.94s/it]                                                       {'loss': 0.6724, 'learning_rate': 1.5123103495364531e-05, 'epoch': 0.35}
 35%|███▍      | 871/2496 [6:11:40<11:15:20, 24.94s/it]this iter is wrong in something... skip...
 35%|███▍      | 872/2496 [6:12:04<11:09:42, 24.74s/it]                                                       {'loss': 0.7262, 'learning_rate': 1.511195502576538e-05, 'epoch': 0.35}
 35%|███▍      | 872/2496 [6:12:04<11:09:42, 24.74s/it] 35%|███▍      | 873/2496 [6:12:32<11:29:22, 25.49s/it]                                                       {'loss': 0.6934, 'learning_rate': 1.5100797948267882e-05, 'epoch': 0.35}
 35%|███▍      | 873/2496 [6:12:32<11:29:22, 25.49s/it] 35%|███▌      | 874/2496 [6:12:57<11:28:43, 25.48s/it]                                                       {'loss': 0.6845, 'learning_rate': 1.508963228165917e-05, 'epoch': 0.35}
 35%|███▌      | 874/2496 [6:12:57<11:28:43, 25.48s/it] 35%|███▌      | 875/2496 [6:13:25<11:50:21, 26.29s/it]                                                       {'loss': 0.7091, 'learning_rate': 1.5078458044740836e-05, 'epoch': 0.35}
 35%|███▌      | 875/2496 [6:13:25<11:50:21, 26.29s/it] 35%|███▌      | 876/2496 [6:13:51<11:42:35, 26.02s/it]                                                       {'loss': 0.7115, 'learning_rate': 1.5067275256328913e-05, 'epoch': 0.35}
 35%|███▌      | 876/2496 [6:13:51<11:42:35, 26.02s/it] 35%|███▌      | 877/2496 [6:14:14<11:23:09, 25.32s/it]                                                       {'loss': 0.733, 'learning_rate': 1.5056083935253827e-05, 'epoch': 0.35}
 35%|███▌      | 877/2496 [6:14:14<11:23:09, 25.32s/it] 35%|███▌      | 878/2496 [6:14:39<11:21:16, 25.26s/it]                                                       {'loss': 0.6823, 'learning_rate': 1.5044884100360382e-05, 'epoch': 0.35}
 35%|███▌      | 878/2496 [6:14:40<11:21:16, 25.26s/it] 35%|███▌      | 879/2496 [6:15:05<11:22:21, 25.32s/it]                                                       {'loss': 0.6994, 'learning_rate': 1.5033675770507704e-05, 'epoch': 0.35}
 35%|███▌      | 879/2496 [6:15:05<11:22:21, 25.32s/it] 35%|███▌      | 880/2496 [6:15:30<11:21:13, 25.29s/it]                                                       {'loss': 0.6951, 'learning_rate': 1.5022458964569237e-05, 'epoch': 0.35}
 35%|███▌      | 880/2496 [6:15:30<11:21:13, 25.29s/it] 35%|███▌      | 881/2496 [6:15:55<11:15:28, 25.10s/it]                                                       {'loss': 0.6967, 'learning_rate': 1.5011233701432684e-05, 'epoch': 0.35}
 35%|███▌      | 881/2496 [6:15:55<11:15:28, 25.10s/it] 35%|███▌      | 882/2496 [6:16:22<11:30:14, 25.66s/it]                                                       {'loss': 0.6915, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.35}
 35%|███▌      | 882/2496 [6:16:22<11:30:14, 25.66s/it] 35%|███▌      | 883/2496 [6:16:46<11:20:55, 25.33s/it]                                                       {'loss': 0.7362, 'learning_rate': 1.4988757879187348e-05, 'epoch': 0.35}
 35%|███▌      | 883/2496 [6:16:46<11:20:55, 25.33s/it] 35%|███▌      | 884/2496 [6:17:12<11:22:47, 25.41s/it]                                                       {'loss': 0.7336, 'learning_rate': 1.497750735792506e-05, 'epoch': 0.35}
 35%|███▌      | 884/2496 [6:17:12<11:22:47, 25.41s/it] 35%|███▌      | 885/2496 [6:17:37<11:18:22, 25.27s/it]                                                       {'loss': 0.2521, 'learning_rate': 1.4966248455157622e-05, 'epoch': 0.35}
 35%|███▌      | 885/2496 [6:17:37<11:18:22, 25.27s/it] 35%|███▌      | 886/2496 [6:18:01<11:07:04, 24.86s/it]                                                       {'loss': 0.7312, 'learning_rate': 1.4954981189843629e-05, 'epoch': 0.35}
 35%|███▌      | 886/2496 [6:18:01<11:07:04, 24.86s/it] 36%|███▌      | 887/2496 [6:18:26<11:07:38, 24.90s/it]                                                       {'loss': 0.25, 'learning_rate': 1.4943705580955759e-05, 'epoch': 0.36}
 36%|███▌      | 887/2496 [6:18:26<11:07:38, 24.90s/it] 36%|███▌      | 888/2496 [6:18:53<11:22:19, 25.46s/it]                                                       {'loss': 0.7489, 'learning_rate': 1.4932421647480737e-05, 'epoch': 0.36}
 36%|███▌      | 888/2496 [6:18:53<11:22:19, 25.46s/it] 36%|███▌      | 889/2496 [6:19:16<11:08:19, 24.95s/it]                                                       {'loss': 0.6847, 'learning_rate': 1.4921129408419312e-05, 'epoch': 0.36}
 36%|███▌      | 889/2496 [6:19:16<11:08:19, 24.95s/it] 36%|███▌      | 890/2496 [6:19:43<11:18:10, 25.34s/it]                                                       {'loss': 0.7343, 'learning_rate': 1.4909828882786209e-05, 'epoch': 0.36}
 36%|███▌      | 890/2496 [6:19:43<11:18:10, 25.34s/it] 36%|███▌      | 891/2496 [6:20:07<11:13:27, 25.18s/it]                                                       {'loss': 0.7172, 'learning_rate': 1.4898520089610115e-05, 'epoch': 0.36}
 36%|███▌      | 891/2496 [6:20:07<11:13:27, 25.18s/it]this iter is wrong in something... skip...
 36%|███▌      | 892/2496 [6:20:33<11:15:33, 25.27s/it]                                                       {'loss': 0.6817, 'learning_rate': 1.4887203047933635e-05, 'epoch': 0.36}
 36%|███▌      | 892/2496 [6:20:33<11:15:33, 25.27s/it] 36%|███▌      | 893/2496 [6:20:57<11:08:49, 25.03s/it]                                                       {'loss': 0.7366, 'learning_rate': 1.4875877776813265e-05, 'epoch': 0.36}
 36%|███▌      | 893/2496 [6:20:57<11:08:49, 25.03s/it] 36%|███▌      | 894/2496 [6:21:22<11:05:24, 24.92s/it]                                                       {'loss': 0.7188, 'learning_rate': 1.4864544295319357e-05, 'epoch': 0.36}
 36%|███▌      | 894/2496 [6:21:22<11:05:24, 24.92s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (3103 > 3072). Running this sequence through the model will result in indexing errors
 36%|███▌      | 895/2496 [6:21:46<11:00:05, 24.74s/it]                                                       {'loss': 0.7243, 'learning_rate': 1.4853202622536086e-05, 'epoch': 0.36}
 36%|███▌      | 895/2496 [6:21:46<11:00:05, 24.74s/it] 36%|███▌      | 896/2496 [6:22:10<10:52:12, 24.46s/it]                                                       {'loss': 0.7344, 'learning_rate': 1.4841852777561426e-05, 'epoch': 0.36}
 36%|███▌      | 896/2496 [6:22:10<10:52:12, 24.46s/it] 36%|███▌      | 897/2496 [6:22:35<10:55:37, 24.60s/it]                                                       {'loss': 0.2462, 'learning_rate': 1.4830494779507103e-05, 'epoch': 0.36}
 36%|███▌      | 897/2496 [6:22:35<10:55:37, 24.60s/it] 36%|███▌      | 898/2496 [6:22:58<10:44:19, 24.19s/it]                                                       {'loss': 0.7137, 'learning_rate': 1.4819128647498582e-05, 'epoch': 0.36}
 36%|███▌      | 898/2496 [6:22:58<10:44:19, 24.19s/it] 36%|███▌      | 899/2496 [6:23:22<10:39:42, 24.03s/it]                                                       {'loss': 0.6808, 'learning_rate': 1.4807754400675019e-05, 'epoch': 0.36}
 36%|███▌      | 899/2496 [6:23:22<10:39:42, 24.03s/it] 36%|███▌      | 900/2496 [6:23:53<11:32:26, 26.03s/it]                                                       {'loss': 0.6991, 'learning_rate': 1.4796372058189235e-05, 'epoch': 0.36}
 36%|███▌      | 900/2496 [6:23:53<11:32:26, 26.03s/it] 36%|███▌      | 901/2496 [6:24:18<11:25:37, 25.79s/it]                                                       {'loss': 0.7076, 'learning_rate': 1.478498163920768e-05, 'epoch': 0.36}
 36%|███▌      | 901/2496 [6:24:18<11:25:37, 25.79s/it] 36%|███▌      | 902/2496 [6:24:42<11:11:30, 25.28s/it]                                                       {'loss': 0.6824, 'learning_rate': 1.4773583162910415e-05, 'epoch': 0.36}
 36%|███▌      | 902/2496 [6:24:42<11:11:30, 25.28s/it] 36%|███▌      | 903/2496 [6:25:07<11:09:18, 25.21s/it]                                                       {'loss': 0.6706, 'learning_rate': 1.4762176648491052e-05, 'epoch': 0.36}
 36%|███▌      | 903/2496 [6:25:07<11:09:18, 25.21s/it] 36%|███▌      | 904/2496 [6:25:31<11:03:01, 24.99s/it]                                                       {'loss': 0.698, 'learning_rate': 1.4750762115156749e-05, 'epoch': 0.36}
 36%|███▌      | 904/2496 [6:25:31<11:03:01, 24.99s/it] 36%|███▋      | 905/2496 [6:25:55<10:54:44, 24.69s/it]                                                       {'loss': 0.7364, 'learning_rate': 1.473933958212817e-05, 'epoch': 0.36}
 36%|███▋      | 905/2496 [6:25:55<10:54:44, 24.69s/it] 36%|███▋      | 906/2496 [6:26:22<11:11:22, 25.34s/it]                                                       {'loss': 0.7148, 'learning_rate': 1.4727909068639438e-05, 'epoch': 0.36}
 36%|███▋      | 906/2496 [6:26:22<11:11:22, 25.34s/it] 36%|███▋      | 907/2496 [6:26:48<11:12:31, 25.39s/it]                                                       {'loss': 0.6958, 'learning_rate': 1.4716470593938124e-05, 'epoch': 0.36}
 36%|███▋      | 907/2496 [6:26:48<11:12:31, 25.39s/it] 36%|███▋      | 908/2496 [6:27:11<10:53:26, 24.69s/it]                                                       {'loss': 0.7097, 'learning_rate': 1.4705024177285198e-05, 'epoch': 0.36}
 36%|███▋      | 908/2496 [6:27:11<10:53:26, 24.69s/it] 36%|███▋      | 909/2496 [6:27:36<10:54:42, 24.75s/it]                                                       {'loss': 0.7233, 'learning_rate': 1.4693569837955007e-05, 'epoch': 0.36}
 36%|███▋      | 909/2496 [6:27:36<10:54:42, 24.75s/it] 36%|███▋      | 910/2496 [6:28:01<11:00:02, 24.97s/it]                                                       {'loss': 0.6991, 'learning_rate': 1.4682107595235242e-05, 'epoch': 0.36}
 36%|███▋      | 910/2496 [6:28:01<11:00:02, 24.97s/it] 36%|███▋      | 911/2496 [6:28:26<11:00:23, 25.00s/it]                                                       {'loss': 0.7299, 'learning_rate': 1.4670637468426892e-05, 'epoch': 0.36}
 36%|███▋      | 911/2496 [6:28:26<11:00:23, 25.00s/it] 37%|███▋      | 912/2496 [6:28:53<11:16:07, 25.61s/it]                                                       {'loss': 0.7005, 'learning_rate': 1.4659159476844231e-05, 'epoch': 0.37}
 37%|███▋      | 912/2496 [6:28:53<11:16:07, 25.61s/it] 37%|███▋      | 913/2496 [6:29:21<11:31:36, 26.21s/it]                                                       {'loss': 0.694, 'learning_rate': 1.4647673639814776e-05, 'epoch': 0.37}
 37%|███▋      | 913/2496 [6:29:21<11:31:36, 26.21s/it] 37%|███▋      | 914/2496 [6:29:51<12:01:10, 27.35s/it]                                                       {'loss': 0.6753, 'learning_rate': 1.463617997667925e-05, 'epoch': 0.37}
 37%|███▋      | 914/2496 [6:29:51<12:01:10, 27.35s/it] 37%|███▋      | 915/2496 [6:30:16<11:39:33, 26.55s/it]                                                       {'loss': 0.7074, 'learning_rate': 1.4624678506791556e-05, 'epoch': 0.37}
 37%|███▋      | 915/2496 [6:30:16<11:39:33, 26.55s/it] 37%|███▋      | 916/2496 [6:30:41<11:29:39, 26.19s/it]                                                       {'loss': 0.7168, 'learning_rate': 1.4613169249518741e-05, 'epoch': 0.37}
 37%|███▋      | 916/2496 [6:30:41<11:29:39, 26.19s/it]this iter is wrong in something... skip...
 37%|███▋      | 917/2496 [6:31:05<11:11:02, 25.50s/it]                                                       {'loss': 0.7054, 'learning_rate': 1.4601652224240975e-05, 'epoch': 0.37}
 37%|███▋      | 917/2496 [6:31:05<11:11:02, 25.50s/it] 37%|███▋      | 918/2496 [6:31:30<11:06:01, 25.32s/it]                                                       {'loss': 0.2473, 'learning_rate': 1.4590127450351492e-05, 'epoch': 0.37}
 37%|███▋      | 918/2496 [6:31:30<11:06:01, 25.32s/it] 37%|███▋      | 919/2496 [6:31:55<11:04:18, 25.27s/it]                                                       {'loss': 0.7155, 'learning_rate': 1.4578594947256584e-05, 'epoch': 0.37}
 37%|███▋      | 919/2496 [6:31:55<11:04:18, 25.27s/it] 37%|███▋      | 920/2496 [6:32:22<11:18:46, 25.84s/it]                                                       {'loss': 0.7227, 'learning_rate': 1.4567054734375557e-05, 'epoch': 0.37}
 37%|███▋      | 920/2496 [6:32:22<11:18:46, 25.84s/it] 37%|███▋      | 921/2496 [6:32:47<11:12:46, 25.63s/it]                                                       {'loss': 0.7239, 'learning_rate': 1.4555506831140698e-05, 'epoch': 0.37}
 37%|███▋      | 921/2496 [6:32:47<11:12:46, 25.63s/it] 37%|███▋      | 922/2496 [6:33:15<11:29:00, 26.26s/it]                                                       {'loss': 0.7223, 'learning_rate': 1.4543951256997246e-05, 'epoch': 0.37}
 37%|███▋      | 922/2496 [6:33:15<11:29:00, 26.26s/it] 37%|███▋      | 923/2496 [6:33:39<11:12:32, 25.65s/it]                                                       {'loss': 0.7085, 'learning_rate': 1.4532388031403356e-05, 'epoch': 0.37}
 37%|███▋      | 923/2496 [6:33:39<11:12:32, 25.65s/it] 37%|███▋      | 924/2496 [6:34:04<11:03:29, 25.32s/it]                                                       {'loss': 0.6863, 'learning_rate': 1.4520817173830058e-05, 'epoch': 0.37}
 37%|███▋      | 924/2496 [6:34:04<11:03:29, 25.32s/it] 37%|███▋      | 925/2496 [6:34:29<11:00:52, 25.24s/it]                                                       {'loss': 0.7206, 'learning_rate': 1.450923870376125e-05, 'epoch': 0.37}
 37%|███▋      | 925/2496 [6:34:29<11:00:52, 25.24s/it] 37%|███▋      | 926/2496 [6:34:55<11:03:57, 25.37s/it]                                                       {'loss': 0.6766, 'learning_rate': 1.4497652640693636e-05, 'epoch': 0.37}
 37%|███▋      | 926/2496 [6:34:55<11:03:57, 25.37s/it] 37%|███▋      | 927/2496 [6:35:19<11:00:02, 25.24s/it]                                                       {'loss': 0.6698, 'learning_rate': 1.448605900413671e-05, 'epoch': 0.37}
 37%|███▋      | 927/2496 [6:35:19<11:00:02, 25.24s/it] 37%|███▋      | 928/2496 [6:35:44<10:52:40, 24.97s/it]                                                       {'loss': 0.7251, 'learning_rate': 1.447445781361272e-05, 'epoch': 0.37}
 37%|███▋      | 928/2496 [6:35:44<10:52:40, 24.97s/it] 37%|███▋      | 929/2496 [6:36:10<11:00:30, 25.29s/it]                                                       {'loss': 0.7321, 'learning_rate': 1.446284908865663e-05, 'epoch': 0.37}
 37%|███▋      | 929/2496 [6:36:10<11:00:30, 25.29s/it] 37%|███▋      | 930/2496 [6:36:33<10:41:01, 24.56s/it]                                                       {'loss': 0.6739, 'learning_rate': 1.445123284881609e-05, 'epoch': 0.37}
 37%|███▋      | 930/2496 [6:36:33<10:41:01, 24.56s/it] 37%|███▋      | 931/2496 [6:36:56<10:28:48, 24.11s/it]                                                       {'loss': 0.6887, 'learning_rate': 1.4439609113651416e-05, 'epoch': 0.37}
 37%|███▋      | 931/2496 [6:36:56<10:28:48, 24.11s/it] 37%|███▋      | 932/2496 [6:37:20<10:26:25, 24.03s/it]                                                       {'loss': 0.6982, 'learning_rate': 1.442797790273553e-05, 'epoch': 0.37}
 37%|███▋      | 932/2496 [6:37:20<10:26:25, 24.03s/it] 37%|███▋      | 933/2496 [6:37:47<10:48:52, 24.91s/it]                                                       {'loss': 0.6855, 'learning_rate': 1.4416339235653949e-05, 'epoch': 0.37}
 37%|███▋      | 933/2496 [6:37:47<10:48:52, 24.91s/it] 37%|███▋      | 934/2496 [6:38:11<10:47:01, 24.85s/it]                                                       {'loss': 0.2566, 'learning_rate': 1.4404693132004752e-05, 'epoch': 0.37}
 37%|███▋      | 934/2496 [6:38:11<10:47:01, 24.85s/it] 37%|███▋      | 935/2496 [6:38:37<10:50:47, 25.01s/it]                                                       {'loss': 0.7389, 'learning_rate': 1.4393039611398523e-05, 'epoch': 0.37}
 37%|███▋      | 935/2496 [6:38:37<10:50:47, 25.01s/it] 38%|███▊      | 936/2496 [6:39:02<10:48:58, 24.96s/it]                                                       {'loss': 0.694, 'learning_rate': 1.4381378693458355e-05, 'epoch': 0.37}
 38%|███▊      | 936/2496 [6:39:02<10:48:58, 24.96s/it] 38%|███▊      | 937/2496 [6:39:28<11:02:19, 25.49s/it]                                                       {'loss': 0.6874, 'learning_rate': 1.436971039781978e-05, 'epoch': 0.38}
 38%|███▊      | 937/2496 [6:39:28<11:02:19, 25.49s/it] 38%|███▊      | 938/2496 [6:39:52<10:49:58, 25.03s/it]                                                       {'loss': 0.7045, 'learning_rate': 1.4358034744130765e-05, 'epoch': 0.38}
 38%|███▊      | 938/2496 [6:39:52<10:49:58, 25.03s/it] 38%|███▊      | 939/2496 [6:40:16<10:42:10, 24.75s/it]                                                       {'loss': 0.722, 'learning_rate': 1.4346351752051663e-05, 'epoch': 0.38}
 38%|███▊      | 939/2496 [6:40:16<10:42:10, 24.75s/it]this iter is wrong in something... skip...
 38%|███▊      | 940/2496 [6:40:40<10:34:51, 24.48s/it]                                                       {'loss': 0.6991, 'learning_rate': 1.4334661441255182e-05, 'epoch': 0.38}
 38%|███▊      | 940/2496 [6:40:40<10:34:51, 24.48s/it] 38%|███▊      | 941/2496 [6:41:07<10:53:35, 25.22s/it]                                                       {'loss': 0.6652, 'learning_rate': 1.432296383142636e-05, 'epoch': 0.38}
 38%|███▊      | 941/2496 [6:41:07<10:53:35, 25.22s/it] 38%|███▊      | 942/2496 [6:41:33<10:56:45, 25.36s/it]                                                       {'loss': 0.6872, 'learning_rate': 1.4311258942262517e-05, 'epoch': 0.38}
 38%|███▊      | 942/2496 [6:41:33<10:56:45, 25.36s/it] 38%|███▊      | 943/2496 [6:41:58<10:56:54, 25.38s/it]                                                       {'loss': 0.684, 'learning_rate': 1.4299546793473236e-05, 'epoch': 0.38}
 38%|███▊      | 943/2496 [6:41:58<10:56:54, 25.38s/it] 38%|███▊      | 944/2496 [6:42:25<11:09:21, 25.88s/it]                                                       {'loss': 0.6281, 'learning_rate': 1.4287827404780323e-05, 'epoch': 0.38}
 38%|███▊      | 944/2496 [6:42:25<11:09:21, 25.88s/it] 38%|███▊      | 945/2496 [6:42:50<11:00:53, 25.57s/it]                                                       {'loss': 0.7023, 'learning_rate': 1.4276100795917777e-05, 'epoch': 0.38}
 38%|███▊      | 945/2496 [6:42:50<11:00:53, 25.57s/it] 38%|███▊      | 946/2496 [6:43:15<10:58:58, 25.51s/it]                                                       {'loss': 0.6797, 'learning_rate': 1.4264366986631753e-05, 'epoch': 0.38}
 38%|███▊      | 946/2496 [6:43:15<10:58:58, 25.51s/it] 38%|███▊      | 947/2496 [6:43:46<11:39:20, 27.09s/it]                                                       {'loss': 0.7371, 'learning_rate': 1.4252625996680526e-05, 'epoch': 0.38}
 38%|███▊      | 947/2496 [6:43:46<11:39:20, 27.09s/it] 38%|███▊      | 948/2496 [6:44:12<11:29:23, 26.72s/it]                                                       {'loss': 0.7259, 'learning_rate': 1.4240877845834473e-05, 'epoch': 0.38}
 38%|███▊      | 948/2496 [6:44:12<11:29:23, 26.72s/it] 38%|███▊      | 949/2496 [6:44:38<11:25:58, 26.61s/it]                                                       {'loss': 0.7034, 'learning_rate': 1.4229122553876022e-05, 'epoch': 0.38}
 38%|███▊      | 949/2496 [6:44:38<11:25:58, 26.61s/it] 38%|███▊      | 950/2496 [6:45:04<11:16:53, 26.27s/it]                                                       {'loss': 0.6873, 'learning_rate': 1.4217360140599625e-05, 'epoch': 0.38}
 38%|███▊      | 950/2496 [6:45:04<11:16:53, 26.27s/it] 38%|███▊      | 951/2496 [6:45:28<10:59:21, 25.61s/it]                                                       {'loss': 0.7088, 'learning_rate': 1.4205590625811729e-05, 'epoch': 0.38}
 38%|███▊      | 951/2496 [6:45:28<10:59:21, 25.61s/it] 38%|███▊      | 952/2496 [6:45:53<10:55:11, 25.46s/it]                                                       {'loss': 0.7253, 'learning_rate': 1.4193814029330736e-05, 'epoch': 0.38}
 38%|███▊      | 952/2496 [6:45:53<10:55:11, 25.46s/it] 38%|███▊      | 953/2496 [6:46:20<11:04:52, 25.85s/it]                                                       {'loss': 0.6906, 'learning_rate': 1.4182030370986976e-05, 'epoch': 0.38}
 38%|███▊      | 953/2496 [6:46:20<11:04:52, 25.85s/it] 38%|███▊      | 954/2496 [6:46:44<10:52:11, 25.38s/it]                                                       {'loss': 0.6829, 'learning_rate': 1.4170239670622663e-05, 'epoch': 0.38}
 38%|███▊      | 954/2496 [6:46:44<10:52:11, 25.38s/it] 38%|███▊      | 955/2496 [6:47:08<10:43:30, 25.06s/it]                                                       {'loss': 0.721, 'learning_rate': 1.4158441948091883e-05, 'epoch': 0.38}
 38%|███▊      | 955/2496 [6:47:08<10:43:30, 25.06s/it] 38%|███▊      | 956/2496 [6:47:35<10:57:18, 25.61s/it]                                                       {'loss': 0.7321, 'learning_rate': 1.4146637223260533e-05, 'epoch': 0.38}
 38%|███▊      | 956/2496 [6:47:35<10:57:18, 25.61s/it] 38%|███▊      | 957/2496 [6:48:00<10:45:51, 25.18s/it]                                                       {'loss': 0.7258, 'learning_rate': 1.4134825516006307e-05, 'epoch': 0.38}
 38%|███▊      | 957/2496 [6:48:00<10:45:51, 25.18s/it] 38%|███▊      | 958/2496 [6:48:24<10:39:44, 24.96s/it]                                                       {'loss': 0.7124, 'learning_rate': 1.4123006846218652e-05, 'epoch': 0.38}
 38%|███▊      | 958/2496 [6:48:24<10:39:44, 24.96s/it] 38%|███▊      | 959/2496 [6:48:48<10:33:27, 24.73s/it]                                                       {'loss': 0.709, 'learning_rate': 1.4111181233798743e-05, 'epoch': 0.38}
 38%|███▊      | 959/2496 [6:48:48<10:33:27, 24.73s/it] 38%|███▊      | 960/2496 [6:49:14<10:44:18, 25.17s/it]                                                       {'loss': 0.7217, 'learning_rate': 1.409934869865945e-05, 'epoch': 0.38}
 38%|███▊      | 960/2496 [6:49:14<10:44:18, 25.17s/it] 39%|███▊      | 961/2496 [6:49:39<10:37:58, 24.94s/it]                                                       {'loss': 0.6994, 'learning_rate': 1.408750926072529e-05, 'epoch': 0.38}
 39%|███▊      | 961/2496 [6:49:39<10:37:58, 24.94s/it] 39%|███▊      | 962/2496 [6:50:05<10:46:49, 25.30s/it]                                                       {'loss': 0.6423, 'learning_rate': 1.4075662939932411e-05, 'epoch': 0.39}
 39%|███▊      | 962/2496 [6:50:05<10:46:49, 25.30s/it] 39%|███▊      | 963/2496 [6:50:31<10:55:01, 25.64s/it]                                                       {'loss': 0.7078, 'learning_rate': 1.4063809756228546e-05, 'epoch': 0.39}
 39%|███▊      | 963/2496 [6:50:31<10:55:01, 25.64s/it] 39%|███▊      | 964/2496 [6:50:59<11:11:46, 26.31s/it]                                                       {'loss': 0.7014, 'learning_rate': 1.4051949729572987e-05, 'epoch': 0.39}
 39%|███▊      | 964/2496 [6:50:59<11:11:46, 26.31s/it] 39%|███▊      | 965/2496 [6:51:27<11:23:06, 26.77s/it]                                                       {'loss': 0.7077, 'learning_rate': 1.4040082879936549e-05, 'epoch': 0.39}
 39%|███▊      | 965/2496 [6:51:27<11:23:06, 26.77s/it] 39%|███▊      | 966/2496 [6:51:53<11:14:47, 26.46s/it]                                                       {'loss': 0.651, 'learning_rate': 1.4028209227301534e-05, 'epoch': 0.39}
 39%|███▊      | 966/2496 [6:51:53<11:14:47, 26.46s/it] 39%|███▊      | 967/2496 [6:52:20<11:16:50, 26.56s/it]                                                       {'loss': 0.6794, 'learning_rate': 1.4016328791661704e-05, 'epoch': 0.39}
 39%|███▊      | 967/2496 [6:52:20<11:16:50, 26.56s/it] 39%|███▉      | 968/2496 [6:52:43<10:55:17, 25.73s/it]                                                       {'loss': 0.6699, 'learning_rate': 1.4004441593022239e-05, 'epoch': 0.39}
 39%|███▉      | 968/2496 [6:52:43<10:55:17, 25.73s/it] 39%|███▉      | 969/2496 [6:53:09<10:52:00, 25.62s/it]                                                       {'loss': 0.6797, 'learning_rate': 1.3992547651399698e-05, 'epoch': 0.39}
 39%|███▉      | 969/2496 [6:53:09<10:52:00, 25.62s/it] 39%|███▉      | 970/2496 [6:53:34<10:50:38, 25.58s/it]                                                       {'loss': 0.6942, 'learning_rate': 1.3980646986822014e-05, 'epoch': 0.39}
 39%|███▉      | 970/2496 [6:53:34<10:50:38, 25.58s/it]this iter is wrong in something... skip...
this iter is wrong in something... skip...
 39%|███▉      | 971/2496 [6:53:57<10:30:52, 24.82s/it]                                                       {'loss': 0.7333, 'learning_rate': 1.3968739619328428e-05, 'epoch': 0.39}
 39%|███▉      | 971/2496 [6:53:57<10:30:52, 24.82s/it] 39%|███▉      | 972/2496 [6:54:22<10:27:36, 24.71s/it]                                                       {'loss': 0.6825, 'learning_rate': 1.395682556896947e-05, 'epoch': 0.39}
 39%|███▉      | 972/2496 [6:54:22<10:27:36, 24.71s/it] 39%|███▉      | 973/2496 [6:54:48<10:38:01, 25.14s/it]                                                       {'loss': 0.7222, 'learning_rate': 1.3944904855806925e-05, 'epoch': 0.39}
 39%|███▉      | 973/2496 [6:54:48<10:38:01, 25.14s/it] 39%|███▉      | 974/2496 [6:55:11<10:24:11, 24.61s/it]                                                       {'loss': 0.7266, 'learning_rate': 1.3932977499913791e-05, 'epoch': 0.39}
 39%|███▉      | 974/2496 [6:55:11<10:24:11, 24.61s/it]this iter is wrong in something... skip...
 39%|███▉      | 975/2496 [6:55:38<10:42:59, 25.36s/it]                                                       {'loss': 0.6932, 'learning_rate': 1.392104352137426e-05, 'epoch': 0.39}
 39%|███▉      | 975/2496 [6:55:38<10:42:59, 25.36s/it] 39%|███▉      | 976/2496 [6:56:02<10:30:43, 24.90s/it]                                                       {'loss': 0.69, 'learning_rate': 1.3909102940283673e-05, 'epoch': 0.39}
 39%|███▉      | 976/2496 [6:56:02<10:30:43, 24.90s/it] 39%|███▉      | 977/2496 [6:56:29<10:45:55, 25.51s/it]                                                       {'loss': 0.7285, 'learning_rate': 1.3897155776748483e-05, 'epoch': 0.39}
 39%|███▉      | 977/2496 [6:56:29<10:45:55, 25.51s/it] 39%|███▉      | 978/2496 [6:56:54<10:40:35, 25.32s/it]                                                       {'loss': 0.7291, 'learning_rate': 1.3885202050886237e-05, 'epoch': 0.39}
 39%|███▉      | 978/2496 [6:56:54<10:40:35, 25.32s/it] 39%|███▉      | 979/2496 [6:57:17<10:23:09, 24.65s/it]                                                       {'loss': 0.6582, 'learning_rate': 1.3873241782825524e-05, 'epoch': 0.39}
 39%|███▉      | 979/2496 [6:57:17<10:23:09, 24.65s/it] 39%|███▉      | 980/2496 [6:57:40<10:08:44, 24.09s/it]                                                       {'loss': 0.7091, 'learning_rate': 1.386127499270595e-05, 'epoch': 0.39}
 39%|███▉      | 980/2496 [6:57:40<10:08:44, 24.09s/it] 39%|███▉      | 981/2496 [6:58:06<10:22:41, 24.66s/it]                                                       {'loss': 0.6865, 'learning_rate': 1.3849301700678115e-05, 'epoch': 0.39}
 39%|███▉      | 981/2496 [6:58:06<10:22:41, 24.66s/it] 39%|███▉      | 982/2496 [6:58:29<10:14:41, 24.36s/it]                                                       {'loss': 0.7003, 'learning_rate': 1.383732192690355e-05, 'epoch': 0.39}
 39%|███▉      | 982/2496 [6:58:29<10:14:41, 24.36s/it] 39%|███▉      | 983/2496 [6:58:55<10:23:08, 24.71s/it]                                                       {'loss': 0.6953, 'learning_rate': 1.3825335691554704e-05, 'epoch': 0.39}
 39%|███▉      | 983/2496 [6:58:55<10:23:08, 24.71s/it] 39%|███▉      | 984/2496 [6:59:23<10:48:38, 25.74s/it]                                                       {'loss': 0.6997, 'learning_rate': 1.3813343014814926e-05, 'epoch': 0.39}
 39%|███▉      | 984/2496 [6:59:23<10:48:38, 25.74s/it] 39%|███▉      | 985/2496 [6:59:47<10:30:45, 25.05s/it]                                                       {'loss': 0.6984, 'learning_rate': 1.3801343916878383e-05, 'epoch': 0.39}
 39%|███▉      | 985/2496 [6:59:47<10:30:45, 25.05s/it] 40%|███▉      | 986/2496 [7:00:12<10:30:40, 25.06s/it]                                                       {'loss': 0.2693, 'learning_rate': 1.3789338417950074e-05, 'epoch': 0.39}
 40%|███▉      | 986/2496 [7:00:12<10:30:40, 25.06s/it]this iter is wrong in something... skip...
 40%|███▉      | 987/2496 [7:00:37<10:31:38, 25.11s/it]                                                       {'loss': 0.7215, 'learning_rate': 1.3777326538245767e-05, 'epoch': 0.4}
 40%|███▉      | 987/2496 [7:00:37<10:31:38, 25.11s/it]this iter is wrong in something... skip...
 40%|███▉      | 988/2496 [7:01:05<10:50:14, 25.87s/it]                                                       {'loss': 0.6916, 'learning_rate': 1.3765308297991982e-05, 'epoch': 0.4}
 40%|███▉      | 988/2496 [7:01:05<10:50:14, 25.87s/it] 40%|███▉      | 989/2496 [7:01:27<10:27:00, 24.96s/it]                                                       {'loss': 0.7021, 'learning_rate': 1.3753283717425945e-05, 'epoch': 0.4}
 40%|███▉      | 989/2496 [7:01:27<10:27:00, 24.96s/it] 40%|███▉      | 990/2496 [7:01:53<10:32:05, 25.18s/it]                                                       {'loss': 0.7027, 'learning_rate': 1.3741252816795552e-05, 'epoch': 0.4}
 40%|███▉      | 990/2496 [7:01:53<10:32:05, 25.18s/it] 40%|███▉      | 991/2496 [7:02:17<10:18:46, 24.67s/it]                                                       {'loss': 0.7076, 'learning_rate': 1.3729215616359355e-05, 'epoch': 0.4}
 40%|███▉      | 991/2496 [7:02:17<10:18:46, 24.67s/it] 40%|███▉      | 992/2496 [7:02:44<10:39:45, 25.52s/it]                                                       {'loss': 0.6566, 'learning_rate': 1.3717172136386506e-05, 'epoch': 0.4}
 40%|███▉      | 992/2496 [7:02:44<10:39:45, 25.52s/it] 40%|███▉      | 993/2496 [7:03:10<10:42:12, 25.64s/it]                                                       {'loss': 0.6684, 'learning_rate': 1.3705122397156727e-05, 'epoch': 0.4}
 40%|███▉      | 993/2496 [7:03:10<10:42:12, 25.64s/it] 40%|███▉      | 994/2496 [7:03:38<10:56:14, 26.22s/it]                                                       {'loss': 0.6985, 'learning_rate': 1.3693066418960292e-05, 'epoch': 0.4}
 40%|███▉      | 994/2496 [7:03:38<10:56:14, 26.22s/it] 40%|███▉      | 995/2496 [7:04:01<10:36:29, 25.44s/it]                                                       {'loss': 0.6869, 'learning_rate': 1.3681004222097964e-05, 'epoch': 0.4}
 40%|███▉      | 995/2496 [7:04:01<10:36:29, 25.44s/it] 40%|███▉      | 996/2496 [7:04:26<10:32:08, 25.29s/it]                                                       {'loss': 0.2574, 'learning_rate': 1.3668935826880996e-05, 'epoch': 0.4}
 40%|███▉      | 996/2496 [7:04:26<10:32:08, 25.29s/it] 40%|███▉      | 997/2496 [7:04:50<10:23:53, 24.97s/it]                                                       {'loss': 0.7086, 'learning_rate': 1.3656861253631061e-05, 'epoch': 0.4}
 40%|███▉      | 997/2496 [7:04:50<10:23:53, 24.97s/it] 40%|███▉      | 998/2496 [7:05:13<10:07:29, 24.33s/it]                                                       {'loss': 0.6909, 'learning_rate': 1.364478052268025e-05, 'epoch': 0.4}
 40%|███▉      | 998/2496 [7:05:13<10:07:29, 24.33s/it] 40%|████      | 999/2496 [7:05:40<10:22:57, 24.97s/it]                                                       {'loss': 0.7199, 'learning_rate': 1.3632693654371012e-05, 'epoch': 0.4}
 40%|████      | 999/2496 [7:05:40<10:22:57, 24.97s/it] 40%|████      | 1000/2496 [7:06:04<10:21:07, 24.91s/it]                                                        {'loss': 0.244, 'learning_rate': 1.3620600669056136e-05, 'epoch': 0.4}
 40%|████      | 1000/2496 [7:06:04<10:21:07, 24.91s/it] 40%|████      | 1001/2496 [7:06:29<10:20:23, 24.90s/it]                                                        {'loss': 0.7142, 'learning_rate': 1.3608501587098708e-05, 'epoch': 0.4}
 40%|████      | 1001/2496 [7:06:29<10:20:23, 24.90s/it] 40%|████      | 1002/2496 [7:06:55<10:27:21, 25.20s/it]                                                        {'loss': 0.6804, 'learning_rate': 1.359639642887208e-05, 'epoch': 0.4}
 40%|████      | 1002/2496 [7:06:55<10:27:21, 25.20s/it] 40%|████      | 1003/2496 [7:07:20<10:25:58, 25.16s/it]                                                        {'loss': 0.7278, 'learning_rate': 1.3584285214759842e-05, 'epoch': 0.4}
 40%|████      | 1003/2496 [7:07:20<10:25:58, 25.16s/it] 40%|████      | 1004/2496 [7:07:45<10:26:00, 25.17s/it]                                                        {'loss': 0.7021, 'learning_rate': 1.3572167965155774e-05, 'epoch': 0.4}
 40%|████      | 1004/2496 [7:07:45<10:26:00, 25.17s/it] 40%|████      | 1005/2496 [7:08:10<10:23:24, 25.09s/it]                                                        {'loss': 0.7033, 'learning_rate': 1.3560044700463824e-05, 'epoch': 0.4}
 40%|████      | 1005/2496 [7:08:10<10:23:24, 25.09s/it] 40%|████      | 1006/2496 [7:08:37<10:35:37, 25.60s/it]                                                        {'loss': 0.6855, 'learning_rate': 1.3547915441098063e-05, 'epoch': 0.4}
 40%|████      | 1006/2496 [7:08:37<10:35:37, 25.60s/it] 40%|████      | 1007/2496 [7:09:02<10:31:14, 25.44s/it]                                                        {'loss': 0.6786, 'learning_rate': 1.3535780207482662e-05, 'epoch': 0.4}
 40%|████      | 1007/2496 [7:09:02<10:31:14, 25.44s/it] 40%|████      | 1008/2496 [7:09:28<10:32:57, 25.52s/it]                                                        {'loss': 0.6578, 'learning_rate': 1.3523639020051849e-05, 'epoch': 0.4}
 40%|████      | 1008/2496 [7:09:28<10:32:57, 25.52s/it] 40%|████      | 1009/2496 [7:09:53<10:28:05, 25.34s/it]                                                        {'loss': 0.2586, 'learning_rate': 1.3511491899249875e-05, 'epoch': 0.4}
 40%|████      | 1009/2496 [7:09:53<10:28:05, 25.34s/it] 40%|████      | 1010/2496 [7:10:18<10:26:15, 25.29s/it]                                                        {'loss': 0.7135, 'learning_rate': 1.3499338865530993e-05, 'epoch': 0.4}
 40%|████      | 1010/2496 [7:10:18<10:26:15, 25.29s/it] 41%|████      | 1011/2496 [7:10:45<10:37:34, 25.76s/it]                                                        {'loss': 0.7056, 'learning_rate': 1.3487179939359394e-05, 'epoch': 0.4}
 41%|████      | 1011/2496 [7:10:45<10:37:34, 25.76s/it] 41%|████      | 1012/2496 [7:11:11<10:42:07, 25.96s/it]                                                        {'loss': 0.706, 'learning_rate': 1.3475015141209212e-05, 'epoch': 0.41}
 41%|████      | 1012/2496 [7:11:11<10:42:07, 25.96s/it]this iter is wrong in something... skip...
 41%|████      | 1013/2496 [7:11:36<10:34:44, 25.68s/it]                                                        {'loss': 0.6963, 'learning_rate': 1.3462844491564452e-05, 'epoch': 0.41}
 41%|████      | 1013/2496 [7:11:36<10:34:44, 25.68s/it] 41%|████      | 1014/2496 [7:12:00<10:19:36, 25.09s/it]                                                        {'loss': 0.7059, 'learning_rate': 1.3450668010918982e-05, 'epoch': 0.41}
 41%|████      | 1014/2496 [7:12:00<10:19:36, 25.09s/it] 41%|████      | 1015/2496 [7:12:28<10:41:49, 26.00s/it]                                                        {'loss': 0.6791, 'learning_rate': 1.3438485719776487e-05, 'epoch': 0.41}
 41%|████      | 1015/2496 [7:12:28<10:41:49, 26.00s/it] 41%|████      | 1016/2496 [7:12:53<10:35:39, 25.77s/it]                                                        {'loss': 0.2446, 'learning_rate': 1.3426297638650427e-05, 'epoch': 0.41}
 41%|████      | 1016/2496 [7:12:53<10:35:39, 25.77s/it] 41%|████      | 1017/2496 [7:13:18<10:25:59, 25.39s/it]                                                        {'loss': 0.7079, 'learning_rate': 1.3414103788064025e-05, 'epoch': 0.41}
 41%|████      | 1017/2496 [7:13:18<10:25:59, 25.39s/it] 41%|████      | 1018/2496 [7:13:43<10:25:05, 25.38s/it]                                                        {'loss': 0.6949, 'learning_rate': 1.3401904188550217e-05, 'epoch': 0.41}
 41%|████      | 1018/2496 [7:13:43<10:25:05, 25.38s/it]this iter is wrong in something... skip...
 41%|████      | 1019/2496 [7:14:07<10:09:47, 24.77s/it]                                                        {'loss': 0.7064, 'learning_rate': 1.3389698860651608e-05, 'epoch': 0.41}
 41%|████      | 1019/2496 [7:14:07<10:09:47, 24.77s/it] 41%|████      | 1020/2496 [7:14:33<10:19:22, 25.18s/it]                                                        {'loss': 0.7207, 'learning_rate': 1.3377487824920459e-05, 'epoch': 0.41}
 41%|████      | 1020/2496 [7:14:33<10:19:22, 25.18s/it] 41%|████      | 1021/2496 [7:14:58<10:16:19, 25.07s/it]                                                        {'loss': 0.6907, 'learning_rate': 1.3365271101918643e-05, 'epoch': 0.41}
 41%|████      | 1021/2496 [7:14:58<10:16:19, 25.07s/it] 41%|████      | 1022/2496 [7:15:23<10:19:46, 25.23s/it]                                                        {'loss': 0.706, 'learning_rate': 1.3353048712217605e-05, 'epoch': 0.41}
 41%|████      | 1022/2496 [7:15:23<10:19:46, 25.23s/it] 41%|████      | 1023/2496 [7:15:48<10:15:58, 25.09s/it]                                                        {'loss': 0.7142, 'learning_rate': 1.334082067639833e-05, 'epoch': 0.41}
 41%|████      | 1023/2496 [7:15:48<10:15:58, 25.09s/it] 41%|████      | 1024/2496 [7:16:12<10:10:41, 24.89s/it]                                                        {'loss': 0.7221, 'learning_rate': 1.3328587015051319e-05, 'epoch': 0.41}
 41%|████      | 1024/2496 [7:16:12<10:10:41, 24.89s/it] 41%|████      | 1025/2496 [7:16:36<10:02:48, 24.59s/it]                                                        {'loss': 0.7002, 'learning_rate': 1.331634774877654e-05, 'epoch': 0.41}
 41%|████      | 1025/2496 [7:16:36<10:02:48, 24.59s/it] 41%|████      | 1026/2496 [7:17:00<9:59:23, 24.47s/it]                                                        {'loss': 0.6912, 'learning_rate': 1.3304102898183396e-05, 'epoch': 0.41}
 41%|████      | 1026/2496 [7:17:00<9:59:23, 24.47s/it] 41%|████      | 1027/2496 [7:17:26<10:06:19, 24.76s/it]                                                        {'loss': 0.7168, 'learning_rate': 1.3291852483890701e-05, 'epoch': 0.41}
 41%|████      | 1027/2496 [7:17:26<10:06:19, 24.76s/it] 41%|████      | 1028/2496 [7:17:48<9:49:17, 24.09s/it]                                                        {'loss': 0.6679, 'learning_rate': 1.327959652652663e-05, 'epoch': 0.41}
 41%|████      | 1028/2496 [7:17:48<9:49:17, 24.09s/it] 41%|████      | 1029/2496 [7:18:13<9:51:28, 24.19s/it]                                                       {'loss': 0.6749, 'learning_rate': 1.32673350467287e-05, 'epoch': 0.41}
 41%|████      | 1029/2496 [7:18:13<9:51:28, 24.19s/it] 41%|████▏     | 1030/2496 [7:18:40<10:13:01, 25.09s/it]                                                        {'loss': 0.7054, 'learning_rate': 1.3255068065143717e-05, 'epoch': 0.41}
 41%|████▏     | 1030/2496 [7:18:40<10:13:01, 25.09s/it] 41%|████▏     | 1031/2496 [7:19:07<10:25:16, 25.61s/it]                                                        {'loss': 0.6702, 'learning_rate': 1.3242795602427763e-05, 'epoch': 0.41}
 41%|████▏     | 1031/2496 [7:19:07<10:25:16, 25.61s/it] 41%|████▏     | 1032/2496 [7:19:30<10:08:56, 24.96s/it]                                                        {'loss': 0.7095, 'learning_rate': 1.3230517679246137e-05, 'epoch': 0.41}
 41%|████▏     | 1032/2496 [7:19:30<10:08:56, 24.96s/it] 41%|████▏     | 1033/2496 [7:19:53<9:54:46, 24.39s/it]                                                        {'loss': 0.7106, 'learning_rate': 1.3218234316273342e-05, 'epoch': 0.41}
 41%|████▏     | 1033/2496 [7:19:53<9:54:46, 24.39s/it]this iter is wrong in something... skip...
 41%|████▏     | 1034/2496 [7:20:20<10:10:11, 25.04s/it]                                                        {'loss': 0.7214, 'learning_rate': 1.320594553419304e-05, 'epoch': 0.41}
 41%|████▏     | 1034/2496 [7:20:20<10:10:11, 25.04s/it]this iter is wrong in something... skip...
 41%|████▏     | 1035/2496 [7:20:45<10:13:25, 25.19s/it]                                                        {'loss': 0.6837, 'learning_rate': 1.3193651353698012e-05, 'epoch': 0.41}
 41%|████▏     | 1035/2496 [7:20:45<10:13:25, 25.19s/it] 42%|████▏     | 1036/2496 [7:21:12<10:23:59, 25.64s/it]                                                        {'loss': 0.6727, 'learning_rate': 1.3181351795490138e-05, 'epoch': 0.41}
 42%|████▏     | 1036/2496 [7:21:12<10:23:59, 25.64s/it] 42%|████▏     | 1037/2496 [7:21:37<10:15:14, 25.30s/it]                                                        {'loss': 0.2525, 'learning_rate': 1.3169046880280344e-05, 'epoch': 0.42}
 42%|████▏     | 1037/2496 [7:21:37<10:15:14, 25.30s/it] 42%|████▏     | 1038/2496 [7:22:02<10:13:46, 25.26s/it]                                                        {'loss': 0.7124, 'learning_rate': 1.3156736628788585e-05, 'epoch': 0.42}
 42%|████▏     | 1038/2496 [7:22:02<10:13:46, 25.26s/it] 42%|████▏     | 1039/2496 [7:22:30<10:34:34, 26.13s/it]                                                        {'loss': 0.7014, 'learning_rate': 1.3144421061743799e-05, 'epoch': 0.42}
 42%|████▏     | 1039/2496 [7:22:30<10:34:34, 26.13s/it] 42%|████▏     | 1040/2496 [7:22:55<10:26:14, 25.81s/it]                                                        {'loss': 0.7263, 'learning_rate': 1.3132100199883867e-05, 'epoch': 0.42}
 42%|████▏     | 1040/2496 [7:22:55<10:26:14, 25.81s/it] 42%|████▏     | 1041/2496 [7:23:20<10:21:13, 25.62s/it]                                                        {'loss': 0.643, 'learning_rate': 1.3119774063955602e-05, 'epoch': 0.42}
 42%|████▏     | 1041/2496 [7:23:20<10:21:13, 25.62s/it] 42%|████▏     | 1042/2496 [7:23:47<10:26:14, 25.84s/it]                                                        {'loss': 0.6657, 'learning_rate': 1.310744267471468e-05, 'epoch': 0.42}
 42%|████▏     | 1042/2496 [7:23:47<10:26:14, 25.84s/it] 42%|████▏     | 1043/2496 [7:24:12<10:19:37, 25.59s/it]                                                        {'loss': 0.2486, 'learning_rate': 1.3095106052925635e-05, 'epoch': 0.42}
 42%|████▏     | 1043/2496 [7:24:12<10:19:37, 25.59s/it] 42%|████▏     | 1044/2496 [7:24:38<10:24:40, 25.81s/it]                                                        {'loss': 0.6763, 'learning_rate': 1.308276421936181e-05, 'epoch': 0.42}
 42%|████▏     | 1044/2496 [7:24:38<10:24:40, 25.81s/it] 42%|████▏     | 1045/2496 [7:25:04<10:24:52, 25.84s/it]                                                        {'loss': 0.6843, 'learning_rate': 1.3070417194805315e-05, 'epoch': 0.42}
 42%|████▏     | 1045/2496 [7:25:04<10:24:52, 25.84s/it] 42%|████▏     | 1046/2496 [7:25:29<10:18:41, 25.60s/it]                                                        {'loss': 0.6972, 'learning_rate': 1.3058065000047018e-05, 'epoch': 0.42}
 42%|████▏     | 1046/2496 [7:25:29<10:18:41, 25.60s/it] 42%|████▏     | 1047/2496 [7:25:54<10:18:40, 25.62s/it]                                                        {'loss': 0.7277, 'learning_rate': 1.304570765588648e-05, 'epoch': 0.42}
 42%|████▏     | 1047/2496 [7:25:54<10:18:40, 25.62s/it] 42%|████▏     | 1048/2496 [7:26:20<10:19:02, 25.65s/it]                                                        {'loss': 0.6949, 'learning_rate': 1.303334518313193e-05, 'epoch': 0.42}
 42%|████▏     | 1048/2496 [7:26:20<10:19:02, 25.65s/it] 42%|████▏     | 1049/2496 [7:26:46<10:18:54, 25.66s/it]                                                        {'loss': 0.6707, 'learning_rate': 1.3020977602600247e-05, 'epoch': 0.42}
 42%|████▏     | 1049/2496 [7:26:46<10:18:54, 25.66s/it] 42%|████▏     | 1050/2496 [7:27:10<10:09:25, 25.29s/it]                                                        {'loss': 0.7152, 'learning_rate': 1.30086049351169e-05, 'epoch': 0.42}
 42%|████▏     | 1050/2496 [7:27:10<10:09:25, 25.29s/it] 42%|████▏     | 1051/2496 [7:27:34<9:56:59, 24.79s/it]                                                        {'loss': 0.6712, 'learning_rate': 1.2996227201515928e-05, 'epoch': 0.42}
 42%|████▏     | 1051/2496 [7:27:34<9:56:59, 24.79s/it] 42%|████▏     | 1052/2496 [7:28:02<10:22:15, 25.86s/it]                                                        {'loss': 0.722, 'learning_rate': 1.2983844422639896e-05, 'epoch': 0.42}
 42%|████▏     | 1052/2496 [7:28:02<10:22:15, 25.86s/it] 42%|████▏     | 1053/2496 [7:28:27<10:12:53, 25.48s/it]                                                        {'loss': 0.7033, 'learning_rate': 1.297145661933987e-05, 'epoch': 0.42}
 42%|████▏     | 1053/2496 [7:28:27<10:12:53, 25.48s/it] 42%|████▏     | 1054/2496 [7:28:53<10:19:38, 25.78s/it]                                                        {'loss': 0.7192, 'learning_rate': 1.2959063812475377e-05, 'epoch': 0.42}
 42%|████▏     | 1054/2496 [7:28:53<10:19:38, 25.78s/it] 42%|████▏     | 1055/2496 [7:29:19<10:21:32, 25.88s/it]                                                        {'loss': 0.6921, 'learning_rate': 1.2946666022914362e-05, 'epoch': 0.42}
 42%|████▏     | 1055/2496 [7:29:19<10:21:32, 25.88s/it] 42%|████▏     | 1056/2496 [7:29:43<10:05:06, 25.21s/it]                                                        {'loss': 0.7251, 'learning_rate': 1.293426327153317e-05, 'epoch': 0.42}
 42%|████▏     | 1056/2496 [7:29:43<10:05:06, 25.21s/it] 42%|████▏     | 1057/2496 [7:30:08<10:04:33, 25.21s/it]                                                        {'loss': 0.7148, 'learning_rate': 1.2921855579216494e-05, 'epoch': 0.42}
 42%|████▏     | 1057/2496 [7:30:08<10:04:33, 25.21s/it] 42%|████▏     | 1058/2496 [7:30:33<10:03:59, 25.20s/it]                                                        {'loss': 0.6966, 'learning_rate': 1.2909442966857349e-05, 'epoch': 0.42}
 42%|████▏     | 1058/2496 [7:30:34<10:03:59, 25.20s/it] 42%|████▏     | 1059/2496 [7:30:58<10:01:10, 25.10s/it]                                                        {'loss': 0.7089, 'learning_rate': 1.2897025455357035e-05, 'epoch': 0.42}
 42%|████▏     | 1059/2496 [7:30:58<10:01:10, 25.10s/it] 42%|████▏     | 1060/2496 [7:31:23<9:59:18, 25.04s/it]                                                        {'loss': 0.692, 'learning_rate': 1.2884603065625106e-05, 'epoch': 0.42}
 42%|████▏     | 1060/2496 [7:31:23<9:59:18, 25.04s/it] 43%|████▎     | 1061/2496 [7:31:49<10:02:48, 25.20s/it]                                                        {'loss': 0.7224, 'learning_rate': 1.2872175818579315e-05, 'epoch': 0.42}
 43%|████▎     | 1061/2496 [7:31:49<10:02:48, 25.20s/it] 43%|████▎     | 1062/2496 [7:32:14<9:59:59, 25.10s/it]                                                        {'loss': 0.681, 'learning_rate': 1.2859743735145618e-05, 'epoch': 0.43}
 43%|████▎     | 1062/2496 [7:32:14<9:59:59, 25.10s/it] 43%|████▎     | 1063/2496 [7:32:39<10:01:34, 25.19s/it]                                                        {'loss': 0.6873, 'learning_rate': 1.2847306836258095e-05, 'epoch': 0.43}
 43%|████▎     | 1063/2496 [7:32:39<10:01:34, 25.19s/it] 43%|████▎     | 1064/2496 [7:33:04<10:02:32, 25.25s/it]                                                        {'loss': 0.7234, 'learning_rate': 1.283486514285894e-05, 'epoch': 0.43}
 43%|████▎     | 1064/2496 [7:33:04<10:02:32, 25.25s/it] 43%|████▎     | 1065/2496 [7:33:30<10:01:04, 25.20s/it]                                                        {'loss': 0.6894, 'learning_rate': 1.2822418675898428e-05, 'epoch': 0.43}
 43%|████▎     | 1065/2496 [7:33:30<10:01:04, 25.20s/it] 43%|████▎     | 1066/2496 [7:33:54<9:56:42, 25.04s/it]                                                        {'loss': 0.6915, 'learning_rate': 1.2809967456334857e-05, 'epoch': 0.43}
 43%|████▎     | 1066/2496 [7:33:54<9:56:42, 25.04s/it] 43%|████▎     | 1067/2496 [7:34:19<9:56:02, 25.03s/it]                                                       {'loss': 0.7468, 'learning_rate': 1.2797511505134543e-05, 'epoch': 0.43}
 43%|████▎     | 1067/2496 [7:34:19<9:56:02, 25.03s/it] 43%|████▎     | 1068/2496 [7:34:45<10:03:02, 25.34s/it]                                                        {'loss': 0.7156, 'learning_rate': 1.2785050843271764e-05, 'epoch': 0.43}
 43%|████▎     | 1068/2496 [7:34:45<10:03:02, 25.34s/it] 43%|████▎     | 1069/2496 [7:35:09<9:53:47, 24.97s/it]                                                        {'loss': 0.6607, 'learning_rate': 1.2772585491728726e-05, 'epoch': 0.43}
 43%|████▎     | 1069/2496 [7:35:09<9:53:47, 24.97s/it] 43%|████▎     | 1070/2496 [7:35:36<10:01:50, 25.32s/it]                                                        {'loss': 0.6664, 'learning_rate': 1.2760115471495538e-05, 'epoch': 0.43}
 43%|████▎     | 1070/2496 [7:35:36<10:01:50, 25.32s/it]this iter is wrong in something... skip...
 43%|████▎     | 1071/2496 [7:36:01<10:05:46, 25.51s/it]                                                        {'loss': 0.6864, 'learning_rate': 1.2747640803570165e-05, 'epoch': 0.43}
 43%|████▎     | 1071/2496 [7:36:01<10:05:46, 25.51s/it]this iter is wrong in something... skip...
 43%|████▎     | 1072/2496 [7:36:26<10:01:07, 25.33s/it]                                                        {'loss': 0.6929, 'learning_rate': 1.2735161508958403e-05, 'epoch': 0.43}
 43%|████▎     | 1072/2496 [7:36:26<10:01:07, 25.33s/it] 43%|████▎     | 1073/2496 [7:36:49<9:42:02, 24.54s/it]                                                        {'loss': 0.7317, 'learning_rate': 1.2722677608673837e-05, 'epoch': 0.43}
 43%|████▎     | 1073/2496 [7:36:49<9:42:02, 24.54s/it] 43%|████▎     | 1074/2496 [7:37:15<9:50:37, 24.92s/it]                                                       {'loss': 0.6507, 'learning_rate': 1.2710189123737804e-05, 'epoch': 0.43}
 43%|████▎     | 1074/2496 [7:37:15<9:50:37, 24.92s/it] 43%|████▎     | 1075/2496 [7:37:40<9:50:01, 24.91s/it]                                                       {'loss': 0.6752, 'learning_rate': 1.2697696075179366e-05, 'epoch': 0.43}
 43%|████▎     | 1075/2496 [7:37:40<9:50:01, 24.91s/it] 43%|████▎     | 1076/2496 [7:38:05<9:53:04, 25.06s/it]                                                       {'loss': 0.7074, 'learning_rate': 1.2685198484035266e-05, 'epoch': 0.43}
 43%|████▎     | 1076/2496 [7:38:05<9:53:04, 25.06s/it] 43%|████▎     | 1077/2496 [7:38:29<9:40:27, 24.54s/it]                                                       {'loss': 0.7224, 'learning_rate': 1.2672696371349902e-05, 'epoch': 0.43}
 43%|████▎     | 1077/2496 [7:38:29<9:40:27, 24.54s/it] 43%|████▎     | 1078/2496 [7:38:52<9:30:25, 24.14s/it]                                                       {'loss': 0.6619, 'learning_rate': 1.2660189758175277e-05, 'epoch': 0.43}
 43%|████▎     | 1078/2496 [7:38:52<9:30:25, 24.14s/it] 43%|████▎     | 1079/2496 [7:39:16<9:33:39, 24.29s/it]                                                       {'loss': 0.6959, 'learning_rate': 1.2647678665570977e-05, 'epoch': 0.43}
 43%|████▎     | 1079/2496 [7:39:16<9:33:39, 24.29s/it] 43%|████▎     | 1080/2496 [7:39:40<9:30:28, 24.17s/it]                                                       {'loss': 0.6802, 'learning_rate': 1.2635163114604131e-05, 'epoch': 0.43}
 43%|████▎     | 1080/2496 [7:39:40<9:30:28, 24.17s/it] 43%|████▎     | 1081/2496 [7:40:04<9:24:51, 23.95s/it]                                                       {'loss': 0.6882, 'learning_rate': 1.2622643126349378e-05, 'epoch': 0.43}
 43%|████▎     | 1081/2496 [7:40:04<9:24:51, 23.95s/it] 43%|████▎     | 1082/2496 [7:40:33<9:58:56, 25.41s/it]                                                       {'loss': 0.6688, 'learning_rate': 1.2610118721888824e-05, 'epoch': 0.43}
 43%|████▎     | 1082/2496 [7:40:33<9:58:56, 25.41s/it] 43%|████▎     | 1083/2496 [7:40:57<9:49:31, 25.03s/it]                                                       {'loss': 0.683, 'learning_rate': 1.2597589922312009e-05, 'epoch': 0.43}
 43%|████▎     | 1083/2496 [7:40:57<9:49:31, 25.03s/it] 43%|████▎     | 1084/2496 [7:41:20<9:34:30, 24.41s/it]                                                       {'loss': 0.7216, 'learning_rate': 1.2585056748715885e-05, 'epoch': 0.43}
 43%|████▎     | 1084/2496 [7:41:20<9:34:30, 24.41s/it] 43%|████▎     | 1085/2496 [7:41:47<9:52:21, 25.19s/it]                                                       {'loss': 0.7265, 'learning_rate': 1.2572519222204752e-05, 'epoch': 0.43}
 43%|████▎     | 1085/2496 [7:41:47<9:52:21, 25.19s/it] 44%|████▎     | 1086/2496 [7:42:11<9:49:14, 25.07s/it]                                                       {'loss': 0.253, 'learning_rate': 1.2559977363890264e-05, 'epoch': 0.44}
 44%|████▎     | 1086/2496 [7:42:11<9:49:14, 25.07s/it] 44%|████▎     | 1087/2496 [7:42:35<9:41:27, 24.76s/it]                                                       {'loss': 0.6754, 'learning_rate': 1.254743119489134e-05, 'epoch': 0.44}
 44%|████▎     | 1087/2496 [7:42:35<9:41:27, 24.76s/it] 44%|████▎     | 1088/2496 [7:43:01<9:49:03, 25.10s/it]                                                       {'loss': 0.696, 'learning_rate': 1.2534880736334182e-05, 'epoch': 0.44}
 44%|████▎     | 1088/2496 [7:43:01<9:49:03, 25.10s/it] 44%|████▎     | 1089/2496 [7:43:27<9:49:04, 25.12s/it]                                                       {'loss': 0.694, 'learning_rate': 1.2522326009352207e-05, 'epoch': 0.44}
 44%|████▎     | 1089/2496 [7:43:27<9:49:04, 25.12s/it] 44%|████▎     | 1090/2496 [7:43:50<9:37:28, 24.64s/it]                                                       {'loss': 0.7087, 'learning_rate': 1.2509767035086014e-05, 'epoch': 0.44}
 44%|████▎     | 1090/2496 [7:43:50<9:37:28, 24.64s/it] 44%|████▎     | 1091/2496 [7:44:14<9:32:01, 24.43s/it]                                                       {'loss': 0.7179, 'learning_rate': 1.2497203834683359e-05, 'epoch': 0.44}
 44%|████▎     | 1091/2496 [7:44:14<9:32:01, 24.43s/it] 44%|████▍     | 1092/2496 [7:44:39<9:33:17, 24.50s/it]                                                       {'loss': 0.6996, 'learning_rate': 1.2484636429299113e-05, 'epoch': 0.44}
 44%|████▍     | 1092/2496 [7:44:39<9:33:17, 24.50s/it] 44%|████▍     | 1093/2496 [7:45:07<9:59:25, 25.64s/it]                                                       {'loss': 0.657, 'learning_rate': 1.2472064840095231e-05, 'epoch': 0.44}
 44%|████▍     | 1093/2496 [7:45:07<9:59:25, 25.64s/it] 44%|████▍     | 1094/2496 [7:45:34<10:10:18, 26.12s/it]                                                        {'loss': 0.6993, 'learning_rate': 1.245948908824071e-05, 'epoch': 0.44}
 44%|████▍     | 1094/2496 [7:45:34<10:10:18, 26.12s/it] 44%|████▍     | 1095/2496 [7:45:58<9:54:39, 25.47s/it]                                                        {'loss': 0.7264, 'learning_rate': 1.2446909194911552e-05, 'epoch': 0.44}
 44%|████▍     | 1095/2496 [7:45:58<9:54:39, 25.47s/it] 44%|████▍     | 1096/2496 [7:46:23<9:52:17, 25.38s/it]                                                       {'loss': 0.7, 'learning_rate': 1.243432518129074e-05, 'epoch': 0.44}
 44%|████▍     | 1096/2496 [7:46:23<9:52:17, 25.38s/it] 44%|████▍     | 1097/2496 [7:46:49<9:51:43, 25.38s/it]                                                       {'loss': 0.672, 'learning_rate': 1.2421737068568196e-05, 'epoch': 0.44}
 44%|████▍     | 1097/2496 [7:46:49<9:51:43, 25.38s/it] 44%|████▍     | 1098/2496 [7:47:14<9:52:16, 25.42s/it]                                                       {'loss': 0.7084, 'learning_rate': 1.2409144877940737e-05, 'epoch': 0.44}
 44%|████▍     | 1098/2496 [7:47:14<9:52:16, 25.42s/it] 44%|████▍     | 1099/2496 [7:47:40<9:52:24, 25.44s/it]                                                       {'loss': 0.7174, 'learning_rate': 1.2396548630612054e-05, 'epoch': 0.44}
 44%|████▍     | 1099/2496 [7:47:40<9:52:24, 25.44s/it] 44%|████▍     | 1100/2496 [7:48:05<9:49:38, 25.34s/it]                                                       {'loss': 0.6941, 'learning_rate': 1.2383948347792658e-05, 'epoch': 0.44}
 44%|████▍     | 1100/2496 [7:48:05<9:49:38, 25.34s/it] 44%|████▍     | 1101/2496 [7:48:29<9:41:55, 25.03s/it]                                                       {'loss': 0.716, 'learning_rate': 1.2371344050699872e-05, 'epoch': 0.44}
 44%|████▍     | 1101/2496 [7:48:29<9:41:55, 25.03s/it]this iter is wrong in something... skip...
 44%|████▍     | 1102/2496 [7:48:57<9:58:36, 25.77s/it]                                                       {'loss': 0.6648, 'learning_rate': 1.2358735760557763e-05, 'epoch': 0.44}
 44%|████▍     | 1102/2496 [7:48:57<9:58:36, 25.77s/it] 44%|████▍     | 1103/2496 [7:49:24<10:06:55, 26.14s/it]                                                        {'loss': 0.6846, 'learning_rate': 1.2346123498597132e-05, 'epoch': 0.44}
 44%|████▍     | 1103/2496 [7:49:24<10:06:55, 26.14s/it] 44%|████▍     | 1104/2496 [7:49:50<10:06:49, 26.16s/it]                                                        {'loss': 0.6905, 'learning_rate': 1.233350728605546e-05, 'epoch': 0.44}
 44%|████▍     | 1104/2496 [7:49:50<10:06:49, 26.16s/it] 44%|████▍     | 1105/2496 [7:50:14<9:55:44, 25.70s/it]                                                        {'loss': 0.6984, 'learning_rate': 1.2320887144176887e-05, 'epoch': 0.44}
 44%|████▍     | 1105/2496 [7:50:14<9:55:44, 25.70s/it] 44%|████▍     | 1106/2496 [7:50:38<9:38:45, 24.98s/it]                                                       {'loss': 0.6712, 'learning_rate': 1.2308263094212165e-05, 'epoch': 0.44}
 44%|████▍     | 1106/2496 [7:50:38<9:38:45, 24.98s/it] 44%|████▍     | 1107/2496 [7:51:02<9:31:31, 24.69s/it]                                                       {'loss': 0.6838, 'learning_rate': 1.2295635157418634e-05, 'epoch': 0.44}
 44%|████▍     | 1107/2496 [7:51:02<9:31:31, 24.69s/it] 44%|████▍     | 1108/2496 [7:51:26<9:25:23, 24.44s/it]                                                       {'loss': 0.6987, 'learning_rate': 1.2283003355060168e-05, 'epoch': 0.44}
 44%|████▍     | 1108/2496 [7:51:26<9:25:23, 24.44s/it] 44%|████▍     | 1109/2496 [7:51:52<9:39:32, 25.07s/it]                                                       {'loss': 0.7018, 'learning_rate': 1.2270367708407157e-05, 'epoch': 0.44}
 44%|████▍     | 1109/2496 [7:51:52<9:39:32, 25.07s/it] 44%|████▍     | 1110/2496 [7:52:15<9:24:34, 24.44s/it]                                                       {'loss': 0.6825, 'learning_rate': 1.2257728238736468e-05, 'epoch': 0.44}
 44%|████▍     | 1110/2496 [7:52:15<9:24:34, 24.44s/it] 45%|████▍     | 1111/2496 [7:52:40<9:24:12, 24.44s/it]                                                       {'loss': 0.7005, 'learning_rate': 1.224508496733139e-05, 'epoch': 0.45}
 45%|████▍     | 1111/2496 [7:52:40<9:24:12, 24.44s/it] 45%|████▍     | 1112/2496 [7:53:04<9:23:50, 24.44s/it]                                                       {'loss': 0.7192, 'learning_rate': 1.2232437915481633e-05, 'epoch': 0.45}
 45%|████▍     | 1112/2496 [7:53:04<9:23:50, 24.44s/it] 45%|████▍     | 1113/2496 [7:53:33<9:57:57, 25.94s/it]                                                       {'loss': 0.6986, 'learning_rate': 1.2219787104483265e-05, 'epoch': 0.45}
 45%|████▍     | 1113/2496 [7:53:33<9:57:57, 25.94s/it]this iter is wrong in something... skip...
 45%|████▍     | 1114/2496 [7:54:02<10:12:47, 26.60s/it]                                                        {'loss': 0.6773, 'learning_rate': 1.2207132555638676e-05, 'epoch': 0.45}
 45%|████▍     | 1114/2496 [7:54:02<10:12:47, 26.60s/it] 45%|████▍     | 1115/2496 [7:54:26<9:58:44, 26.01s/it]                                                        {'loss': 0.6777, 'learning_rate': 1.2194474290256563e-05, 'epoch': 0.45}
 45%|████▍     | 1115/2496 [7:54:26<9:58:44, 26.01s/it] 45%|████▍     | 1116/2496 [7:54:51<9:48:42, 25.60s/it]                                                       {'loss': 0.2373, 'learning_rate': 1.2181812329651869e-05, 'epoch': 0.45}
 45%|████▍     | 1116/2496 [7:54:51<9:48:42, 25.60s/it] 45%|████▍     | 1117/2496 [7:55:14<9:33:25, 24.95s/it]                                                       {'loss': 0.7044, 'learning_rate': 1.2169146695145773e-05, 'epoch': 0.45}
 45%|████▍     | 1117/2496 [7:55:14<9:33:25, 24.95s/it] 45%|████▍     | 1118/2496 [7:55:39<9:33:50, 24.99s/it]                                                       {'loss': 0.7028, 'learning_rate': 1.2156477408065625e-05, 'epoch': 0.45}
 45%|████▍     | 1118/2496 [7:55:39<9:33:50, 24.99s/it] 45%|████▍     | 1119/2496 [7:56:03<9:26:01, 24.66s/it]                                                       {'loss': 0.7111, 'learning_rate': 1.2143804489744941e-05, 'epoch': 0.45}
 45%|████▍     | 1119/2496 [7:56:03<9:26:01, 24.66s/it] 45%|████▍     | 1120/2496 [7:56:31<9:46:48, 25.59s/it]                                                       {'loss': 0.6754, 'learning_rate': 1.2131127961523342e-05, 'epoch': 0.45}
 45%|████▍     | 1120/2496 [7:56:31<9:46:48, 25.59s/it] 45%|████▍     | 1121/2496 [7:56:58<9:53:40, 25.91s/it]                                                       {'loss': 0.7284, 'learning_rate': 1.2118447844746523e-05, 'epoch': 0.45}
 45%|████▍     | 1121/2496 [7:56:58<9:53:40, 25.91s/it] 45%|████▍     | 1122/2496 [7:57:23<9:50:30, 25.79s/it]                                                       {'loss': 0.6747, 'learning_rate': 1.2105764160766235e-05, 'epoch': 0.45}
 45%|████▍     | 1122/2496 [7:57:23<9:50:30, 25.79s/it]this iter is wrong in something... skip...
 45%|████▍     | 1123/2496 [7:57:51<10:02:16, 26.32s/it]                                                        {'loss': 0.7102, 'learning_rate': 1.2093076930940231e-05, 'epoch': 0.45}
 45%|████▍     | 1123/2496 [7:57:51<10:02:16, 26.32s/it] 45%|████▌     | 1124/2496 [7:58:18<10:06:41, 26.53s/it]                                                        {'loss': 0.6613, 'learning_rate': 1.2080386176632223e-05, 'epoch': 0.45}
 45%|████▌     | 1124/2496 [7:58:18<10:06:41, 26.53s/it] 45%|████▌     | 1125/2496 [7:58:44<10:04:02, 26.44s/it]                                                        {'loss': 0.6743, 'learning_rate': 1.2067691919211879e-05, 'epoch': 0.45}
 45%|████▌     | 1125/2496 [7:58:44<10:04:02, 26.44s/it] 45%|████▌     | 1126/2496 [7:59:08<9:48:11, 25.76s/it]                                                        {'loss': 0.6979, 'learning_rate': 1.2054994180054747e-05, 'epoch': 0.45}
 45%|████▌     | 1126/2496 [7:59:08<9:48:11, 25.76s/it] 45%|████▌     | 1127/2496 [7:59:35<9:55:01, 26.08s/it]                                                       {'loss': 0.6447, 'learning_rate': 1.2042292980542244e-05, 'epoch': 0.45}
 45%|████▌     | 1127/2496 [7:59:35<9:55:01, 26.08s/it]this iter is wrong in something... skip...
 45%|████▌     | 1128/2496 [8:00:00<9:48:03, 25.79s/it]                                                       {'loss': 0.2213, 'learning_rate': 1.2029588342061623e-05, 'epoch': 0.45}
 45%|████▌     | 1128/2496 [8:00:00<9:48:03, 25.79s/it] 45%|████▌     | 1129/2496 [8:00:25<9:38:52, 25.41s/it]                                                       {'loss': 0.7098, 'learning_rate': 1.201688028600591e-05, 'epoch': 0.45}
 45%|████▌     | 1129/2496 [8:00:25<9:38:52, 25.41s/it] 45%|████▌     | 1130/2496 [8:00:52<9:53:34, 26.07s/it]                                                       {'loss': 0.692, 'learning_rate': 1.2004168833773899e-05, 'epoch': 0.45}
 45%|████▌     | 1130/2496 [8:00:52<9:53:34, 26.07s/it] 45%|████▌     | 1131/2496 [8:01:19<9:56:24, 26.22s/it]                                                       {'loss': 0.7127, 'learning_rate': 1.1991454006770107e-05, 'epoch': 0.45}
 45%|████▌     | 1131/2496 [8:01:19<9:56:24, 26.22s/it] 45%|████▌     | 1132/2496 [8:01:42<9:35:39, 25.32s/it]                                                       {'loss': 0.6625, 'learning_rate': 1.1978735826404715e-05, 'epoch': 0.45}
 45%|████▌     | 1132/2496 [8:01:42<9:35:39, 25.32s/it] 45%|████▌     | 1133/2496 [8:02:07<9:33:37, 25.25s/it]                                                       {'loss': 0.7285, 'learning_rate': 1.1966014314093568e-05, 'epoch': 0.45}
 45%|████▌     | 1133/2496 [8:02:07<9:33:37, 25.25s/it] 45%|████▌     | 1134/2496 [8:02:32<9:31:20, 25.17s/it]                                                       {'loss': 0.6729, 'learning_rate': 1.1953289491258113e-05, 'epoch': 0.45}
 45%|████▌     | 1134/2496 [8:02:32<9:31:20, 25.17s/it] 45%|████▌     | 1135/2496 [8:02:56<9:24:20, 24.88s/it]                                                       {'loss': 0.7203, 'learning_rate': 1.1940561379325371e-05, 'epoch': 0.45}
 45%|████▌     | 1135/2496 [8:02:56<9:24:20, 24.88s/it] 46%|████▌     | 1136/2496 [8:03:20<9:17:23, 24.59s/it]                                                       {'loss': 0.7047, 'learning_rate': 1.1927829999727911e-05, 'epoch': 0.46}
 46%|████▌     | 1136/2496 [8:03:20<9:17:23, 24.59s/it] 46%|████▌     | 1137/2496 [8:03:45<9:15:59, 24.55s/it]                                                       {'loss': 0.7121, 'learning_rate': 1.1915095373903789e-05, 'epoch': 0.46}
 46%|████▌     | 1137/2496 [8:03:45<9:15:59, 24.55s/it] 46%|████▌     | 1138/2496 [8:04:09<9:14:11, 24.49s/it]                                                       {'loss': 0.6974, 'learning_rate': 1.1902357523296544e-05, 'epoch': 0.46}
 46%|████▌     | 1138/2496 [8:04:09<9:14:11, 24.49s/it] 46%|████▌     | 1139/2496 [8:04:35<9:21:16, 24.82s/it]                                                       {'loss': 0.6632, 'learning_rate': 1.1889616469355135e-05, 'epoch': 0.46}
 46%|████▌     | 1139/2496 [8:04:35<9:21:16, 24.82s/it]this iter is wrong in something... skip...
 46%|████▌     | 1140/2496 [8:04:59<9:19:03, 24.74s/it]                                                       {'loss': 0.6958, 'learning_rate': 1.1876872233533909e-05, 'epoch': 0.46}
 46%|████▌     | 1140/2496 [8:04:59<9:19:03, 24.74s/it] 46%|████▌     | 1141/2496 [8:05:24<9:16:33, 24.64s/it]                                                       {'loss': 0.6798, 'learning_rate': 1.1864124837292588e-05, 'epoch': 0.46}
 46%|████▌     | 1141/2496 [8:05:24<9:16:33, 24.64s/it]this iter is wrong in something... skip...
 46%|████▌     | 1142/2496 [8:05:50<9:24:43, 25.02s/it]                                                       {'loss': 0.733, 'learning_rate': 1.1851374302096203e-05, 'epoch': 0.46}
 46%|████▌     | 1142/2496 [8:05:50<9:24:43, 25.02s/it] 46%|████▌     | 1143/2496 [8:06:16<9:33:32, 25.43s/it]                                                       {'loss': 0.7196, 'learning_rate': 1.1838620649415075e-05, 'epoch': 0.46}
 46%|████▌     | 1143/2496 [8:06:16<9:33:32, 25.43s/it] 46%|████▌     | 1144/2496 [8:06:41<9:31:20, 25.36s/it]                                                       {'loss': 0.7027, 'learning_rate': 1.1825863900724772e-05, 'epoch': 0.46}
 46%|████▌     | 1144/2496 [8:06:41<9:31:20, 25.36s/it] 46%|████▌     | 1145/2496 [8:07:06<9:28:22, 25.24s/it]                                                       {'loss': 0.7447, 'learning_rate': 1.181310407750608e-05, 'epoch': 0.46}
 46%|████▌     | 1145/2496 [8:07:06<9:28:22, 25.24s/it] 46%|████▌     | 1146/2496 [8:07:32<9:32:07, 25.43s/it]                                                       {'loss': 0.6874, 'learning_rate': 1.1800341201244954e-05, 'epoch': 0.46}
 46%|████▌     | 1146/2496 [8:07:32<9:32:07, 25.43s/it] 46%|████▌     | 1147/2496 [8:07:58<9:39:32, 25.78s/it]                                                       {'loss': 0.6629, 'learning_rate': 1.17875752934325e-05, 'epoch': 0.46}
 46%|████▌     | 1147/2496 [8:07:58<9:39:32, 25.78s/it] 46%|████▌     | 1148/2496 [8:08:24<9:34:28, 25.57s/it]                                                       {'loss': 0.68, 'learning_rate': 1.1774806375564923e-05, 'epoch': 0.46}
 46%|████▌     | 1148/2496 [8:08:24<9:34:28, 25.57s/it] 46%|████▌     | 1149/2496 [8:08:51<9:45:43, 26.09s/it]                                                       {'loss': 0.686, 'learning_rate': 1.1762034469143492e-05, 'epoch': 0.46}
 46%|████▌     | 1149/2496 [8:08:51<9:45:43, 26.09s/it] 46%|████▌     | 1150/2496 [8:09:17<9:43:45, 26.02s/it]                                                       {'loss': 0.6978, 'learning_rate': 1.1749259595674518e-05, 'epoch': 0.46}
 46%|████▌     | 1150/2496 [8:09:17<9:43:45, 26.02s/it] 46%|████▌     | 1151/2496 [8:09:44<9:52:22, 26.43s/it]                                                       {'loss': 0.7042, 'learning_rate': 1.1736481776669307e-05, 'epoch': 0.46}
 46%|████▌     | 1151/2496 [8:09:44<9:52:22, 26.43s/it]this iter is wrong in something... skip...
 46%|████▌     | 1152/2496 [8:10:10<9:48:14, 26.26s/it]                                                       {'loss': 0.6828, 'learning_rate': 1.1723701033644113e-05, 'epoch': 0.46}
 46%|████▌     | 1152/2496 [8:10:10<9:48:14, 26.26s/it] 46%|████▌     | 1153/2496 [8:10:35<9:40:42, 25.94s/it]                                                       {'loss': 0.7037, 'learning_rate': 1.171091738812013e-05, 'epoch': 0.46}
 46%|████▌     | 1153/2496 [8:10:35<9:40:42, 25.94s/it] 46%|████▌     | 1154/2496 [8:11:00<9:35:54, 25.75s/it]                                                       {'loss': 0.7156, 'learning_rate': 1.169813086162343e-05, 'epoch': 0.46}
 46%|████▌     | 1154/2496 [8:11:00<9:35:54, 25.75s/it]this iter is wrong in something... skip...
 46%|████▋     | 1155/2496 [8:11:27<9:40:31, 25.97s/it]                                                       {'loss': 0.7103, 'learning_rate': 1.1685341475684935e-05, 'epoch': 0.46}
 46%|████▋     | 1155/2496 [8:11:27<9:40:31, 25.97s/it] 46%|████▋     | 1156/2496 [8:11:51<9:29:28, 25.50s/it]                                                       {'loss': 0.6733, 'learning_rate': 1.1672549251840384e-05, 'epoch': 0.46}
 46%|████▋     | 1156/2496 [8:11:51<9:29:28, 25.50s/it] 46%|████▋     | 1157/2496 [8:12:15<9:18:47, 25.04s/it]                                                       {'loss': 0.6816, 'learning_rate': 1.1659754211630305e-05, 'epoch': 0.46}
 46%|████▋     | 1157/2496 [8:12:15<9:18:47, 25.04s/it] 46%|████▋     | 1158/2496 [8:12:40<9:15:35, 24.91s/it]                                                       {'loss': 0.7173, 'learning_rate': 1.1646956376599952e-05, 'epoch': 0.46}
 46%|████▋     | 1158/2496 [8:12:40<9:15:35, 24.91s/it] 46%|████▋     | 1159/2496 [8:13:05<9:15:37, 24.93s/it]                                                       {'loss': 0.6942, 'learning_rate': 1.1634155768299286e-05, 'epoch': 0.46}
 46%|████▋     | 1159/2496 [8:13:05<9:15:37, 24.93s/it] 46%|████▋     | 1160/2496 [8:13:29<9:10:08, 24.71s/it]                                                       {'loss': 0.7112, 'learning_rate': 1.162135240828296e-05, 'epoch': 0.46}
 46%|████▋     | 1160/2496 [8:13:29<9:10:08, 24.71s/it] 47%|████▋     | 1161/2496 [8:13:54<9:11:41, 24.79s/it]                                                       {'loss': 0.7022, 'learning_rate': 1.160854631811023e-05, 'epoch': 0.47}
 47%|████▋     | 1161/2496 [8:13:54<9:11:41, 24.79s/it] 47%|████▋     | 1162/2496 [8:14:20<9:17:37, 25.08s/it]                                                       {'loss': 0.6852, 'learning_rate': 1.1595737519344971e-05, 'epoch': 0.47}
 47%|████▋     | 1162/2496 [8:14:20<9:17:37, 25.08s/it] 47%|████▋     | 1163/2496 [8:14:45<9:15:48, 25.02s/it]                                                       {'loss': 0.7067, 'learning_rate': 1.158292603355561e-05, 'epoch': 0.47}
 47%|████▋     | 1163/2496 [8:14:45<9:15:48, 25.02s/it] 47%|████▋     | 1164/2496 [8:15:12<9:27:09, 25.55s/it]                                                       {'loss': 0.7253, 'learning_rate': 1.15701118823151e-05, 'epoch': 0.47}
 47%|████▋     | 1164/2496 [8:15:12<9:27:09, 25.55s/it] 47%|████▋     | 1165/2496 [8:15:39<9:37:34, 26.04s/it]                                                       {'loss': 0.693, 'learning_rate': 1.1557295087200887e-05, 'epoch': 0.47}
 47%|████▋     | 1165/2496 [8:15:39<9:37:34, 26.04s/it] 47%|████▋     | 1166/2496 [8:16:03<9:24:02, 25.45s/it]                                                       {'loss': 0.6825, 'learning_rate': 1.1544475669794855e-05, 'epoch': 0.47}
 47%|████▋     | 1166/2496 [8:16:03<9:24:02, 25.45s/it] 47%|████▋     | 1167/2496 [8:16:33<9:56:53, 26.95s/it]                                                       {'loss': 0.6748, 'learning_rate': 1.153165365168332e-05, 'epoch': 0.47}
 47%|████▋     | 1167/2496 [8:16:33<9:56:53, 26.95s/it] 47%|████▋     | 1168/2496 [8:16:59<9:51:35, 26.73s/it]                                                       {'loss': 0.677, 'learning_rate': 1.1518829054456973e-05, 'epoch': 0.47}
 47%|████▋     | 1168/2496 [8:16:59<9:51:35, 26.73s/it] 47%|████▋     | 1169/2496 [8:17:24<9:38:58, 26.18s/it]                                                       {'loss': 0.2496, 'learning_rate': 1.1506001899710838e-05, 'epoch': 0.47}
 47%|████▋     | 1169/2496 [8:17:24<9:38:58, 26.18s/it] 47%|████▋     | 1170/2496 [8:17:52<9:45:58, 26.51s/it]                                                       {'loss': 0.6709, 'learning_rate': 1.1493172209044259e-05, 'epoch': 0.47}
 47%|████▋     | 1170/2496 [8:17:52<9:45:58, 26.51s/it] 47%|████▋     | 1171/2496 [8:18:18<9:43:28, 26.42s/it]                                                       {'loss': 0.7043, 'learning_rate': 1.1480340004060842e-05, 'epoch': 0.47}
 47%|████▋     | 1171/2496 [8:18:18<9:43:28, 26.42s/it] 47%|████▋     | 1172/2496 [8:18:43<9:35:31, 26.08s/it]                                                       {'loss': 0.706, 'learning_rate': 1.1467505306368429e-05, 'epoch': 0.47}
 47%|████▋     | 1172/2496 [8:18:43<9:35:31, 26.08s/it] 47%|████▋     | 1173/2496 [8:19:08<9:25:36, 25.65s/it]                                                       {'loss': 0.6883, 'learning_rate': 1.1454668137579059e-05, 'epoch': 0.47}
 47%|████▋     | 1173/2496 [8:19:08<9:25:36, 25.65s/it] 47%|████▋     | 1174/2496 [8:19:33<9:24:59, 25.64s/it]                                                       {'loss': 0.7054, 'learning_rate': 1.1441828519308933e-05, 'epoch': 0.47}
 47%|████▋     | 1174/2496 [8:19:33<9:24:59, 25.64s/it] 47%|████▋     | 1175/2496 [8:19:57<9:14:02, 25.16s/it]                                                       {'loss': 0.6761, 'learning_rate': 1.1428986473178375e-05, 'epoch': 0.47}
 47%|████▋     | 1175/2496 [8:19:57<9:14:02, 25.16s/it] 47%|████▋     | 1176/2496 [8:20:23<9:13:53, 25.18s/it]                                                       {'loss': 0.2385, 'learning_rate': 1.1416142020811798e-05, 'epoch': 0.47}
 47%|████▋     | 1176/2496 [8:20:23<9:13:53, 25.18s/it] 47%|████▋     | 1177/2496 [8:20:47<9:10:06, 25.02s/it]                                                       {'loss': 0.7274, 'learning_rate': 1.1403295183837669e-05, 'epoch': 0.47}
 47%|████▋     | 1177/2496 [8:20:47<9:10:06, 25.02s/it] 47%|████▋     | 1178/2496 [8:21:17<9:42:29, 26.52s/it]                                                       {'loss': 0.7124, 'learning_rate': 1.1390445983888465e-05, 'epoch': 0.47}
 47%|████▋     | 1178/2496 [8:21:17<9:42:29, 26.52s/it] 47%|████▋     | 1179/2496 [8:21:45<9:47:42, 26.77s/it]                                                       {'loss': 0.6853, 'learning_rate': 1.137759444260065e-05, 'epoch': 0.47}
 47%|████▋     | 1179/2496 [8:21:45<9:47:42, 26.77s/it] 47%|████▋     | 1180/2496 [8:22:07<9:19:06, 25.49s/it]                                                       {'loss': 0.7134, 'learning_rate': 1.1364740581614622e-05, 'epoch': 0.47}
 47%|████▋     | 1180/2496 [8:22:07<9:19:06, 25.49s/it] 47%|████▋     | 1181/2496 [8:22:33<9:23:50, 25.73s/it]                                                       {'loss': 0.7165, 'learning_rate': 1.1351884422574693e-05, 'epoch': 0.47}
 47%|████▋     | 1181/2496 [8:22:33<9:23:50, 25.73s/it] 47%|████▋     | 1182/2496 [8:23:00<9:31:16, 26.09s/it]                                                       {'loss': 0.6909, 'learning_rate': 1.1339025987129033e-05, 'epoch': 0.47}
 47%|████▋     | 1182/2496 [8:23:00<9:31:16, 26.09s/it] 47%|████▋     | 1183/2496 [8:23:25<9:23:36, 25.75s/it]                                                       {'loss': 0.2613, 'learning_rate': 1.132616529692966e-05, 'epoch': 0.47}
 47%|████▋     | 1183/2496 [8:23:25<9:23:36, 25.75s/it] 47%|████▋     | 1184/2496 [8:23:51<9:20:22, 25.63s/it]                                                       {'loss': 0.6931, 'learning_rate': 1.1313302373632382e-05, 'epoch': 0.47}
 47%|████▋     | 1184/2496 [8:23:51<9:20:22, 25.63s/it] 47%|████▋     | 1185/2496 [8:24:17<9:25:15, 25.87s/it]                                                       {'loss': 0.6815, 'learning_rate': 1.1300437238896758e-05, 'epoch': 0.47}
 47%|████▋     | 1185/2496 [8:24:17<9:25:15, 25.87s/it] 48%|████▊     | 1186/2496 [8:24:41<9:09:39, 25.18s/it]                                                       {'loss': 0.6963, 'learning_rate': 1.1287569914386092e-05, 'epoch': 0.48}
 48%|████▊     | 1186/2496 [8:24:41<9:09:39, 25.18s/it] 48%|████▊     | 1187/2496 [8:25:06<9:10:14, 25.22s/it]                                                       {'loss': 0.6658, 'learning_rate': 1.1274700421767351e-05, 'epoch': 0.48}
 48%|████▊     | 1187/2496 [8:25:06<9:10:14, 25.22s/it] 48%|████▊     | 1188/2496 [8:25:30<9:00:54, 24.81s/it]                                                       {'loss': 0.7066, 'learning_rate': 1.1261828782711172e-05, 'epoch': 0.48}
 48%|████▊     | 1188/2496 [8:25:30<9:00:54, 24.81s/it]this iter is wrong in something... skip...
 48%|████▊     | 1189/2496 [8:25:56<9:09:29, 25.23s/it]                                                       {'loss': 0.6995, 'learning_rate': 1.1248955018891798e-05, 'epoch': 0.48}
 48%|████▊     | 1189/2496 [8:25:56<9:09:29, 25.23s/it] 48%|████▊     | 1190/2496 [8:26:21<9:06:26, 25.10s/it]                                                       {'loss': 0.6823, 'learning_rate': 1.1236079151987047e-05, 'epoch': 0.48}
 48%|████▊     | 1190/2496 [8:26:21<9:06:26, 25.10s/it] 48%|████▊     | 1191/2496 [8:26:46<9:09:16, 25.25s/it]                                                       {'loss': 0.7132, 'learning_rate': 1.1223201203678289e-05, 'epoch': 0.48}
 48%|████▊     | 1191/2496 [8:26:47<9:09:16, 25.25s/it] 48%|████▊     | 1192/2496 [8:27:12<9:09:49, 25.30s/it]                                                       {'loss': 0.7189, 'learning_rate': 1.1210321195650385e-05, 'epoch': 0.48}
 48%|████▊     | 1192/2496 [8:27:12<9:09:49, 25.30s/it] 48%|████▊     | 1193/2496 [8:27:36<8:59:28, 24.84s/it]                                                       {'loss': 0.7114, 'learning_rate': 1.1197439149591676e-05, 'epoch': 0.48}
 48%|████▊     | 1193/2496 [8:27:36<8:59:28, 24.84s/it] 48%|████▊     | 1194/2496 [8:28:03<9:16:18, 25.64s/it]                                                       {'loss': 0.6864, 'learning_rate': 1.1184555087193927e-05, 'epoch': 0.48}
 48%|████▊     | 1194/2496 [8:28:03<9:16:18, 25.64s/it] 48%|████▊     | 1195/2496 [8:28:31<9:29:17, 26.26s/it]                                                       {'loss': 0.665, 'learning_rate': 1.1171669030152303e-05, 'epoch': 0.48}
 48%|████▊     | 1195/2496 [8:28:31<9:29:17, 26.26s/it] 48%|████▊     | 1196/2496 [8:28:57<9:26:23, 26.14s/it]                                                       {'loss': 0.2418, 'learning_rate': 1.115878100016533e-05, 'epoch': 0.48}
 48%|████▊     | 1196/2496 [8:28:57<9:26:23, 26.14s/it] 48%|████▊     | 1197/2496 [8:29:22<9:23:16, 26.02s/it]                                                       {'loss': 0.6707, 'learning_rate': 1.1145891018934842e-05, 'epoch': 0.48}
 48%|████▊     | 1197/2496 [8:29:22<9:23:16, 26.02s/it] 48%|████▊     | 1198/2496 [8:29:48<9:18:06, 25.80s/it]                                                       {'loss': 0.671, 'learning_rate': 1.1132999108165981e-05, 'epoch': 0.48}
 48%|████▊     | 1198/2496 [8:29:48<9:18:06, 25.80s/it] 48%|████▊     | 1199/2496 [8:30:13<9:15:59, 25.72s/it]                                                       {'loss': 0.6893, 'learning_rate': 1.1120105289567116e-05, 'epoch': 0.48}
 48%|████▊     | 1199/2496 [8:30:13<9:15:59, 25.72s/it] 48%|████▊     | 1200/2496 [8:30:40<9:19:25, 25.90s/it]                                                       {'loss': 0.637, 'learning_rate': 1.1107209584849845e-05, 'epoch': 0.48}
 48%|████▊     | 1200/2496 [8:30:40<9:19:25, 25.90s/it] 48%|████▊     | 1201/2496 [8:31:08<9:36:27, 26.71s/it]                                                       {'loss': 0.6863, 'learning_rate': 1.1094312015728932e-05, 'epoch': 0.48}
 48%|████▊     | 1201/2496 [8:31:08<9:36:27, 26.71s/it] 48%|████▊     | 1202/2496 [8:31:34<9:33:02, 26.57s/it]                                                       {'loss': 0.7207, 'learning_rate': 1.1081412603922289e-05, 'epoch': 0.48}
 48%|████▊     | 1202/2496 [8:31:34<9:33:02, 26.57s/it] 48%|████▊     | 1203/2496 [8:31:58<9:14:41, 25.74s/it]                                                       {'loss': 0.6981, 'learning_rate': 1.1068511371150919e-05, 'epoch': 0.48}
 48%|████▊     | 1203/2496 [8:31:58<9:14:41, 25.74s/it] 48%|████▊     | 1204/2496 [8:32:25<9:20:38, 26.04s/it]                                                       {'loss': 0.7238, 'learning_rate': 1.1055608339138902e-05, 'epoch': 0.48}
 48%|████▊     | 1204/2496 [8:32:25<9:20:38, 26.04s/it] 48%|████▊     | 1205/2496 [8:32:54<9:37:10, 26.82s/it]                                                       {'loss': 0.6877, 'learning_rate': 1.1042703529613344e-05, 'epoch': 0.48}
 48%|████▊     | 1205/2496 [8:32:54<9:37:10, 26.82s/it] 48%|████▊     | 1206/2496 [8:33:20<9:30:33, 26.54s/it]                                                       {'loss': 0.6722, 'learning_rate': 1.102979696430434e-05, 'epoch': 0.48}
 48%|████▊     | 1206/2496 [8:33:20<9:30:33, 26.54s/it] 48%|████▊     | 1207/2496 [8:33:43<9:12:05, 25.70s/it]                                                       {'loss': 0.6719, 'learning_rate': 1.1016888664944957e-05, 'epoch': 0.48}
 48%|████▊     | 1207/2496 [8:33:43<9:12:05, 25.70s/it] 48%|████▊     | 1208/2496 [8:34:08<9:03:17, 25.31s/it]                                                       {'loss': 0.6829, 'learning_rate': 1.1003978653271157e-05, 'epoch': 0.48}
 48%|████▊     | 1208/2496 [8:34:08<9:03:17, 25.31s/it] 48%|████▊     | 1209/2496 [8:34:33<9:02:33, 25.29s/it]                                                       {'loss': 0.7355, 'learning_rate': 1.0991066951021802e-05, 'epoch': 0.48}
 48%|████▊     | 1209/2496 [8:34:33<9:02:33, 25.29s/it] 48%|████▊     | 1210/2496 [8:34:59<9:05:06, 25.43s/it]                                                       {'loss': 0.6684, 'learning_rate': 1.0978153579938604e-05, 'epoch': 0.48}
 48%|████▊     | 1210/2496 [8:34:59<9:05:06, 25.43s/it] 49%|████▊     | 1211/2496 [8:35:23<8:59:58, 25.21s/it]                                                       {'loss': 0.7376, 'learning_rate': 1.096523856176607e-05, 'epoch': 0.49}
 49%|████▊     | 1211/2496 [8:35:23<8:59:58, 25.21s/it] 49%|████▊     | 1212/2496 [8:35:47<8:47:27, 24.65s/it]                                                       {'loss': 0.7064, 'learning_rate': 1.0952321918251499e-05, 'epoch': 0.49}
 49%|████▊     | 1212/2496 [8:35:47<8:47:27, 24.65s/it] 49%|████▊     | 1213/2496 [8:36:12<8:51:49, 24.87s/it]                                                       {'loss': 0.674, 'learning_rate': 1.0939403671144903e-05, 'epoch': 0.49}
 49%|████▊     | 1213/2496 [8:36:12<8:51:49, 24.87s/it]this iter is wrong in something... skip...
 49%|████▊     | 1214/2496 [8:36:37<8:51:34, 24.88s/it]                                                       {'loss': 0.6453, 'learning_rate': 1.0926483842199023e-05, 'epoch': 0.49}
 49%|████▊     | 1214/2496 [8:36:37<8:51:34, 24.88s/it] 49%|████▊     | 1215/2496 [8:37:05<9:10:44, 25.80s/it]                                                       {'loss': 0.6981, 'learning_rate': 1.0913562453169241e-05, 'epoch': 0.49}
 49%|████▊     | 1215/2496 [8:37:05<9:10:44, 25.80s/it] 49%|████▊     | 1216/2496 [8:37:30<9:04:45, 25.54s/it]                                                       {'loss': 0.6787, 'learning_rate': 1.0900639525813573e-05, 'epoch': 0.49}
 49%|████▊     | 1216/2496 [8:37:30<9:04:45, 25.54s/it] 49%|████▉     | 1217/2496 [8:37:55<9:00:47, 25.37s/it]                                                       {'loss': 0.6697, 'learning_rate': 1.0887715081892626e-05, 'epoch': 0.49}
 49%|████▉     | 1217/2496 [8:37:55<9:00:47, 25.37s/it] 49%|████▉     | 1218/2496 [8:38:21<9:08:15, 25.74s/it]                                                       {'loss': 0.6887, 'learning_rate': 1.0874789143169569e-05, 'epoch': 0.49}
 49%|████▉     | 1218/2496 [8:38:21<9:08:15, 25.74s/it] 49%|████▉     | 1219/2496 [8:38:47<9:08:07, 25.75s/it]                                                       {'loss': 0.6995, 'learning_rate': 1.086186173141007e-05, 'epoch': 0.49}
 49%|████▉     | 1219/2496 [8:38:47<9:08:07, 25.75s/it] 49%|████▉     | 1220/2496 [8:39:15<9:20:34, 26.36s/it]                                                       {'loss': 0.6775, 'learning_rate': 1.0848932868382292e-05, 'epoch': 0.49}
 49%|████▉     | 1220/2496 [8:39:15<9:20:34, 26.36s/it] 49%|████▉     | 1221/2496 [8:39:41<9:20:38, 26.38s/it]                                                       {'loss': 0.6782, 'learning_rate': 1.0836002575856835e-05, 'epoch': 0.49}
 49%|████▉     | 1221/2496 [8:39:41<9:20:38, 26.38s/it] 49%|████▉     | 1222/2496 [8:40:06<9:09:11, 25.86s/it]                                                       {'loss': 0.6978, 'learning_rate': 1.0823070875606712e-05, 'epoch': 0.49}
 49%|████▉     | 1222/2496 [8:40:06<9:09:11, 25.86s/it] 49%|████▉     | 1223/2496 [8:40:30<8:59:08, 25.41s/it]                                                       {'loss': 0.706, 'learning_rate': 1.0810137789407298e-05, 'epoch': 0.49}
 49%|████▉     | 1223/2496 [8:40:30<8:59:08, 25.41s/it] 49%|████▉     | 1224/2496 [8:40:53<8:40:54, 24.57s/it]                                                       {'loss': 0.6919, 'learning_rate': 1.0797203339036308e-05, 'epoch': 0.49}
 49%|████▉     | 1224/2496 [8:40:53<8:40:54, 24.57s/it] 49%|████▉     | 1225/2496 [8:41:20<8:55:44, 25.29s/it]                                                       {'loss': 0.6724, 'learning_rate': 1.0784267546273754e-05, 'epoch': 0.49}
 49%|████▉     | 1225/2496 [8:41:20<8:55:44, 25.29s/it] 49%|████▉     | 1226/2496 [8:41:44<8:47:53, 24.94s/it]                                                       {'loss': 0.7215, 'learning_rate': 1.0771330432901905e-05, 'epoch': 0.49}
 49%|████▉     | 1226/2496 [8:41:44<8:47:53, 24.94s/it] 49%|████▉     | 1227/2496 [8:42:09<8:44:55, 24.82s/it]                                                       {'loss': 0.2465, 'learning_rate': 1.0758392020705258e-05, 'epoch': 0.49}
 49%|████▉     | 1227/2496 [8:42:09<8:44:55, 24.82s/it] 49%|████▉     | 1228/2496 [8:42:33<8:42:07, 24.71s/it]                                                       {'loss': 0.7065, 'learning_rate': 1.0745452331470492e-05, 'epoch': 0.49}
 49%|████▉     | 1228/2496 [8:42:33<8:42:07, 24.71s/it] 49%|████▉     | 1229/2496 [8:42:56<8:31:13, 24.21s/it]                                                       {'loss': 0.6949, 'learning_rate': 1.0732511386986439e-05, 'epoch': 0.49}
 49%|████▉     | 1229/2496 [8:42:56<8:31:13, 24.21s/it] 49%|████▉     | 1230/2496 [8:43:23<8:44:18, 24.85s/it]                                                       {'loss': 0.7173, 'learning_rate': 1.0719569209044047e-05, 'epoch': 0.49}
 49%|████▉     | 1230/2496 [8:43:23<8:44:18, 24.85s/it] 49%|████▉     | 1231/2496 [8:43:47<8:43:47, 24.84s/it]                                                       {'loss': 0.2397, 'learning_rate': 1.070662581943634e-05, 'epoch': 0.49}
 49%|████▉     | 1231/2496 [8:43:47<8:43:47, 24.84s/it] 49%|████▉     | 1232/2496 [8:44:14<8:53:53, 25.34s/it]                                                       {'loss': 0.7171, 'learning_rate': 1.0693681239958376e-05, 'epoch': 0.49}
 49%|████▉     | 1232/2496 [8:44:14<8:53:53, 25.34s/it] 49%|████▉     | 1233/2496 [8:44:42<9:08:46, 26.07s/it]                                                       {'loss': 0.6789, 'learning_rate': 1.0680735492407225e-05, 'epoch': 0.49}
 49%|████▉     | 1233/2496 [8:44:42<9:08:46, 26.07s/it] 49%|████▉     | 1234/2496 [8:45:10<9:25:27, 26.88s/it]                                                       {'loss': 0.6956, 'learning_rate': 1.0667788598581921e-05, 'epoch': 0.49}
 49%|████▉     | 1234/2496 [8:45:10<9:25:27, 26.88s/it]this iter is wrong in something... skip...
 49%|████▉     | 1235/2496 [8:45:38<9:27:25, 27.00s/it]                                                       {'loss': 0.676, 'learning_rate': 1.0654840580283423e-05, 'epoch': 0.49}
 49%|████▉     | 1235/2496 [8:45:38<9:27:25, 27.00s/it] 50%|████▉     | 1236/2496 [8:46:02<9:12:29, 26.31s/it]                                                       {'loss': 0.6651, 'learning_rate': 1.0641891459314598e-05, 'epoch': 0.5}
 50%|████▉     | 1236/2496 [8:46:02<9:12:29, 26.31s/it] 50%|████▉     | 1237/2496 [8:46:27<9:01:58, 25.83s/it]                                                       {'loss': 0.7289, 'learning_rate': 1.0628941257480148e-05, 'epoch': 0.5}
 50%|████▉     | 1237/2496 [8:46:27<9:01:58, 25.83s/it] 50%|████▉     | 1238/2496 [8:46:51<8:49:11, 25.24s/it]                                                       {'loss': 0.6885, 'learning_rate': 1.0615989996586615e-05, 'epoch': 0.5}
 50%|████▉     | 1238/2496 [8:46:51<8:49:11, 25.24s/it] 50%|████▉     | 1239/2496 [8:47:16<8:46:14, 25.12s/it]                                                       {'loss': 0.6925, 'learning_rate': 1.0603037698442316e-05, 'epoch': 0.5}
 50%|████▉     | 1239/2496 [8:47:16<8:46:14, 25.12s/it] 50%|████▉     | 1240/2496 [8:47:39<8:34:51, 24.59s/it]                                                       {'loss': 0.7136, 'learning_rate': 1.0590084384857309e-05, 'epoch': 0.5}
 50%|████▉     | 1240/2496 [8:47:39<8:34:51, 24.59s/it] 50%|████▉     | 1241/2496 [8:48:07<8:57:07, 25.68s/it]                                                       {'loss': 0.7078, 'learning_rate': 1.0577130077643376e-05, 'epoch': 0.5}
 50%|████▉     | 1241/2496 [8:48:07<8:57:07, 25.68s/it] 50%|████▉     | 1242/2496 [8:48:33<8:58:48, 25.78s/it]                                                       {'loss': 0.6744, 'learning_rate': 1.0564174798613957e-05, 'epoch': 0.5}
 50%|████▉     | 1242/2496 [8:48:33<8:58:48, 25.78s/it] 50%|████▉     | 1243/2496 [8:48:58<8:49:58, 25.38s/it]                                                       {'loss': 0.7197, 'learning_rate': 1.0551218569584138e-05, 'epoch': 0.5}
 50%|████▉     | 1243/2496 [8:48:58<8:49:58, 25.38s/it] 50%|████▉     | 1244/2496 [8:49:23<8:47:29, 25.28s/it]                                                       {'loss': 0.6422, 'learning_rate': 1.0538261412370603e-05, 'epoch': 0.5}
 50%|████▉     | 1244/2496 [8:49:23<8:47:29, 25.28s/it] 50%|████▉     | 1245/2496 [8:49:47<8:42:06, 25.04s/it]                                                       {'loss': 0.674, 'learning_rate': 1.0525303348791599e-05, 'epoch': 0.5}
 50%|████▉     | 1245/2496 [8:49:47<8:42:06, 25.04s/it] 50%|████▉     | 1246/2496 [8:50:11<8:32:39, 24.61s/it]                                                       {'loss': 0.7002, 'learning_rate': 1.0512344400666892e-05, 'epoch': 0.5}
 50%|████▉     | 1246/2496 [8:50:11<8:32:39, 24.61s/it]this iter is wrong in something... skip...
 50%|████▉     | 1247/2496 [8:50:36<8:38:01, 24.88s/it]                                                       {'loss': 0.6998, 'learning_rate': 1.0499384589817752e-05, 'epoch': 0.5}
 50%|████▉     | 1247/2496 [8:50:36<8:38:01, 24.88s/it]this iter is wrong in something... skip...
 50%|█████     | 1248/2496 [8:51:01<8:34:06, 24.72s/it]                                                       {'loss': 0.6721, 'learning_rate': 1.0486423938066888e-05, 'epoch': 0.5}
 50%|█████     | 1248/2496 [8:51:01<8:34:06, 24.72s/it] 50%|█████     | 1249/2496 [8:51:26<8:38:39, 24.96s/it]                                                       {'loss': 0.6814, 'learning_rate': 1.047346246723843e-05, 'epoch': 0.5}
 50%|█████     | 1249/2496 [8:51:26<8:38:39, 24.96s/it] 50%|█████     | 1250/2496 [8:51:51<8:35:55, 24.84s/it]                                                       {'loss': 0.6841, 'learning_rate': 1.046050019915789e-05, 'epoch': 0.5}
 50%|█████     | 1250/2496 [8:51:51<8:35:55, 24.84s/it] 50%|█████     | 1251/2496 [8:52:17<8:40:48, 25.10s/it]                                                       {'loss': 0.719, 'learning_rate': 1.044753715565212e-05, 'epoch': 0.5}
 50%|█████     | 1251/2496 [8:52:17<8:40:48, 25.10s/it] 50%|█████     | 1252/2496 [8:52:43<8:46:55, 25.41s/it]                                                       {'loss': 0.6908, 'learning_rate': 1.0434573358549278e-05, 'epoch': 0.5}
 50%|█████     | 1252/2496 [8:52:43<8:46:55, 25.41s/it] 50%|█████     | 1253/2496 [8:53:08<8:44:04, 25.30s/it]                                                       {'loss': 0.6803, 'learning_rate': 1.042160882967879e-05, 'epoch': 0.5}
 50%|█████     | 1253/2496 [8:53:08<8:44:04, 25.30s/it] 50%|█████     | 1254/2496 [8:53:34<8:47:54, 25.50s/it]                                                       {'loss': 0.6736, 'learning_rate': 1.0408643590871312e-05, 'epoch': 0.5}
 50%|█████     | 1254/2496 [8:53:34<8:47:54, 25.50s/it] 50%|█████     | 1255/2496 [8:54:00<8:54:33, 25.84s/it]                                                       {'loss': 0.67, 'learning_rate': 1.0395677663958703e-05, 'epoch': 0.5}
 50%|█████     | 1255/2496 [8:54:00<8:54:33, 25.84s/it] 50%|█████     | 1256/2496 [8:54:24<8:42:01, 25.26s/it]                                                       {'loss': 0.7067, 'learning_rate': 1.0382711070773972e-05, 'epoch': 0.5}
 50%|█████     | 1256/2496 [8:54:24<8:42:01, 25.26s/it] 50%|█████     | 1257/2496 [8:54:49<8:36:30, 25.01s/it]                                                       {'loss': 0.727, 'learning_rate': 1.036974383315126e-05, 'epoch': 0.5}
 50%|█████     | 1257/2496 [8:54:49<8:36:30, 25.01s/it] 50%|█████     | 1258/2496 [8:55:13<8:33:36, 24.89s/it]                                                       {'loss': 0.7004, 'learning_rate': 1.0356775972925781e-05, 'epoch': 0.5}
 50%|█████     | 1258/2496 [8:55:13<8:33:36, 24.89s/it] 50%|█████     | 1259/2496 [8:55:38<8:30:17, 24.75s/it]                                                       {'loss': 0.6953, 'learning_rate': 1.0343807511933803e-05, 'epoch': 0.5}
 50%|█████     | 1259/2496 [8:55:38<8:30:17, 24.75s/it] 50%|█████     | 1260/2496 [8:56:04<8:39:13, 25.21s/it]                                                       {'loss': 0.6881, 'learning_rate': 1.0330838472012617e-05, 'epoch': 0.5}
 50%|█████     | 1260/2496 [8:56:04<8:39:13, 25.21s/it] 51%|█████     | 1261/2496 [8:56:29<8:38:19, 25.18s/it]                                                       {'loss': 0.6818, 'learning_rate': 1.0317868875000463e-05, 'epoch': 0.51}
 51%|█████     | 1261/2496 [8:56:29<8:38:19, 25.18s/it] 51%|█████     | 1262/2496 [8:56:55<8:41:39, 25.36s/it]                                                       {'loss': 0.6961, 'learning_rate': 1.0304898742736544e-05, 'epoch': 0.51}
 51%|█████     | 1262/2496 [8:56:55<8:41:39, 25.36s/it] 51%|█████     | 1263/2496 [8:57:21<8:42:57, 25.45s/it]                                                       {'loss': 0.683, 'learning_rate': 1.029192809706095e-05, 'epoch': 0.51}
 51%|█████     | 1263/2496 [8:57:21<8:42:57, 25.45s/it] 51%|█████     | 1264/2496 [8:57:47<8:49:42, 25.80s/it]                                                       {'loss': 0.702, 'learning_rate': 1.0278956959814641e-05, 'epoch': 0.51}
 51%|█████     | 1264/2496 [8:57:47<8:49:42, 25.80s/it] 51%|█████     | 1265/2496 [8:58:14<8:55:18, 26.09s/it]                                                       {'loss': 0.6999, 'learning_rate': 1.0265985352839408e-05, 'epoch': 0.51}
 51%|█████     | 1265/2496 [8:58:14<8:55:18, 26.09s/it] 51%|█████     | 1266/2496 [8:58:40<8:53:53, 26.04s/it]                                                       {'loss': 0.6721, 'learning_rate': 1.025301329797782e-05, 'epoch': 0.51}
 51%|█████     | 1266/2496 [8:58:40<8:53:53, 26.04s/it] 51%|█████     | 1267/2496 [8:59:04<8:43:29, 25.56s/it]                                                       {'loss': 0.6883, 'learning_rate': 1.0240040817073215e-05, 'epoch': 0.51}
 51%|█████     | 1267/2496 [8:59:04<8:43:29, 25.56s/it] 51%|█████     | 1268/2496 [8:59:30<8:46:38, 25.73s/it]                                                       {'loss': 0.6703, 'learning_rate': 1.022706793196964e-05, 'epoch': 0.51}
 51%|█████     | 1268/2496 [8:59:30<8:46:38, 25.73s/it] 51%|█████     | 1269/2496 [8:59:58<8:55:37, 26.19s/it]                                                       {'loss': 0.6866, 'learning_rate': 1.0214094664511826e-05, 'epoch': 0.51}
 51%|█████     | 1269/2496 [8:59:58<8:55:37, 26.19s/it] 51%|█████     | 1270/2496 [9:00:22<8:41:45, 25.53s/it]                                                       {'loss': 0.2499, 'learning_rate': 1.0201121036545145e-05, 'epoch': 0.51}
 51%|█████     | 1270/2496 [9:00:22<8:41:45, 25.53s/it] 51%|█████     | 1271/2496 [9:00:46<8:31:19, 25.04s/it]                                                       {'loss': 0.7308, 'learning_rate': 1.0188147069915579e-05, 'epoch': 0.51}
 51%|█████     | 1271/2496 [9:00:46<8:31:19, 25.04s/it] 51%|█████     | 1272/2496 [9:01:10<8:28:36, 24.93s/it]                                                       {'loss': 0.6894, 'learning_rate': 1.017517278646968e-05, 'epoch': 0.51}
 51%|█████     | 1272/2496 [9:01:10<8:28:36, 24.93s/it] 51%|█████     | 1273/2496 [9:01:36<8:31:18, 25.08s/it]                                                       {'loss': 0.7297, 'learning_rate': 1.016219820805453e-05, 'epoch': 0.51}
 51%|█████     | 1273/2496 [9:01:36<8:31:18, 25.08s/it] 51%|█████     | 1274/2496 [9:02:01<8:30:36, 25.07s/it]                                                       {'loss': 0.6963, 'learning_rate': 1.0149223356517713e-05, 'epoch': 0.51}
 51%|█████     | 1274/2496 [9:02:01<8:30:36, 25.07s/it] 51%|█████     | 1275/2496 [9:02:29<8:50:27, 26.07s/it]                                                       {'loss': 0.7096, 'learning_rate': 1.0136248253707267e-05, 'epoch': 0.51}
 51%|█████     | 1275/2496 [9:02:29<8:50:27, 26.07s/it] 51%|█████     | 1276/2496 [9:02:54<8:39:26, 25.55s/it]                                                       {'loss': 0.7424, 'learning_rate': 1.0123272921471655e-05, 'epoch': 0.51}
 51%|█████     | 1276/2496 [9:02:54<8:39:26, 25.55s/it] 51%|█████     | 1277/2496 [9:03:18<8:30:38, 25.13s/it]                                                       {'loss': 0.6647, 'learning_rate': 1.0110297381659731e-05, 'epoch': 0.51}
 51%|█████     | 1277/2496 [9:03:18<8:30:38, 25.13s/it]this iter is wrong in something... skip...
 51%|█████     | 1278/2496 [9:03:40<8:15:33, 24.41s/it]                                                       {'loss': 0.7109, 'learning_rate': 1.0097321656120696e-05, 'epoch': 0.51}
 51%|█████     | 1278/2496 [9:03:40<8:15:33, 24.41s/it] 51%|█████     | 1279/2496 [9:04:07<8:26:21, 24.96s/it]                                                       {'loss': 0.6737, 'learning_rate': 1.0084345766704058e-05, 'epoch': 0.51}
 51%|█████     | 1279/2496 [9:04:07<8:26:21, 24.96s/it] 51%|█████▏    | 1280/2496 [9:04:31<8:24:00, 24.87s/it]                                                       {'loss': 0.6764, 'learning_rate': 1.0071369735259606e-05, 'epoch': 0.51}
 51%|█████▏    | 1280/2496 [9:04:31<8:24:00, 24.87s/it] 51%|█████▏    | 1281/2496 [9:04:56<8:22:07, 24.80s/it]                                                       {'loss': 0.6845, 'learning_rate': 1.0058393583637376e-05, 'epoch': 0.51}
 51%|█████▏    | 1281/2496 [9:04:56<8:22:07, 24.80s/it] 51%|█████▏    | 1282/2496 [9:05:20<8:17:02, 24.57s/it]                                                       {'loss': 0.6902, 'learning_rate': 1.0045417333687586e-05, 'epoch': 0.51}
 51%|█████▏    | 1282/2496 [9:05:20<8:17:02, 24.57s/it] 51%|█████▏    | 1283/2496 [9:05:46<8:28:09, 25.14s/it]                                                       {'loss': 0.6884, 'learning_rate': 1.0032441007260646e-05, 'epoch': 0.51}
 51%|█████▏    | 1283/2496 [9:05:46<8:28:09, 25.14s/it] 51%|█████▏    | 1284/2496 [9:06:10<8:15:18, 24.52s/it]                                                       {'loss': 0.6935, 'learning_rate': 1.0019464626207068e-05, 'epoch': 0.51}
 51%|█████▏    | 1284/2496 [9:06:10<8:15:18, 24.52s/it] 51%|█████▏    | 1285/2496 [9:06:37<8:34:22, 25.49s/it]                                                       {'loss': 0.6368, 'learning_rate': 1.0006488212377469e-05, 'epoch': 0.51}
 51%|█████▏    | 1285/2496 [9:06:37<8:34:22, 25.49s/it] 52%|█████▏    | 1286/2496 [9:07:03<8:35:16, 25.55s/it]                                                       {'loss': 0.6841, 'learning_rate': 9.993511787622531e-06, 'epoch': 0.52}
 52%|█████▏    | 1286/2496 [9:07:03<8:35:16, 25.55s/it] 52%|█████▏    | 1287/2496 [9:07:30<8:40:52, 25.85s/it]                                                       {'loss': 0.6951, 'learning_rate': 9.980535373792935e-06, 'epoch': 0.52}
 52%|█████▏    | 1287/2496 [9:07:30<8:40:52, 25.85s/it] 52%|█████▏    | 1288/2496 [9:07:54<8:30:38, 25.36s/it]                                                       {'loss': 0.706, 'learning_rate': 9.967558992739358e-06, 'epoch': 0.52}
 52%|█████▏    | 1288/2496 [9:07:54<8:30:38, 25.36s/it] 52%|█████▏    | 1289/2496 [9:08:18<8:25:55, 25.15s/it]                                                       {'loss': 0.2506, 'learning_rate': 9.954582666312415e-06, 'epoch': 0.52}
 52%|█████▏    | 1289/2496 [9:08:18<8:25:55, 25.15s/it] 52%|█████▏    | 1290/2496 [9:08:45<8:34:31, 25.60s/it]                                                       {'loss': 0.7011, 'learning_rate': 9.94160641636263e-06, 'epoch': 0.52}
 52%|█████▏    | 1290/2496 [9:08:45<8:34:31, 25.60s/it] 52%|█████▏    | 1291/2496 [9:09:13<8:47:58, 26.29s/it]                                                       {'loss': 0.6924, 'learning_rate': 9.928630264740394e-06, 'epoch': 0.52}
 52%|█████▏    | 1291/2496 [9:09:13<8:47:58, 26.29s/it] 52%|█████▏    | 1292/2496 [9:09:38<8:42:37, 26.04s/it]                                                       {'loss': 0.6981, 'learning_rate': 9.915654233295945e-06, 'epoch': 0.52}
 52%|█████▏    | 1292/2496 [9:09:38<8:42:37, 26.04s/it] 52%|█████▏    | 1293/2496 [9:10:05<8:44:07, 26.14s/it]                                                       {'loss': 0.6875, 'learning_rate': 9.902678343879309e-06, 'epoch': 0.52}
 52%|█████▏    | 1293/2496 [9:10:05<8:44:07, 26.14s/it] 52%|█████▏    | 1294/2496 [9:10:31<8:43:18, 26.12s/it]                                                       {'loss': 0.709, 'learning_rate': 9.889702618340274e-06, 'epoch': 0.52}
 52%|█████▏    | 1294/2496 [9:10:31<8:43:18, 26.12s/it] 52%|█████▏    | 1295/2496 [9:10:56<8:36:49, 25.82s/it]                                                       {'loss': 0.6997, 'learning_rate': 9.87672707852835e-06, 'epoch': 0.52}
 52%|█████▏    | 1295/2496 [9:10:56<8:36:49, 25.82s/it] 52%|█████▏    | 1296/2496 [9:11:20<8:26:12, 25.31s/it]                                                       {'loss': 0.7066, 'learning_rate': 9.863751746292738e-06, 'epoch': 0.52}
 52%|█████▏    | 1296/2496 [9:11:20<8:26:12, 25.31s/it] 52%|█████▏    | 1297/2496 [9:11:45<8:23:42, 25.21s/it]                                                       {'loss': 0.6995, 'learning_rate': 9.850776643482292e-06, 'epoch': 0.52}
 52%|█████▏    | 1297/2496 [9:11:45<8:23:42, 25.21s/it] 52%|█████▏    | 1298/2496 [9:12:08<8:07:59, 24.44s/it]                                                       {'loss': 0.7164, 'learning_rate': 9.837801791945472e-06, 'epoch': 0.52}
 52%|█████▏    | 1298/2496 [9:12:08<8:07:59, 24.44s/it] 52%|█████▏    | 1299/2496 [9:12:31<8:01:54, 24.16s/it]                                                       {'loss': 0.699, 'learning_rate': 9.824827213530323e-06, 'epoch': 0.52}
 52%|█████▏    | 1299/2496 [9:12:31<8:01:54, 24.16s/it] 52%|█████▏    | 1300/2496 [9:12:55<8:01:40, 24.16s/it]                                                       {'loss': 0.6847, 'learning_rate': 9.81185293008442e-06, 'epoch': 0.52}
 52%|█████▏    | 1300/2496 [9:12:55<8:01:40, 24.16s/it] 52%|█████▏    | 1301/2496 [9:13:21<8:11:51, 24.70s/it]                                                       {'loss': 0.7359, 'learning_rate': 9.798878963454856e-06, 'epoch': 0.52}
 52%|█████▏    | 1301/2496 [9:13:21<8:11:51, 24.70s/it] 52%|█████▏    | 1302/2496 [9:13:45<8:06:25, 24.44s/it]                                                       {'loss': 0.6905, 'learning_rate': 9.785905335488177e-06, 'epoch': 0.52}
 52%|█████▏    | 1302/2496 [9:13:45<8:06:25, 24.44s/it] 52%|█████▏    | 1303/2496 [9:14:11<8:15:26, 24.92s/it]                                                       {'loss': 0.6994, 'learning_rate': 9.772932068030363e-06, 'epoch': 0.52}
 52%|█████▏    | 1303/2496 [9:14:11<8:15:26, 24.92s/it] 52%|█████▏    | 1304/2496 [9:14:34<8:04:15, 24.38s/it]                                                       {'loss': 0.7152, 'learning_rate': 9.759959182926788e-06, 'epoch': 0.52}
 52%|█████▏    | 1304/2496 [9:14:34<8:04:15, 24.38s/it] 52%|█████▏    | 1305/2496 [9:14:59<8:04:25, 24.40s/it]                                                       {'loss': 0.668, 'learning_rate': 9.74698670202218e-06, 'epoch': 0.52}
 52%|█████▏    | 1305/2496 [9:14:59<8:04:25, 24.40s/it] 52%|█████▏    | 1306/2496 [9:15:23<8:00:45, 24.24s/it]                                                       {'loss': 0.6872, 'learning_rate': 9.734014647160594e-06, 'epoch': 0.52}
 52%|█████▏    | 1306/2496 [9:15:23<8:00:45, 24.24s/it] 52%|█████▏    | 1307/2496 [9:15:47<8:03:12, 24.38s/it]                                                       {'loss': 0.6834, 'learning_rate': 9.721043040185362e-06, 'epoch': 0.52}
 52%|█████▏    | 1307/2496 [9:15:47<8:03:12, 24.38s/it]this iter is wrong in something... skip...
 52%|█████▏    | 1308/2496 [9:16:14<8:15:16, 25.01s/it]                                                       {'loss': 0.6905, 'learning_rate': 9.708071902939053e-06, 'epoch': 0.52}
 52%|█████▏    | 1308/2496 [9:16:14<8:15:16, 25.01s/it] 52%|█████▏    | 1309/2496 [9:16:38<8:10:59, 24.82s/it]                                                       {'loss': 0.6755, 'learning_rate': 9.69510125726346e-06, 'epoch': 0.52}
 52%|█████▏    | 1309/2496 [9:16:38<8:10:59, 24.82s/it] 52%|█████▏    | 1310/2496 [9:17:04<8:14:12, 25.00s/it]                                                       {'loss': 0.6914, 'learning_rate': 9.682131124999539e-06, 'epoch': 0.52}
 52%|█████▏    | 1310/2496 [9:17:04<8:14:12, 25.00s/it] 53%|█████▎    | 1311/2496 [9:17:28<8:11:30, 24.89s/it]                                                       {'loss': 0.7048, 'learning_rate': 9.669161527987387e-06, 'epoch': 0.53}
 53%|█████▎    | 1311/2496 [9:17:28<8:11:30, 24.89s/it] 53%|█████▎    | 1312/2496 [9:17:54<8:19:10, 25.30s/it]                                                       {'loss': 0.6982, 'learning_rate': 9.656192488066199e-06, 'epoch': 0.53}
 53%|█████▎    | 1312/2496 [9:17:54<8:19:10, 25.30s/it] 53%|█████▎    | 1313/2496 [9:18:18<8:10:53, 24.90s/it]                                                       {'loss': 0.6503, 'learning_rate': 9.643224027074224e-06, 'epoch': 0.53}
 53%|█████▎    | 1313/2496 [9:18:18<8:10:53, 24.90s/it] 53%|█████▎    | 1314/2496 [9:18:45<8:19:54, 25.38s/it]                                                       {'loss': 0.6925, 'learning_rate': 9.630256166848746e-06, 'epoch': 0.53}
 53%|█████▎    | 1314/2496 [9:18:45<8:19:54, 25.38s/it] 53%|█████▎    | 1315/2496 [9:19:11<8:24:35, 25.64s/it]                                                       {'loss': 0.6904, 'learning_rate': 9.61728892922603e-06, 'epoch': 0.53}
 53%|█████▎    | 1315/2496 [9:19:11<8:24:35, 25.64s/it] 53%|█████▎    | 1316/2496 [9:19:37<8:23:44, 25.61s/it]                                                       {'loss': 0.648, 'learning_rate': 9.6043223360413e-06, 'epoch': 0.53}
 53%|█████▎    | 1316/2496 [9:19:37<8:23:44, 25.61s/it] 53%|█████▎    | 1317/2496 [9:20:03<8:26:38, 25.78s/it]                                                       {'loss': 0.693, 'learning_rate': 9.591356409128691e-06, 'epoch': 0.53}
 53%|█████▎    | 1317/2496 [9:20:03<8:26:38, 25.78s/it]this iter is wrong in something... skip...
 53%|█████▎    | 1318/2496 [9:20:30<8:35:12, 26.24s/it]                                                       {'loss': 0.7032, 'learning_rate': 9.578391170321217e-06, 'epoch': 0.53}
 53%|█████▎    | 1318/2496 [9:20:30<8:35:12, 26.24s/it] 53%|█████▎    | 1319/2496 [9:20:54<8:22:56, 25.64s/it]                                                       {'loss': 0.7304, 'learning_rate': 9.565426641450723e-06, 'epoch': 0.53}
 53%|█████▎    | 1319/2496 [9:20:54<8:22:56, 25.64s/it] 53%|█████▎    | 1320/2496 [9:21:20<8:22:51, 25.66s/it]                                                       {'loss': 0.716, 'learning_rate': 9.552462844347883e-06, 'epoch': 0.53}
 53%|█████▎    | 1320/2496 [9:21:20<8:22:51, 25.66s/it] 53%|█████▎    | 1321/2496 [9:21:44<8:10:30, 25.05s/it]                                                       {'loss': 0.7116, 'learning_rate': 9.539499800842113e-06, 'epoch': 0.53}
 53%|█████▎    | 1321/2496 [9:21:44<8:10:30, 25.05s/it] 53%|█████▎    | 1322/2496 [9:22:10<8:17:58, 25.45s/it]                                                       {'loss': 0.7013, 'learning_rate': 9.526537532761573e-06, 'epoch': 0.53}
 53%|█████▎    | 1322/2496 [9:22:10<8:17:58, 25.45s/it] 53%|█████▎    | 1323/2496 [9:22:36<8:21:17, 25.64s/it]                                                       {'loss': 0.6663, 'learning_rate': 9.513576061933119e-06, 'epoch': 0.53}
 53%|█████▎    | 1323/2496 [9:22:36<8:21:17, 25.64s/it] 53%|█████▎    | 1324/2496 [9:23:01<8:15:07, 25.35s/it]                                                       {'loss': 0.6854, 'learning_rate': 9.50061541018225e-06, 'epoch': 0.53}
 53%|█████▎    | 1324/2496 [9:23:01<8:15:07, 25.35s/it] 53%|█████▎    | 1325/2496 [9:23:24<8:01:08, 24.65s/it]                                                       {'loss': 0.7053, 'learning_rate': 9.48765559933311e-06, 'epoch': 0.53}
 53%|█████▎    | 1325/2496 [9:23:24<8:01:08, 24.65s/it] 53%|█████▎    | 1326/2496 [9:23:50<8:07:03, 24.98s/it]                                                       {'loss': 0.6805, 'learning_rate': 9.474696651208406e-06, 'epoch': 0.53}
 53%|█████▎    | 1326/2496 [9:23:50<8:07:03, 24.98s/it] 53%|█████▎    | 1327/2496 [9:24:19<8:30:07, 26.18s/it]                                                       {'loss': 0.6756, 'learning_rate': 9.4617385876294e-06, 'epoch': 0.53}
 53%|█████▎    | 1327/2496 [9:24:19<8:30:07, 26.18s/it]this iter is wrong in something... skip...
 53%|█████▎    | 1328/2496 [9:24:44<8:26:50, 26.04s/it]                                                       {'loss': 0.6997, 'learning_rate': 9.448781430415865e-06, 'epoch': 0.53}
 53%|█████▎    | 1328/2496 [9:24:44<8:26:50, 26.04s/it] 53%|█████▎    | 1329/2496 [9:25:11<8:28:28, 26.14s/it]                                                       {'loss': 0.6991, 'learning_rate': 9.435825201386044e-06, 'epoch': 0.53}
 53%|█████▎    | 1329/2496 [9:25:11<8:28:28, 26.14s/it] 53%|█████▎    | 1330/2496 [9:25:34<8:11:28, 25.29s/it]                                                       {'loss': 0.6865, 'learning_rate': 9.422869922356625e-06, 'epoch': 0.53}
 53%|█████▎    | 1330/2496 [9:25:34<8:11:28, 25.29s/it] 53%|█████▎    | 1331/2496 [9:25:59<8:08:55, 25.18s/it]                                                       {'loss': 0.6727, 'learning_rate': 9.409915615142693e-06, 'epoch': 0.53}
 53%|█████▎    | 1331/2496 [9:25:59<8:08:55, 25.18s/it] 53%|█████▎    | 1332/2496 [9:26:24<8:09:39, 25.24s/it]                                                       {'loss': 0.7014, 'learning_rate': 9.396962301557688e-06, 'epoch': 0.53}
 53%|█████▎    | 1332/2496 [9:26:24<8:09:39, 25.24s/it] 53%|█████▎    | 1333/2496 [9:26:48<8:01:21, 24.83s/it]                                                       {'loss': 0.7003, 'learning_rate': 9.384010003413388e-06, 'epoch': 0.53}
 53%|█████▎    | 1333/2496 [9:26:48<8:01:21, 24.83s/it] 53%|█████▎    | 1334/2496 [9:27:15<8:11:57, 25.40s/it]                                                       {'loss': 0.7278, 'learning_rate': 9.371058742519853e-06, 'epoch': 0.53}
 53%|█████▎    | 1334/2496 [9:27:15<8:11:57, 25.40s/it] 53%|█████▎    | 1335/2496 [9:27:39<8:01:53, 24.90s/it]                                                       {'loss': 0.6969, 'learning_rate': 9.358108540685406e-06, 'epoch': 0.53}
 53%|█████▎    | 1335/2496 [9:27:39<8:01:53, 24.90s/it] 54%|█████▎    | 1336/2496 [9:28:03<7:58:28, 24.75s/it]                                                       {'loss': 0.6674, 'learning_rate': 9.345159419716578e-06, 'epoch': 0.54}
 54%|█████▎    | 1336/2496 [9:28:03<7:58:28, 24.75s/it] 54%|█████▎    | 1337/2496 [9:28:29<8:02:39, 24.99s/it]                                                       {'loss': 0.6734, 'learning_rate': 9.332211401418084e-06, 'epoch': 0.54}
 54%|█████▎    | 1337/2496 [9:28:29<8:02:39, 24.99s/it] 54%|█████▎    | 1338/2496 [9:28:55<8:07:50, 25.28s/it]                                                       {'loss': 0.6593, 'learning_rate': 9.319264507592776e-06, 'epoch': 0.54}
 54%|█████▎    | 1338/2496 [9:28:55<8:07:50, 25.28s/it] 54%|█████▎    | 1339/2496 [9:29:21<8:11:59, 25.51s/it]                                                       {'loss': 0.7211, 'learning_rate': 9.306318760041625e-06, 'epoch': 0.54}
 54%|█████▎    | 1339/2496 [9:29:21<8:11:59, 25.51s/it] 54%|█████▎    | 1340/2496 [9:29:48<8:21:13, 26.02s/it]                                                       {'loss': 0.6779, 'learning_rate': 9.293374180563664e-06, 'epoch': 0.54}
 54%|█████▎    | 1340/2496 [9:29:48<8:21:13, 26.02s/it] 54%|█████▎    | 1341/2496 [9:30:15<8:25:33, 26.26s/it]                                                       {'loss': 0.6817, 'learning_rate': 9.280430790955957e-06, 'epoch': 0.54}
 54%|█████▎    | 1341/2496 [9:30:15<8:25:33, 26.26s/it] 54%|█████▍    | 1342/2496 [9:30:42<8:30:01, 26.52s/it]                                                       {'loss': 0.6583, 'learning_rate': 9.267488613013564e-06, 'epoch': 0.54}
 54%|█████▍    | 1342/2496 [9:30:42<8:30:01, 26.52s/it] 54%|█████▍    | 1343/2496 [9:31:08<8:26:27, 26.35s/it]                                                       {'loss': 0.7103, 'learning_rate': 9.254547668529511e-06, 'epoch': 0.54}
 54%|█████▍    | 1343/2496 [9:31:08<8:26:27, 26.35s/it] 54%|█████▍    | 1344/2496 [9:31:32<8:12:42, 25.66s/it]                                                       {'loss': 0.7271, 'learning_rate': 9.241607979294745e-06, 'epoch': 0.54}
 54%|█████▍    | 1344/2496 [9:31:32<8:12:42, 25.66s/it]this iter is wrong in something... skip...
 54%|█████▍    | 1345/2496 [9:31:57<8:06:48, 25.38s/it]                                                       {'loss': 0.6704, 'learning_rate': 9.228669567098098e-06, 'epoch': 0.54}
 54%|█████▍    | 1345/2496 [9:31:57<8:06:48, 25.38s/it] 54%|█████▍    | 1346/2496 [9:32:23<8:10:11, 25.58s/it]                                                       {'loss': 0.6534, 'learning_rate': 9.215732453726249e-06, 'epoch': 0.54}
 54%|█████▍    | 1346/2496 [9:32:23<8:10:11, 25.58s/it] 54%|█████▍    | 1347/2496 [9:32:47<8:02:17, 25.19s/it]                                                       {'loss': 0.684, 'learning_rate': 9.202796660963697e-06, 'epoch': 0.54}
 54%|█████▍    | 1347/2496 [9:32:47<8:02:17, 25.19s/it] 54%|█████▍    | 1348/2496 [9:33:15<8:16:47, 25.96s/it]                                                       {'loss': 0.7244, 'learning_rate': 9.189862210592703e-06, 'epoch': 0.54}
 54%|█████▍    | 1348/2496 [9:33:15<8:16:47, 25.96s/it] 54%|█████▍    | 1349/2496 [9:33:42<8:26:08, 26.48s/it]                                                       {'loss': 0.6958, 'learning_rate': 9.176929124393293e-06, 'epoch': 0.54}
 54%|█████▍    | 1349/2496 [9:33:42<8:26:08, 26.48s/it] 54%|█████▍    | 1350/2496 [9:34:07<8:17:15, 26.03s/it]                                                       {'loss': 0.6316, 'learning_rate': 9.163997424143167e-06, 'epoch': 0.54}
 54%|█████▍    | 1350/2496 [9:34:07<8:17:15, 26.03s/it] 54%|█████▍    | 1351/2496 [9:34:32<8:10:13, 25.69s/it]                                                       {'loss': 0.7086, 'learning_rate': 9.151067131617711e-06, 'epoch': 0.54}
 54%|█████▍    | 1351/2496 [9:34:32<8:10:13, 25.69s/it] 54%|█████▍    | 1352/2496 [9:34:57<8:01:54, 25.27s/it]                                                       {'loss': 0.6614, 'learning_rate': 9.138138268589935e-06, 'epoch': 0.54}
 54%|█████▍    | 1352/2496 [9:34:57<8:01:54, 25.27s/it] 54%|█████▍    | 1353/2496 [9:35:20<7:49:22, 24.64s/it]                                                       {'loss': 0.6957, 'learning_rate': 9.125210856830433e-06, 'epoch': 0.54}
 54%|█████▍    | 1353/2496 [9:35:20<7:49:22, 24.64s/it] 54%|█████▍    | 1354/2496 [9:35:46<7:57:46, 25.10s/it]                                                       {'loss': 0.6677, 'learning_rate': 9.112284918107376e-06, 'epoch': 0.54}
 54%|█████▍    | 1354/2496 [9:35:46<7:57:46, 25.10s/it] 54%|█████▍    | 1355/2496 [9:36:09<7:48:13, 24.62s/it]                                                       {'loss': 0.7032, 'learning_rate': 9.09936047418643e-06, 'epoch': 0.54}
 54%|█████▍    | 1355/2496 [9:36:09<7:48:13, 24.62s/it] 54%|█████▍    | 1356/2496 [9:36:35<7:53:03, 24.90s/it]                                                       {'loss': 0.6755, 'learning_rate': 9.086437546830764e-06, 'epoch': 0.54}
 54%|█████▍    | 1356/2496 [9:36:35<7:53:03, 24.90s/it] 54%|█████▍    | 1357/2496 [9:36:58<7:44:38, 24.48s/it]                                                       {'loss': 0.7328, 'learning_rate': 9.073516157800979e-06, 'epoch': 0.54}
 54%|█████▍    | 1357/2496 [9:36:58<7:44:38, 24.48s/it] 54%|█████▍    | 1358/2496 [9:37:24<7:49:50, 24.77s/it]                                                       {'loss': 0.7005, 'learning_rate': 9.060596328855095e-06, 'epoch': 0.54}
 54%|█████▍    | 1358/2496 [9:37:24<7:49:50, 24.77s/it]this iter is wrong in something... skip...
 54%|█████▍    | 1359/2496 [9:37:48<7:46:34, 24.62s/it]                                                       {'loss': 0.2493, 'learning_rate': 9.047678081748506e-06, 'epoch': 0.54}
 54%|█████▍    | 1359/2496 [9:37:48<7:46:34, 24.62s/it] 54%|█████▍    | 1360/2496 [9:38:17<8:10:40, 25.92s/it]                                                       {'loss': 0.6924, 'learning_rate': 9.034761438233932e-06, 'epoch': 0.54}
 54%|█████▍    | 1360/2496 [9:38:17<8:10:40, 25.92s/it] 55%|█████▍    | 1361/2496 [9:38:40<7:53:45, 25.04s/it]                                                       {'loss': 0.6962, 'learning_rate': 9.0218464200614e-06, 'epoch': 0.55}
 55%|█████▍    | 1361/2496 [9:38:40<7:53:45, 25.04s/it]this iter is wrong in something... skip...
 55%|█████▍    | 1362/2496 [9:39:06<7:57:32, 25.27s/it]                                                       {'loss': 0.6683, 'learning_rate': 9.0089330489782e-06, 'epoch': 0.55}
 55%|█████▍    | 1362/2496 [9:39:06<7:57:32, 25.27s/it] 55%|█████▍    | 1363/2496 [9:39:31<7:54:42, 25.14s/it]                                                       {'loss': 0.6601, 'learning_rate': 8.996021346728847e-06, 'epoch': 0.55}
 55%|█████▍    | 1363/2496 [9:39:31<7:54:42, 25.14s/it] 55%|█████▍    | 1364/2496 [9:39:58<8:08:17, 25.88s/it]                                                       {'loss': 0.6667, 'learning_rate': 8.983111335055047e-06, 'epoch': 0.55}
 55%|█████▍    | 1364/2496 [9:39:58<8:08:17, 25.88s/it] 55%|█████▍    | 1365/2496 [9:40:22<7:53:06, 25.10s/it]                                                       {'loss': 0.6614, 'learning_rate': 8.970203035695662e-06, 'epoch': 0.55}
 55%|█████▍    | 1365/2496 [9:40:22<7:53:06, 25.10s/it] 55%|█████▍    | 1366/2496 [9:40:47<7:57:00, 25.33s/it]                                                       {'loss': 0.6694, 'learning_rate': 8.957296470386661e-06, 'epoch': 0.55}
 55%|█████▍    | 1366/2496 [9:40:47<7:57:00, 25.33s/it] 55%|█████▍    | 1367/2496 [9:41:11<7:47:12, 24.83s/it]                                                       {'loss': 0.6619, 'learning_rate': 8.944391660861101e-06, 'epoch': 0.55}
 55%|█████▍    | 1367/2496 [9:41:11<7:47:12, 24.83s/it] 55%|█████▍    | 1368/2496 [9:41:37<7:51:23, 25.07s/it]                                                       {'loss': 0.688, 'learning_rate': 8.931488628849084e-06, 'epoch': 0.55}
 55%|█████▍    | 1368/2496 [9:41:37<7:51:23, 25.07s/it] 55%|█████▍    | 1369/2496 [9:42:01<7:48:27, 24.94s/it]                                                       {'loss': 0.6818, 'learning_rate': 8.918587396077716e-06, 'epoch': 0.55}
 55%|█████▍    | 1369/2496 [9:42:01<7:48:27, 24.94s/it] 55%|█████▍    | 1370/2496 [9:42:27<7:50:03, 25.05s/it]                                                       {'loss': 0.6632, 'learning_rate': 8.905687984271071e-06, 'epoch': 0.55}
 55%|█████▍    | 1370/2496 [9:42:27<7:50:03, 25.05s/it] 55%|█████▍    | 1371/2496 [9:42:54<8:02:10, 25.72s/it]                                                       {'loss': 0.7341, 'learning_rate': 8.892790415150161e-06, 'epoch': 0.55}
 55%|█████▍    | 1371/2496 [9:42:54<8:02:10, 25.72s/it] 55%|█████▍    | 1372/2496 [9:43:19<7:58:15, 25.53s/it]                                                       {'loss': 0.7374, 'learning_rate': 8.879894710432887e-06, 'epoch': 0.55}
 55%|█████▍    | 1372/2496 [9:43:19<7:58:15, 25.53s/it] 55%|█████▌    | 1373/2496 [9:43:44<7:52:19, 25.24s/it]                                                       {'loss': 0.6769, 'learning_rate': 8.867000891834024e-06, 'epoch': 0.55}
 55%|█████▌    | 1373/2496 [9:43:44<7:52:19, 25.24s/it] 55%|█████▌    | 1374/2496 [9:44:11<8:05:43, 25.97s/it]                                                       {'loss': 0.7344, 'learning_rate': 8.85410898106516e-06, 'epoch': 0.55}
 55%|█████▌    | 1374/2496 [9:44:11<8:05:43, 25.97s/it] 55%|█████▌    | 1375/2496 [9:44:35<7:53:53, 25.36s/it]                                                       {'loss': 0.6588, 'learning_rate': 8.841218999834674e-06, 'epoch': 0.55}
 55%|█████▌    | 1375/2496 [9:44:35<7:53:53, 25.36s/it] 55%|█████▌    | 1376/2496 [9:45:01<7:56:30, 25.53s/it]                                                       {'loss': 0.6721, 'learning_rate': 8.828330969847695e-06, 'epoch': 0.55}
 55%|█████▌    | 1376/2496 [9:45:01<7:56:30, 25.53s/it] 55%|█████▌    | 1377/2496 [9:45:28<8:02:47, 25.89s/it]                                                       {'loss': 0.6681, 'learning_rate': 8.815444912806073e-06, 'epoch': 0.55}
 55%|█████▌    | 1377/2496 [9:45:28<8:02:47, 25.89s/it] 55%|█████▌    | 1378/2496 [9:46:01<8:40:53, 27.95s/it]                                                       {'loss': 0.6847, 'learning_rate': 8.802560850408328e-06, 'epoch': 0.55}
 55%|█████▌    | 1378/2496 [9:46:01<8:40:53, 27.95s/it] 55%|█████▌    | 1379/2496 [9:46:24<8:15:08, 26.60s/it]                                                       {'loss': 0.6574, 'learning_rate': 8.789678804349617e-06, 'epoch': 0.55}
 55%|█████▌    | 1379/2496 [9:46:24<8:15:08, 26.60s/it] 55%|█████▌    | 1380/2496 [9:46:49<8:07:39, 26.22s/it]                                                       {'loss': 0.6965, 'learning_rate': 8.776798796321715e-06, 'epoch': 0.55}
 55%|█████▌    | 1380/2496 [9:46:49<8:07:39, 26.22s/it] 55%|█████▌    | 1381/2496 [9:47:15<8:03:55, 26.04s/it]                                                       {'loss': 0.663, 'learning_rate': 8.763920848012951e-06, 'epoch': 0.55}
 55%|█████▌    | 1381/2496 [9:47:15<8:03:55, 26.04s/it] 55%|█████▌    | 1382/2496 [9:47:41<8:03:07, 26.02s/it]                                                       {'loss': 0.6414, 'learning_rate': 8.751044981108204e-06, 'epoch': 0.55}
 55%|█████▌    | 1382/2496 [9:47:41<8:03:07, 26.02s/it] 55%|█████▌    | 1383/2496 [9:48:06<7:57:43, 25.75s/it]                                                       {'loss': 0.6781, 'learning_rate': 8.738171217288831e-06, 'epoch': 0.55}
 55%|█████▌    | 1383/2496 [9:48:06<7:57:43, 25.75s/it]WARNING: tokenization mismatch: 1 vs. 624. (ignored)
 55%|█████▌    | 1384/2496 [9:48:30<7:48:33, 25.28s/it]                                                       {'loss': 0.6646, 'learning_rate': 8.725299578232652e-06, 'epoch': 0.55}
 55%|█████▌    | 1384/2496 [9:48:30<7:48:33, 25.28s/it] 55%|█████▌    | 1385/2496 [9:48:56<7:50:48, 25.43s/it]                                                       {'loss': 0.6772, 'learning_rate': 8.712430085613913e-06, 'epoch': 0.55}
 55%|█████▌    | 1385/2496 [9:48:56<7:50:48, 25.43s/it] 56%|█████▌    | 1386/2496 [9:49:20<7:40:11, 24.88s/it]                                                       {'loss': 0.7138, 'learning_rate': 8.699562761103242e-06, 'epoch': 0.56}
 56%|█████▌    | 1386/2496 [9:49:20<7:40:11, 24.88s/it] 56%|█████▌    | 1387/2496 [9:49:45<7:40:58, 24.94s/it]                                                       {'loss': 0.2379, 'learning_rate': 8.686697626367621e-06, 'epoch': 0.56}
 56%|█████▌    | 1387/2496 [9:49:45<7:40:58, 24.94s/it] 56%|█████▌    | 1388/2496 [9:50:09<7:37:29, 24.77s/it]                                                       {'loss': 0.6795, 'learning_rate': 8.673834703070341e-06, 'epoch': 0.56}
 56%|█████▌    | 1388/2496 [9:50:09<7:37:29, 24.77s/it]this iter is wrong in something... skip...
 56%|█████▌    | 1389/2496 [9:50:34<7:35:05, 24.67s/it]                                                       {'loss': 0.2505, 'learning_rate': 8.66097401287097e-06, 'epoch': 0.56}
 56%|█████▌    | 1389/2496 [9:50:34<7:35:05, 24.67s/it] 56%|█████▌    | 1390/2496 [9:50:57<7:26:54, 24.24s/it]                                                       {'loss': 0.6806, 'learning_rate': 8.648115577425313e-06, 'epoch': 0.56}
 56%|█████▌    | 1390/2496 [9:50:57<7:26:54, 24.24s/it] 56%|█████▌    | 1391/2496 [9:51:23<7:39:18, 24.94s/it]                                                       {'loss': 0.6611, 'learning_rate': 8.63525941838538e-06, 'epoch': 0.56}
 56%|█████▌    | 1391/2496 [9:51:23<7:39:18, 24.94s/it]this iter is wrong in something... skip...
 56%|█████▌    | 1392/2496 [9:51:50<7:49:17, 25.51s/it]                                                       {'loss': 0.6762, 'learning_rate': 8.622405557399353e-06, 'epoch': 0.56}
 56%|█████▌    | 1392/2496 [9:51:50<7:49:17, 25.51s/it] 56%|█████▌    | 1393/2496 [9:52:18<7:59:19, 26.07s/it]                                                       {'loss': 0.6579, 'learning_rate': 8.609554016111536e-06, 'epoch': 0.56}
 56%|█████▌    | 1393/2496 [9:52:18<7:59:19, 26.07s/it] 56%|█████▌    | 1394/2496 [9:52:43<7:54:24, 25.83s/it]                                                       {'loss': 0.7025, 'learning_rate': 8.596704816162336e-06, 'epoch': 0.56}
 56%|█████▌    | 1394/2496 [9:52:43<7:54:24, 25.83s/it] 56%|█████▌    | 1395/2496 [9:53:08<7:49:02, 25.56s/it]                                                       {'loss': 0.2528, 'learning_rate': 8.583857979188203e-06, 'epoch': 0.56}
 56%|█████▌    | 1395/2496 [9:53:08<7:49:02, 25.56s/it] 56%|█████▌    | 1396/2496 [9:53:32<7:41:11, 25.16s/it]                                                       {'loss': 0.6907, 'learning_rate': 8.571013526821629e-06, 'epoch': 0.56}
 56%|█████▌    | 1396/2496 [9:53:32<7:41:11, 25.16s/it] 56%|█████▌    | 1397/2496 [9:53:57<7:37:06, 24.96s/it]                                                       {'loss': 0.687, 'learning_rate': 8.558171480691072e-06, 'epoch': 0.56}
 56%|█████▌    | 1397/2496 [9:53:57<7:37:06, 24.96s/it] 56%|█████▌    | 1398/2496 [9:54:22<7:37:06, 24.98s/it]                                                       {'loss': 0.7025, 'learning_rate': 8.545331862420945e-06, 'epoch': 0.56}
 56%|█████▌    | 1398/2496 [9:54:22<7:37:06, 24.98s/it] 56%|█████▌    | 1399/2496 [9:54:47<7:41:29, 25.24s/it]                                                       {'loss': 0.6536, 'learning_rate': 8.532494693631576e-06, 'epoch': 0.56}
 56%|█████▌    | 1399/2496 [9:54:47<7:41:29, 25.24s/it] 56%|█████▌    | 1400/2496 [9:55:13<7:45:27, 25.48s/it]                                                       {'loss': 0.701, 'learning_rate': 8.51965999593916e-06, 'epoch': 0.56}
 56%|█████▌    | 1400/2496 [9:55:13<7:45:27, 25.48s/it] 56%|█████▌    | 1401/2496 [9:55:39<7:43:55, 25.42s/it]                                                       {'loss': 0.6739, 'learning_rate': 8.506827790955744e-06, 'epoch': 0.56}
 56%|█████▌    | 1401/2496 [9:55:39<7:43:55, 25.42s/it] 56%|█████▌    | 1402/2496 [9:56:03<7:37:08, 25.07s/it]                                                       {'loss': 0.6971, 'learning_rate': 8.493998100289165e-06, 'epoch': 0.56}
 56%|█████▌    | 1402/2496 [9:56:03<7:37:08, 25.07s/it] 56%|█████▌    | 1403/2496 [9:56:28<7:39:04, 25.20s/it]                                                       {'loss': 0.6592, 'learning_rate': 8.481170945543032e-06, 'epoch': 0.56}
 56%|█████▌    | 1403/2496 [9:56:28<7:39:04, 25.20s/it] 56%|█████▋    | 1404/2496 [9:56:54<7:40:31, 25.30s/it]                                                       {'loss': 0.686, 'learning_rate': 8.468346348316683e-06, 'epoch': 0.56}
 56%|█████▋    | 1404/2496 [9:56:54<7:40:31, 25.30s/it] 56%|█████▋    | 1405/2496 [9:57:18<7:33:48, 24.96s/it]                                                       {'loss': 0.6977, 'learning_rate': 8.455524330205147e-06, 'epoch': 0.56}
 56%|█████▋    | 1405/2496 [9:57:18<7:33:48, 24.96s/it] 56%|█████▋    | 1406/2496 [9:57:44<7:37:47, 25.20s/it]                                                       {'loss': 0.6674, 'learning_rate': 8.442704912799117e-06, 'epoch': 0.56}
 56%|█████▋    | 1406/2496 [9:57:44<7:37:47, 25.20s/it] 56%|█████▋    | 1407/2496 [9:58:09<7:36:45, 25.17s/it]                                                       {'loss': 0.6894, 'learning_rate': 8.429888117684904e-06, 'epoch': 0.56}
 56%|█████▋    | 1407/2496 [9:58:09<7:36:45, 25.17s/it] 56%|█████▋    | 1408/2496 [9:58:35<7:40:30, 25.40s/it]                                                       {'loss': 0.6683, 'learning_rate': 8.417073966444393e-06, 'epoch': 0.56}
 56%|█████▋    | 1408/2496 [9:58:35<7:40:30, 25.40s/it] 56%|█████▋    | 1409/2496 [9:59:00<7:40:06, 25.40s/it]                                                       {'loss': 0.7095, 'learning_rate': 8.404262480655032e-06, 'epoch': 0.56}
 56%|█████▋    | 1409/2496 [9:59:00<7:40:06, 25.40s/it] 56%|█████▋    | 1410/2496 [9:59:26<7:41:19, 25.49s/it]                                                       {'loss': 0.6475, 'learning_rate': 8.391453681889772e-06, 'epoch': 0.56}
 56%|█████▋    | 1410/2496 [9:59:26<7:41:19, 25.49s/it] 57%|█████▋    | 1411/2496 [9:59:50<7:30:07, 24.89s/it]                                                       {'loss': 0.6749, 'learning_rate': 8.378647591717042e-06, 'epoch': 0.57}
 57%|█████▋    | 1411/2496 [9:59:50<7:30:07, 24.89s/it] 57%|█████▋    | 1412/2496 [10:00:17<7:41:03, 25.52s/it]                                                        {'loss': 0.6436, 'learning_rate': 8.365844231700715e-06, 'epoch': 0.57}
 57%|█████▋    | 1412/2496 [10:00:17<7:41:03, 25.52s/it] 57%|█████▋    | 1413/2496 [10:00:45<7:56:30, 26.40s/it]                                                        {'loss': 0.6618, 'learning_rate': 8.353043623400054e-06, 'epoch': 0.57}
 57%|█████▋    | 1413/2496 [10:00:45<7:56:30, 26.40s/it] 57%|█████▋    | 1414/2496 [10:01:10<7:48:28, 25.98s/it]                                                        {'loss': 0.6928, 'learning_rate': 8.340245788369697e-06, 'epoch': 0.57}
 57%|█████▋    | 1414/2496 [10:01:10<7:48:28, 25.98s/it]this iter is wrong in something... skip...
 57%|█████▋    | 1415/2496 [10:01:40<8:10:42, 27.24s/it]                                                        {'loss': 0.6962, 'learning_rate': 8.327450748159616e-06, 'epoch': 0.57}
 57%|█████▋    | 1415/2496 [10:01:40<8:10:42, 27.24s/it]this iter is wrong in something... skip...
 57%|█████▋    | 1416/2496 [10:02:05<7:57:47, 26.54s/it]                                                        {'loss': 0.712, 'learning_rate': 8.314658524315068e-06, 'epoch': 0.57}
 57%|█████▋    | 1416/2496 [10:02:05<7:57:47, 26.54s/it] 57%|█████▋    | 1417/2496 [10:02:30<7:45:46, 25.90s/it]                                                        {'loss': 0.6712, 'learning_rate': 8.301869138376575e-06, 'epoch': 0.57}
 57%|█████▋    | 1417/2496 [10:02:30<7:45:46, 25.90s/it] 57%|█████▋    | 1418/2496 [10:02:56<7:48:16, 26.06s/it]                                                        {'loss': 0.6763, 'learning_rate': 8.289082611879875e-06, 'epoch': 0.57}
 57%|█████▋    | 1418/2496 [10:02:56<7:48:16, 26.06s/it] 57%|█████▋    | 1419/2496 [10:03:21<7:45:00, 25.91s/it]                                                        {'loss': 0.6936, 'learning_rate': 8.276298966355887e-06, 'epoch': 0.57}
 57%|█████▋    | 1419/2496 [10:03:21<7:45:00, 25.91s/it] 57%|█████▋    | 1420/2496 [10:03:49<7:50:49, 26.25s/it]                                                        {'loss': 0.6837, 'learning_rate': 8.263518223330698e-06, 'epoch': 0.57}
 57%|█████▋    | 1420/2496 [10:03:49<7:50:49, 26.25s/it] 57%|█████▋    | 1421/2496 [10:04:14<7:43:50, 25.89s/it]                                                        {'loss': 0.2419, 'learning_rate': 8.250740404325483e-06, 'epoch': 0.57}
 57%|█████▋    | 1421/2496 [10:04:14<7:43:50, 25.89s/it] 57%|█████▋    | 1422/2496 [10:04:40<7:48:27, 26.17s/it]                                                        {'loss': 0.6916, 'learning_rate': 8.237965530856511e-06, 'epoch': 0.57}
 57%|█████▋    | 1422/2496 [10:04:40<7:48:27, 26.17s/it] 57%|█████▋    | 1423/2496 [10:05:06<7:46:52, 26.11s/it]                                                        {'loss': 0.7029, 'learning_rate': 8.225193624435084e-06, 'epoch': 0.57}
 57%|█████▋    | 1423/2496 [10:05:06<7:46:52, 26.11s/it] 57%|█████▋    | 1424/2496 [10:05:33<7:50:36, 26.34s/it]                                                        {'loss': 0.6991, 'learning_rate': 8.212424706567502e-06, 'epoch': 0.57}
 57%|█████▋    | 1424/2496 [10:05:33<7:50:36, 26.34s/it] 57%|█████▋    | 1425/2496 [10:06:00<7:51:00, 26.39s/it]                                                        {'loss': 0.6945, 'learning_rate': 8.199658798755048e-06, 'epoch': 0.57}
 57%|█████▋    | 1425/2496 [10:06:00<7:51:00, 26.39s/it] 57%|█████▋    | 1426/2496 [10:06:26<7:48:02, 26.25s/it]                                                        {'loss': 0.7095, 'learning_rate': 8.186895922493924e-06, 'epoch': 0.57}
 57%|█████▋    | 1426/2496 [10:06:26<7:48:02, 26.25s/it] 57%|█████▋    | 1427/2496 [10:06:52<7:50:21, 26.40s/it]                                                        {'loss': 0.6734, 'learning_rate': 8.17413609927523e-06, 'epoch': 0.57}
 57%|█████▋    | 1427/2496 [10:06:52<7:50:21, 26.40s/it] 57%|█████▋    | 1428/2496 [10:07:20<7:53:46, 26.62s/it]                                                        {'loss': 0.6839, 'learning_rate': 8.16137935058493e-06, 'epoch': 0.57}
 57%|█████▋    | 1428/2496 [10:07:20<7:53:46, 26.62s/it] 57%|█████▋    | 1429/2496 [10:07:44<7:39:50, 25.86s/it]                                                        {'loss': 0.6672, 'learning_rate': 8.148625697903797e-06, 'epoch': 0.57}
 57%|█████▋    | 1429/2496 [10:07:44<7:39:50, 25.86s/it] 57%|█████▋    | 1430/2496 [10:08:09<7:35:05, 25.62s/it]                                                        {'loss': 0.6872, 'learning_rate': 8.135875162707415e-06, 'epoch': 0.57}
 57%|█████▋    | 1430/2496 [10:08:09<7:35:05, 25.62s/it] 57%|█████▋    | 1431/2496 [10:08:33<7:26:48, 25.17s/it]                                                        {'loss': 0.6905, 'learning_rate': 8.123127766466093e-06, 'epoch': 0.57}
 57%|█████▋    | 1431/2496 [10:08:33<7:26:48, 25.17s/it]WARNING: tokenization mismatch: 1 vs. 70. (ignored)
 57%|█████▋    | 1432/2496 [10:09:06<8:08:32, 27.55s/it]                                                        {'loss': 0.7014, 'learning_rate': 8.11038353064487e-06, 'epoch': 0.57}
 57%|█████▋    | 1432/2496 [10:09:06<8:08:32, 27.55s/it] 57%|█████▋    | 1433/2496 [10:09:31<7:52:29, 26.67s/it]                                                        {'loss': 0.69, 'learning_rate': 8.097642476703456e-06, 'epoch': 0.57}
 57%|█████▋    | 1433/2496 [10:09:31<7:52:29, 26.67s/it]this iter is wrong in something... skip...
 57%|█████▋    | 1434/2496 [10:09:57<7:53:09, 26.73s/it]                                                        {'loss': 0.689, 'learning_rate': 8.084904626096211e-06, 'epoch': 0.57}
 57%|█████▋    | 1434/2496 [10:09:57<7:53:09, 26.73s/it] 57%|█████▋    | 1435/2496 [10:10:22<7:43:20, 26.20s/it]                                                        {'loss': 0.6857, 'learning_rate': 8.072170000272092e-06, 'epoch': 0.57}
 57%|█████▋    | 1435/2496 [10:10:22<7:43:20, 26.20s/it] 58%|█████▊    | 1436/2496 [10:10:47<7:32:00, 25.59s/it]                                                        {'loss': 0.672, 'learning_rate': 8.059438620674632e-06, 'epoch': 0.58}
 58%|█████▊    | 1436/2496 [10:10:47<7:32:00, 25.59s/it] 58%|█████▊    | 1437/2496 [10:11:12<7:31:58, 25.61s/it]                                                        {'loss': 0.6841, 'learning_rate': 8.046710508741892e-06, 'epoch': 0.58}
 58%|█████▊    | 1437/2496 [10:11:12<7:31:58, 25.61s/it] 58%|█████▊    | 1438/2496 [10:11:37<7:25:22, 25.26s/it]                                                        {'loss': 0.7072, 'learning_rate': 8.033985685906436e-06, 'epoch': 0.58}
 58%|█████▊    | 1438/2496 [10:11:37<7:25:22, 25.26s/it]this iter is wrong in something... skip...
 58%|█████▊    | 1439/2496 [10:12:03<7:28:28, 25.46s/it]                                                        {'loss': 0.7311, 'learning_rate': 8.021264173595286e-06, 'epoch': 0.58}
 58%|█████▊    | 1439/2496 [10:12:03<7:28:28, 25.46s/it] 58%|█████▊    | 1440/2496 [10:12:30<7:37:04, 25.97s/it]                                                        {'loss': 0.6526, 'learning_rate': 8.008545993229897e-06, 'epoch': 0.58}
 58%|█████▊    | 1440/2496 [10:12:30<7:37:04, 25.97s/it] 58%|█████▊    | 1441/2496 [10:12:55<7:30:49, 25.64s/it]                                                        {'loss': 0.7022, 'learning_rate': 7.995831166226103e-06, 'epoch': 0.58}
 58%|█████▊    | 1441/2496 [10:12:55<7:30:49, 25.64s/it]this iter is wrong in something... skip...
 58%|█████▊    | 1442/2496 [10:13:19<7:21:58, 25.16s/it]                                                        {'loss': 0.6857, 'learning_rate': 7.983119713994095e-06, 'epoch': 0.58}
 58%|█████▊    | 1442/2496 [10:13:19<7:21:58, 25.16s/it] 58%|█████▊    | 1443/2496 [10:13:44<7:21:46, 25.17s/it]                                                        {'loss': 0.6956, 'learning_rate': 7.970411657938382e-06, 'epoch': 0.58}
 58%|█████▊    | 1443/2496 [10:13:44<7:21:46, 25.17s/it] 58%|█████▊    | 1444/2496 [10:14:10<7:25:42, 25.42s/it]                                                        {'loss': 0.7173, 'learning_rate': 7.957707019457757e-06, 'epoch': 0.58}
 58%|█████▊    | 1444/2496 [10:14:10<7:25:42, 25.42s/it] 58%|█████▊    | 1445/2496 [10:14:33<7:13:53, 24.77s/it]                                                        {'loss': 0.6651, 'learning_rate': 7.945005819945257e-06, 'epoch': 0.58}
 58%|█████▊    | 1445/2496 [10:14:33<7:13:53, 24.77s/it] 58%|█████▊    | 1446/2496 [10:14:58<7:14:17, 24.82s/it]                                                        {'loss': 0.6975, 'learning_rate': 7.932308080788124e-06, 'epoch': 0.58}
 58%|█████▊    | 1446/2496 [10:14:58<7:14:17, 24.82s/it] 58%|█████▊    | 1447/2496 [10:15:22<7:09:59, 24.59s/it]                                                        {'loss': 0.6923, 'learning_rate': 7.91961382336778e-06, 'epoch': 0.58}
 58%|█████▊    | 1447/2496 [10:15:22<7:09:59, 24.59s/it] 58%|█████▊    | 1448/2496 [10:15:48<7:16:25, 24.99s/it]                                                        {'loss': 0.6844, 'learning_rate': 7.90692306905977e-06, 'epoch': 0.58}
 58%|█████▊    | 1448/2496 [10:15:48<7:16:25, 24.99s/it] 58%|█████▊    | 1449/2496 [10:16:13<7:15:34, 24.96s/it]                                                        {'loss': 0.7112, 'learning_rate': 7.894235839233767e-06, 'epoch': 0.58}
 58%|█████▊    | 1449/2496 [10:16:13<7:15:34, 24.96s/it] 58%|█████▊    | 1450/2496 [10:16:36<7:06:28, 24.46s/it]                                                        {'loss': 0.7004, 'learning_rate': 7.881552155253478e-06, 'epoch': 0.58}
 58%|█████▊    | 1450/2496 [10:16:36<7:06:28, 24.46s/it] 58%|█████▊    | 1451/2496 [10:17:00<7:03:25, 24.31s/it]                                                        {'loss': 0.6566, 'learning_rate': 7.868872038476663e-06, 'epoch': 0.58}
 58%|█████▊    | 1451/2496 [10:17:00<7:03:25, 24.31s/it]this iter is wrong in something... skip...
 58%|█████▊    | 1452/2496 [10:17:25<7:04:29, 24.40s/it]                                                        {'loss': 0.6636, 'learning_rate': 7.856195510255059e-06, 'epoch': 0.58}
 58%|█████▊    | 1452/2496 [10:17:25<7:04:29, 24.40s/it] 58%|█████▊    | 1453/2496 [10:17:49<7:03:22, 24.36s/it]                                                        {'loss': 0.6887, 'learning_rate': 7.843522591934375e-06, 'epoch': 0.58}
 58%|█████▊    | 1453/2496 [10:17:49<7:03:22, 24.36s/it] 58%|█████▊    | 1454/2496 [10:18:12<6:53:56, 23.84s/it]                                                        {'loss': 0.6815, 'learning_rate': 7.830853304854232e-06, 'epoch': 0.58}
 58%|█████▊    | 1454/2496 [10:18:12<6:53:56, 23.84s/it] 58%|█████▊    | 1455/2496 [10:18:37<7:01:53, 24.32s/it]                                                        {'loss': 0.6901, 'learning_rate': 7.818187670348133e-06, 'epoch': 0.58}
 58%|█████▊    | 1455/2496 [10:18:37<7:01:53, 24.32s/it] 58%|█████▊    | 1456/2496 [10:19:00<6:54:10, 23.89s/it]                                                        {'loss': 0.7027, 'learning_rate': 7.805525709743442e-06, 'epoch': 0.58}
 58%|█████▊    | 1456/2496 [10:19:00<6:54:10, 23.89s/it] 58%|█████▊    | 1457/2496 [10:19:25<7:01:10, 24.32s/it]                                                        {'loss': 0.6459, 'learning_rate': 7.792867444361325e-06, 'epoch': 0.58}
 58%|█████▊    | 1457/2496 [10:19:25<7:01:10, 24.32s/it] 58%|█████▊    | 1458/2496 [10:19:50<7:03:40, 24.49s/it]                                                        {'loss': 0.6894, 'learning_rate': 7.780212895516737e-06, 'epoch': 0.58}
 58%|█████▊    | 1458/2496 [10:19:50<7:03:40, 24.49s/it] 58%|█████▊    | 1459/2496 [10:20:14<7:01:16, 24.38s/it]                                                        {'loss': 0.6729, 'learning_rate': 7.767562084518368e-06, 'epoch': 0.58}
 58%|█████▊    | 1459/2496 [10:20:14<7:01:16, 24.38s/it]this iter is wrong in something... skip...
 58%|█████▊    | 1460/2496 [10:20:40<7:07:32, 24.76s/it]                                                        {'loss': 0.673, 'learning_rate': 7.754915032668613e-06, 'epoch': 0.58}
 58%|█████▊    | 1460/2496 [10:20:40<7:07:32, 24.76s/it] 59%|█████▊    | 1461/2496 [10:21:05<7:07:54, 24.81s/it]                                                        {'loss': 0.6816, 'learning_rate': 7.742271761263537e-06, 'epoch': 0.59}
 59%|█████▊    | 1461/2496 [10:21:05<7:07:54, 24.81s/it] 59%|█████▊    | 1462/2496 [10:21:30<7:09:44, 24.94s/it]                                                        {'loss': 0.2627, 'learning_rate': 7.729632291592844e-06, 'epoch': 0.59}
 59%|█████▊    | 1462/2496 [10:21:30<7:09:44, 24.94s/it] 59%|█████▊    | 1463/2496 [10:21:55<7:07:46, 24.85s/it]                                                        {'loss': 0.7059, 'learning_rate': 7.716996644939834e-06, 'epoch': 0.59}
 59%|█████▊    | 1463/2496 [10:21:55<7:07:46, 24.85s/it] 59%|█████▊    | 1464/2496 [10:22:20<7:08:37, 24.92s/it]                                                        {'loss': 0.6892, 'learning_rate': 7.704364842581369e-06, 'epoch': 0.59}
 59%|█████▊    | 1464/2496 [10:22:20<7:08:37, 24.92s/it] 59%|█████▊    | 1465/2496 [10:22:46<7:12:51, 25.19s/it]                                                        {'loss': 0.6703, 'learning_rate': 7.691736905787838e-06, 'epoch': 0.59}
 59%|█████▊    | 1465/2496 [10:22:46<7:12:51, 25.19s/it] 59%|█████▊    | 1466/2496 [10:23:11<7:12:08, 25.17s/it]                                                        {'loss': 0.6532, 'learning_rate': 7.679112855823118e-06, 'epoch': 0.59}
 59%|█████▊    | 1466/2496 [10:23:11<7:12:08, 25.17s/it] 59%|█████▉    | 1467/2496 [10:23:36<7:13:11, 25.26s/it]                                                        {'loss': 0.6786, 'learning_rate': 7.666492713944544e-06, 'epoch': 0.59}
 59%|█████▉    | 1467/2496 [10:23:36<7:13:11, 25.26s/it] 59%|█████▉    | 1468/2496 [10:24:03<7:22:03, 25.80s/it]                                                        {'loss': 0.655, 'learning_rate': 7.653876501402873e-06, 'epoch': 0.59}
 59%|█████▉    | 1468/2496 [10:24:03<7:22:03, 25.80s/it] 59%|█████▉    | 1469/2496 [10:24:26<7:06:45, 24.93s/it]                                                        {'loss': 0.6976, 'learning_rate': 7.64126423944224e-06, 'epoch': 0.59}
 59%|█████▉    | 1469/2496 [10:24:26<7:06:45, 24.93s/it] 59%|█████▉    | 1470/2496 [10:24:51<7:07:47, 25.02s/it]                                                        {'loss': 0.2529, 'learning_rate': 7.628655949300133e-06, 'epoch': 0.59}
 59%|█████▉    | 1470/2496 [10:24:51<7:07:47, 25.02s/it] 59%|█████▉    | 1471/2496 [10:25:17<7:09:23, 25.14s/it]                                                        {'loss': 0.6716, 'learning_rate': 7.616051652207341e-06, 'epoch': 0.59}
 59%|█████▉    | 1471/2496 [10:25:17<7:09:23, 25.14s/it] 59%|█████▉    | 1472/2496 [10:25:40<7:01:05, 24.67s/it]                                                        {'loss': 0.6979, 'learning_rate': 7.603451369387951e-06, 'epoch': 0.59}
 59%|█████▉    | 1472/2496 [10:25:40<7:01:05, 24.67s/it] 59%|█████▉    | 1473/2496 [10:26:08<7:16:20, 25.59s/it]                                                        {'loss': 0.6637, 'learning_rate': 7.590855122059265e-06, 'epoch': 0.59}
 59%|█████▉    | 1473/2496 [10:26:08<7:16:20, 25.59s/it] 59%|█████▉    | 1474/2496 [10:26:33<7:12:50, 25.41s/it]                                                        {'loss': 0.6961, 'learning_rate': 7.578262931431806e-06, 'epoch': 0.59}
 59%|█████▉    | 1474/2496 [10:26:33<7:12:50, 25.41s/it] 59%|█████▉    | 1475/2496 [10:26:59<7:13:37, 25.48s/it]                                                        {'loss': 0.6835, 'learning_rate': 7.565674818709261e-06, 'epoch': 0.59}
 59%|█████▉    | 1475/2496 [10:26:59<7:13:37, 25.48s/it] 59%|█████▉    | 1476/2496 [10:27:24<7:12:16, 25.43s/it]                                                        {'loss': 0.6733, 'learning_rate': 7.55309080508845e-06, 'epoch': 0.59}
 59%|█████▉    | 1476/2496 [10:27:24<7:12:16, 25.43s/it] 59%|█████▉    | 1477/2496 [10:27:50<7:14:30, 25.58s/it]                                                        {'loss': 0.6906, 'learning_rate': 7.540510911759293e-06, 'epoch': 0.59}
 59%|█████▉    | 1477/2496 [10:27:50<7:14:30, 25.58s/it]this iter is wrong in something... skip...
 59%|█████▉    | 1478/2496 [10:28:14<7:08:00, 25.23s/it]                                                        {'loss': 0.6934, 'learning_rate': 7.527935159904772e-06, 'epoch': 0.59}
 59%|█████▉    | 1478/2496 [10:28:14<7:08:00, 25.23s/it] 59%|█████▉    | 1479/2496 [10:28:39<7:05:11, 25.09s/it]                                                        {'loss': 0.684, 'learning_rate': 7.51536357070089e-06, 'epoch': 0.59}
 59%|█████▉    | 1479/2496 [10:28:39<7:05:11, 25.09s/it] 59%|█████▉    | 1480/2496 [10:29:04<7:02:07, 24.93s/it]                                                        {'loss': 0.7078, 'learning_rate': 7.5027961653166446e-06, 'epoch': 0.59}
 59%|█████▉    | 1480/2496 [10:29:04<7:02:07, 24.93s/it] 59%|█████▉    | 1481/2496 [10:29:28<6:58:23, 24.73s/it]                                                        {'loss': 0.6564, 'learning_rate': 7.490232964913988e-06, 'epoch': 0.59}
 59%|█████▉    | 1481/2496 [10:29:28<6:58:23, 24.73s/it] 59%|█████▉    | 1482/2496 [10:29:52<6:52:17, 24.40s/it]                                                        {'loss': 0.6655, 'learning_rate': 7.477673990647793e-06, 'epoch': 0.59}
 59%|█████▉    | 1482/2496 [10:29:52<6:52:17, 24.40s/it] 59%|█████▉    | 1483/2496 [10:30:18<7:01:09, 24.94s/it]                                                        {'loss': 0.6439, 'learning_rate': 7.465119263665819e-06, 'epoch': 0.59}
 59%|█████▉    | 1483/2496 [10:30:18<7:01:09, 24.94s/it] 59%|█████▉    | 1484/2496 [10:30:43<7:03:40, 25.12s/it]                                                        {'loss': 0.6584, 'learning_rate': 7.452568805108662e-06, 'epoch': 0.59}
 59%|█████▉    | 1484/2496 [10:30:43<7:03:40, 25.12s/it]this iter is wrong in something... skip...
 59%|█████▉    | 1485/2496 [10:31:08<6:58:35, 24.84s/it]                                                        {'loss': 0.7184, 'learning_rate': 7.440022636109742e-06, 'epoch': 0.59}
 59%|█████▉    | 1485/2496 [10:31:08<6:58:35, 24.84s/it] 60%|█████▉    | 1486/2496 [10:31:33<6:58:41, 24.87s/it]                                                        {'loss': 0.7066, 'learning_rate': 7.427480777795248e-06, 'epoch': 0.6}
 60%|█████▉    | 1486/2496 [10:31:33<6:58:41, 24.87s/it] 60%|█████▉    | 1487/2496 [10:32:00<7:11:31, 25.66s/it]                                                        {'loss': 0.6833, 'learning_rate': 7.414943251284119e-06, 'epoch': 0.6}
 60%|█████▉    | 1487/2496 [10:32:00<7:11:31, 25.66s/it] 60%|█████▉    | 1488/2496 [10:32:24<7:03:51, 25.23s/it]                                                        {'loss': 0.6757, 'learning_rate': 7.402410077687994e-06, 'epoch': 0.6}
 60%|█████▉    | 1488/2496 [10:32:24<7:03:51, 25.23s/it] 60%|█████▉    | 1489/2496 [10:32:51<7:09:05, 25.57s/it]                                                        {'loss': 0.6697, 'learning_rate': 7.389881278111182e-06, 'epoch': 0.6}
 60%|█████▉    | 1489/2496 [10:32:51<7:09:05, 25.57s/it] 60%|█████▉    | 1490/2496 [10:33:15<7:03:10, 25.24s/it]                                                        {'loss': 0.6579, 'learning_rate': 7.377356873650625e-06, 'epoch': 0.6}
 60%|█████▉    | 1490/2496 [10:33:15<7:03:10, 25.24s/it] 60%|█████▉    | 1491/2496 [10:33:42<7:11:25, 25.76s/it]                                                        {'loss': 0.6912, 'learning_rate': 7.364836885395869e-06, 'epoch': 0.6}
 60%|█████▉    | 1491/2496 [10:33:42<7:11:25, 25.76s/it] 60%|█████▉    | 1492/2496 [10:34:09<7:15:40, 26.04s/it]                                                        {'loss': 0.674, 'learning_rate': 7.352321334429026e-06, 'epoch': 0.6}
 60%|█████▉    | 1492/2496 [10:34:09<7:15:40, 26.04s/it] 60%|█████▉    | 1493/2496 [10:34:35<7:18:19, 26.22s/it]                                                        {'loss': 0.6735, 'learning_rate': 7.339810241824726e-06, 'epoch': 0.6}
 60%|█████▉    | 1493/2496 [10:34:35<7:18:19, 26.22s/it] 60%|█████▉    | 1494/2496 [10:35:03<7:22:41, 26.51s/it]                                                        {'loss': 0.6669, 'learning_rate': 7.327303628650104e-06, 'epoch': 0.6}
 60%|█████▉    | 1494/2496 [10:35:03<7:22:41, 26.51s/it] 60%|█████▉    | 1495/2496 [10:35:27<7:11:00, 25.83s/it]                                                        {'loss': 0.6917, 'learning_rate': 7.314801515964734e-06, 'epoch': 0.6}
 60%|█████▉    | 1495/2496 [10:35:27<7:11:00, 25.83s/it] 60%|█████▉    | 1496/2496 [10:35:53<7:14:39, 26.08s/it]                                                        {'loss': 0.6755, 'learning_rate': 7.3023039248206375e-06, 'epoch': 0.6}
 60%|█████▉    | 1496/2496 [10:35:53<7:14:39, 26.08s/it] 60%|█████▉    | 1497/2496 [10:36:18<7:06:49, 25.63s/it]                                                        {'loss': 0.6575, 'learning_rate': 7.2898108762622e-06, 'epoch': 0.6}
 60%|█████▉    | 1497/2496 [10:36:18<7:06:49, 25.63s/it] 60%|██████    | 1498/2496 [10:36:44<7:08:49, 25.78s/it]                                                        {'loss': 0.6743, 'learning_rate': 7.277322391326167e-06, 'epoch': 0.6}
 60%|██████    | 1498/2496 [10:36:44<7:08:49, 25.78s/it] 60%|██████    | 1499/2496 [10:37:12<7:19:13, 26.43s/it]                                                        {'loss': 0.6676, 'learning_rate': 7.2648384910416015e-06, 'epoch': 0.6}
 60%|██████    | 1499/2496 [10:37:12<7:19:13, 26.43s/it] 60%|██████    | 1500/2496 [10:37:40<7:27:02, 26.93s/it]                                                        {'loss': 0.6695, 'learning_rate': 7.2523591964298345e-06, 'epoch': 0.6}
 60%|██████    | 1500/2496 [10:37:40<7:27:02, 26.93s/it] 60%|██████    | 1501/2496 [10:38:04<7:12:33, 26.08s/it]                                                        {'loss': 0.688, 'learning_rate': 7.239884528504464e-06, 'epoch': 0.6}
 60%|██████    | 1501/2496 [10:38:04<7:12:33, 26.08s/it] 60%|██████    | 1502/2496 [10:38:36<7:37:46, 27.63s/it]                                                        {'loss': 0.6579, 'learning_rate': 7.227414508271275e-06, 'epoch': 0.6}
 60%|██████    | 1502/2496 [10:38:36<7:37:46, 27.63s/it] 60%|██████    | 1503/2496 [10:39:01<7:27:37, 27.05s/it]                                                        {'loss': 0.6681, 'learning_rate': 7.214949156728239e-06, 'epoch': 0.6}
 60%|██████    | 1503/2496 [10:39:01<7:27:37, 27.05s/it] 60%|██████    | 1504/2496 [10:39:28<7:25:09, 26.92s/it]                                                        {'loss': 0.6535, 'learning_rate': 7.2024884948654585e-06, 'epoch': 0.6}
 60%|██████    | 1504/2496 [10:39:28<7:25:09, 26.92s/it]this iter is wrong in something... skip...
 60%|██████    | 1505/2496 [10:39:54<7:18:30, 26.55s/it]                                                        {'loss': 0.6657, 'learning_rate': 7.190032543665144e-06, 'epoch': 0.6}
 60%|██████    | 1505/2496 [10:39:54<7:18:30, 26.55s/it]this iter is wrong in something... skip...
 60%|██████    | 1506/2496 [10:40:21<7:23:52, 26.90s/it]                                                        {'loss': 0.6841, 'learning_rate': 7.1775813241015755e-06, 'epoch': 0.6}
 60%|██████    | 1506/2496 [10:40:21<7:23:52, 26.90s/it] 60%|██████    | 1507/2496 [10:40:45<7:09:47, 26.07s/it]                                                        {'loss': 0.6824, 'learning_rate': 7.165134857141063e-06, 'epoch': 0.6}
 60%|██████    | 1507/2496 [10:40:45<7:09:47, 26.07s/it] 60%|██████    | 1508/2496 [10:41:10<6:59:53, 25.50s/it]                                                        {'loss': 0.6838, 'learning_rate': 7.152693163741909e-06, 'epoch': 0.6}
 60%|██████    | 1508/2496 [10:41:10<6:59:53, 25.50s/it] 60%|██████    | 1509/2496 [10:41:38<7:13:41, 26.36s/it]                                                        {'loss': 0.6869, 'learning_rate': 7.140256264854386e-06, 'epoch': 0.6}
 60%|██████    | 1509/2496 [10:41:38<7:13:41, 26.36s/it] 60%|██████    | 1510/2496 [10:42:02<7:03:42, 25.78s/it]                                                        {'loss': 0.7166, 'learning_rate': 7.127824181420684e-06, 'epoch': 0.6}
 60%|██████    | 1510/2496 [10:42:02<7:03:42, 25.78s/it] 61%|██████    | 1511/2496 [10:42:28<7:01:01, 25.65s/it]                                                        {'loss': 0.6809, 'learning_rate': 7.115396934374898e-06, 'epoch': 0.61}
 61%|██████    | 1511/2496 [10:42:28<7:01:01, 25.65s/it] 61%|██████    | 1512/2496 [10:42:51<6:49:11, 24.95s/it]                                                        {'loss': 0.6575, 'learning_rate': 7.102974544642969e-06, 'epoch': 0.61}
 61%|██████    | 1512/2496 [10:42:51<6:49:11, 24.95s/it] 61%|██████    | 1513/2496 [10:43:18<6:59:55, 25.63s/it]                                                        {'loss': 0.6865, 'learning_rate': 7.090557033142655e-06, 'epoch': 0.61}
 61%|██████    | 1513/2496 [10:43:18<6:59:55, 25.63s/it] 61%|██████    | 1514/2496 [10:43:42<6:49:02, 24.99s/it]                                                        {'loss': 0.6797, 'learning_rate': 7.078144420783508e-06, 'epoch': 0.61}
 61%|██████    | 1514/2496 [10:43:42<6:49:02, 24.99s/it] 61%|██████    | 1515/2496 [10:44:08<6:55:31, 25.41s/it]                                                        {'loss': 0.6436, 'learning_rate': 7.065736728466832e-06, 'epoch': 0.61}
 61%|██████    | 1515/2496 [10:44:08<6:55:31, 25.41s/it] 61%|██████    | 1516/2496 [10:44:35<7:00:50, 25.77s/it]                                                        {'loss': 0.6793, 'learning_rate': 7.053333977085642e-06, 'epoch': 0.61}
 61%|██████    | 1516/2496 [10:44:35<7:00:50, 25.77s/it] 61%|██████    | 1517/2496 [10:44:58<6:48:03, 25.01s/it]                                                        {'loss': 0.6871, 'learning_rate': 7.0409361875246275e-06, 'epoch': 0.61}
 61%|██████    | 1517/2496 [10:44:58<6:48:03, 25.01s/it] 61%|██████    | 1518/2496 [10:45:22<6:43:43, 24.77s/it]                                                        {'loss': 0.684, 'learning_rate': 7.028543380660136e-06, 'epoch': 0.61}
 61%|██████    | 1518/2496 [10:45:22<6:43:43, 24.77s/it] 61%|██████    | 1519/2496 [10:45:48<6:46:01, 24.93s/it]                                                        {'loss': 0.6732, 'learning_rate': 7.0161555773601075e-06, 'epoch': 0.61}
 61%|██████    | 1519/2496 [10:45:48<6:46:01, 24.93s/it] 61%|██████    | 1520/2496 [10:46:13<6:50:25, 25.23s/it]                                                        {'loss': 0.6702, 'learning_rate': 7.003772798484076e-06, 'epoch': 0.61}
 61%|██████    | 1520/2496 [10:46:13<6:50:25, 25.23s/it] 61%|██████    | 1521/2496 [10:46:38<6:47:19, 25.07s/it]                                                        {'loss': 0.6895, 'learning_rate': 6.991395064883102e-06, 'epoch': 0.61}
 61%|██████    | 1521/2496 [10:46:38<6:47:19, 25.07s/it]this iter is wrong in something... skip...
 61%|██████    | 1522/2496 [10:47:01<6:38:24, 24.54s/it]                                                        {'loss': 0.6731, 'learning_rate': 6.979022397399755e-06, 'epoch': 0.61}
 61%|██████    | 1522/2496 [10:47:01<6:38:24, 24.54s/it]this iter is wrong in something... skip...
 61%|██████    | 1523/2496 [10:47:28<6:45:07, 24.98s/it]                                                        {'loss': 0.6883, 'learning_rate': 6.966654816868073e-06, 'epoch': 0.61}
 61%|██████    | 1523/2496 [10:47:28<6:45:07, 24.98s/it] 61%|██████    | 1524/2496 [10:47:53<6:47:45, 25.17s/it]                                                        {'loss': 0.6677, 'learning_rate': 6.9542923441135226e-06, 'epoch': 0.61}
 61%|██████    | 1524/2496 [10:47:53<6:47:45, 25.17s/it] 61%|██████    | 1525/2496 [10:48:19<6:53:06, 25.53s/it]                                                        {'loss': 0.6944, 'learning_rate': 6.941934999952984e-06, 'epoch': 0.61}
 61%|██████    | 1525/2496 [10:48:19<6:53:06, 25.53s/it] 61%|██████    | 1526/2496 [10:48:43<6:43:03, 24.93s/it]                                                        {'loss': 0.6358, 'learning_rate': 6.929582805194685e-06, 'epoch': 0.61}
 61%|██████    | 1526/2496 [10:48:43<6:43:03, 24.93s/it] 61%|██████    | 1527/2496 [10:49:07<6:39:49, 24.76s/it]                                                        {'loss': 0.6787, 'learning_rate': 6.9172357806381955e-06, 'epoch': 0.61}
 61%|██████    | 1527/2496 [10:49:07<6:39:49, 24.76s/it] 61%|██████    | 1528/2496 [10:49:32<6:40:07, 24.80s/it]                                                        {'loss': 0.6787, 'learning_rate': 6.90489394707437e-06, 'epoch': 0.61}
 61%|██████    | 1528/2496 [10:49:32<6:40:07, 24.80s/it] 61%|██████▏   | 1529/2496 [10:49:56<6:36:19, 24.59s/it]                                                        {'loss': 0.6883, 'learning_rate': 6.892557325285321e-06, 'epoch': 0.61}
 61%|██████▏   | 1529/2496 [10:49:56<6:36:19, 24.59s/it] 61%|██████▏   | 1530/2496 [10:50:22<6:41:17, 24.93s/it]                                                        {'loss': 0.6665, 'learning_rate': 6.880225936044402e-06, 'epoch': 0.61}
 61%|██████▏   | 1530/2496 [10:50:22<6:41:17, 24.93s/it] 61%|██████▏   | 1531/2496 [10:50:49<6:48:44, 25.41s/it]                                                        {'loss': 0.6329, 'learning_rate': 6.867899800116136e-06, 'epoch': 0.61}
 61%|██████▏   | 1531/2496 [10:50:49<6:48:44, 25.41s/it] 61%|██████▏   | 1532/2496 [10:51:14<6:46:45, 25.32s/it]                                                        {'loss': 0.6794, 'learning_rate': 6.855578938256205e-06, 'epoch': 0.61}
 61%|██████▏   | 1532/2496 [10:51:14<6:46:45, 25.32s/it]this iter is wrong in something... skip...
 61%|██████▏   | 1533/2496 [10:51:41<6:56:04, 25.92s/it]                                                        {'loss': 0.6591, 'learning_rate': 6.843263371211415e-06, 'epoch': 0.61}
 61%|██████▏   | 1533/2496 [10:51:41<6:56:04, 25.92s/it] 61%|██████▏   | 1534/2496 [10:52:07<6:54:34, 25.86s/it]                                                        {'loss': 0.6662, 'learning_rate': 6.830953119719656e-06, 'epoch': 0.61}
 61%|██████▏   | 1534/2496 [10:52:07<6:54:34, 25.86s/it] 61%|██████▏   | 1535/2496 [10:52:34<6:59:20, 26.18s/it]                                                        {'loss': 0.6934, 'learning_rate': 6.818648204509863e-06, 'epoch': 0.61}
 61%|██████▏   | 1535/2496 [10:52:34<6:59:20, 26.18s/it] 62%|██████▏   | 1536/2496 [10:52:57<6:47:19, 25.46s/it]                                                        {'loss': 0.7183, 'learning_rate': 6.806348646301991e-06, 'epoch': 0.62}
 62%|██████▏   | 1536/2496 [10:52:57<6:47:19, 25.46s/it] 62%|██████▏   | 1537/2496 [10:53:24<6:52:02, 25.78s/it]                                                        {'loss': 0.6827, 'learning_rate': 6.794054465806965e-06, 'epoch': 0.62}
 62%|██████▏   | 1537/2496 [10:53:24<6:52:02, 25.78s/it] 62%|██████▏   | 1538/2496 [10:53:50<6:54:00, 25.93s/it]                                                        {'loss': 0.6721, 'learning_rate': 6.7817656837266596e-06, 'epoch': 0.62}
 62%|██████▏   | 1538/2496 [10:53:50<6:54:00, 25.93s/it]this iter is wrong in something... skip...
 62%|██████▏   | 1539/2496 [10:54:16<6:50:23, 25.73s/it]                                                        {'loss': 0.6946, 'learning_rate': 6.7694823207538665e-06, 'epoch': 0.62}
 62%|██████▏   | 1539/2496 [10:54:16<6:50:23, 25.73s/it] 62%|██████▏   | 1540/2496 [10:54:42<6:52:14, 25.87s/it]                                                        {'loss': 0.7001, 'learning_rate': 6.757204397572241e-06, 'epoch': 0.62}
 62%|██████▏   | 1540/2496 [10:54:42<6:52:14, 25.87s/it] 62%|██████▏   | 1541/2496 [10:55:07<6:49:21, 25.72s/it]                                                        {'loss': 0.6429, 'learning_rate': 6.744931934856287e-06, 'epoch': 0.62}
 62%|██████▏   | 1541/2496 [10:55:07<6:49:21, 25.72s/it] 62%|██████▏   | 1542/2496 [10:55:32<6:44:14, 25.42s/it]                                                        {'loss': 0.6739, 'learning_rate': 6.732664953271305e-06, 'epoch': 0.62}
 62%|██████▏   | 1542/2496 [10:55:32<6:44:14, 25.42s/it] 62%|██████▏   | 1543/2496 [10:55:57<6:42:10, 25.32s/it]                                                        {'loss': 0.7301, 'learning_rate': 6.720403473473371e-06, 'epoch': 0.62}
 62%|██████▏   | 1543/2496 [10:55:57<6:42:10, 25.32s/it] 62%|██████▏   | 1544/2496 [10:56:21<6:37:44, 25.07s/it]                                                        {'loss': 0.6885, 'learning_rate': 6.708147516109302e-06, 'epoch': 0.62}
 62%|██████▏   | 1544/2496 [10:56:21<6:37:44, 25.07s/it]this iter is wrong in something... skip...
 62%|██████▏   | 1545/2496 [10:56:47<6:38:14, 25.13s/it]                                                        {'loss': 0.6446, 'learning_rate': 6.695897101816606e-06, 'epoch': 0.62}
 62%|██████▏   | 1545/2496 [10:56:47<6:38:14, 25.13s/it] 62%|██████▏   | 1546/2496 [10:57:12<6:37:41, 25.12s/it]                                                        {'loss': 0.6697, 'learning_rate': 6.683652251223464e-06, 'epoch': 0.62}
 62%|██████▏   | 1546/2496 [10:57:12<6:37:41, 25.12s/it] 62%|██████▏   | 1547/2496 [10:57:35<6:30:14, 24.67s/it]                                                        {'loss': 0.6869, 'learning_rate': 6.671412984948686e-06, 'epoch': 0.62}
 62%|██████▏   | 1547/2496 [10:57:35<6:30:14, 24.67s/it] 62%|██████▏   | 1548/2496 [10:58:03<6:42:39, 25.48s/it]                                                        {'loss': 0.6758, 'learning_rate': 6.65917932360167e-06, 'epoch': 0.62}
 62%|██████▏   | 1548/2496 [10:58:03<6:42:39, 25.48s/it] 62%|██████▏   | 1549/2496 [10:58:27<6:38:33, 25.25s/it]                                                        {'loss': 0.6771, 'learning_rate': 6.646951287782399e-06, 'epoch': 0.62}
 62%|██████▏   | 1549/2496 [10:58:27<6:38:33, 25.25s/it] 62%|██████▏   | 1550/2496 [10:58:52<6:33:03, 24.93s/it]                                                        {'loss': 0.6871, 'learning_rate': 6.63472889808136e-06, 'epoch': 0.62}
 62%|██████▏   | 1550/2496 [10:58:52<6:33:03, 24.93s/it] 62%|██████▏   | 1551/2496 [10:59:17<6:34:09, 25.03s/it]                                                        {'loss': 0.7169, 'learning_rate': 6.622512175079543e-06, 'epoch': 0.62}
 62%|██████▏   | 1551/2496 [10:59:17<6:34:09, 25.03s/it] 62%|██████▏   | 1552/2496 [10:59:45<6:46:39, 25.85s/it]                                                        {'loss': 0.7034, 'learning_rate': 6.610301139348394e-06, 'epoch': 0.62}
 62%|██████▏   | 1552/2496 [10:59:45<6:46:39, 25.85s/it] 62%|██████▏   | 1553/2496 [11:00:08<6:33:53, 25.06s/it]                                                        {'loss': 0.7017, 'learning_rate': 6.598095811449785e-06, 'epoch': 0.62}
 62%|██████▏   | 1553/2496 [11:00:08<6:33:53, 25.06s/it]this iter is wrong in something... skip...
 62%|██████▏   | 1554/2496 [11:00:33<6:32:51, 25.02s/it]                                                        {'loss': 0.2541, 'learning_rate': 6.585896211935976e-06, 'epoch': 0.62}
 62%|██████▏   | 1554/2496 [11:00:33<6:32:51, 25.02s/it]this iter is wrong in something... skip...
 62%|██████▏   | 1555/2496 [11:00:56<6:25:16, 24.57s/it]                                                        {'loss': 0.6871, 'learning_rate': 6.573702361349576e-06, 'epoch': 0.62}
 62%|██████▏   | 1555/2496 [11:00:56<6:25:16, 24.57s/it] 62%|██████▏   | 1556/2496 [11:01:22<6:30:16, 24.91s/it]                                                        {'loss': 0.6781, 'learning_rate': 6.5615142802235175e-06, 'epoch': 0.62}
 62%|██████▏   | 1556/2496 [11:01:22<6:30:16, 24.91s/it] 62%|██████▏   | 1557/2496 [11:01:48<6:37:00, 25.37s/it]                                                        {'loss': 0.6385, 'learning_rate': 6.549331989081018e-06, 'epoch': 0.62}
 62%|██████▏   | 1557/2496 [11:01:48<6:37:00, 25.37s/it] 62%|██████▏   | 1558/2496 [11:02:12<6:28:37, 24.86s/it]                                                        {'loss': 0.683, 'learning_rate': 6.537155508435548e-06, 'epoch': 0.62}
 62%|██████▏   | 1558/2496 [11:02:12<6:28:37, 24.86s/it] 62%|██████▏   | 1559/2496 [11:02:38<6:33:16, 25.18s/it]                                                        {'loss': 0.7056, 'learning_rate': 6.524984858790792e-06, 'epoch': 0.62}
 62%|██████▏   | 1559/2496 [11:02:38<6:33:16, 25.18s/it] 62%|██████▎   | 1560/2496 [11:03:01<6:23:56, 24.61s/it]                                                        {'loss': 0.6768, 'learning_rate': 6.512820060640608e-06, 'epoch': 0.62}
 62%|██████▎   | 1560/2496 [11:03:01<6:23:56, 24.61s/it] 63%|██████▎   | 1561/2496 [11:03:26<6:25:05, 24.71s/it]                                                        {'loss': 0.6609, 'learning_rate': 6.500661134469013e-06, 'epoch': 0.63}
 63%|██████▎   | 1561/2496 [11:03:26<6:25:05, 24.71s/it] 63%|██████▎   | 1562/2496 [11:03:51<6:22:18, 24.56s/it]                                                        {'loss': 0.7127, 'learning_rate': 6.488508100750126e-06, 'epoch': 0.63}
 63%|██████▎   | 1562/2496 [11:03:51<6:22:18, 24.56s/it] 63%|██████▎   | 1563/2496 [11:04:15<6:21:08, 24.51s/it]                                                        {'loss': 0.6951, 'learning_rate': 6.476360979948153e-06, 'epoch': 0.63}
 63%|██████▎   | 1563/2496 [11:04:15<6:21:08, 24.51s/it] 63%|██████▎   | 1564/2496 [11:04:41<6:26:12, 24.86s/it]                                                        {'loss': 0.6894, 'learning_rate': 6.46421979251734e-06, 'epoch': 0.63}
 63%|██████▎   | 1564/2496 [11:04:41<6:26:12, 24.86s/it] 63%|██████▎   | 1565/2496 [11:05:06<6:26:55, 24.94s/it]                                                        {'loss': 0.6821, 'learning_rate': 6.452084558901941e-06, 'epoch': 0.63}
 63%|██████▎   | 1565/2496 [11:05:06<6:26:55, 24.94s/it] 63%|██████▎   | 1566/2496 [11:05:29<6:17:20, 24.34s/it]                                                        {'loss': 0.64, 'learning_rate': 6.43995529953618e-06, 'epoch': 0.63}
 63%|██████▎   | 1566/2496 [11:05:29<6:17:20, 24.34s/it] 63%|██████▎   | 1567/2496 [11:05:53<6:14:39, 24.20s/it]                                                        {'loss': 0.6762, 'learning_rate': 6.4278320348442255e-06, 'epoch': 0.63}
 63%|██████▎   | 1567/2496 [11:05:53<6:14:39, 24.20s/it] 63%|██████▎   | 1568/2496 [11:06:16<6:09:43, 23.90s/it]                                                        {'loss': 0.6837, 'learning_rate': 6.415714785240159e-06, 'epoch': 0.63}
 63%|██████▎   | 1568/2496 [11:06:16<6:09:43, 23.90s/it] 63%|██████▎   | 1569/2496 [11:06:41<6:15:27, 24.30s/it]                                                        {'loss': 0.6533, 'learning_rate': 6.403603571127921e-06, 'epoch': 0.63}
 63%|██████▎   | 1569/2496 [11:06:41<6:15:27, 24.30s/it] 63%|██████▎   | 1570/2496 [11:07:05<6:13:21, 24.19s/it]                                                        {'loss': 0.6756, 'learning_rate': 6.391498412901298e-06, 'epoch': 0.63}
 63%|██████▎   | 1570/2496 [11:07:05<6:13:21, 24.19s/it] 63%|██████▎   | 1571/2496 [11:07:30<6:16:58, 24.45s/it]                                                        {'loss': 0.2632, 'learning_rate': 6.379399330943865e-06, 'epoch': 0.63}
 63%|██████▎   | 1571/2496 [11:07:30<6:16:58, 24.45s/it]this iter is wrong in something... skip...
 63%|██████▎   | 1572/2496 [11:07:54<6:13:11, 24.23s/it]                                                        {'loss': 0.6861, 'learning_rate': 6.367306345628989e-06, 'epoch': 0.63}
 63%|██████▎   | 1572/2496 [11:07:54<6:13:11, 24.23s/it] 63%|██████▎   | 1573/2496 [11:08:20<6:20:30, 24.74s/it]                                                        {'loss': 0.6732, 'learning_rate': 6.3552194773197515e-06, 'epoch': 0.63}
 63%|██████▎   | 1573/2496 [11:08:20<6:20:30, 24.74s/it] 63%|██████▎   | 1574/2496 [11:08:44<6:20:19, 24.75s/it]                                                        {'loss': 0.6758, 'learning_rate': 6.34313874636894e-06, 'epoch': 0.63}
 63%|██████▎   | 1574/2496 [11:08:44<6:20:19, 24.75s/it] 63%|██████▎   | 1575/2496 [11:09:10<6:24:21, 25.04s/it]                                                        {'loss': 0.6755, 'learning_rate': 6.331064173119008e-06, 'epoch': 0.63}
 63%|██████▎   | 1575/2496 [11:09:10<6:24:21, 25.04s/it] 63%|██████▎   | 1576/2496 [11:09:36<6:27:05, 25.24s/it]                                                        {'loss': 0.6715, 'learning_rate': 6.318995777902036e-06, 'epoch': 0.63}
 63%|██████▎   | 1576/2496 [11:09:36<6:27:05, 25.24s/it] 63%|██████▎   | 1577/2496 [11:10:01<6:24:49, 25.12s/it]                                                        {'loss': 0.7037, 'learning_rate': 6.306933581039712e-06, 'epoch': 0.63}
 63%|██████▎   | 1577/2496 [11:10:01<6:24:49, 25.12s/it] 63%|██████▎   | 1578/2496 [11:10:28<6:33:05, 25.69s/it]                                                        {'loss': 0.6948, 'learning_rate': 6.294877602843276e-06, 'epoch': 0.63}
 63%|██████▎   | 1578/2496 [11:10:28<6:33:05, 25.69s/it] 63%|██████▎   | 1579/2496 [11:10:53<6:28:57, 25.45s/it]                                                        {'loss': 0.6868, 'learning_rate': 6.2828278636134985e-06, 'epoch': 0.63}
 63%|██████▎   | 1579/2496 [11:10:53<6:28:57, 25.45s/it] 63%|██████▎   | 1580/2496 [11:11:18<6:29:13, 25.50s/it]                                                        {'loss': 0.6475, 'learning_rate': 6.270784383640648e-06, 'epoch': 0.63}
 63%|██████▎   | 1580/2496 [11:11:18<6:29:13, 25.50s/it] 63%|██████▎   | 1581/2496 [11:11:44<6:31:06, 25.65s/it]                                                        {'loss': 0.6462, 'learning_rate': 6.258747183204449e-06, 'epoch': 0.63}
 63%|██████▎   | 1581/2496 [11:11:44<6:31:06, 25.65s/it] 63%|██████▎   | 1582/2496 [11:12:09<6:27:21, 25.43s/it]                                                        {'loss': 0.2256, 'learning_rate': 6.246716282574059e-06, 'epoch': 0.63}
 63%|██████▎   | 1582/2496 [11:12:09<6:27:21, 25.43s/it] 63%|██████▎   | 1583/2496 [11:12:32<6:17:20, 24.80s/it]                                                        {'loss': 0.6786, 'learning_rate': 6.234691702008022e-06, 'epoch': 0.63}
 63%|██████▎   | 1583/2496 [11:12:32<6:17:20, 24.80s/it]this iter is wrong in something... skip...
 63%|██████▎   | 1584/2496 [11:12:59<6:26:45, 25.44s/it]                                                        {'loss': 0.7034, 'learning_rate': 6.222673461754236e-06, 'epoch': 0.63}
 63%|██████▎   | 1584/2496 [11:12:59<6:26:45, 25.44s/it] 64%|██████▎   | 1585/2496 [11:13:23<6:19:52, 25.02s/it]                                                        {'loss': 0.7306, 'learning_rate': 6.21066158204993e-06, 'epoch': 0.63}
 64%|██████▎   | 1585/2496 [11:13:23<6:19:52, 25.02s/it] 64%|██████▎   | 1586/2496 [11:13:48<6:17:27, 24.89s/it]                                                        {'loss': 0.682, 'learning_rate': 6.198656083121619e-06, 'epoch': 0.64}
 64%|██████▎   | 1586/2496 [11:13:48<6:17:27, 24.89s/it] 64%|██████▎   | 1587/2496 [11:14:15<6:27:56, 25.61s/it]                                                        {'loss': 0.7008, 'learning_rate': 6.186656985185078e-06, 'epoch': 0.64}
 64%|██████▎   | 1587/2496 [11:14:15<6:27:56, 25.61s/it] 64%|██████▎   | 1588/2496 [11:14:41<6:27:14, 25.59s/it]                                                        {'loss': 0.6829, 'learning_rate': 6.174664308445297e-06, 'epoch': 0.64}
 64%|██████▎   | 1588/2496 [11:14:41<6:27:14, 25.59s/it]this iter is wrong in something... skip...
 64%|██████▎   | 1589/2496 [11:15:05<6:19:45, 25.12s/it]                                                        {'loss': 0.6758, 'learning_rate': 6.162678073096457e-06, 'epoch': 0.64}
 64%|██████▎   | 1589/2496 [11:15:05<6:19:45, 25.12s/it] 64%|██████▎   | 1590/2496 [11:15:32<6:27:48, 25.68s/it]                                                        {'loss': 0.6671, 'learning_rate': 6.150698299321889e-06, 'epoch': 0.64}
 64%|██████▎   | 1590/2496 [11:15:32<6:27:48, 25.68s/it]this iter is wrong in something... skip...
 64%|██████▎   | 1591/2496 [11:15:56<6:21:49, 25.31s/it]                                                        {'loss': 0.2546, 'learning_rate': 6.138725007294051e-06, 'epoch': 0.64}
 64%|██████▎   | 1591/2496 [11:15:56<6:21:49, 25.31s/it] 64%|██████▍   | 1592/2496 [11:16:20<6:14:01, 24.82s/it]                                                        {'loss': 0.7018, 'learning_rate': 6.12675821717448e-06, 'epoch': 0.64}
 64%|██████▍   | 1592/2496 [11:16:20<6:14:01, 24.82s/it] 64%|██████▍   | 1593/2496 [11:16:44<6:11:36, 24.69s/it]                                                        {'loss': 0.7081, 'learning_rate': 6.114797949113766e-06, 'epoch': 0.64}
 64%|██████▍   | 1593/2496 [11:16:44<6:11:36, 24.69s/it] 64%|██████▍   | 1594/2496 [11:17:11<6:19:48, 25.26s/it]                                                        {'loss': 0.6931, 'learning_rate': 6.102844223251522e-06, 'epoch': 0.64}
 64%|██████▍   | 1594/2496 [11:17:11<6:19:48, 25.26s/it] 64%|██████▍   | 1595/2496 [11:17:37<6:23:21, 25.53s/it]                                                        {'loss': 0.6598, 'learning_rate': 6.09089705971633e-06, 'epoch': 0.64}
 64%|██████▍   | 1595/2496 [11:17:37<6:23:21, 25.53s/it] 64%|██████▍   | 1596/2496 [11:18:02<6:19:02, 25.27s/it]                                                        {'loss': 0.6867, 'learning_rate': 6.078956478625743e-06, 'epoch': 0.64}
 64%|██████▍   | 1596/2496 [11:18:02<6:19:02, 25.27s/it]this iter is wrong in something... skip...
 64%|██████▍   | 1597/2496 [11:18:29<6:26:25, 25.79s/it]                                                        {'loss': 0.7041, 'learning_rate': 6.067022500086211e-06, 'epoch': 0.64}
 64%|██████▍   | 1597/2496 [11:18:29<6:26:25, 25.79s/it]this iter is wrong in something... skip...
 64%|██████▍   | 1598/2496 [11:18:56<6:31:50, 26.18s/it]                                                        {'loss': 0.653, 'learning_rate': 6.0550951441930795e-06, 'epoch': 0.64}
 64%|██████▍   | 1598/2496 [11:18:56<6:31:50, 26.18s/it] 64%|██████▍   | 1599/2496 [11:19:21<6:25:31, 25.79s/it]                                                        {'loss': 0.6639, 'learning_rate': 6.043174431030534e-06, 'epoch': 0.64}
 64%|██████▍   | 1599/2496 [11:19:21<6:25:31, 25.79s/it] 64%|██████▍   | 1600/2496 [11:19:48<6:31:41, 26.23s/it]                                                        {'loss': 0.6763, 'learning_rate': 6.031260380671573e-06, 'epoch': 0.64}
 64%|██████▍   | 1600/2496 [11:19:48<6:31:41, 26.23s/it] 64%|██████▍   | 1601/2496 [11:20:12<6:23:12, 25.69s/it]                                                        {'loss': 0.6783, 'learning_rate': 6.019353013177989e-06, 'epoch': 0.64}
 64%|██████▍   | 1601/2496 [11:20:12<6:23:12, 25.69s/it] 64%|██████▍   | 1602/2496 [11:20:38<6:20:22, 25.53s/it]                                                        {'loss': 0.6718, 'learning_rate': 6.007452348600306e-06, 'epoch': 0.64}
 64%|██████▍   | 1602/2496 [11:20:38<6:20:22, 25.53s/it]this iter is wrong in something... skip...
 64%|██████▍   | 1603/2496 [11:21:05<6:28:40, 26.11s/it]                                                        {'loss': 0.6892, 'learning_rate': 5.995558406977768e-06, 'epoch': 0.64}
 64%|██████▍   | 1603/2496 [11:21:05<6:28:40, 26.11s/it] 64%|██████▍   | 1604/2496 [11:21:30<6:22:32, 25.73s/it]                                                        {'loss': 0.2461, 'learning_rate': 5.9836712083383e-06, 'epoch': 0.64}
 64%|██████▍   | 1604/2496 [11:21:30<6:22:32, 25.73s/it] 64%|██████▍   | 1605/2496 [11:21:57<6:26:43, 26.04s/it]                                                        {'loss': 0.6444, 'learning_rate': 5.971790772698467e-06, 'epoch': 0.64}
 64%|██████▍   | 1605/2496 [11:21:57<6:26:43, 26.04s/it] 64%|██████▍   | 1606/2496 [11:22:21<6:18:42, 25.53s/it]                                                        {'loss': 0.679, 'learning_rate': 5.959917120063452e-06, 'epoch': 0.64}
 64%|██████▍   | 1606/2496 [11:22:21<6:18:42, 25.53s/it] 64%|██████▍   | 1607/2496 [11:22:44<6:06:04, 24.71s/it]                                                        {'loss': 0.6726, 'learning_rate': 5.948050270427017e-06, 'epoch': 0.64}
 64%|██████▍   | 1607/2496 [11:22:44<6:06:04, 24.71s/it] 64%|██████▍   | 1608/2496 [11:23:08<6:05:06, 24.67s/it]                                                        {'loss': 0.667, 'learning_rate': 5.9361902437714584e-06, 'epoch': 0.64}
 64%|██████▍   | 1608/2496 [11:23:08<6:05:06, 24.67s/it] 64%|██████▍   | 1609/2496 [11:23:33<6:03:12, 24.57s/it]                                                        {'loss': 0.6637, 'learning_rate': 5.924337060067591e-06, 'epoch': 0.64}
 64%|██████▍   | 1609/2496 [11:23:33<6:03:12, 24.57s/it] 65%|██████▍   | 1610/2496 [11:23:58<6:06:05, 24.79s/it]                                                        {'loss': 0.6939, 'learning_rate': 5.912490739274712e-06, 'epoch': 0.64}
 65%|██████▍   | 1610/2496 [11:23:58<6:06:05, 24.79s/it] 65%|██████▍   | 1611/2496 [11:24:23<6:05:56, 24.81s/it]                                                        {'loss': 0.6908, 'learning_rate': 5.900651301340552e-06, 'epoch': 0.65}
 65%|██████▍   | 1611/2496 [11:24:23<6:05:56, 24.81s/it] 65%|██████▍   | 1612/2496 [11:24:48<6:06:46, 24.89s/it]                                                        {'loss': 0.67, 'learning_rate': 5.88881876620126e-06, 'epoch': 0.65}
 65%|██████▍   | 1612/2496 [11:24:48<6:06:46, 24.89s/it] 65%|██████▍   | 1613/2496 [11:25:17<6:24:40, 26.14s/it]                                                        {'loss': 0.6725, 'learning_rate': 5.876993153781353e-06, 'epoch': 0.65}
 65%|██████▍   | 1613/2496 [11:25:17<6:24:40, 26.14s/it] 65%|██████▍   | 1614/2496 [11:25:41<6:14:53, 25.50s/it]                                                        {'loss': 0.6943, 'learning_rate': 5.865174483993697e-06, 'epoch': 0.65}
 65%|██████▍   | 1614/2496 [11:25:41<6:14:53, 25.50s/it] 65%|██████▍   | 1615/2496 [11:26:06<6:10:09, 25.21s/it]                                                        {'loss': 0.6968, 'learning_rate': 5.8533627767394685e-06, 'epoch': 0.65}
 65%|██████▍   | 1615/2496 [11:26:06<6:10:09, 25.21s/it] 65%|██████▍   | 1616/2496 [11:26:34<6:22:03, 26.05s/it]                                                        {'loss': 0.6596, 'learning_rate': 5.841558051908118e-06, 'epoch': 0.65}
 65%|██████▍   | 1616/2496 [11:26:34<6:22:03, 26.05s/it] 65%|██████▍   | 1617/2496 [11:26:59<6:17:11, 25.75s/it]                                                        {'loss': 0.6769, 'learning_rate': 5.829760329377336e-06, 'epoch': 0.65}
 65%|██████▍   | 1617/2496 [11:26:59<6:17:11, 25.75s/it] 65%|██████▍   | 1618/2496 [11:27:27<6:27:00, 26.45s/it]                                                        {'loss': 0.6943, 'learning_rate': 5.81796962901303e-06, 'epoch': 0.65}
 65%|██████▍   | 1618/2496 [11:27:27<6:27:00, 26.45s/it] 65%|██████▍   | 1619/2496 [11:27:54<6:29:16, 26.63s/it]                                                        {'loss': 0.6577, 'learning_rate': 5.806185970669267e-06, 'epoch': 0.65}
 65%|██████▍   | 1619/2496 [11:27:54<6:29:16, 26.63s/it] 65%|██████▍   | 1620/2496 [11:28:18<6:18:41, 25.94s/it]                                                        {'loss': 0.651, 'learning_rate': 5.794409374188272e-06, 'epoch': 0.65}
 65%|██████▍   | 1620/2496 [11:28:18<6:18:41, 25.94s/it] 65%|██████▍   | 1621/2496 [11:28:44<6:19:48, 26.04s/it]                                                        {'loss': 0.6453, 'learning_rate': 5.7826398594003766e-06, 'epoch': 0.65}
 65%|██████▍   | 1621/2496 [11:28:44<6:19:48, 26.04s/it] 65%|██████▍   | 1622/2496 [11:29:09<6:13:33, 25.64s/it]                                                        {'loss': 0.6931, 'learning_rate': 5.7708774461239826e-06, 'epoch': 0.65}
 65%|██████▍   | 1622/2496 [11:29:09<6:13:33, 25.64s/it] 65%|██████▌   | 1623/2496 [11:29:36<6:16:41, 25.89s/it]                                                        {'loss': 0.6217, 'learning_rate': 5.759122154165528e-06, 'epoch': 0.65}
 65%|██████▌   | 1623/2496 [11:29:36<6:16:41, 25.89s/it] 65%|██████▌   | 1624/2496 [11:30:00<6:08:24, 25.35s/it]                                                        {'loss': 0.6737, 'learning_rate': 5.747374003319474e-06, 'epoch': 0.65}
 65%|██████▌   | 1624/2496 [11:30:00<6:08:24, 25.35s/it] 65%|██████▌   | 1625/2496 [11:30:26<6:12:52, 25.69s/it]                                                        {'loss': 0.6628, 'learning_rate': 5.735633013368252e-06, 'epoch': 0.65}
 65%|██████▌   | 1625/2496 [11:30:26<6:12:52, 25.69s/it] 65%|██████▌   | 1626/2496 [11:30:52<6:13:53, 25.79s/it]                                                        {'loss': 0.6885, 'learning_rate': 5.723899204082224e-06, 'epoch': 0.65}
 65%|██████▌   | 1626/2496 [11:30:52<6:13:53, 25.79s/it] 65%|██████▌   | 1627/2496 [11:31:18<6:15:15, 25.91s/it]                                                        {'loss': 0.6839, 'learning_rate': 5.71217259521968e-06, 'epoch': 0.65}
 65%|██████▌   | 1627/2496 [11:31:18<6:15:15, 25.91s/it] 65%|██████▌   | 1628/2496 [11:31:42<6:06:42, 25.35s/it]                                                        {'loss': 0.6738, 'learning_rate': 5.7004532065267645e-06, 'epoch': 0.65}
 65%|██████▌   | 1628/2496 [11:31:42<6:06:42, 25.35s/it] 65%|██████▌   | 1629/2496 [11:32:06<5:57:32, 24.74s/it]                                                        {'loss': 0.6961, 'learning_rate': 5.688741057737486e-06, 'epoch': 0.65}
 65%|██████▌   | 1629/2496 [11:32:06<5:57:32, 24.74s/it] 65%|██████▌   | 1630/2496 [11:32:32<6:03:40, 25.20s/it]                                                        {'loss': 0.6993, 'learning_rate': 5.677036168573642e-06, 'epoch': 0.65}
 65%|██████▌   | 1630/2496 [11:32:32<6:03:40, 25.20s/it] 65%|██████▌   | 1631/2496 [11:32:57<6:02:28, 25.14s/it]                                                        {'loss': 0.7007, 'learning_rate': 5.66533855874482e-06, 'epoch': 0.65}
 65%|██████▌   | 1631/2496 [11:32:57<6:02:28, 25.14s/it] 65%|██████▌   | 1632/2496 [11:33:20<5:54:53, 24.65s/it]                                                        {'loss': 0.6673, 'learning_rate': 5.653648247948342e-06, 'epoch': 0.65}
 65%|██████▌   | 1632/2496 [11:33:20<5:54:53, 24.65s/it] 65%|██████▌   | 1633/2496 [11:33:46<5:59:36, 25.00s/it]                                                        {'loss': 0.6932, 'learning_rate': 5.641965255869235e-06, 'epoch': 0.65}
 65%|██████▌   | 1633/2496 [11:33:46<5:59:36, 25.00s/it] 65%|██████▌   | 1634/2496 [11:34:12<6:03:50, 25.33s/it]                                                        {'loss': 0.6725, 'learning_rate': 5.630289602180223e-06, 'epoch': 0.65}
 65%|██████▌   | 1634/2496 [11:34:12<6:03:50, 25.33s/it] 66%|██████▌   | 1635/2496 [11:34:38<6:05:29, 25.47s/it]                                                        {'loss': 0.6415, 'learning_rate': 5.61862130654165e-06, 'epoch': 0.65}
 66%|██████▌   | 1635/2496 [11:34:38<6:05:29, 25.47s/it] 66%|██████▌   | 1636/2496 [11:35:03<6:04:02, 25.40s/it]                                                        {'loss': 0.6999, 'learning_rate': 5.606960388601479e-06, 'epoch': 0.66}
 66%|██████▌   | 1636/2496 [11:35:03<6:04:02, 25.40s/it] 66%|██████▌   | 1637/2496 [11:35:29<6:03:48, 25.41s/it]                                                        {'loss': 0.6852, 'learning_rate': 5.595306867995254e-06, 'epoch': 0.66}
 66%|██████▌   | 1637/2496 [11:35:29<6:03:48, 25.41s/it] 66%|██████▌   | 1638/2496 [11:35:54<6:02:15, 25.33s/it]                                                        {'loss': 0.6698, 'learning_rate': 5.58366076434605e-06, 'epoch': 0.66}
 66%|██████▌   | 1638/2496 [11:35:54<6:02:15, 25.33s/it] 66%|██████▌   | 1639/2496 [11:36:20<6:03:10, 25.43s/it]                                                        {'loss': 0.6538, 'learning_rate': 5.5720220972644735e-06, 'epoch': 0.66}
 66%|██████▌   | 1639/2496 [11:36:20<6:03:10, 25.43s/it] 66%|██████▌   | 1640/2496 [11:36:44<5:58:53, 25.16s/it]                                                        {'loss': 0.6838, 'learning_rate': 5.560390886348586e-06, 'epoch': 0.66}
 66%|██████▌   | 1640/2496 [11:36:44<5:58:53, 25.16s/it] 66%|██████▌   | 1641/2496 [11:37:12<6:09:02, 25.90s/it]                                                        {'loss': 0.6606, 'learning_rate': 5.548767151183912e-06, 'epoch': 0.66}
 66%|██████▌   | 1641/2496 [11:37:12<6:09:02, 25.90s/it] 66%|██████▌   | 1642/2496 [11:37:38<6:09:03, 25.93s/it]                                                        {'loss': 0.637, 'learning_rate': 5.537150911343374e-06, 'epoch': 0.66}
 66%|██████▌   | 1642/2496 [11:37:38<6:09:03, 25.93s/it] 66%|██████▌   | 1643/2496 [11:38:03<6:06:54, 25.81s/it]                                                        {'loss': 0.6914, 'learning_rate': 5.525542186387281e-06, 'epoch': 0.66}
 66%|██████▌   | 1643/2496 [11:38:03<6:06:54, 25.81s/it] 66%|██████▌   | 1644/2496 [11:38:28<6:00:27, 25.38s/it]                                                        {'loss': 0.663, 'learning_rate': 5.513940995863291e-06, 'epoch': 0.66}
 66%|██████▌   | 1644/2496 [11:38:28<6:00:27, 25.38s/it] 66%|██████▌   | 1645/2496 [11:38:52<5:55:48, 25.09s/it]                                                        {'loss': 0.6825, 'learning_rate': 5.502347359306368e-06, 'epoch': 0.66}
 66%|██████▌   | 1645/2496 [11:38:52<5:55:48, 25.09s/it] 66%|██████▌   | 1646/2496 [11:39:17<5:53:50, 24.98s/it]                                                        {'loss': 0.6932, 'learning_rate': 5.4907612962387526e-06, 'epoch': 0.66}
 66%|██████▌   | 1646/2496 [11:39:17<5:53:50, 24.98s/it] 66%|██████▌   | 1647/2496 [11:39:44<6:02:56, 25.65s/it]                                                        {'loss': 0.6879, 'learning_rate': 5.479182826169942e-06, 'epoch': 0.66}
 66%|██████▌   | 1647/2496 [11:39:44<6:02:56, 25.65s/it] 66%|██████▌   | 1648/2496 [11:40:10<6:01:47, 25.60s/it]                                                        {'loss': 0.6496, 'learning_rate': 5.4676119685966485e-06, 'epoch': 0.66}
 66%|██████▌   | 1648/2496 [11:40:10<6:01:47, 25.60s/it] 66%|██████▌   | 1649/2496 [11:40:35<5:59:25, 25.46s/it]                                                        {'loss': 0.6492, 'learning_rate': 5.456048743002756e-06, 'epoch': 0.66}
 66%|██████▌   | 1649/2496 [11:40:35<5:59:25, 25.46s/it] 66%|██████▌   | 1650/2496 [11:40:59<5:56:08, 25.26s/it]                                                        {'loss': 0.6951, 'learning_rate': 5.444493168859304e-06, 'epoch': 0.66}
 66%|██████▌   | 1650/2496 [11:40:59<5:56:08, 25.26s/it]this iter is wrong in something... skip...
 66%|██████▌   | 1651/2496 [11:41:24<5:51:40, 24.97s/it]                                                        {'loss': 0.6465, 'learning_rate': 5.432945265624448e-06, 'epoch': 0.66}
 66%|██████▌   | 1651/2496 [11:41:24<5:51:40, 24.97s/it] 66%|██████▌   | 1652/2496 [11:41:50<5:58:25, 25.48s/it]                                                        {'loss': 0.7028, 'learning_rate': 5.42140505274342e-06, 'epoch': 0.66}
 66%|██████▌   | 1652/2496 [11:41:50<5:58:25, 25.48s/it] 66%|██████▌   | 1653/2496 [11:42:15<5:55:52, 25.33s/it]                                                        {'loss': 0.6828, 'learning_rate': 5.409872549648511e-06, 'epoch': 0.66}
 66%|██████▌   | 1653/2496 [11:42:15<5:55:52, 25.33s/it] 66%|██████▋   | 1654/2496 [11:42:39<5:49:49, 24.93s/it]                                                        {'loss': 0.6873, 'learning_rate': 5.3983477757590294e-06, 'epoch': 0.66}
 66%|██████▋   | 1654/2496 [11:42:39<5:49:49, 24.93s/it] 66%|██████▋   | 1655/2496 [11:43:05<5:51:06, 25.05s/it]                                                        {'loss': 0.693, 'learning_rate': 5.386830750481258e-06, 'epoch': 0.66}
 66%|██████▋   | 1655/2496 [11:43:05<5:51:06, 25.05s/it] 66%|██████▋   | 1656/2496 [11:43:35<6:11:59, 26.57s/it]                                                        {'loss': 0.6488, 'learning_rate': 5.375321493208447e-06, 'epoch': 0.66}
 66%|██████▋   | 1656/2496 [11:43:35<6:11:59, 26.57s/it] 66%|██████▋   | 1657/2496 [11:44:00<6:04:20, 26.06s/it]                                                        {'loss': 0.6721, 'learning_rate': 5.363820023320752e-06, 'epoch': 0.66}
 66%|██████▋   | 1657/2496 [11:44:00<6:04:20, 26.06s/it] 66%|██████▋   | 1658/2496 [11:44:32<6:28:46, 27.84s/it]                                                        {'loss': 0.6816, 'learning_rate': 5.352326360185227e-06, 'epoch': 0.66}
 66%|██████▋   | 1658/2496 [11:44:32<6:28:46, 27.84s/it]this iter is wrong in something... skip...
 66%|██████▋   | 1659/2496 [11:44:55<6:07:51, 26.37s/it]                                                        {'loss': 0.6537, 'learning_rate': 5.340840523155769e-06, 'epoch': 0.66}
 66%|██████▋   | 1659/2496 [11:44:55<6:07:51, 26.37s/it] 67%|██████▋   | 1660/2496 [11:45:18<5:53:34, 25.38s/it]                                                        {'loss': 0.6635, 'learning_rate': 5.329362531573111e-06, 'epoch': 0.66}
 67%|██████▋   | 1660/2496 [11:45:18<5:53:34, 25.38s/it]this iter is wrong in something... skip...
 67%|██████▋   | 1661/2496 [11:45:42<5:46:56, 24.93s/it]                                                        {'loss': 0.701, 'learning_rate': 5.317892404764764e-06, 'epoch': 0.67}
 67%|██████▋   | 1661/2496 [11:45:42<5:46:56, 24.93s/it] 67%|██████▋   | 1662/2496 [11:46:07<5:50:38, 25.23s/it]                                                        {'loss': 0.6645, 'learning_rate': 5.306430162044992e-06, 'epoch': 0.67}
 67%|██████▋   | 1662/2496 [11:46:07<5:50:38, 25.23s/it] 67%|██████▋   | 1663/2496 [11:46:31<5:42:11, 24.65s/it]                                                        {'loss': 0.7086, 'learning_rate': 5.294975822714804e-06, 'epoch': 0.67}
 67%|██████▋   | 1663/2496 [11:46:31<5:42:11, 24.65s/it] 67%|██████▋   | 1664/2496 [11:46:56<5:45:37, 24.93s/it]                                                        {'loss': 0.6732, 'learning_rate': 5.2835294060618805e-06, 'epoch': 0.67}
 67%|██████▋   | 1664/2496 [11:46:56<5:45:37, 24.93s/it] 67%|██████▋   | 1665/2496 [11:47:22<5:50:04, 25.28s/it]                                                        {'loss': 0.7201, 'learning_rate': 5.272090931360564e-06, 'epoch': 0.67}
 67%|██████▋   | 1665/2496 [11:47:22<5:50:04, 25.28s/it] 67%|██████▋   | 1666/2496 [11:47:51<6:04:26, 26.35s/it]                                                        {'loss': 0.647, 'learning_rate': 5.260660417871834e-06, 'epoch': 0.67}
 67%|██████▋   | 1666/2496 [11:47:51<6:04:26, 26.35s/it] 67%|██████▋   | 1667/2496 [11:48:17<6:00:42, 26.11s/it]                                                        {'loss': 0.6711, 'learning_rate': 5.249237884843252e-06, 'epoch': 0.67}
 67%|██████▋   | 1667/2496 [11:48:17<6:00:42, 26.11s/it] 67%|██████▋   | 1668/2496 [11:48:41<5:51:25, 25.47s/it]                                                        {'loss': 0.6726, 'learning_rate': 5.237823351508953e-06, 'epoch': 0.67}
 67%|██████▋   | 1668/2496 [11:48:41<5:51:25, 25.47s/it] 67%|██████▋   | 1669/2496 [11:49:06<5:51:31, 25.50s/it]                                                        {'loss': 0.6565, 'learning_rate': 5.2264168370895894e-06, 'epoch': 0.67}
 67%|██████▋   | 1669/2496 [11:49:06<5:51:31, 25.50s/it]this iter is wrong in something... skip...
 67%|██████▋   | 1670/2496 [11:49:32<5:52:10, 25.58s/it]                                                        {'loss': 0.6668, 'learning_rate': 5.215018360792324e-06, 'epoch': 0.67}
 67%|██████▋   | 1670/2496 [11:49:32<5:52:10, 25.58s/it] 67%|██████▋   | 1671/2496 [11:49:57<5:47:39, 25.28s/it]                                                        {'loss': 0.6881, 'learning_rate': 5.203627941810768e-06, 'epoch': 0.67}
 67%|██████▋   | 1671/2496 [11:49:57<5:47:39, 25.28s/it] 67%|██████▋   | 1672/2496 [11:50:24<5:56:30, 25.96s/it]                                                        {'loss': 0.6629, 'learning_rate': 5.192245599324982e-06, 'epoch': 0.67}
 67%|██████▋   | 1672/2496 [11:50:24<5:56:30, 25.96s/it] 67%|██████▋   | 1673/2496 [11:50:50<5:54:27, 25.84s/it]                                                        {'loss': 0.639, 'learning_rate': 5.18087135250142e-06, 'epoch': 0.67}
 67%|██████▋   | 1673/2496 [11:50:50<5:54:27, 25.84s/it] 67%|██████▋   | 1674/2496 [11:51:15<5:49:19, 25.50s/it]                                                        {'loss': 0.673, 'learning_rate': 5.1695052204929004e-06, 'epoch': 0.67}
 67%|██████▋   | 1674/2496 [11:51:15<5:49:19, 25.50s/it] 67%|██████▋   | 1675/2496 [11:51:40<5:47:11, 25.37s/it]                                                        {'loss': 0.6944, 'learning_rate': 5.158147222438579e-06, 'epoch': 0.67}
 67%|██████▋   | 1675/2496 [11:51:40<5:47:11, 25.37s/it] 67%|██████▋   | 1676/2496 [11:52:06<5:49:14, 25.55s/it]                                                        {'loss': 0.6516, 'learning_rate': 5.1467973774639146e-06, 'epoch': 0.67}
 67%|██████▋   | 1676/2496 [11:52:06<5:49:14, 25.55s/it] 67%|██████▋   | 1677/2496 [11:52:32<5:51:06, 25.72s/it]                                                        {'loss': 0.6608, 'learning_rate': 5.135455704680646e-06, 'epoch': 0.67}
 67%|██████▋   | 1677/2496 [11:52:32<5:51:06, 25.72s/it]this iter is wrong in something... skip...
 67%|██████▋   | 1678/2496 [11:52:57<5:47:56, 25.52s/it]                                                        {'loss': 0.6725, 'learning_rate': 5.124122223186734e-06, 'epoch': 0.67}
 67%|██████▋   | 1678/2496 [11:52:57<5:47:56, 25.52s/it] 67%|██████▋   | 1679/2496 [11:53:21<5:43:03, 25.19s/it]                                                        {'loss': 0.6636, 'learning_rate': 5.112796952066365e-06, 'epoch': 0.67}
 67%|██████▋   | 1679/2496 [11:53:21<5:43:03, 25.19s/it] 67%|██████▋   | 1680/2496 [11:53:46<5:40:46, 25.06s/it]                                                        {'loss': 0.7041, 'learning_rate': 5.101479910389888e-06, 'epoch': 0.67}
 67%|██████▋   | 1680/2496 [11:53:46<5:40:46, 25.06s/it] 67%|██████▋   | 1681/2496 [11:54:08<5:28:43, 24.20s/it]                                                        {'loss': 0.6625, 'learning_rate': 5.090171117213794e-06, 'epoch': 0.67}
 67%|██████▋   | 1681/2496 [11:54:08<5:28:43, 24.20s/it]this iter is wrong in something... skip...
 67%|██████▋   | 1682/2496 [11:54:33<5:29:34, 24.29s/it]                                                        {'loss': 0.6849, 'learning_rate': 5.078870591580691e-06, 'epoch': 0.67}
 67%|██████▋   | 1682/2496 [11:54:33<5:29:34, 24.29s/it] 67%|██████▋   | 1683/2496 [11:54:56<5:26:09, 24.07s/it]                                                        {'loss': 0.6735, 'learning_rate': 5.067578352519267e-06, 'epoch': 0.67}
 67%|██████▋   | 1683/2496 [11:54:56<5:26:09, 24.07s/it] 67%|██████▋   | 1684/2496 [11:55:21<5:30:41, 24.44s/it]                                                        {'loss': 0.6756, 'learning_rate': 5.0562944190442435e-06, 'epoch': 0.67}
 67%|██████▋   | 1684/2496 [11:55:21<5:30:41, 24.44s/it] 68%|██████▊   | 1685/2496 [11:55:46<5:31:45, 24.54s/it]                                                        {'loss': 0.6783, 'learning_rate': 5.045018810156374e-06, 'epoch': 0.67}
 68%|██████▊   | 1685/2496 [11:55:46<5:31:45, 24.54s/it] 68%|██████▊   | 1686/2496 [11:56:13<5:40:57, 25.26s/it]                                                        {'loss': 0.6551, 'learning_rate': 5.03375154484238e-06, 'epoch': 0.68}
 68%|██████▊   | 1686/2496 [11:56:13<5:40:57, 25.26s/it] 68%|██████▊   | 1687/2496 [11:56:39<5:41:18, 25.31s/it]                                                        {'loss': 0.6725, 'learning_rate': 5.022492642074943e-06, 'epoch': 0.68}
 68%|██████▊   | 1687/2496 [11:56:39<5:41:18, 25.31s/it] 68%|██████▊   | 1688/2496 [11:57:02<5:33:25, 24.76s/it]                                                        {'loss': 0.7011, 'learning_rate': 5.0112421208126535e-06, 'epoch': 0.68}
 68%|██████▊   | 1688/2496 [11:57:02<5:33:25, 24.76s/it] 68%|██████▊   | 1689/2496 [11:57:28<5:35:41, 24.96s/it]                                                        {'loss': 0.6952, 'learning_rate': 5.000000000000003e-06, 'epoch': 0.68}
 68%|██████▊   | 1689/2496 [11:57:28<5:35:41, 24.96s/it] 68%|██████▊   | 1690/2496 [11:57:52<5:32:00, 24.72s/it]                                                        {'loss': 0.6818, 'learning_rate': 4.988766298567318e-06, 'epoch': 0.68}
 68%|██████▊   | 1690/2496 [11:57:52<5:32:00, 24.72s/it] 68%|██████▊   | 1691/2496 [11:58:17<5:32:03, 24.75s/it]                                                        {'loss': 0.6859, 'learning_rate': 4.977541035430764e-06, 'epoch': 0.68}
 68%|██████▊   | 1691/2496 [11:58:17<5:32:03, 24.75s/it] 68%|██████▊   | 1692/2496 [11:58:44<5:43:36, 25.64s/it]                                                        {'loss': 0.6829, 'learning_rate': 4.966324229492297e-06, 'epoch': 0.68}
 68%|██████▊   | 1692/2496 [11:58:44<5:43:36, 25.64s/it] 68%|██████▊   | 1693/2496 [11:59:11<5:49:05, 26.08s/it]                                                        {'loss': 0.6561, 'learning_rate': 4.955115899639623e-06, 'epoch': 0.68}
 68%|██████▊   | 1693/2496 [11:59:11<5:49:05, 26.08s/it] 68%|██████▊   | 1694/2496 [11:59:37<5:45:10, 25.82s/it]                                                        {'loss': 0.6644, 'learning_rate': 4.943916064746175e-06, 'epoch': 0.68}
 68%|██████▊   | 1694/2496 [11:59:37<5:45:10, 25.82s/it] 68%|██████▊   | 1695/2496 [12:00:01<5:40:57, 25.54s/it]                                                        {'loss': 0.6746, 'learning_rate': 4.932724743671089e-06, 'epoch': 0.68}
 68%|██████▊   | 1695/2496 [12:00:01<5:40:57, 25.54s/it] 68%|██████▊   | 1696/2496 [12:00:26<5:38:08, 25.36s/it]                                                        {'loss': 0.6953, 'learning_rate': 4.9215419552591684e-06, 'epoch': 0.68}
 68%|██████▊   | 1696/2496 [12:00:26<5:38:08, 25.36s/it] 68%|██████▊   | 1697/2496 [12:00:51<5:34:30, 25.12s/it]                                                        {'loss': 0.6986, 'learning_rate': 4.910367718340836e-06, 'epoch': 0.68}
 68%|██████▊   | 1697/2496 [12:00:51<5:34:30, 25.12s/it] 68%|██████▊   | 1698/2496 [12:01:18<5:41:45, 25.70s/it]                                                        {'loss': 0.6999, 'learning_rate': 4.899202051732119e-06, 'epoch': 0.68}
 68%|██████▊   | 1698/2496 [12:01:18<5:41:45, 25.70s/it] 68%|██████▊   | 1699/2496 [12:01:42<5:32:38, 25.04s/it]                                                        {'loss': 0.6873, 'learning_rate': 4.888044974234622e-06, 'epoch': 0.68}
 68%|██████▊   | 1699/2496 [12:01:42<5:32:38, 25.04s/it] 68%|██████▊   | 1700/2496 [12:02:06<5:29:26, 24.83s/it]                                                        {'loss': 0.6924, 'learning_rate': 4.876896504635472e-06, 'epoch': 0.68}
 68%|██████▊   | 1700/2496 [12:02:06<5:29:26, 24.83s/it] 68%|██████▊   | 1701/2496 [12:02:31<5:29:00, 24.83s/it]                                                        {'loss': 0.6892, 'learning_rate': 4.8657566617073135e-06, 'epoch': 0.68}
 68%|██████▊   | 1701/2496 [12:02:31<5:29:00, 24.83s/it] 68%|██████▊   | 1702/2496 [12:02:56<5:28:33, 24.83s/it]                                                        {'loss': 0.242, 'learning_rate': 4.854625464208266e-06, 'epoch': 0.68}
 68%|██████▊   | 1702/2496 [12:02:56<5:28:33, 24.83s/it] 68%|██████▊   | 1703/2496 [12:03:20<5:27:43, 24.80s/it]                                                        {'loss': 0.6823, 'learning_rate': 4.84350293088188e-06, 'epoch': 0.68}
 68%|██████▊   | 1703/2496 [12:03:20<5:27:43, 24.80s/it] 68%|██████▊   | 1704/2496 [12:03:45<5:26:22, 24.73s/it]                                                        {'loss': 0.66, 'learning_rate': 4.832389080457118e-06, 'epoch': 0.68}
 68%|██████▊   | 1704/2496 [12:03:45<5:26:22, 24.73s/it] 68%|██████▊   | 1705/2496 [12:04:10<5:26:57, 24.80s/it]                                                        {'loss': 0.6571, 'learning_rate': 4.821283931648332e-06, 'epoch': 0.68}
 68%|██████▊   | 1705/2496 [12:04:10<5:26:57, 24.80s/it] 68%|██████▊   | 1706/2496 [12:04:34<5:25:11, 24.70s/it]                                                        {'loss': 0.6569, 'learning_rate': 4.810187503155217e-06, 'epoch': 0.68}
 68%|██████▊   | 1706/2496 [12:04:34<5:25:11, 24.70s/it] 68%|██████▊   | 1707/2496 [12:05:01<5:32:24, 25.28s/it]                                                        {'loss': 0.6741, 'learning_rate': 4.7990998136627774e-06, 'epoch': 0.68}
 68%|██████▊   | 1707/2496 [12:05:01<5:32:24, 25.28s/it]this iter is wrong in something... skip...
 68%|██████▊   | 1708/2496 [12:05:25<5:28:51, 25.04s/it]                                                        {'loss': 0.6948, 'learning_rate': 4.788020881841313e-06, 'epoch': 0.68}
 68%|██████▊   | 1708/2496 [12:05:25<5:28:51, 25.04s/it] 68%|██████▊   | 1709/2496 [12:05:51<5:32:27, 25.35s/it]                                                        {'loss': 0.635, 'learning_rate': 4.776950726346364e-06, 'epoch': 0.68}
 68%|██████▊   | 1709/2496 [12:05:51<5:32:27, 25.35s/it]this iter is wrong in something... skip...
 69%|██████▊   | 1710/2496 [12:06:15<5:24:33, 24.78s/it]                                                        {'loss': 0.6477, 'learning_rate': 4.765889365818708e-06, 'epoch': 0.68}
 69%|██████▊   | 1710/2496 [12:06:15<5:24:33, 24.78s/it] 69%|██████▊   | 1711/2496 [12:06:41<5:28:40, 25.12s/it]                                                        {'loss': 0.6317, 'learning_rate': 4.754836818884295e-06, 'epoch': 0.69}
 69%|██████▊   | 1711/2496 [12:06:41<5:28:40, 25.12s/it] 69%|██████▊   | 1712/2496 [12:07:06<5:28:55, 25.17s/it]                                                        {'loss': 0.6596, 'learning_rate': 4.743793104154253e-06, 'epoch': 0.69}
 69%|██████▊   | 1712/2496 [12:07:06<5:28:55, 25.17s/it] 69%|██████▊   | 1713/2496 [12:07:30<5:24:09, 24.84s/it]                                                        {'loss': 0.69, 'learning_rate': 4.732758240224819e-06, 'epoch': 0.69}
 69%|██████▊   | 1713/2496 [12:07:30<5:24:09, 24.84s/it] 69%|██████▊   | 1714/2496 [12:07:56<5:28:52, 25.23s/it]                                                        {'loss': 0.6728, 'learning_rate': 4.721732245677341e-06, 'epoch': 0.69}
 69%|██████▊   | 1714/2496 [12:07:56<5:28:52, 25.23s/it] 69%|██████▊   | 1715/2496 [12:08:22<5:29:22, 25.30s/it]                                                        {'loss': 0.6989, 'learning_rate': 4.710715139078228e-06, 'epoch': 0.69}
 69%|██████▊   | 1715/2496 [12:08:22<5:29:22, 25.30s/it] 69%|██████▉   | 1716/2496 [12:08:46<5:26:34, 25.12s/it]                                                        {'loss': 0.2476, 'learning_rate': 4.69970693897892e-06, 'epoch': 0.69}
 69%|██████▉   | 1716/2496 [12:08:46<5:26:34, 25.12s/it] 69%|██████▉   | 1717/2496 [12:09:12<5:26:07, 25.12s/it]                                                        {'loss': 0.6791, 'learning_rate': 4.6887076639158544e-06, 'epoch': 0.69}
 69%|██████▉   | 1717/2496 [12:09:12<5:26:07, 25.12s/it] 69%|██████▉   | 1718/2496 [12:09:36<5:23:14, 24.93s/it]                                                        {'loss': 0.7332, 'learning_rate': 4.677717332410458e-06, 'epoch': 0.69}
 69%|██████▉   | 1718/2496 [12:09:36<5:23:14, 24.93s/it] 69%|██████▉   | 1719/2496 [12:10:03<5:28:48, 25.39s/it]                                                        {'loss': 0.6825, 'learning_rate': 4.666735962969073e-06, 'epoch': 0.69}
 69%|██████▉   | 1719/2496 [12:10:03<5:28:48, 25.39s/it] 69%|██████▉   | 1720/2496 [12:10:26<5:19:48, 24.73s/it]                                                        {'loss': 0.683, 'learning_rate': 4.655763574082973e-06, 'epoch': 0.69}
 69%|██████▉   | 1720/2496 [12:10:26<5:19:48, 24.73s/it] 69%|██████▉   | 1721/2496 [12:10:49<5:15:14, 24.41s/it]                                                        {'loss': 0.724, 'learning_rate': 4.644800184228301e-06, 'epoch': 0.69}
 69%|██████▉   | 1721/2496 [12:10:49<5:15:14, 24.41s/it] 69%|██████▉   | 1722/2496 [12:11:13<5:13:36, 24.31s/it]                                                        {'loss': 0.6729, 'learning_rate': 4.633845811866044e-06, 'epoch': 0.69}
 69%|██████▉   | 1722/2496 [12:11:13<5:13:36, 24.31s/it] 69%|██████▉   | 1723/2496 [12:11:40<5:21:31, 24.96s/it]                                                        {'loss': 0.6815, 'learning_rate': 4.622900475442e-06, 'epoch': 0.69}
 69%|██████▉   | 1723/2496 [12:11:40<5:21:31, 24.96s/it] 69%|██████▉   | 1724/2496 [12:12:06<5:24:57, 25.26s/it]                                                        {'loss': 0.677, 'learning_rate': 4.6119641933867655e-06, 'epoch': 0.69}
 69%|██████▉   | 1724/2496 [12:12:06<5:24:57, 25.26s/it] 69%|██████▉   | 1725/2496 [12:12:32<5:28:28, 25.56s/it]                                                        {'loss': 0.6551, 'learning_rate': 4.601036984115684e-06, 'epoch': 0.69}
 69%|██████▉   | 1725/2496 [12:12:32<5:28:28, 25.56s/it] 69%|██████▉   | 1726/2496 [12:12:58<5:29:01, 25.64s/it]                                                        {'loss': 0.7042, 'learning_rate': 4.59011886602882e-06, 'epoch': 0.69}
 69%|██████▉   | 1726/2496 [12:12:58<5:29:01, 25.64s/it]this iter is wrong in something... skip...
 69%|██████▉   | 1727/2496 [12:13:22<5:23:58, 25.28s/it]                                                        {'loss': 0.6957, 'learning_rate': 4.579209857510924e-06, 'epoch': 0.69}
 69%|██████▉   | 1727/2496 [12:13:22<5:23:58, 25.28s/it] 69%|██████▉   | 1728/2496 [12:13:47<5:21:37, 25.13s/it]                                                        {'loss': 0.6705, 'learning_rate': 4.568309976931419e-06, 'epoch': 0.69}
 69%|██████▉   | 1728/2496 [12:13:47<5:21:37, 25.13s/it] 69%|██████▉   | 1729/2496 [12:14:13<5:24:05, 25.35s/it]                                                        {'loss': 0.6797, 'learning_rate': 4.557419242644356e-06, 'epoch': 0.69}
 69%|██████▉   | 1729/2496 [12:14:13<5:24:05, 25.35s/it] 69%|██████▉   | 1730/2496 [12:14:38<5:21:33, 25.19s/it]                                                        {'loss': 0.6975, 'learning_rate': 4.546537672988373e-06, 'epoch': 0.69}
 69%|██████▉   | 1730/2496 [12:14:38<5:21:33, 25.19s/it] 69%|██████▉   | 1731/2496 [12:15:03<5:21:19, 25.20s/it]                                                        {'loss': 0.6816, 'learning_rate': 4.535665286286691e-06, 'epoch': 0.69}
 69%|██████▉   | 1731/2496 [12:15:03<5:21:19, 25.20s/it] 69%|██████▉   | 1732/2496 [12:15:27<5:14:28, 24.70s/it]                                                        {'loss': 0.676, 'learning_rate': 4.524802100847057e-06, 'epoch': 0.69}
 69%|██████▉   | 1732/2496 [12:15:27<5:14:28, 24.70s/it] 69%|██████▉   | 1733/2496 [12:15:51<5:13:01, 24.62s/it]                                                        {'loss': 0.6482, 'learning_rate': 4.513948134961723e-06, 'epoch': 0.69}
 69%|██████▉   | 1733/2496 [12:15:51<5:13:01, 24.62s/it] 69%|██████▉   | 1734/2496 [12:16:15<5:09:20, 24.36s/it]                                                        {'loss': 0.6558, 'learning_rate': 4.503103406907434e-06, 'epoch': 0.69}
 69%|██████▉   | 1734/2496 [12:16:15<5:09:20, 24.36s/it] 70%|██████▉   | 1735/2496 [12:16:41<5:17:52, 25.06s/it]                                                        {'loss': 0.6738, 'learning_rate': 4.492267934945361e-06, 'epoch': 0.69}
 70%|██████▉   | 1735/2496 [12:16:41<5:17:52, 25.06s/it] 70%|██████▉   | 1736/2496 [12:17:08<5:21:14, 25.36s/it]                                                        {'loss': 0.6805, 'learning_rate': 4.481441737321092e-06, 'epoch': 0.7}
 70%|██████▉   | 1736/2496 [12:17:08<5:21:14, 25.36s/it] 70%|██████▉   | 1737/2496 [12:17:34<5:24:55, 25.69s/it]                                                        {'loss': 0.6677, 'learning_rate': 4.4706248322646075e-06, 'epoch': 0.7}
 70%|██████▉   | 1737/2496 [12:17:34<5:24:55, 25.69s/it] 70%|██████▉   | 1738/2496 [12:17:57<5:16:07, 25.02s/it]                                                        {'loss': 0.7129, 'learning_rate': 4.459817237990226e-06, 'epoch': 0.7}
 70%|██████▉   | 1738/2496 [12:17:57<5:16:07, 25.02s/it] 70%|██████▉   | 1739/2496 [12:18:22<5:12:16, 24.75s/it]                                                        {'loss': 0.673, 'learning_rate': 4.449018972696606e-06, 'epoch': 0.7}
 70%|██████▉   | 1739/2496 [12:18:22<5:12:16, 24.75s/it]this iter is wrong in something... skip...
 70%|██████▉   | 1740/2496 [12:18:48<5:18:29, 25.28s/it]                                                        {'loss': 0.6688, 'learning_rate': 4.438230054566678e-06, 'epoch': 0.7}
 70%|██████▉   | 1740/2496 [12:18:48<5:18:29, 25.28s/it] 70%|██████▉   | 1741/2496 [12:19:13<5:18:26, 25.31s/it]                                                        {'loss': 0.6398, 'learning_rate': 4.42745050176765e-06, 'epoch': 0.7}
 70%|██████▉   | 1741/2496 [12:19:13<5:18:26, 25.31s/it] 70%|██████▉   | 1742/2496 [12:19:40<5:22:22, 25.65s/it]                                                        {'loss': 0.664, 'learning_rate': 4.416680332450946e-06, 'epoch': 0.7}
 70%|██████▉   | 1742/2496 [12:19:40<5:22:22, 25.65s/it] 70%|██████▉   | 1743/2496 [12:20:07<5:27:49, 26.12s/it]                                                        {'loss': 0.6377, 'learning_rate': 4.405919564752196e-06, 'epoch': 0.7}
 70%|██████▉   | 1743/2496 [12:20:07<5:27:49, 26.12s/it] 70%|██████▉   | 1744/2496 [12:20:34<5:29:53, 26.32s/it]                                                        {'loss': 0.676, 'learning_rate': 4.395168216791206e-06, 'epoch': 0.7}
 70%|██████▉   | 1744/2496 [12:20:34<5:29:53, 26.32s/it] 70%|██████▉   | 1745/2496 [12:20:58<5:21:48, 25.71s/it]                                                        {'loss': 0.6738, 'learning_rate': 4.384426306671906e-06, 'epoch': 0.7}
 70%|██████▉   | 1745/2496 [12:20:58<5:21:48, 25.71s/it] 70%|██████▉   | 1746/2496 [12:21:23<5:17:53, 25.43s/it]                                                        {'loss': 0.6472, 'learning_rate': 4.373693852482339e-06, 'epoch': 0.7}
 70%|██████▉   | 1746/2496 [12:21:23<5:17:53, 25.43s/it] 70%|██████▉   | 1747/2496 [12:21:49<5:19:27, 25.59s/it]                                                        {'loss': 0.6674, 'learning_rate': 4.362970872294631e-06, 'epoch': 0.7}
 70%|██████▉   | 1747/2496 [12:21:49<5:19:27, 25.59s/it] 70%|███████   | 1748/2496 [12:22:14<5:17:50, 25.50s/it]                                                        {'loss': 0.7155, 'learning_rate': 4.3522573841649514e-06, 'epoch': 0.7}
 70%|███████   | 1748/2496 [12:22:14<5:17:50, 25.50s/it] 70%|███████   | 1749/2496 [12:22:39<5:15:42, 25.36s/it]                                                        {'loss': 0.6636, 'learning_rate': 4.34155340613348e-06, 'epoch': 0.7}
 70%|███████   | 1749/2496 [12:22:39<5:15:42, 25.36s/it] 70%|███████   | 1750/2496 [12:23:05<5:18:08, 25.59s/it]                                                        {'loss': 0.6761, 'learning_rate': 4.330858956224399e-06, 'epoch': 0.7}
 70%|███████   | 1750/2496 [12:23:05<5:18:08, 25.59s/it] 70%|███████   | 1751/2496 [12:23:30<5:15:36, 25.42s/it]                                                        {'loss': 0.6605, 'learning_rate': 4.320174052445828e-06, 'epoch': 0.7}
 70%|███████   | 1751/2496 [12:23:30<5:15:36, 25.42s/it] 70%|███████   | 1752/2496 [12:23:53<5:05:22, 24.63s/it]                                                        {'loss': 0.6863, 'learning_rate': 4.309498712789817e-06, 'epoch': 0.7}
 70%|███████   | 1752/2496 [12:23:53<5:05:22, 24.63s/it]this iter is wrong in something... skip...
 70%|███████   | 1753/2496 [12:24:17<5:01:08, 24.32s/it]                                                        {'loss': 0.7274, 'learning_rate': 4.29883295523232e-06, 'epoch': 0.7}
 70%|███████   | 1753/2496 [12:24:17<5:01:08, 24.32s/it] 70%|███████   | 1754/2496 [12:24:40<4:55:38, 23.91s/it]                                                        {'loss': 0.6613, 'learning_rate': 4.2881767977331505e-06, 'epoch': 0.7}
 70%|███████   | 1754/2496 [12:24:40<4:55:38, 23.91s/it] 70%|███████   | 1755/2496 [12:25:05<4:59:08, 24.22s/it]                                                        {'loss': 0.6658, 'learning_rate': 4.277530258235955e-06, 'epoch': 0.7}
 70%|███████   | 1755/2496 [12:25:05<4:59:08, 24.22s/it] 70%|███████   | 1756/2496 [12:25:29<5:00:17, 24.35s/it]                                                        {'loss': 0.6711, 'learning_rate': 4.266893354668182e-06, 'epoch': 0.7}
 70%|███████   | 1756/2496 [12:25:29<5:00:17, 24.35s/it] 70%|███████   | 1757/2496 [12:25:53<4:57:11, 24.13s/it]                                                        {'loss': 0.6575, 'learning_rate': 4.256266104941061e-06, 'epoch': 0.7}
 70%|███████   | 1757/2496 [12:25:53<4:57:11, 24.13s/it] 70%|███████   | 1758/2496 [12:26:18<5:00:08, 24.40s/it]                                                        {'loss': 0.7059, 'learning_rate': 4.245648526949568e-06, 'epoch': 0.7}
 70%|███████   | 1758/2496 [12:26:18<5:00:08, 24.40s/it] 70%|███████   | 1759/2496 [12:26:45<5:10:45, 25.30s/it]                                                        {'loss': 0.67, 'learning_rate': 4.235040638572376e-06, 'epoch': 0.7}
 70%|███████   | 1759/2496 [12:26:45<5:10:45, 25.30s/it] 71%|███████   | 1760/2496 [12:27:10<5:08:03, 25.11s/it]                                                        {'loss': 0.2488, 'learning_rate': 4.2244424576718664e-06, 'epoch': 0.7}
 71%|███████   | 1760/2496 [12:27:10<5:08:03, 25.11s/it] 71%|███████   | 1761/2496 [12:27:35<5:05:58, 24.98s/it]                                                        {'loss': 0.6982, 'learning_rate': 4.213854002094056e-06, 'epoch': 0.71}
 71%|███████   | 1761/2496 [12:27:35<5:05:58, 24.98s/it]this iter is wrong in something... skip...
 71%|███████   | 1762/2496 [12:27:59<5:03:58, 24.85s/it]                                                        {'loss': 0.6609, 'learning_rate': 4.203275289668581e-06, 'epoch': 0.71}
 71%|███████   | 1762/2496 [12:27:59<5:03:58, 24.85s/it] 71%|███████   | 1763/2496 [12:28:23<4:59:32, 24.52s/it]                                                        {'loss': 0.6727, 'learning_rate': 4.1927063382087e-06, 'epoch': 0.71}
 71%|███████   | 1763/2496 [12:28:23<4:59:32, 24.52s/it] 71%|███████   | 1764/2496 [12:28:47<4:58:35, 24.47s/it]                                                        {'loss': 0.649, 'learning_rate': 4.182147165511206e-06, 'epoch': 0.71}
 71%|███████   | 1764/2496 [12:28:47<4:58:35, 24.47s/it] 71%|███████   | 1765/2496 [12:29:11<4:55:25, 24.25s/it]                                                        {'loss': 0.6722, 'learning_rate': 4.171597789356434e-06, 'epoch': 0.71}
 71%|███████   | 1765/2496 [12:29:11<4:55:25, 24.25s/it] 71%|███████   | 1766/2496 [12:29:37<5:00:20, 24.69s/it]                                                        {'loss': 0.6324, 'learning_rate': 4.16105822750823e-06, 'epoch': 0.71}
 71%|███████   | 1766/2496 [12:29:37<5:00:20, 24.69s/it] 71%|███████   | 1767/2496 [12:30:04<5:10:34, 25.56s/it]                                                        {'loss': 0.648, 'learning_rate': 4.150528497713911e-06, 'epoch': 0.71}
 71%|███████   | 1767/2496 [12:30:04<5:10:34, 25.56s/it] 71%|███████   | 1768/2496 [12:30:30<5:10:19, 25.58s/it]                                                        {'loss': 0.6633, 'learning_rate': 4.140008617704235e-06, 'epoch': 0.71}
 71%|███████   | 1768/2496 [12:30:30<5:10:19, 25.58s/it] 71%|███████   | 1769/2496 [12:30:55<5:07:30, 25.38s/it]                                                        {'loss': 0.2482, 'learning_rate': 4.129498605193369e-06, 'epoch': 0.71}
 71%|███████   | 1769/2496 [12:30:55<5:07:30, 25.38s/it]this iter is wrong in something... skip...
 71%|███████   | 1770/2496 [12:31:20<5:05:35, 25.26s/it]                                                        {'loss': 0.7022, 'learning_rate': 4.118998477878879e-06, 'epoch': 0.71}
 71%|███████   | 1770/2496 [12:31:20<5:05:35, 25.26s/it] 71%|███████   | 1771/2496 [12:31:45<5:04:51, 25.23s/it]                                                        {'loss': 0.6725, 'learning_rate': 4.108508253441672e-06, 'epoch': 0.71}
 71%|███████   | 1771/2496 [12:31:45<5:04:51, 25.23s/it] 71%|███████   | 1772/2496 [12:32:11<5:07:20, 25.47s/it]                                                        {'loss': 0.6568, 'learning_rate': 4.0980279495459865e-06, 'epoch': 0.71}
 71%|███████   | 1772/2496 [12:32:11<5:07:20, 25.47s/it] 71%|███████   | 1773/2496 [12:32:37<5:09:27, 25.68s/it]                                                        {'loss': 0.6604, 'learning_rate': 4.087557583839358e-06, 'epoch': 0.71}
 71%|███████   | 1773/2496 [12:32:37<5:09:27, 25.68s/it] 71%|███████   | 1774/2496 [12:33:03<5:09:53, 25.75s/it]                                                        {'loss': 0.703, 'learning_rate': 4.077097173952581e-06, 'epoch': 0.71}
 71%|███████   | 1774/2496 [12:33:03<5:09:53, 25.75s/it] 71%|███████   | 1775/2496 [12:33:29<5:11:17, 25.90s/it]                                                        {'loss': 0.6693, 'learning_rate': 4.0666467374996865e-06, 'epoch': 0.71}
 71%|███████   | 1775/2496 [12:33:29<5:11:17, 25.90s/it] 71%|███████   | 1776/2496 [12:33:54<5:05:06, 25.43s/it]                                                        {'loss': 0.6898, 'learning_rate': 4.056206292077916e-06, 'epoch': 0.71}
 71%|███████   | 1776/2496 [12:33:54<5:05:06, 25.43s/it] 71%|███████   | 1777/2496 [12:34:19<5:04:59, 25.45s/it]                                                        {'loss': 0.6468, 'learning_rate': 4.045775855267687e-06, 'epoch': 0.71}
 71%|███████   | 1777/2496 [12:34:19<5:04:59, 25.45s/it] 71%|███████   | 1778/2496 [12:34:46<5:09:19, 25.85s/it]                                                        {'loss': 0.6603, 'learning_rate': 4.035355444632556e-06, 'epoch': 0.71}
 71%|███████   | 1778/2496 [12:34:46<5:09:19, 25.85s/it] 71%|███████▏  | 1779/2496 [12:35:13<5:11:15, 26.05s/it]                                                        {'loss': 0.6951, 'learning_rate': 4.02494507771921e-06, 'epoch': 0.71}
 71%|███████▏  | 1779/2496 [12:35:13<5:11:15, 26.05s/it] 71%|███████▏  | 1780/2496 [12:35:38<5:09:13, 25.91s/it]                                                        {'loss': 0.7009, 'learning_rate': 4.0145447720574115e-06, 'epoch': 0.71}
 71%|███████▏  | 1780/2496 [12:35:38<5:09:13, 25.91s/it] 71%|███████▏  | 1781/2496 [12:36:03<5:04:35, 25.56s/it]                                                        {'loss': 0.6792, 'learning_rate': 4.004154545159982e-06, 'epoch': 0.71}
 71%|███████▏  | 1781/2496 [12:36:03<5:04:35, 25.56s/it]this iter is wrong in something... skip...
 71%|███████▏  | 1782/2496 [12:36:28<5:01:32, 25.34s/it]                                                        {'loss': 0.6785, 'learning_rate': 3.993774414522779e-06, 'epoch': 0.71}
 71%|███████▏  | 1782/2496 [12:36:28<5:01:32, 25.34s/it] 71%|███████▏  | 1783/2496 [12:36:51<4:55:20, 24.85s/it]                                                        {'loss': 0.6871, 'learning_rate': 3.9834043976246584e-06, 'epoch': 0.71}
 71%|███████▏  | 1783/2496 [12:36:51<4:55:20, 24.85s/it] 71%|███████▏  | 1784/2496 [12:37:18<5:00:35, 25.33s/it]                                                        {'loss': 0.687, 'learning_rate': 3.973044511927441e-06, 'epoch': 0.71}
 71%|███████▏  | 1784/2496 [12:37:18<5:00:35, 25.33s/it] 72%|███████▏  | 1785/2496 [12:37:44<5:04:12, 25.67s/it]                                                        {'loss': 0.6999, 'learning_rate': 3.96269477487588e-06, 'epoch': 0.72}
 72%|███████▏  | 1785/2496 [12:37:44<5:04:12, 25.67s/it] 72%|███████▏  | 1786/2496 [12:38:09<5:00:50, 25.42s/it]                                                        {'loss': 0.6596, 'learning_rate': 3.952355203897663e-06, 'epoch': 0.72}
 72%|███████▏  | 1786/2496 [12:38:09<5:00:50, 25.42s/it] 72%|███████▏  | 1787/2496 [12:38:36<5:03:32, 25.69s/it]                                                        {'loss': 0.6519, 'learning_rate': 3.942025816403341e-06, 'epoch': 0.72}
 72%|███████▏  | 1787/2496 [12:38:36<5:03:32, 25.69s/it] 72%|███████▏  | 1788/2496 [12:39:01<5:03:17, 25.70s/it]                                                        {'loss': 0.649, 'learning_rate': 3.931706629786317e-06, 'epoch': 0.72}
 72%|███████▏  | 1788/2496 [12:39:01<5:03:17, 25.70s/it] 72%|███████▏  | 1789/2496 [12:39:24<4:53:40, 24.92s/it]                                                        {'loss': 0.6638, 'learning_rate': 3.921397661422828e-06, 'epoch': 0.72}
 72%|███████▏  | 1789/2496 [12:39:24<4:53:40, 24.92s/it] 72%|███████▏  | 1790/2496 [12:39:50<4:54:27, 25.02s/it]                                                        {'loss': 0.6722, 'learning_rate': 3.911098928671891e-06, 'epoch': 0.72}
 72%|███████▏  | 1790/2496 [12:39:50<4:54:27, 25.02s/it] 72%|███████▏  | 1791/2496 [12:40:14<4:53:22, 24.97s/it]                                                        {'loss': 0.6752, 'learning_rate': 3.900810448875301e-06, 'epoch': 0.72}
 72%|███████▏  | 1791/2496 [12:40:14<4:53:22, 24.97s/it] 72%|███████▏  | 1792/2496 [12:40:40<4:55:51, 25.21s/it]                                                        {'loss': 0.6476, 'learning_rate': 3.890532239357582e-06, 'epoch': 0.72}
 72%|███████▏  | 1792/2496 [12:40:40<4:55:51, 25.21s/it] 72%|███████▏  | 1793/2496 [12:41:05<4:54:51, 25.17s/it]                                                        {'loss': 0.2438, 'learning_rate': 3.8802643174259635e-06, 'epoch': 0.72}
 72%|███████▏  | 1793/2496 [12:41:05<4:54:51, 25.17s/it] 72%|███████▏  | 1794/2496 [12:41:30<4:53:36, 25.10s/it]                                                        {'loss': 0.6559, 'learning_rate': 3.870006700370348e-06, 'epoch': 0.72}
 72%|███████▏  | 1794/2496 [12:41:30<4:53:36, 25.10s/it]this iter is wrong in something... skip...
 72%|███████▏  | 1795/2496 [12:41:55<4:51:44, 24.97s/it]                                                        {'loss': 0.2495, 'learning_rate': 3.859759405463295e-06, 'epoch': 0.72}
 72%|███████▏  | 1795/2496 [12:41:55<4:51:44, 24.97s/it] 72%|███████▏  | 1796/2496 [12:42:20<4:52:20, 25.06s/it]                                                        {'loss': 0.677, 'learning_rate': 3.84952244995998e-06, 'epoch': 0.72}
 72%|███████▏  | 1796/2496 [12:42:20<4:52:20, 25.06s/it] 72%|███████▏  | 1797/2496 [12:42:43<4:43:38, 24.35s/it]                                                        {'loss': 0.6815, 'learning_rate': 3.8392958510981645e-06, 'epoch': 0.72}
 72%|███████▏  | 1797/2496 [12:42:43<4:43:38, 24.35s/it] 72%|███████▏  | 1798/2496 [12:43:12<4:58:23, 25.65s/it]                                                        {'loss': 0.6588, 'learning_rate': 3.82907962609817e-06, 'epoch': 0.72}
 72%|███████▏  | 1798/2496 [12:43:12<4:58:23, 25.65s/it] 72%|███████▏  | 1799/2496 [12:43:36<4:54:46, 25.38s/it]                                                        {'loss': 0.6822, 'learning_rate': 3.818873792162858e-06, 'epoch': 0.72}
 72%|███████▏  | 1799/2496 [12:43:36<4:54:46, 25.38s/it] 72%|███████▏  | 1800/2496 [12:44:01<4:51:27, 25.13s/it]                                                        {'loss': 0.6375, 'learning_rate': 3.8086783664775827e-06, 'epoch': 0.72}
 72%|███████▏  | 1800/2496 [12:44:01<4:51:27, 25.13s/it] 72%|███████▏  | 1801/2496 [12:44:26<4:52:06, 25.22s/it]                                                        {'loss': 0.6646, 'learning_rate': 3.7984933662101777e-06, 'epoch': 0.72}
 72%|███████▏  | 1801/2496 [12:44:26<4:52:06, 25.22s/it] 72%|███████▏  | 1802/2496 [12:44:52<4:51:59, 25.24s/it]                                                        {'loss': 0.6899, 'learning_rate': 3.7883188085109233e-06, 'epoch': 0.72}
 72%|███████▏  | 1802/2496 [12:44:52<4:51:59, 25.24s/it] 72%|███████▏  | 1803/2496 [12:45:20<5:01:16, 26.08s/it]                                                        {'loss': 0.6536, 'learning_rate': 3.778154710512513e-06, 'epoch': 0.72}
 72%|███████▏  | 1803/2496 [12:45:20<5:01:16, 26.08s/it] 72%|███████▏  | 1804/2496 [12:45:51<5:18:11, 27.59s/it]                                                        {'loss': 0.6555, 'learning_rate': 3.7680010893300165e-06, 'epoch': 0.72}
 72%|███████▏  | 1804/2496 [12:45:51<5:18:11, 27.59s/it] 72%|███████▏  | 1805/2496 [12:46:16<5:10:59, 27.00s/it]                                                        {'loss': 0.6849, 'learning_rate': 3.75785796206089e-06, 'epoch': 0.72}
 72%|███████▏  | 1805/2496 [12:46:16<5:10:59, 27.00s/it] 72%|███████▏  | 1806/2496 [12:46:39<4:56:55, 25.82s/it]                                                        {'loss': 0.7039, 'learning_rate': 3.747725345784893e-06, 'epoch': 0.72}
 72%|███████▏  | 1806/2496 [12:46:39<4:56:55, 25.82s/it] 72%|███████▏  | 1807/2496 [12:47:04<4:51:04, 25.35s/it]                                                        {'loss': 0.6597, 'learning_rate': 3.737603257564092e-06, 'epoch': 0.72}
 72%|███████▏  | 1807/2496 [12:47:04<4:51:04, 25.35s/it] 72%|███████▏  | 1808/2496 [12:47:33<5:05:02, 26.60s/it]                                                        {'loss': 0.6981, 'learning_rate': 3.7274917144428357e-06, 'epoch': 0.72}
 72%|███████▏  | 1808/2496 [12:47:33<5:05:02, 26.60s/it] 72%|███████▏  | 1809/2496 [12:47:58<5:00:07, 26.21s/it]                                                        {'loss': 0.656, 'learning_rate': 3.7173907334477e-06, 'epoch': 0.72}
 72%|███████▏  | 1809/2496 [12:47:58<5:00:07, 26.21s/it] 73%|███████▎  | 1810/2496 [12:48:25<5:01:18, 26.35s/it]                                                        {'loss': 0.6903, 'learning_rate': 3.7073003315874945e-06, 'epoch': 0.73}
 73%|███████▎  | 1810/2496 [12:48:25<5:01:18, 26.35s/it] 73%|███████▎  | 1811/2496 [12:48:51<4:58:54, 26.18s/it]                                                        {'loss': 0.6615, 'learning_rate': 3.6972205258531944e-06, 'epoch': 0.73}
 73%|███████▎  | 1811/2496 [12:48:51<4:58:54, 26.18s/it] 73%|███████▎  | 1812/2496 [12:49:19<5:04:18, 26.69s/it]                                                        {'loss': 0.6779, 'learning_rate': 3.687151333217952e-06, 'epoch': 0.73}
 73%|███████▎  | 1812/2496 [12:49:19<5:04:18, 26.69s/it]this iter is wrong in something... skip...
 73%|███████▎  | 1813/2496 [12:49:47<5:08:45, 27.12s/it]                                                        {'loss': 0.6235, 'learning_rate': 3.6770927706370308e-06, 'epoch': 0.73}
 73%|███████▎  | 1813/2496 [12:49:47<5:08:45, 27.12s/it] 73%|███████▎  | 1814/2496 [12:50:14<5:08:50, 27.17s/it]                                                        {'loss': 0.677, 'learning_rate': 3.6670448550478078e-06, 'epoch': 0.73}
 73%|███████▎  | 1814/2496 [12:50:14<5:08:50, 27.17s/it] 73%|███████▎  | 1815/2496 [12:50:42<5:09:26, 27.26s/it]                                                        {'loss': 0.641, 'learning_rate': 3.657007603369728e-06, 'epoch': 0.73}
 73%|███████▎  | 1815/2496 [12:50:42<5:09:26, 27.26s/it] 73%|███████▎  | 1816/2496 [12:51:12<5:17:59, 28.06s/it]                                                        {'loss': 0.6427, 'learning_rate': 3.6469810325042766e-06, 'epoch': 0.73}
 73%|███████▎  | 1816/2496 [12:51:12<5:17:59, 28.06s/it] 73%|███████▎  | 1817/2496 [12:51:41<5:20:22, 28.31s/it]                                                        {'loss': 0.6573, 'learning_rate': 3.636965159334952e-06, 'epoch': 0.73}
 73%|███████▎  | 1817/2496 [12:51:41<5:20:22, 28.31s/it] 73%|███████▎  | 1818/2496 [12:52:07<5:13:06, 27.71s/it]                                                        {'loss': 0.6676, 'learning_rate': 3.626960000727249e-06, 'epoch': 0.73}
 73%|███████▎  | 1818/2496 [12:52:07<5:13:06, 27.71s/it] 73%|███████▎  | 1819/2496 [12:52:34<5:09:23, 27.42s/it]                                                        {'loss': 0.7065, 'learning_rate': 3.616965573528608e-06, 'epoch': 0.73}
 73%|███████▎  | 1819/2496 [12:52:34<5:09:23, 27.42s/it] 73%|███████▎  | 1820/2496 [12:53:01<5:07:27, 27.29s/it]                                                        {'loss': 0.6501, 'learning_rate': 3.6069818945684075e-06, 'epoch': 0.73}
 73%|███████▎  | 1820/2496 [12:53:01<5:07:27, 27.29s/it] 73%|███████▎  | 1821/2496 [12:53:24<4:54:05, 26.14s/it]                                                        {'loss': 0.6964, 'learning_rate': 3.597008980657929e-06, 'epoch': 0.73}
 73%|███████▎  | 1821/2496 [12:53:24<4:54:05, 26.14s/it] 73%|███████▎  | 1822/2496 [12:53:49<4:50:09, 25.83s/it]                                                        {'loss': 0.2338, 'learning_rate': 3.5870468485903187e-06, 'epoch': 0.73}
 73%|███████▎  | 1822/2496 [12:53:49<4:50:09, 25.83s/it] 73%|███████▎  | 1823/2496 [12:54:13<4:44:35, 25.37s/it]                                                        {'loss': 0.704, 'learning_rate': 3.5770955151405685e-06, 'epoch': 0.73}
 73%|███████▎  | 1823/2496 [12:54:13<4:44:35, 25.37s/it] 73%|███████▎  | 1824/2496 [12:54:38<4:43:04, 25.27s/it]                                                        {'loss': 0.6716, 'learning_rate': 3.567154997065494e-06, 'epoch': 0.73}
 73%|███████▎  | 1824/2496 [12:54:38<4:43:04, 25.27s/it] 73%|███████▎  | 1825/2496 [12:55:09<5:00:37, 26.88s/it]                                                        {'loss': 0.6546, 'learning_rate': 3.5572253111036968e-06, 'epoch': 0.73}
 73%|███████▎  | 1825/2496 [12:55:09<5:00:37, 26.88s/it]this iter is wrong in something... skip...
 73%|███████▎  | 1826/2496 [12:55:35<4:56:41, 26.57s/it]                                                        {'loss': 0.665, 'learning_rate': 3.547306473975536e-06, 'epoch': 0.73}
 73%|███████▎  | 1826/2496 [12:55:35<4:56:41, 26.57s/it]this iter is wrong in something... skip...
 73%|███████▎  | 1827/2496 [12:56:02<4:56:48, 26.62s/it]                                                        {'loss': 0.6186, 'learning_rate': 3.537398502383097e-06, 'epoch': 0.73}
 73%|███████▎  | 1827/2496 [12:56:02<4:56:48, 26.62s/it] 73%|███████▎  | 1828/2496 [12:56:25<4:45:18, 25.63s/it]                                                        {'loss': 0.6987, 'learning_rate': 3.5275014130101805e-06, 'epoch': 0.73}
 73%|███████▎  | 1828/2496 [12:56:25<4:45:18, 25.63s/it] 73%|███████▎  | 1829/2496 [12:56:51<4:45:59, 25.73s/it]                                                        {'loss': 0.6571, 'learning_rate': 3.5176152225222593e-06, 'epoch': 0.73}
 73%|███████▎  | 1829/2496 [12:56:51<4:45:59, 25.73s/it] 73%|███████▎  | 1830/2496 [12:57:16<4:42:44, 25.47s/it]                                                        {'loss': 0.6438, 'learning_rate': 3.5077399475664474e-06, 'epoch': 0.73}
 73%|███████▎  | 1830/2496 [12:57:16<4:42:44, 25.47s/it] 73%|███████▎  | 1831/2496 [12:57:42<4:43:50, 25.61s/it]                                                        {'loss': 0.6705, 'learning_rate': 3.4978756047714903e-06, 'epoch': 0.73}
 73%|███████▎  | 1831/2496 [12:57:42<4:43:50, 25.61s/it] 73%|███████▎  | 1832/2496 [12:58:07<4:43:35, 25.63s/it]                                                        {'loss': 0.6807, 'learning_rate': 3.4880222107477126e-06, 'epoch': 0.73}
 73%|███████▎  | 1832/2496 [12:58:07<4:43:35, 25.63s/it] 73%|███████▎  | 1833/2496 [12:58:36<4:51:32, 26.38s/it]                                                        {'loss': 0.6472, 'learning_rate': 3.4781797820870036e-06, 'epoch': 0.73}
 73%|███████▎  | 1833/2496 [12:58:36<4:51:32, 26.38s/it] 73%|███████▎  | 1834/2496 [12:58:59<4:40:10, 25.39s/it]                                                        {'loss': 0.6864, 'learning_rate': 3.4683483353628033e-06, 'epoch': 0.73}
 73%|███████▎  | 1834/2496 [12:58:59<4:40:10, 25.39s/it] 74%|███████▎  | 1835/2496 [12:59:26<4:46:19, 25.99s/it]                                                        {'loss': 0.7014, 'learning_rate': 3.458527887130044e-06, 'epoch': 0.74}
 74%|███████▎  | 1835/2496 [12:59:26<4:46:19, 25.99s/it] 74%|███████▎  | 1836/2496 [12:59:54<4:51:29, 26.50s/it]                                                        {'loss': 0.6365, 'learning_rate': 3.4487184539251396e-06, 'epoch': 0.74}
 74%|███████▎  | 1836/2496 [12:59:54<4:51:29, 26.50s/it] 74%|███████▎  | 1837/2496 [13:00:20<4:50:18, 26.43s/it]                                                        {'loss': 0.6467, 'learning_rate': 3.438920052265965e-06, 'epoch': 0.74}
 74%|███████▎  | 1837/2496 [13:00:20<4:50:18, 26.43s/it] 74%|███████▎  | 1838/2496 [13:00:44<4:41:54, 25.71s/it]                                                        {'loss': 0.6805, 'learning_rate': 3.429132698651806e-06, 'epoch': 0.74}
 74%|███████▎  | 1838/2496 [13:00:44<4:41:54, 25.71s/it] 74%|███████▎  | 1839/2496 [13:01:11<4:46:15, 26.14s/it]                                                        {'loss': 0.6777, 'learning_rate': 3.419356409563361e-06, 'epoch': 0.74}
 74%|███████▎  | 1839/2496 [13:01:11<4:46:15, 26.14s/it] 74%|███████▎  | 1840/2496 [13:01:37<4:43:49, 25.96s/it]                                                        {'loss': 0.6518, 'learning_rate': 3.409591201462682e-06, 'epoch': 0.74}
 74%|███████▎  | 1840/2496 [13:01:37<4:43:49, 25.96s/it] 74%|███████▍  | 1841/2496 [13:02:01<4:37:41, 25.44s/it]                                                        {'loss': 0.6756, 'learning_rate': 3.399837090793173e-06, 'epoch': 0.74}
 74%|███████▍  | 1841/2496 [13:02:01<4:37:41, 25.44s/it] 74%|███████▍  | 1842/2496 [13:02:27<4:37:50, 25.49s/it]                                                        {'loss': 0.7003, 'learning_rate': 3.390094093979541e-06, 'epoch': 0.74}
 74%|███████▍  | 1842/2496 [13:02:27<4:37:50, 25.49s/it] 74%|███████▍  | 1843/2496 [13:02:53<4:41:40, 25.88s/it]                                                        {'loss': 0.6642, 'learning_rate': 3.380362227427789e-06, 'epoch': 0.74}
 74%|███████▍  | 1843/2496 [13:02:53<4:41:40, 25.88s/it] 74%|███████▍  | 1844/2496 [13:03:18<4:37:12, 25.51s/it]                                                        {'loss': 0.6686, 'learning_rate': 3.3706415075251764e-06, 'epoch': 0.74}
 74%|███████▍  | 1844/2496 [13:03:18<4:37:12, 25.51s/it] 74%|███████▍  | 1845/2496 [13:03:45<4:42:00, 25.99s/it]                                                        {'loss': 0.6473, 'learning_rate': 3.360931950640185e-06, 'epoch': 0.74}
 74%|███████▍  | 1845/2496 [13:03:45<4:42:00, 25.99s/it] 74%|███████▍  | 1846/2496 [13:04:13<4:48:17, 26.61s/it]                                                        {'loss': 0.6689, 'learning_rate': 3.3512335731225033e-06, 'epoch': 0.74}
 74%|███████▍  | 1846/2496 [13:04:13<4:48:17, 26.61s/it] 74%|███████▍  | 1847/2496 [13:04:37<4:39:13, 25.81s/it]                                                        {'loss': 0.6738, 'learning_rate': 3.341546391302999e-06, 'epoch': 0.74}
 74%|███████▍  | 1847/2496 [13:04:37<4:39:13, 25.81s/it] 74%|███████▍  | 1848/2496 [13:05:00<4:29:01, 24.91s/it]                                                        {'loss': 0.6874, 'learning_rate': 3.331870421493688e-06, 'epoch': 0.74}
 74%|███████▍  | 1848/2496 [13:05:00<4:29:01, 24.91s/it] 74%|███████▍  | 1849/2496 [13:05:23<4:23:24, 24.43s/it]                                                        {'loss': 0.6613, 'learning_rate': 3.322205679987697e-06, 'epoch': 0.74}
 74%|███████▍  | 1849/2496 [13:05:23<4:23:24, 24.43s/it] 74%|███████▍  | 1850/2496 [13:05:50<4:31:08, 25.18s/it]                                                        {'loss': 0.6532, 'learning_rate': 3.312552183059259e-06, 'epoch': 0.74}
 74%|███████▍  | 1850/2496 [13:05:50<4:31:08, 25.18s/it] 74%|███████▍  | 1851/2496 [13:06:14<4:27:15, 24.86s/it]                                                        {'loss': 0.6668, 'learning_rate': 3.3029099469636627e-06, 'epoch': 0.74}
 74%|███████▍  | 1851/2496 [13:06:14<4:27:15, 24.86s/it] 74%|███████▍  | 1852/2496 [13:06:40<4:28:39, 25.03s/it]                                                        {'loss': 0.6639, 'learning_rate': 3.293278987937234e-06, 'epoch': 0.74}
 74%|███████▍  | 1852/2496 [13:06:40<4:28:39, 25.03s/it] 74%|███████▍  | 1853/2496 [13:07:05<4:30:45, 25.26s/it]                                                        {'loss': 0.6595, 'learning_rate': 3.283659322197318e-06, 'epoch': 0.74}
 74%|███████▍  | 1853/2496 [13:07:05<4:30:45, 25.26s/it] 74%|███████▍  | 1854/2496 [13:07:35<4:42:24, 26.39s/it]                                                        {'loss': 0.6488, 'learning_rate': 3.2740509659422403e-06, 'epoch': 0.74}
 74%|███████▍  | 1854/2496 [13:07:35<4:42:24, 26.39s/it] 74%|███████▍  | 1855/2496 [13:07:58<4:32:16, 25.49s/it]                                                        {'loss': 0.6941, 'learning_rate': 3.2644539353512804e-06, 'epoch': 0.74}
 74%|███████▍  | 1855/2496 [13:07:58<4:32:16, 25.49s/it] 74%|███████▍  | 1856/2496 [13:08:24<4:32:49, 25.58s/it]                                                        {'loss': 0.6282, 'learning_rate': 3.254868246584644e-06, 'epoch': 0.74}
 74%|███████▍  | 1856/2496 [13:08:24<4:32:49, 25.58s/it] 74%|███████▍  | 1857/2496 [13:08:49<4:32:37, 25.60s/it]                                                        {'loss': 0.6801, 'learning_rate': 3.245293915783444e-06, 'epoch': 0.74}
 74%|███████▍  | 1857/2496 [13:08:49<4:32:37, 25.60s/it] 74%|███████▍  | 1858/2496 [13:09:14<4:29:48, 25.37s/it]                                                        {'loss': 0.6657, 'learning_rate': 3.2357309590696697e-06, 'epoch': 0.74}
 74%|███████▍  | 1858/2496 [13:09:14<4:29:48, 25.37s/it] 74%|███████▍  | 1859/2496 [13:09:38<4:25:18, 24.99s/it]                                                        {'loss': 0.6712, 'learning_rate': 3.2261793925461494e-06, 'epoch': 0.74}
 74%|███████▍  | 1859/2496 [13:09:38<4:25:18, 24.99s/it] 75%|███████▍  | 1860/2496 [13:10:03<4:25:01, 25.00s/it]                                                        {'loss': 0.6456, 'learning_rate': 3.2166392322965423e-06, 'epoch': 0.75}
 75%|███████▍  | 1860/2496 [13:10:03<4:25:01, 25.00s/it] 75%|███████▍  | 1861/2496 [13:10:29<4:28:04, 25.33s/it]                                                        {'loss': 0.654, 'learning_rate': 3.2071104943852915e-06, 'epoch': 0.75}
 75%|███████▍  | 1861/2496 [13:10:29<4:28:04, 25.33s/it] 75%|███████▍  | 1862/2496 [13:10:54<4:25:49, 25.16s/it]                                                        {'loss': 0.6724, 'learning_rate': 3.1975931948576045e-06, 'epoch': 0.75}
 75%|███████▍  | 1862/2496 [13:10:54<4:25:49, 25.16s/it] 75%|███████▍  | 1863/2496 [13:11:20<4:26:40, 25.28s/it]                                                        {'loss': 0.6776, 'learning_rate': 3.188087349739446e-06, 'epoch': 0.75}
 75%|███████▍  | 1863/2496 [13:11:20<4:26:40, 25.28s/it]this iter is wrong in something... skip...
 75%|███████▍  | 1864/2496 [13:11:44<4:24:29, 25.11s/it]                                                        {'loss': 0.6495, 'learning_rate': 3.1785929750374744e-06, 'epoch': 0.75}
 75%|███████▍  | 1864/2496 [13:11:44<4:24:29, 25.11s/it]this iter is wrong in something... skip...
 75%|███████▍  | 1865/2496 [13:12:10<4:25:17, 25.23s/it]                                                        {'loss': 0.6627, 'learning_rate': 3.1691100867390344e-06, 'epoch': 0.75}
 75%|███████▍  | 1865/2496 [13:12:10<4:25:17, 25.23s/it] 75%|███████▍  | 1866/2496 [13:12:33<4:17:14, 24.50s/it]                                                        {'loss': 0.7101, 'learning_rate': 3.1596387008121386e-06, 'epoch': 0.75}
 75%|███████▍  | 1866/2496 [13:12:33<4:17:14, 24.50s/it] 75%|███████▍  | 1867/2496 [13:13:00<4:25:42, 25.35s/it]                                                        {'loss': 0.7058, 'learning_rate': 3.1501788332054306e-06, 'epoch': 0.75}
 75%|███████▍  | 1867/2496 [13:13:00<4:25:42, 25.35s/it] 75%|███████▍  | 1868/2496 [13:13:28<4:33:36, 26.14s/it]                                                        {'loss': 0.6568, 'learning_rate': 3.140730499848149e-06, 'epoch': 0.75}
 75%|███████▍  | 1868/2496 [13:13:28<4:33:36, 26.14s/it] 75%|███████▍  | 1869/2496 [13:13:54<4:31:40, 26.00s/it]                                                        {'loss': 0.6873, 'learning_rate': 3.1312937166501135e-06, 'epoch': 0.75}
 75%|███████▍  | 1869/2496 [13:13:54<4:31:40, 26.00s/it] 75%|███████▍  | 1870/2496 [13:14:19<4:29:23, 25.82s/it]                                                        {'loss': 0.6583, 'learning_rate': 3.121868499501702e-06, 'epoch': 0.75}
 75%|███████▍  | 1870/2496 [13:14:19<4:29:23, 25.82s/it] 75%|███████▍  | 1871/2496 [13:14:44<4:24:58, 25.44s/it]                                                        {'loss': 0.6739, 'learning_rate': 3.1124548642738072e-06, 'epoch': 0.75}
 75%|███████▍  | 1871/2496 [13:14:44<4:24:58, 25.44s/it] 75%|███████▌  | 1872/2496 [13:15:08<4:22:39, 25.26s/it]                                                        {'loss': 0.2464, 'learning_rate': 3.103052826817826e-06, 'epoch': 0.75}
 75%|███████▌  | 1872/2496 [13:15:08<4:22:39, 25.26s/it] 75%|███████▌  | 1873/2496 [13:15:34<4:21:44, 25.21s/it]                                                        {'loss': 0.6881, 'learning_rate': 3.0936624029656247e-06, 'epoch': 0.75}
 75%|███████▌  | 1873/2496 [13:15:34<4:21:44, 25.21s/it] 75%|███████▌  | 1874/2496 [13:15:57<4:15:30, 24.65s/it]                                                        {'loss': 0.6774, 'learning_rate': 3.0842836085295126e-06, 'epoch': 0.75}
 75%|███████▌  | 1874/2496 [13:15:57<4:15:30, 24.65s/it] 75%|███████▌  | 1875/2496 [13:16:29<4:37:33, 26.82s/it]                                                        {'loss': 0.6878, 'learning_rate': 3.074916459302211e-06, 'epoch': 0.75}
 75%|███████▌  | 1875/2496 [13:16:29<4:37:33, 26.82s/it] 75%|███████▌  | 1876/2496 [13:16:55<4:35:37, 26.67s/it]                                                        {'loss': 0.6857, 'learning_rate': 3.06556097105684e-06, 'epoch': 0.75}
 75%|███████▌  | 1876/2496 [13:16:55<4:35:37, 26.67s/it] 75%|███████▌  | 1877/2496 [13:17:20<4:29:30, 26.12s/it]                                                        {'loss': 0.2365, 'learning_rate': 3.0562171595468882e-06, 'epoch': 0.75}
 75%|███████▌  | 1877/2496 [13:17:20<4:29:30, 26.12s/it] 75%|███████▌  | 1878/2496 [13:17:46<4:27:50, 26.00s/it]                                                        {'loss': 0.6504, 'learning_rate': 3.046885040506167e-06, 'epoch': 0.75}
 75%|███████▌  | 1878/2496 [13:17:46<4:27:50, 26.00s/it] 75%|███████▌  | 1879/2496 [13:18:11<4:25:31, 25.82s/it]                                                        {'loss': 0.6598, 'learning_rate': 3.0375646296488127e-06, 'epoch': 0.75}
 75%|███████▌  | 1879/2496 [13:18:11<4:25:31, 25.82s/it] 75%|███████▌  | 1880/2496 [13:18:38<4:28:30, 26.15s/it]                                                        {'loss': 0.6588, 'learning_rate': 3.0282559426692415e-06, 'epoch': 0.75}
 75%|███████▌  | 1880/2496 [13:18:38<4:28:30, 26.15s/it] 75%|███████▌  | 1881/2496 [13:19:03<4:23:56, 25.75s/it]                                                        {'loss': 0.2308, 'learning_rate': 3.0189589952421217e-06, 'epoch': 0.75}
 75%|███████▌  | 1881/2496 [13:19:03<4:23:56, 25.75s/it] 75%|███████▌  | 1882/2496 [13:19:28<4:21:44, 25.58s/it]                                                        {'loss': 0.667, 'learning_rate': 3.0096738030223647e-06, 'epoch': 0.75}
 75%|███████▌  | 1882/2496 [13:19:28<4:21:44, 25.58s/it] 75%|███████▌  | 1883/2496 [13:19:53<4:20:47, 25.53s/it]                                                        {'loss': 0.6631, 'learning_rate': 3.0004003816450864e-06, 'epoch': 0.75}
 75%|███████▌  | 1883/2496 [13:19:53<4:20:47, 25.53s/it] 75%|███████▌  | 1884/2496 [13:20:18<4:17:28, 25.24s/it]                                                        {'loss': 0.6676, 'learning_rate': 2.9911387467255737e-06, 'epoch': 0.75}
 75%|███████▌  | 1884/2496 [13:20:18<4:17:28, 25.24s/it] 76%|███████▌  | 1885/2496 [13:20:44<4:20:26, 25.58s/it]                                                        {'loss': 0.6932, 'learning_rate': 2.9818889138592668e-06, 'epoch': 0.76}
 76%|███████▌  | 1885/2496 [13:20:44<4:20:26, 25.58s/it] 76%|███████▌  | 1886/2496 [13:21:10<4:18:54, 25.47s/it]                                                        {'loss': 0.6341, 'learning_rate': 2.972650898621747e-06, 'epoch': 0.76}
 76%|███████▌  | 1886/2496 [13:21:10<4:18:54, 25.47s/it] 76%|███████▌  | 1887/2496 [13:21:35<4:18:40, 25.49s/it]                                                        {'loss': 0.6438, 'learning_rate': 2.9634247165686837e-06, 'epoch': 0.76}
 76%|███████▌  | 1887/2496 [13:21:35<4:18:40, 25.49s/it] 76%|███████▌  | 1888/2496 [13:22:00<4:16:48, 25.34s/it]                                                        {'loss': 0.6714, 'learning_rate': 2.9542103832358183e-06, 'epoch': 0.76}
 76%|███████▌  | 1888/2496 [13:22:00<4:16:48, 25.34s/it] 76%|███████▌  | 1889/2496 [13:22:27<4:21:54, 25.89s/it]                                                        {'loss': 0.6919, 'learning_rate': 2.945007914138951e-06, 'epoch': 0.76}
 76%|███████▌  | 1889/2496 [13:22:27<4:21:54, 25.89s/it] 76%|███████▌  | 1890/2496 [13:22:53<4:19:45, 25.72s/it]                                                        {'loss': 0.6839, 'learning_rate': 2.935817324773893e-06, 'epoch': 0.76}
 76%|███████▌  | 1890/2496 [13:22:53<4:19:45, 25.72s/it] 76%|███████▌  | 1891/2496 [13:23:17<4:14:42, 25.26s/it]                                                        {'loss': 0.65, 'learning_rate': 2.926638630616462e-06, 'epoch': 0.76}
 76%|███████▌  | 1891/2496 [13:23:17<4:14:42, 25.26s/it] 76%|███████▌  | 1892/2496 [13:23:41<4:10:47, 24.91s/it]                                                        {'loss': 0.6571, 'learning_rate': 2.9174718471224416e-06, 'epoch': 0.76}
 76%|███████▌  | 1892/2496 [13:23:41<4:10:47, 24.91s/it] 76%|███████▌  | 1893/2496 [13:24:06<4:09:51, 24.86s/it]                                                        {'loss': 0.6751, 'learning_rate': 2.9083169897275554e-06, 'epoch': 0.76}
 76%|███████▌  | 1893/2496 [13:24:06<4:09:51, 24.86s/it] 76%|███████▌  | 1894/2496 [13:24:31<4:11:22, 25.05s/it]                                                        {'loss': 0.6733, 'learning_rate': 2.8991740738474463e-06, 'epoch': 0.76}
 76%|███████▌  | 1894/2496 [13:24:31<4:11:22, 25.05s/it] 76%|███████▌  | 1895/2496 [13:24:55<4:07:08, 24.67s/it]                                                        {'loss': 0.6478, 'learning_rate': 2.890043114877653e-06, 'epoch': 0.76}
 76%|███████▌  | 1895/2496 [13:24:55<4:07:08, 24.67s/it] 76%|███████▌  | 1896/2496 [13:25:20<4:08:39, 24.87s/it]                                                        {'loss': 0.6942, 'learning_rate': 2.880924128193583e-06, 'epoch': 0.76}
 76%|███████▌  | 1896/2496 [13:25:20<4:08:39, 24.87s/it] 76%|███████▌  | 1897/2496 [13:25:46<4:12:15, 25.27s/it]                                                        {'loss': 0.6732, 'learning_rate': 2.871817129150473e-06, 'epoch': 0.76}
 76%|███████▌  | 1897/2496 [13:25:46<4:12:15, 25.27s/it] 76%|███████▌  | 1898/2496 [13:26:12<4:13:26, 25.43s/it]                                                        {'loss': 0.6766, 'learning_rate': 2.862722133083379e-06, 'epoch': 0.76}
 76%|███████▌  | 1898/2496 [13:26:12<4:13:26, 25.43s/it] 76%|███████▌  | 1899/2496 [13:26:37<4:09:40, 25.09s/it]                                                        {'loss': 0.677, 'learning_rate': 2.8536391553071506e-06, 'epoch': 0.76}
 76%|███████▌  | 1899/2496 [13:26:37<4:09:40, 25.09s/it] 76%|███████▌  | 1900/2496 [13:27:03<4:12:06, 25.38s/it]                                                        {'loss': 0.5997, 'learning_rate': 2.844568211116393e-06, 'epoch': 0.76}
 76%|███████▌  | 1900/2496 [13:27:03<4:12:06, 25.38s/it] 76%|███████▌  | 1901/2496 [13:27:31<4:21:41, 26.39s/it]                                                        {'loss': 0.6636, 'learning_rate': 2.835509315785453e-06, 'epoch': 0.76}
 76%|███████▌  | 1901/2496 [13:27:31<4:21:41, 26.39s/it] 76%|███████▌  | 1902/2496 [13:27:58<4:20:50, 26.35s/it]                                                        {'loss': 0.6798, 'learning_rate': 2.82646248456839e-06, 'epoch': 0.76}
 76%|███████▌  | 1902/2496 [13:27:58<4:20:50, 26.35s/it] 76%|███████▌  | 1903/2496 [13:28:22<4:14:14, 25.72s/it]                                                        {'loss': 0.6906, 'learning_rate': 2.817427732698942e-06, 'epoch': 0.76}
 76%|███████▌  | 1903/2496 [13:28:22<4:14:14, 25.72s/it] 76%|███████▋  | 1904/2496 [13:28:47<4:10:58, 25.44s/it]                                                        {'loss': 0.6847, 'learning_rate': 2.808405075390506e-06, 'epoch': 0.76}
 76%|███████▋  | 1904/2496 [13:28:47<4:10:58, 25.44s/it] 76%|███████▋  | 1905/2496 [13:29:10<4:04:28, 24.82s/it]                                                        {'loss': 0.6793, 'learning_rate': 2.799394527836129e-06, 'epoch': 0.76}
 76%|███████▋  | 1905/2496 [13:29:10<4:04:28, 24.82s/it] 76%|███████▋  | 1906/2496 [13:29:35<4:04:32, 24.87s/it]                                                        {'loss': 0.6742, 'learning_rate': 2.7903961052084503e-06, 'epoch': 0.76}
 76%|███████▋  | 1906/2496 [13:29:35<4:04:32, 24.87s/it] 76%|███████▋  | 1907/2496 [13:29:58<3:57:49, 24.23s/it]                                                        {'loss': 0.6966, 'learning_rate': 2.781409822659695e-06, 'epoch': 0.76}
 76%|███████▋  | 1907/2496 [13:29:58<3:57:49, 24.23s/it] 76%|███████▋  | 1908/2496 [13:30:23<3:59:35, 24.45s/it]                                                        {'loss': 0.6877, 'learning_rate': 2.7724356953216547e-06, 'epoch': 0.76}
 76%|███████▋  | 1908/2496 [13:30:23<3:59:35, 24.45s/it] 76%|███████▋  | 1909/2496 [13:30:48<4:00:49, 24.62s/it]                                                        {'loss': 0.2474, 'learning_rate': 2.763473738305641e-06, 'epoch': 0.76}
 76%|███████▋  | 1909/2496 [13:30:48<4:00:49, 24.62s/it] 77%|███████▋  | 1910/2496 [13:31:11<3:57:02, 24.27s/it]                                                        {'loss': 0.6414, 'learning_rate': 2.7545239667024825e-06, 'epoch': 0.77}
 77%|███████▋  | 1910/2496 [13:31:11<3:57:02, 24.27s/it] 77%|███████▋  | 1911/2496 [13:31:38<4:03:52, 25.01s/it]                                                        {'loss': 0.6461, 'learning_rate': 2.745586395582481e-06, 'epoch': 0.77}
 77%|███████▋  | 1911/2496 [13:31:38<4:03:52, 25.01s/it] 77%|███████▋  | 1912/2496 [13:32:04<4:05:26, 25.22s/it]                                                        {'loss': 0.6767, 'learning_rate': 2.736661039995403e-06, 'epoch': 0.77}
 77%|███████▋  | 1912/2496 [13:32:04<4:05:26, 25.22s/it] 77%|███████▋  | 1913/2496 [13:32:30<4:07:52, 25.51s/it]                                                        {'loss': 0.6594, 'learning_rate': 2.7277479149704377e-06, 'epoch': 0.77}
 77%|███████▋  | 1913/2496 [13:32:30<4:07:52, 25.51s/it] 77%|███████▋  | 1914/2496 [13:32:57<4:11:24, 25.92s/it]                                                        {'loss': 0.6634, 'learning_rate': 2.7188470355161757e-06, 'epoch': 0.77}
 77%|███████▋  | 1914/2496 [13:32:57<4:11:24, 25.92s/it] 77%|███████▋  | 1915/2496 [13:33:23<4:11:41, 25.99s/it]                                                        {'loss': 0.6548, 'learning_rate': 2.7099584166206073e-06, 'epoch': 0.77}
 77%|███████▋  | 1915/2496 [13:33:23<4:11:41, 25.99s/it] 77%|███████▋  | 1916/2496 [13:33:48<4:07:33, 25.61s/it]                                                        {'loss': 0.6896, 'learning_rate': 2.7010820732510567e-06, 'epoch': 0.77}
 77%|███████▋  | 1916/2496 [13:33:48<4:07:33, 25.61s/it] 77%|███████▋  | 1917/2496 [13:34:13<4:05:34, 25.45s/it]                                                        {'loss': 0.2486, 'learning_rate': 2.6922180203541847e-06, 'epoch': 0.77}
 77%|███████▋  | 1917/2496 [13:34:13<4:05:34, 25.45s/it] 77%|███████▋  | 1918/2496 [13:34:40<4:10:17, 25.98s/it]                                                        {'loss': 0.6568, 'learning_rate': 2.6833662728559616e-06, 'epoch': 0.77}
 77%|███████▋  | 1918/2496 [13:34:40<4:10:17, 25.98s/it] 77%|███████▋  | 1919/2496 [13:35:07<4:13:29, 26.36s/it]                                                        {'loss': 0.6431, 'learning_rate': 2.674526845661628e-06, 'epoch': 0.77}
 77%|███████▋  | 1919/2496 [13:35:07<4:13:29, 26.36s/it] 77%|███████▋  | 1920/2496 [13:35:31<4:06:32, 25.68s/it]                                                        {'loss': 0.7016, 'learning_rate': 2.665699753655684e-06, 'epoch': 0.77}
 77%|███████▋  | 1920/2496 [13:35:31<4:06:32, 25.68s/it] 77%|███████▋  | 1921/2496 [13:35:56<4:04:23, 25.50s/it]                                                        {'loss': 0.6356, 'learning_rate': 2.656885011701863e-06, 'epoch': 0.77}
 77%|███████▋  | 1921/2496 [13:35:56<4:04:23, 25.50s/it] 77%|███████▋  | 1922/2496 [13:36:23<4:08:38, 25.99s/it]                                                        {'loss': 0.6623, 'learning_rate': 2.6480826346430933e-06, 'epoch': 0.77}
 77%|███████▋  | 1922/2496 [13:36:23<4:08:38, 25.99s/it] 77%|███████▋  | 1923/2496 [13:36:48<4:03:36, 25.51s/it]                                                        {'loss': 0.6615, 'learning_rate': 2.6392926373014825e-06, 'epoch': 0.77}
 77%|███████▋  | 1923/2496 [13:36:48<4:03:36, 25.51s/it]this iter is wrong in something... skip...
 77%|███████▋  | 1924/2496 [13:37:15<4:07:03, 25.91s/it]                                                        {'loss': 0.6687, 'learning_rate': 2.6305150344783015e-06, 'epoch': 0.77}
 77%|███████▋  | 1924/2496 [13:37:15<4:07:03, 25.91s/it] 77%|███████▋  | 1925/2496 [13:37:40<4:05:25, 25.79s/it]                                                        {'loss': 0.6166, 'learning_rate': 2.6217498409539465e-06, 'epoch': 0.77}
 77%|███████▋  | 1925/2496 [13:37:40<4:05:25, 25.79s/it] 77%|███████▋  | 1926/2496 [13:38:04<4:00:41, 25.34s/it]                                                        {'loss': 0.6846, 'learning_rate': 2.612997071487913e-06, 'epoch': 0.77}
 77%|███████▋  | 1926/2496 [13:38:04<4:00:41, 25.34s/it] 77%|███████▋  | 1927/2496 [13:38:31<4:04:23, 25.77s/it]                                                        {'loss': 0.6439, 'learning_rate': 2.6042567408187768e-06, 'epoch': 0.77}
 77%|███████▋  | 1927/2496 [13:38:31<4:04:23, 25.77s/it] 77%|███████▋  | 1928/2496 [13:38:58<4:06:41, 26.06s/it]                                                        {'loss': 0.6988, 'learning_rate': 2.595528863664174e-06, 'epoch': 0.77}
 77%|███████▋  | 1928/2496 [13:38:58<4:06:41, 26.06s/it] 77%|███████▋  | 1929/2496 [13:39:23<4:04:03, 25.83s/it]                                                        {'loss': 0.6835, 'learning_rate': 2.586813454720771e-06, 'epoch': 0.77}
 77%|███████▋  | 1929/2496 [13:39:23<4:04:03, 25.83s/it] 77%|███████▋  | 1930/2496 [13:39:49<4:03:30, 25.81s/it]                                                        {'loss': 0.6994, 'learning_rate': 2.5781105286642293e-06, 'epoch': 0.77}
 77%|███████▋  | 1930/2496 [13:39:49<4:03:30, 25.81s/it]this iter is wrong in something... skip...
 77%|███████▋  | 1931/2496 [13:40:15<4:02:54, 25.80s/it]                                                        {'loss': 0.6981, 'learning_rate': 2.5694201001492027e-06, 'epoch': 0.77}
 77%|███████▋  | 1931/2496 [13:40:15<4:02:54, 25.80s/it] 77%|███████▋  | 1932/2496 [13:40:41<4:02:43, 25.82s/it]                                                        {'loss': 0.6526, 'learning_rate': 2.5607421838092927e-06, 'epoch': 0.77}
 77%|███████▋  | 1932/2496 [13:40:41<4:02:43, 25.82s/it] 77%|███████▋  | 1933/2496 [13:41:07<4:03:15, 25.93s/it]                                                        {'loss': 0.6798, 'learning_rate': 2.552076794257028e-06, 'epoch': 0.77}
 77%|███████▋  | 1933/2496 [13:41:07<4:03:15, 25.93s/it] 77%|███████▋  | 1934/2496 [13:41:32<4:00:32, 25.68s/it]                                                        {'loss': 0.6748, 'learning_rate': 2.5434239460838617e-06, 'epoch': 0.77}
 77%|███████▋  | 1934/2496 [13:41:32<4:00:32, 25.68s/it]this iter is wrong in something... skip...
 78%|███████▊  | 1935/2496 [13:41:57<3:58:12, 25.48s/it]                                                        {'loss': 0.6842, 'learning_rate': 2.5347836538601113e-06, 'epoch': 0.78}
 78%|███████▊  | 1935/2496 [13:41:57<3:58:12, 25.48s/it] 78%|███████▊  | 1936/2496 [13:42:22<3:55:34, 25.24s/it]                                                        {'loss': 0.6868, 'learning_rate': 2.526155932134956e-06, 'epoch': 0.78}
 78%|███████▊  | 1936/2496 [13:42:22<3:55:34, 25.24s/it] 78%|███████▊  | 1937/2496 [13:42:48<3:58:43, 25.62s/it]                                                        {'loss': 0.6424, 'learning_rate': 2.517540795436413e-06, 'epoch': 0.78}
 78%|███████▊  | 1937/2496 [13:42:48<3:58:43, 25.62s/it] 78%|███████▊  | 1938/2496 [13:43:13<3:55:23, 25.31s/it]                                                        {'loss': 0.6519, 'learning_rate': 2.5089382582712995e-06, 'epoch': 0.78}
 78%|███████▊  | 1938/2496 [13:43:13<3:55:23, 25.31s/it]this iter is wrong in something... skip...
 78%|███████▊  | 1939/2496 [13:43:37<3:50:59, 24.88s/it]                                                        {'loss': 0.6911, 'learning_rate': 2.5003483351252267e-06, 'epoch': 0.78}
 78%|███████▊  | 1939/2496 [13:43:37<3:50:59, 24.88s/it] 78%|███████▊  | 1940/2496 [13:44:00<3:46:04, 24.40s/it]                                                        {'loss': 0.678, 'learning_rate': 2.491771040462555e-06, 'epoch': 0.78}
 78%|███████▊  | 1940/2496 [13:44:00<3:46:04, 24.40s/it] 78%|███████▊  | 1941/2496 [13:44:26<3:50:36, 24.93s/it]                                                        {'loss': 0.6846, 'learning_rate': 2.48320638872639e-06, 'epoch': 0.78}
 78%|███████▊  | 1941/2496 [13:44:26<3:50:36, 24.93s/it] 78%|███████▊  | 1942/2496 [13:44:53<3:55:45, 25.53s/it]                                                        {'loss': 0.6597, 'learning_rate': 2.474654394338537e-06, 'epoch': 0.78}
 78%|███████▊  | 1942/2496 [13:44:53<3:55:45, 25.53s/it] 78%|███████▊  | 1943/2496 [13:45:19<3:55:20, 25.54s/it]                                                        {'loss': 0.6851, 'learning_rate': 2.4661150716994973e-06, 'epoch': 0.78}
 78%|███████▊  | 1943/2496 [13:45:19<3:55:20, 25.54s/it] 78%|███████▊  | 1944/2496 [13:45:43<3:51:45, 25.19s/it]                                                        {'loss': 0.715, 'learning_rate': 2.457588435188436e-06, 'epoch': 0.78}
 78%|███████▊  | 1944/2496 [13:45:43<3:51:45, 25.19s/it] 78%|███████▊  | 1945/2496 [13:46:07<3:47:41, 24.79s/it]                                                        {'loss': 0.7076, 'learning_rate': 2.4490744991631452e-06, 'epoch': 0.78}
 78%|███████▊  | 1945/2496 [13:46:07<3:47:41, 24.79s/it] 78%|███████▊  | 1946/2496 [13:46:31<3:45:05, 24.56s/it]                                                        {'loss': 0.6554, 'learning_rate': 2.4405732779600376e-06, 'epoch': 0.78}
 78%|███████▊  | 1946/2496 [13:46:31<3:45:05, 24.56s/it] 78%|███████▊  | 1947/2496 [13:46:56<3:47:48, 24.90s/it]                                                        {'loss': 0.6607, 'learning_rate': 2.4320847858941167e-06, 'epoch': 0.78}
 78%|███████▊  | 1947/2496 [13:46:56<3:47:48, 24.90s/it] 78%|███████▊  | 1948/2496 [13:47:22<3:47:47, 24.94s/it]                                                        {'loss': 0.7053, 'learning_rate': 2.4236090372589537e-06, 'epoch': 0.78}
 78%|███████▊  | 1948/2496 [13:47:22<3:47:47, 24.94s/it]this iter is wrong in something... skip...
 78%|███████▊  | 1949/2496 [13:47:46<3:45:41, 24.76s/it]                                                        {'loss': 0.6822, 'learning_rate': 2.415146046326654e-06, 'epoch': 0.78}
 78%|███████▊  | 1949/2496 [13:47:46<3:45:41, 24.76s/it] 78%|███████▊  | 1950/2496 [13:48:11<3:45:09, 24.74s/it]                                                        {'loss': 0.6774, 'learning_rate': 2.406695827347848e-06, 'epoch': 0.78}
 78%|███████▊  | 1950/2496 [13:48:11<3:45:09, 24.74s/it] 78%|███████▊  | 1951/2496 [13:48:36<3:47:31, 25.05s/it]                                                        {'loss': 0.6996, 'learning_rate': 2.3982583945516557e-06, 'epoch': 0.78}
 78%|███████▊  | 1951/2496 [13:48:36<3:47:31, 25.05s/it] 78%|███████▊  | 1952/2496 [13:49:03<3:51:38, 25.55s/it]                                                        {'loss': 0.6462, 'learning_rate': 2.3898337621456637e-06, 'epoch': 0.78}
 78%|███████▊  | 1952/2496 [13:49:03<3:51:38, 25.55s/it] 78%|███████▊  | 1953/2496 [13:49:28<3:48:22, 25.24s/it]                                                        {'loss': 0.6493, 'learning_rate': 2.3814219443159113e-06, 'epoch': 0.78}
 78%|███████▊  | 1953/2496 [13:49:28<3:48:22, 25.24s/it] 78%|███████▊  | 1954/2496 [13:49:54<3:51:52, 25.67s/it]                                                        {'loss': 0.6613, 'learning_rate': 2.3730229552268603e-06, 'epoch': 0.78}
 78%|███████▊  | 1954/2496 [13:49:54<3:51:52, 25.67s/it] 78%|███████▊  | 1955/2496 [13:50:19<3:49:40, 25.47s/it]                                                        {'loss': 0.664, 'learning_rate': 2.3646368090213632e-06, 'epoch': 0.78}
 78%|███████▊  | 1955/2496 [13:50:19<3:49:40, 25.47s/it] 78%|███████▊  | 1956/2496 [13:50:46<3:52:28, 25.83s/it]                                                        {'loss': 0.6473, 'learning_rate': 2.3562635198206476e-06, 'epoch': 0.78}
 78%|███████▊  | 1956/2496 [13:50:46<3:52:28, 25.83s/it] 78%|███████▊  | 1957/2496 [13:51:11<3:50:14, 25.63s/it]                                                        {'loss': 0.6783, 'learning_rate': 2.347903101724297e-06, 'epoch': 0.78}
 78%|███████▊  | 1957/2496 [13:51:11<3:50:14, 25.63s/it]this iter is wrong in something... skip...
 78%|███████▊  | 1958/2496 [13:51:37<3:49:38, 25.61s/it]                                                        {'loss': 0.6386, 'learning_rate': 2.339555568810221e-06, 'epoch': 0.78}
 78%|███████▊  | 1958/2496 [13:51:37<3:49:38, 25.61s/it] 78%|███████▊  | 1959/2496 [13:52:03<3:50:08, 25.71s/it]                                                        {'loss': 0.6475, 'learning_rate': 2.331220935134625e-06, 'epoch': 0.78}
 78%|███████▊  | 1959/2496 [13:52:03<3:50:08, 25.71s/it] 79%|███████▊  | 1960/2496 [13:52:29<3:51:30, 25.92s/it]                                                        {'loss': 0.6528, 'learning_rate': 2.322899214732005e-06, 'epoch': 0.79}
 79%|███████▊  | 1960/2496 [13:52:29<3:51:30, 25.92s/it] 79%|███████▊  | 1961/2496 [13:52:52<3:44:40, 25.20s/it]                                                        {'loss': 0.6756, 'learning_rate': 2.314590421615098e-06, 'epoch': 0.79}
 79%|███████▊  | 1961/2496 [13:52:52<3:44:40, 25.20s/it]this iter is wrong in something... skip...
 79%|███████▊  | 1962/2496 [13:53:17<3:42:25, 24.99s/it]                                                        {'loss': 0.6453, 'learning_rate': 2.3062945697748873e-06, 'epoch': 0.79}
 79%|███████▊  | 1962/2496 [13:53:17<3:42:25, 24.99s/it] 79%|███████▊  | 1963/2496 [13:53:46<3:51:36, 26.07s/it]                                                        {'loss': 0.6838, 'learning_rate': 2.298011673180559e-06, 'epoch': 0.79}
 79%|███████▊  | 1963/2496 [13:53:46<3:51:36, 26.07s/it] 79%|███████▊  | 1964/2496 [13:54:14<3:58:02, 26.85s/it]                                                        {'loss': 0.6693, 'learning_rate': 2.2897417457794825e-06, 'epoch': 0.79}
 79%|███████▊  | 1964/2496 [13:54:14<3:58:02, 26.85s/it] 79%|███████▊  | 1965/2496 [13:54:43<4:02:02, 27.35s/it]                                                        {'loss': 0.2463, 'learning_rate': 2.281484801497186e-06, 'epoch': 0.79}
 79%|███████▊  | 1965/2496 [13:54:43<4:02:02, 27.35s/it] 79%|███████▉  | 1966/2496 [13:55:07<3:53:37, 26.45s/it]                                                        {'loss': 0.6632, 'learning_rate': 2.273240854237343e-06, 'epoch': 0.79}
 79%|███████▉  | 1966/2496 [13:55:07<3:53:37, 26.45s/it] 79%|███████▉  | 1967/2496 [13:55:30<3:44:44, 25.49s/it]                                                        {'loss': 0.6955, 'learning_rate': 2.265009917881742e-06, 'epoch': 0.79}
 79%|███████▉  | 1967/2496 [13:55:30<3:44:44, 25.49s/it]this iter is wrong in something... skip...
 79%|███████▉  | 1968/2496 [13:55:53<3:37:24, 24.71s/it]                                                        {'loss': 0.6683, 'learning_rate': 2.256792006290255e-06, 'epoch': 0.79}
 79%|███████▉  | 1968/2496 [13:55:53<3:37:24, 24.71s/it] 79%|███████▉  | 1969/2496 [13:56:17<3:33:19, 24.29s/it]                                                        {'loss': 0.6394, 'learning_rate': 2.2485871333008248e-06, 'epoch': 0.79}
 79%|███████▉  | 1969/2496 [13:56:17<3:33:19, 24.29s/it] 79%|███████▉  | 1970/2496 [13:56:40<3:30:09, 23.97s/it]                                                        {'loss': 0.649, 'learning_rate': 2.240395312729444e-06, 'epoch': 0.79}
 79%|███████▉  | 1970/2496 [13:56:40<3:30:09, 23.97s/it] 79%|███████▉  | 1971/2496 [13:57:04<3:30:43, 24.08s/it]                                                        {'loss': 0.641, 'learning_rate': 2.2322165583701184e-06, 'epoch': 0.79}
 79%|███████▉  | 1971/2496 [13:57:04<3:30:43, 24.08s/it] 79%|███████▉  | 1972/2496 [13:57:27<3:28:25, 23.87s/it]                                                        {'loss': 0.6724, 'learning_rate': 2.2240508839948582e-06, 'epoch': 0.79}
 79%|███████▉  | 1972/2496 [13:57:27<3:28:25, 23.87s/it]this iter is wrong in something... skip...
 79%|███████▉  | 1973/2496 [13:57:52<3:28:28, 23.92s/it]                                                        {'loss': 0.665, 'learning_rate': 2.2158983033536487e-06, 'epoch': 0.79}
 79%|███████▉  | 1973/2496 [13:57:52<3:28:28, 23.92s/it]this iter is wrong in something... skip...
 79%|███████▉  | 1974/2496 [13:58:15<3:27:58, 23.91s/it]                                                        {'loss': 0.6581, 'learning_rate': 2.2077588301744234e-06, 'epoch': 0.79}
 79%|███████▉  | 1974/2496 [13:58:15<3:27:58, 23.91s/it] 79%|███████▉  | 1975/2496 [13:58:39<3:25:50, 23.70s/it]                                                        {'loss': 0.6724, 'learning_rate': 2.199632478163042e-06, 'epoch': 0.79}
 79%|███████▉  | 1975/2496 [13:58:39<3:25:50, 23.70s/it] 79%|███████▉  | 1976/2496 [13:59:05<3:31:08, 24.36s/it]                                                        {'loss': 0.659, 'learning_rate': 2.1915192610032776e-06, 'epoch': 0.79}
 79%|███████▉  | 1976/2496 [13:59:05<3:31:08, 24.36s/it] 79%|███████▉  | 1977/2496 [13:59:31<3:35:40, 24.93s/it]                                                        {'loss': 0.6596, 'learning_rate': 2.183419192356783e-06, 'epoch': 0.79}
 79%|███████▉  | 1977/2496 [13:59:31<3:35:40, 24.93s/it] 79%|███████▉  | 1978/2496 [13:59:55<3:32:19, 24.59s/it]                                                        {'loss': 0.6893, 'learning_rate': 2.1753322858630633e-06, 'epoch': 0.79}
 79%|███████▉  | 1978/2496 [13:59:55<3:32:19, 24.59s/it] 79%|███████▉  | 1979/2496 [14:00:21<3:37:43, 25.27s/it]                                                        {'loss': 0.6594, 'learning_rate': 2.167258555139473e-06, 'epoch': 0.79}
 79%|███████▉  | 1979/2496 [14:00:21<3:37:43, 25.27s/it] 79%|███████▉  | 1980/2496 [14:00:45<3:33:38, 24.84s/it]                                                        {'loss': 0.6498, 'learning_rate': 2.1591980137811684e-06, 'epoch': 0.79}
 79%|███████▉  | 1980/2496 [14:00:45<3:33:38, 24.84s/it] 79%|███████▉  | 1981/2496 [14:01:11<3:34:56, 25.04s/it]                                                        {'loss': 0.6687, 'learning_rate': 2.151150675361107e-06, 'epoch': 0.79}
 79%|███████▉  | 1981/2496 [14:01:11<3:34:56, 25.04s/it] 79%|███████▉  | 1982/2496 [14:01:36<3:34:01, 24.98s/it]                                                        {'loss': 0.2219, 'learning_rate': 2.1431165534300023e-06, 'epoch': 0.79}
 79%|███████▉  | 1982/2496 [14:01:36<3:34:01, 24.98s/it] 79%|███████▉  | 1983/2496 [14:02:00<3:32:32, 24.86s/it]                                                        {'loss': 0.6596, 'learning_rate': 2.1350956615163254e-06, 'epoch': 0.79}
 79%|███████▉  | 1983/2496 [14:02:00<3:32:32, 24.86s/it] 79%|███████▉  | 1984/2496 [14:02:26<3:33:24, 25.01s/it]                                                        {'loss': 0.6831, 'learning_rate': 2.1270880131262604e-06, 'epoch': 0.79}
 79%|███████▉  | 1984/2496 [14:02:26<3:33:24, 25.01s/it] 80%|███████▉  | 1985/2496 [14:02:50<3:31:27, 24.83s/it]                                                        {'loss': 0.6518, 'learning_rate': 2.1190936217436896e-06, 'epoch': 0.8}
 80%|███████▉  | 1985/2496 [14:02:50<3:31:27, 24.83s/it] 80%|███████▉  | 1986/2496 [14:03:21<3:47:55, 26.81s/it]                                                        {'loss': 0.6334, 'learning_rate': 2.1111125008301868e-06, 'epoch': 0.8}
 80%|███████▉  | 1986/2496 [14:03:21<3:47:55, 26.81s/it] 80%|███████▉  | 1987/2496 [14:03:47<3:43:23, 26.33s/it]                                                        {'loss': 0.6703, 'learning_rate': 2.1031446638249654e-06, 'epoch': 0.8}
 80%|███████▉  | 1987/2496 [14:03:47<3:43:23, 26.33s/it] 80%|███████▉  | 1988/2496 [14:04:13<3:44:01, 26.46s/it]                                                        {'loss': 0.6934, 'learning_rate': 2.0951901241448715e-06, 'epoch': 0.8}
 80%|███████▉  | 1988/2496 [14:04:13<3:44:01, 26.46s/it] 80%|███████▉  | 1989/2496 [14:04:37<3:36:18, 25.60s/it]                                                        {'loss': 0.6949, 'learning_rate': 2.0872488951843683e-06, 'epoch': 0.8}
 80%|███████▉  | 1989/2496 [14:04:37<3:36:18, 25.60s/it] 80%|███████▉  | 1990/2496 [14:05:02<3:34:05, 25.39s/it]                                                        {'loss': 0.7019, 'learning_rate': 2.0793209903154963e-06, 'epoch': 0.8}
 80%|███████▉  | 1990/2496 [14:05:02<3:34:05, 25.39s/it] 80%|███████▉  | 1991/2496 [14:05:27<3:33:17, 25.34s/it]                                                        {'loss': 0.665, 'learning_rate': 2.0714064228878663e-06, 'epoch': 0.8}
 80%|███████▉  | 1991/2496 [14:05:27<3:33:17, 25.34s/it] 80%|███████▉  | 1992/2496 [14:05:51<3:30:05, 25.01s/it]                                                        {'loss': 0.6515, 'learning_rate': 2.0635052062286323e-06, 'epoch': 0.8}
 80%|███████▉  | 1992/2496 [14:05:51<3:30:05, 25.01s/it] 80%|███████▉  | 1993/2496 [14:06:18<3:33:48, 25.50s/it]                                                        {'loss': 0.6797, 'learning_rate': 2.0556173536424584e-06, 'epoch': 0.8}
 80%|███████▉  | 1993/2496 [14:06:18<3:33:48, 25.50s/it] 80%|███████▉  | 1994/2496 [14:06:45<3:38:17, 26.09s/it]                                                        {'loss': 0.6591, 'learning_rate': 2.0477428784115096e-06, 'epoch': 0.8}
 80%|███████▉  | 1994/2496 [14:06:45<3:38:17, 26.09s/it] 80%|███████▉  | 1995/2496 [14:07:11<3:36:41, 25.95s/it]                                                        {'loss': 0.641, 'learning_rate': 2.0398817937954275e-06, 'epoch': 0.8}
 80%|███████▉  | 1995/2496 [14:07:11<3:36:41, 25.95s/it] 80%|███████▉  | 1996/2496 [14:07:37<3:37:11, 26.06s/it]                                                        {'loss': 0.6457, 'learning_rate': 2.032034113031306e-06, 'epoch': 0.8}
 80%|███████▉  | 1996/2496 [14:07:37<3:37:11, 26.06s/it] 80%|████████  | 1997/2496 [14:08:02<3:32:08, 25.51s/it]                                                        {'loss': 0.6371, 'learning_rate': 2.0241998493336647e-06, 'epoch': 0.8}
 80%|████████  | 1997/2496 [14:08:02<3:32:08, 25.51s/it] 80%|████████  | 1998/2496 [14:08:27<3:30:22, 25.35s/it]                                                        {'loss': 0.6718, 'learning_rate': 2.0163790158944283e-06, 'epoch': 0.8}
 80%|████████  | 1998/2496 [14:08:27<3:30:22, 25.35s/it] 80%|████████  | 1999/2496 [14:08:51<3:27:12, 25.01s/it]                                                        {'loss': 0.6319, 'learning_rate': 2.0085716258829145e-06, 'epoch': 0.8}
 80%|████████  | 1999/2496 [14:08:51<3:27:12, 25.01s/it] 80%|████████  | 2000/2496 [14:09:17<3:30:17, 25.44s/it]                                                        {'loss': 0.6759, 'learning_rate': 2.0007776924458023e-06, 'epoch': 0.8}
 80%|████████  | 2000/2496 [14:09:17<3:30:17, 25.44s/it] 80%|████████  | 2001/2496 [14:09:43<3:31:15, 25.61s/it]                                                        {'loss': 0.6795, 'learning_rate': 1.992997228707103e-06, 'epoch': 0.8}
 80%|████████  | 2001/2496 [14:09:43<3:31:15, 25.61s/it] 80%|████████  | 2002/2496 [14:10:07<3:26:49, 25.12s/it]                                                        {'loss': 0.6642, 'learning_rate': 1.9852302477681583e-06, 'epoch': 0.8}
 80%|████████  | 2002/2496 [14:10:07<3:26:49, 25.12s/it] 80%|████████  | 2003/2496 [14:10:32<3:26:19, 25.11s/it]                                                        {'loss': 0.6856, 'learning_rate': 1.9774767627075998e-06, 'epoch': 0.8}
 80%|████████  | 2003/2496 [14:10:32<3:26:19, 25.11s/it] 80%|████████  | 2004/2496 [14:10:55<3:20:39, 24.47s/it]                                                        {'loss': 0.6623, 'learning_rate': 1.96973678658133e-06, 'epoch': 0.8}
 80%|████████  | 2004/2496 [14:10:55<3:20:39, 24.47s/it]this iter is wrong in something... skip...
 80%|████████  | 2005/2496 [14:11:20<3:20:54, 24.55s/it]                                                        {'loss': 0.2375, 'learning_rate': 1.9620103324225117e-06, 'epoch': 0.8}
 80%|████████  | 2005/2496 [14:11:20<3:20:54, 24.55s/it] 80%|████████  | 2006/2496 [14:11:45<3:21:45, 24.71s/it]                                                        {'loss': 0.6952, 'learning_rate': 1.9542974132415394e-06, 'epoch': 0.8}
 80%|████████  | 2006/2496 [14:11:45<3:21:45, 24.71s/it] 80%|████████  | 2007/2496 [14:12:11<3:23:14, 24.94s/it]                                                        {'loss': 0.6933, 'learning_rate': 1.9465980420260065e-06, 'epoch': 0.8}
 80%|████████  | 2007/2496 [14:12:11<3:23:14, 24.94s/it] 80%|████████  | 2008/2496 [14:12:35<3:22:35, 24.91s/it]                                                        {'loss': 0.6499, 'learning_rate': 1.938912231740706e-06, 'epoch': 0.8}
 80%|████████  | 2008/2496 [14:12:35<3:22:35, 24.91s/it] 80%|████████  | 2009/2496 [14:13:01<3:22:50, 24.99s/it]                                                        {'loss': 0.6742, 'learning_rate': 1.931239995327583e-06, 'epoch': 0.8}
 80%|████████  | 2009/2496 [14:13:01<3:22:50, 24.99s/it]this iter is wrong in something... skip...
 81%|████████  | 2010/2496 [14:13:27<3:26:23, 25.48s/it]                                                        {'loss': 0.6981, 'learning_rate': 1.923581345705736e-06, 'epoch': 0.81}
 81%|████████  | 2010/2496 [14:13:27<3:26:23, 25.48s/it] 81%|████████  | 2011/2496 [14:13:54<3:29:10, 25.88s/it]                                                        {'loss': 0.6599, 'learning_rate': 1.915936295771379e-06, 'epoch': 0.81}
 81%|████████  | 2011/2496 [14:13:54<3:29:10, 25.88s/it] 81%|████████  | 2012/2496 [14:14:20<3:28:32, 25.85s/it]                                                        {'loss': 0.6898, 'learning_rate': 1.9083048583978315e-06, 'epoch': 0.81}
 81%|████████  | 2012/2496 [14:14:20<3:28:32, 25.85s/it] 81%|████████  | 2013/2496 [14:14:44<3:23:13, 25.25s/it]                                                        {'loss': 0.6522, 'learning_rate': 1.9006870464354843e-06, 'epoch': 0.81}
 81%|████████  | 2013/2496 [14:14:44<3:23:13, 25.25s/it] 81%|████████  | 2014/2496 [14:15:09<3:23:21, 25.31s/it]                                                        {'loss': 0.6478, 'learning_rate': 1.8930828727117856e-06, 'epoch': 0.81}
 81%|████████  | 2014/2496 [14:15:09<3:23:21, 25.31s/it] 81%|████████  | 2015/2496 [14:15:35<3:24:30, 25.51s/it]                                                        {'loss': 0.6573, 'learning_rate': 1.8854923500312284e-06, 'epoch': 0.81}
 81%|████████  | 2015/2496 [14:15:35<3:24:30, 25.51s/it] 81%|████████  | 2016/2496 [14:16:01<3:24:01, 25.50s/it]                                                        {'loss': 0.676, 'learning_rate': 1.8779154911753083e-06, 'epoch': 0.81}
 81%|████████  | 2016/2496 [14:16:01<3:24:01, 25.50s/it] 81%|████████  | 2017/2496 [14:16:26<3:22:42, 25.39s/it]                                                        {'loss': 0.637, 'learning_rate': 1.8703523089025133e-06, 'epoch': 0.81}
 81%|████████  | 2017/2496 [14:16:26<3:22:42, 25.39s/it] 81%|████████  | 2018/2496 [14:16:52<3:24:37, 25.69s/it]                                                        {'loss': 0.6886, 'learning_rate': 1.8628028159483069e-06, 'epoch': 0.81}
 81%|████████  | 2018/2496 [14:16:52<3:24:37, 25.69s/it] 81%|████████  | 2019/2496 [14:17:17<3:22:09, 25.43s/it]                                                        {'loss': 0.678, 'learning_rate': 1.8552670250251003e-06, 'epoch': 0.81}
 81%|████████  | 2019/2496 [14:17:17<3:22:09, 25.43s/it] 81%|████████  | 2020/2496 [14:17:43<3:23:30, 25.65s/it]                                                        {'loss': 0.6911, 'learning_rate': 1.8477449488222277e-06, 'epoch': 0.81}
 81%|████████  | 2020/2496 [14:17:43<3:23:30, 25.65s/it]this iter is wrong in something... skip...
 81%|████████  | 2021/2496 [14:18:08<3:21:17, 25.43s/it]                                                        {'loss': 0.6349, 'learning_rate': 1.8402366000059368e-06, 'epoch': 0.81}
 81%|████████  | 2021/2496 [14:18:08<3:21:17, 25.43s/it] 81%|████████  | 2022/2496 [14:18:34<3:22:56, 25.69s/it]                                                        {'loss': 0.6516, 'learning_rate': 1.8327419912193534e-06, 'epoch': 0.81}
 81%|████████  | 2022/2496 [14:18:34<3:22:56, 25.69s/it] 81%|████████  | 2023/2496 [14:19:01<3:24:49, 25.98s/it]                                                        {'loss': 0.6805, 'learning_rate': 1.8252611350824668e-06, 'epoch': 0.81}
 81%|████████  | 2023/2496 [14:19:01<3:24:49, 25.98s/it]this iter is wrong in something... skip...
 81%|████████  | 2024/2496 [14:19:26<3:22:29, 25.74s/it]                                                        {'loss': 0.6548, 'learning_rate': 1.8177940441921138e-06, 'epoch': 0.81}
 81%|████████  | 2024/2496 [14:19:26<3:22:29, 25.74s/it] 81%|████████  | 2025/2496 [14:19:53<3:25:24, 26.17s/it]                                                        {'loss': 0.6544, 'learning_rate': 1.8103407311219523e-06, 'epoch': 0.81}
 81%|████████  | 2025/2496 [14:19:53<3:25:24, 26.17s/it] 81%|████████  | 2026/2496 [14:20:17<3:20:00, 25.53s/it]                                                        {'loss': 0.6471, 'learning_rate': 1.802901208422435e-06, 'epoch': 0.81}
 81%|████████  | 2026/2496 [14:20:17<3:20:00, 25.53s/it] 81%|████████  | 2027/2496 [14:20:45<3:23:43, 26.06s/it]                                                        {'loss': 0.6929, 'learning_rate': 1.7954754886207915e-06, 'epoch': 0.81}
 81%|████████  | 2027/2496 [14:20:45<3:23:43, 26.06s/it] 81%|████████▏ | 2028/2496 [14:21:09<3:20:24, 25.69s/it]                                                        {'loss': 0.6549, 'learning_rate': 1.788063584221017e-06, 'epoch': 0.81}
 81%|████████▏ | 2028/2496 [14:21:09<3:20:24, 25.69s/it] 81%|████████▏ | 2029/2496 [14:21:35<3:18:38, 25.52s/it]                                                        {'loss': 0.6641, 'learning_rate': 1.7806655077038415e-06, 'epoch': 0.81}
 81%|████████▏ | 2029/2496 [14:21:35<3:18:38, 25.52s/it] 81%|████████▏ | 2030/2496 [14:22:02<3:21:48, 25.98s/it]                                                        {'loss': 0.6657, 'learning_rate': 1.7732812715267022e-06, 'epoch': 0.81}
 81%|████████▏ | 2030/2496 [14:22:02<3:21:48, 25.98s/it] 81%|████████▏ | 2031/2496 [14:22:25<3:14:59, 25.16s/it]                                                        {'loss': 0.6845, 'learning_rate': 1.7659108881237452e-06, 'epoch': 0.81}
 81%|████████▏ | 2031/2496 [14:22:25<3:14:59, 25.16s/it] 81%|████████▏ | 2032/2496 [14:22:48<3:09:25, 24.49s/it]                                                        {'loss': 0.6922, 'learning_rate': 1.7585543699057772e-06, 'epoch': 0.81}
 81%|████████▏ | 2032/2496 [14:22:48<3:09:25, 24.49s/it] 81%|████████▏ | 2033/2496 [14:23:12<3:08:30, 24.43s/it]                                                        {'loss': 0.6793, 'learning_rate': 1.7512117292602603e-06, 'epoch': 0.81}
 81%|████████▏ | 2033/2496 [14:23:12<3:08:30, 24.43s/it] 81%|████████▏ | 2034/2496 [14:23:40<3:15:42, 25.42s/it]                                                        {'loss': 0.6951, 'learning_rate': 1.7438829785512933e-06, 'epoch': 0.81}
 81%|████████▏ | 2034/2496 [14:23:40<3:15:42, 25.42s/it] 82%|████████▏ | 2035/2496 [14:24:05<3:15:24, 25.43s/it]                                                        {'loss': 0.691, 'learning_rate': 1.736568130119588e-06, 'epoch': 0.82}
 82%|████████▏ | 2035/2496 [14:24:05<3:15:24, 25.43s/it] 82%|████████▏ | 2036/2496 [14:24:31<3:16:40, 25.65s/it]                                                        {'loss': 0.6436, 'learning_rate': 1.7292671962824348e-06, 'epoch': 0.82}
 82%|████████▏ | 2036/2496 [14:24:31<3:16:40, 25.65s/it]this iter is wrong in something... skip...
 82%|████████▏ | 2037/2496 [14:24:57<3:16:12, 25.65s/it]                                                        {'loss': 0.66, 'learning_rate': 1.7219801893337073e-06, 'epoch': 0.82}
 82%|████████▏ | 2037/2496 [14:24:57<3:16:12, 25.65s/it] 82%|████████▏ | 2038/2496 [14:25:21<3:10:39, 24.98s/it]                                                        {'loss': 0.6878, 'learning_rate': 1.714707121543816e-06, 'epoch': 0.82}
 82%|████████▏ | 2038/2496 [14:25:21<3:10:39, 24.98s/it] 82%|████████▏ | 2039/2496 [14:25:46<3:11:29, 25.14s/it]                                                        {'loss': 0.6548, 'learning_rate': 1.7074480051597097e-06, 'epoch': 0.82}
 82%|████████▏ | 2039/2496 [14:25:46<3:11:29, 25.14s/it] 82%|████████▏ | 2040/2496 [14:26:10<3:07:46, 24.71s/it]                                                        {'loss': 0.6513, 'learning_rate': 1.7002028524048354e-06, 'epoch': 0.82}
 82%|████████▏ | 2040/2496 [14:26:10<3:07:46, 24.71s/it] 82%|████████▏ | 2041/2496 [14:26:36<3:10:47, 25.16s/it]                                                        {'loss': 0.6733, 'learning_rate': 1.6929716754791381e-06, 'epoch': 0.82}
 82%|████████▏ | 2041/2496 [14:26:36<3:10:47, 25.16s/it] 82%|████████▏ | 2042/2496 [14:27:00<3:07:19, 24.76s/it]                                                        {'loss': 0.6751, 'learning_rate': 1.685754486559017e-06, 'epoch': 0.82}
 82%|████████▏ | 2042/2496 [14:27:00<3:07:19, 24.76s/it] 82%|████████▏ | 2043/2496 [14:27:25<3:07:06, 24.78s/it]                                                        {'loss': 0.6518, 'learning_rate': 1.678551297797325e-06, 'epoch': 0.82}
 82%|████████▏ | 2043/2496 [14:27:25<3:07:06, 24.78s/it] 82%|████████▏ | 2044/2496 [14:27:47<3:01:52, 24.14s/it]                                                        {'loss': 0.7032, 'learning_rate': 1.6713621213233433e-06, 'epoch': 0.82}
 82%|████████▏ | 2044/2496 [14:27:47<3:01:52, 24.14s/it] 82%|████████▏ | 2045/2496 [14:28:12<3:01:55, 24.20s/it]                                                        {'loss': 0.6315, 'learning_rate': 1.6641869692427492e-06, 'epoch': 0.82}
 82%|████████▏ | 2045/2496 [14:28:12<3:01:55, 24.20s/it] 82%|████████▏ | 2046/2496 [14:28:34<2:58:17, 23.77s/it]                                                        {'loss': 0.6701, 'learning_rate': 1.6570258536376083e-06, 'epoch': 0.82}
 82%|████████▏ | 2046/2496 [14:28:34<2:58:17, 23.77s/it] 82%|████████▏ | 2047/2496 [14:28:59<3:00:39, 24.14s/it]                                                        {'loss': 0.7017, 'learning_rate': 1.6498787865663523e-06, 'epoch': 0.82}
 82%|████████▏ | 2047/2496 [14:28:59<3:00:39, 24.14s/it] 82%|████████▏ | 2048/2496 [14:29:25<3:03:27, 24.57s/it]                                                        {'loss': 0.6617, 'learning_rate': 1.642745780063758e-06, 'epoch': 0.82}
 82%|████████▏ | 2048/2496 [14:29:25<3:03:27, 24.57s/it] 82%|████████▏ | 2049/2496 [14:29:52<3:09:21, 25.42s/it]                                                        {'loss': 0.6666, 'learning_rate': 1.635626846140921e-06, 'epoch': 0.82}
 82%|████████▏ | 2049/2496 [14:29:52<3:09:21, 25.42s/it] 82%|████████▏ | 2050/2496 [14:30:19<3:11:28, 25.76s/it]                                                        {'loss': 0.6483, 'learning_rate': 1.628521996785245e-06, 'epoch': 0.82}
 82%|████████▏ | 2050/2496 [14:30:19<3:11:28, 25.76s/it] 82%|████████▏ | 2051/2496 [14:30:44<3:10:08, 25.64s/it]                                                        {'loss': 0.6519, 'learning_rate': 1.6214312439604163e-06, 'epoch': 0.82}
 82%|████████▏ | 2051/2496 [14:30:44<3:10:08, 25.64s/it] 82%|████████▏ | 2052/2496 [14:31:09<3:07:03, 25.28s/it]                                                        {'loss': 0.6492, 'learning_rate': 1.614354599606378e-06, 'epoch': 0.82}
 82%|████████▏ | 2052/2496 [14:31:09<3:07:03, 25.28s/it] 82%|████████▏ | 2053/2496 [14:31:34<3:07:07, 25.34s/it]                                                        {'loss': 0.6753, 'learning_rate': 1.6072920756393263e-06, 'epoch': 0.82}
 82%|████████▏ | 2053/2496 [14:31:34<3:07:07, 25.34s/it] 82%|████████▏ | 2054/2496 [14:31:59<3:04:52, 25.10s/it]                                                        {'loss': 0.6833, 'learning_rate': 1.6002436839516766e-06, 'epoch': 0.82}
 82%|████████▏ | 2054/2496 [14:31:59<3:04:52, 25.10s/it] 82%|████████▏ | 2055/2496 [14:32:24<3:04:41, 25.13s/it]                                                        {'loss': 0.6516, 'learning_rate': 1.5932094364120453e-06, 'epoch': 0.82}
 82%|████████▏ | 2055/2496 [14:32:24<3:04:41, 25.13s/it] 82%|████████▏ | 2056/2496 [14:32:51<3:08:07, 25.65s/it]                                                        {'loss': 0.671, 'learning_rate': 1.5861893448652298e-06, 'epoch': 0.82}
 82%|████████▏ | 2056/2496 [14:32:51<3:08:07, 25.65s/it] 82%|████████▏ | 2057/2496 [14:33:17<3:09:16, 25.87s/it]                                                        {'loss': 0.6584, 'learning_rate': 1.5791834211321955e-06, 'epoch': 0.82}
 82%|████████▏ | 2057/2496 [14:33:17<3:09:16, 25.87s/it] 82%|████████▏ | 2058/2496 [14:33:43<3:09:16, 25.93s/it]                                                        {'loss': 0.6844, 'learning_rate': 1.5721916770100532e-06, 'epoch': 0.82}
 82%|████████▏ | 2058/2496 [14:33:43<3:09:16, 25.93s/it] 82%|████████▏ | 2059/2496 [14:34:08<3:05:18, 25.44s/it]                                                        {'loss': 0.6453, 'learning_rate': 1.5652141242720277e-06, 'epoch': 0.82}
 82%|████████▏ | 2059/2496 [14:34:08<3:05:18, 25.44s/it]this iter is wrong in something... skip...
 83%|████████▎ | 2060/2496 [14:34:32<3:02:08, 25.06s/it]                                                        {'loss': 0.6522, 'learning_rate': 1.5582507746674557e-06, 'epoch': 0.83}
 83%|████████▎ | 2060/2496 [14:34:32<3:02:08, 25.06s/it] 83%|████████▎ | 2061/2496 [14:34:56<2:59:32, 24.76s/it]                                                        {'loss': 0.659, 'learning_rate': 1.5513016399217518e-06, 'epoch': 0.83}
 83%|████████▎ | 2061/2496 [14:34:56<2:59:32, 24.76s/it] 83%|████████▎ | 2062/2496 [14:35:24<3:06:07, 25.73s/it]                                                        {'loss': 0.644, 'learning_rate': 1.5443667317364008e-06, 'epoch': 0.83}
 83%|████████▎ | 2062/2496 [14:35:24<3:06:07, 25.73s/it] 83%|████████▎ | 2063/2496 [14:35:51<3:07:51, 26.03s/it]                                                        {'loss': 0.6457, 'learning_rate': 1.5374460617889242e-06, 'epoch': 0.83}
 83%|████████▎ | 2063/2496 [14:35:51<3:07:51, 26.03s/it] 83%|████████▎ | 2064/2496 [14:36:17<3:07:43, 26.07s/it]                                                        {'loss': 0.6556, 'learning_rate': 1.5305396417328755e-06, 'epoch': 0.83}
 83%|████████▎ | 2064/2496 [14:36:17<3:07:43, 26.07s/it] 83%|████████▎ | 2065/2496 [14:36:43<3:08:22, 26.22s/it]                                                        {'loss': 0.6802, 'learning_rate': 1.5236474831978064e-06, 'epoch': 0.83}
 83%|████████▎ | 2065/2496 [14:36:43<3:08:22, 26.22s/it] 83%|████████▎ | 2066/2496 [14:37:15<3:19:37, 27.85s/it]                                                        {'loss': 0.6301, 'learning_rate': 1.5167695977892583e-06, 'epoch': 0.83}
 83%|████████▎ | 2066/2496 [14:37:15<3:19:37, 27.85s/it] 83%|████████▎ | 2067/2496 [14:37:39<3:11:12, 26.74s/it]                                                        {'loss': 0.6726, 'learning_rate': 1.5099059970887398e-06, 'epoch': 0.83}
 83%|████████▎ | 2067/2496 [14:37:39<3:11:12, 26.74s/it] 83%|████████▎ | 2068/2496 [14:38:04<3:06:46, 26.18s/it]                                                        {'loss': 0.7013, 'learning_rate': 1.5030566926537016e-06, 'epoch': 0.83}
 83%|████████▎ | 2068/2496 [14:38:04<3:06:46, 26.18s/it] 83%|████████▎ | 2069/2496 [14:38:30<3:05:09, 26.02s/it]                                                        {'loss': 0.6494, 'learning_rate': 1.4962216960175214e-06, 'epoch': 0.83}
 83%|████████▎ | 2069/2496 [14:38:30<3:05:09, 26.02s/it] 83%|████████▎ | 2070/2496 [14:38:56<3:06:16, 26.24s/it]                                                        {'loss': 0.671, 'learning_rate': 1.489401018689488e-06, 'epoch': 0.83}
 83%|████████▎ | 2070/2496 [14:38:56<3:06:16, 26.24s/it] 83%|████████▎ | 2071/2496 [14:39:20<2:59:51, 25.39s/it]                                                        {'loss': 0.6678, 'learning_rate': 1.4825946721547747e-06, 'epoch': 0.83}
 83%|████████▎ | 2071/2496 [14:39:20<2:59:51, 25.39s/it] 83%|████████▎ | 2072/2496 [14:39:42<2:53:10, 24.51s/it]                                                        {'loss': 0.6777, 'learning_rate': 1.4758026678744253e-06, 'epoch': 0.83}
 83%|████████▎ | 2072/2496 [14:39:42<2:53:10, 24.51s/it] 83%|████████▎ | 2073/2496 [14:40:08<2:56:09, 24.99s/it]                                                        {'loss': 0.6295, 'learning_rate': 1.469025017285335e-06, 'epoch': 0.83}
 83%|████████▎ | 2073/2496 [14:40:08<2:56:09, 24.99s/it] 83%|████████▎ | 2074/2496 [14:40:34<2:57:28, 25.23s/it]                                                        {'loss': 0.6149, 'learning_rate': 1.4622617318002263e-06, 'epoch': 0.83}
 83%|████████▎ | 2074/2496 [14:40:34<2:57:28, 25.23s/it] 83%|████████▎ | 2075/2496 [14:41:00<2:58:21, 25.42s/it]                                                        {'loss': 0.6958, 'learning_rate': 1.4555128228076298e-06, 'epoch': 0.83}
 83%|████████▎ | 2075/2496 [14:41:00<2:58:21, 25.42s/it] 83%|████████▎ | 2076/2496 [14:41:24<2:55:27, 25.06s/it]                                                        {'loss': 0.6647, 'learning_rate': 1.4487783016718726e-06, 'epoch': 0.83}
 83%|████████▎ | 2076/2496 [14:41:24<2:55:27, 25.06s/it] 83%|████████▎ | 2077/2496 [14:41:49<2:54:20, 24.97s/it]                                                        {'loss': 0.6399, 'learning_rate': 1.442058179733058e-06, 'epoch': 0.83}
 83%|████████▎ | 2077/2496 [14:41:49<2:54:20, 24.97s/it] 83%|████████▎ | 2078/2496 [14:42:16<2:57:46, 25.52s/it]                                                        {'loss': 0.6321, 'learning_rate': 1.4353524683070319e-06, 'epoch': 0.83}
 83%|████████▎ | 2078/2496 [14:42:16<2:57:46, 25.52s/it] 83%|████████▎ | 2079/2496 [14:42:41<2:57:49, 25.59s/it]                                                        {'loss': 0.6393, 'learning_rate': 1.4286611786853843e-06, 'epoch': 0.83}
 83%|████████▎ | 2079/2496 [14:42:41<2:57:49, 25.59s/it] 83%|████████▎ | 2080/2496 [14:43:08<2:59:24, 25.88s/it]                                                        {'loss': 0.6357, 'learning_rate': 1.4219843221354158e-06, 'epoch': 0.83}
 83%|████████▎ | 2080/2496 [14:43:08<2:59:24, 25.88s/it] 83%|████████▎ | 2081/2496 [14:43:34<2:59:15, 25.92s/it]                                                        {'loss': 0.6661, 'learning_rate': 1.4153219099001258e-06, 'epoch': 0.83}
 83%|████████▎ | 2081/2496 [14:43:34<2:59:15, 25.92s/it] 83%|████████▎ | 2082/2496 [14:44:00<2:59:38, 26.04s/it]                                                        {'loss': 0.6461, 'learning_rate': 1.4086739531981886e-06, 'epoch': 0.83}
 83%|████████▎ | 2082/2496 [14:44:00<2:59:38, 26.04s/it] 83%|████████▎ | 2083/2496 [14:44:25<2:55:36, 25.51s/it]                                                        {'loss': 0.682, 'learning_rate': 1.4020404632239415e-06, 'epoch': 0.83}
 83%|████████▎ | 2083/2496 [14:44:25<2:55:36, 25.51s/it] 83%|████████▎ | 2084/2496 [14:44:50<2:54:27, 25.41s/it]                                                        {'loss': 0.2319, 'learning_rate': 1.3954214511473575e-06, 'epoch': 0.83}
 83%|████████▎ | 2084/2496 [14:44:50<2:54:27, 25.41s/it] 84%|████████▎ | 2085/2496 [14:45:13<2:49:58, 24.81s/it]                                                        {'loss': 0.6922, 'learning_rate': 1.3888169281140284e-06, 'epoch': 0.84}
 84%|████████▎ | 2085/2496 [14:45:13<2:49:58, 24.81s/it] 84%|████████▎ | 2086/2496 [14:45:38<2:50:07, 24.90s/it]                                                        {'loss': 0.2559, 'learning_rate': 1.3822269052451599e-06, 'epoch': 0.84}
 84%|████████▎ | 2086/2496 [14:45:38<2:50:07, 24.90s/it] 84%|████████▎ | 2087/2496 [14:46:07<2:56:28, 25.89s/it]                                                        {'loss': 0.6812, 'learning_rate': 1.3756513936375282e-06, 'epoch': 0.84}
 84%|████████▎ | 2087/2496 [14:46:07<2:56:28, 25.89s/it] 84%|████████▎ | 2088/2496 [14:46:31<2:52:56, 25.43s/it]                                                        {'loss': 0.6625, 'learning_rate': 1.3690904043634789e-06, 'epoch': 0.84}
 84%|████████▎ | 2088/2496 [14:46:31<2:52:56, 25.43s/it] 84%|████████▎ | 2089/2496 [14:46:57<2:53:14, 25.54s/it]                                                        {'loss': 0.6553, 'learning_rate': 1.362543948470909e-06, 'epoch': 0.84}
 84%|████████▎ | 2089/2496 [14:46:57<2:53:14, 25.54s/it] 84%|████████▎ | 2090/2496 [14:47:23<2:54:30, 25.79s/it]                                                        {'loss': 0.6396, 'learning_rate': 1.3560120369832319e-06, 'epoch': 0.84}
 84%|████████▎ | 2090/2496 [14:47:23<2:54:30, 25.79s/it] 84%|████████▍ | 2091/2496 [14:47:47<2:50:40, 25.29s/it]                                                        {'loss': 0.6749, 'learning_rate': 1.3494946808993804e-06, 'epoch': 0.84}
 84%|████████▍ | 2091/2496 [14:47:47<2:50:40, 25.29s/it]this iter is wrong in something... skip...
 84%|████████▍ | 2092/2496 [14:48:10<2:45:21, 24.56s/it]                                                        {'loss': 0.6908, 'learning_rate': 1.3429918911937755e-06, 'epoch': 0.84}
 84%|████████▍ | 2092/2496 [14:48:10<2:45:21, 24.56s/it] 84%|████████▍ | 2093/2496 [14:48:35<2:44:48, 24.54s/it]                                                        {'loss': 0.6567, 'learning_rate': 1.3365036788163067e-06, 'epoch': 0.84}
 84%|████████▍ | 2093/2496 [14:48:35<2:44:48, 24.54s/it] 84%|████████▍ | 2094/2496 [14:48:59<2:44:41, 24.58s/it]                                                        {'loss': 0.6465, 'learning_rate': 1.3300300546923172e-06, 'epoch': 0.84}
 84%|████████▍ | 2094/2496 [14:48:59<2:44:41, 24.58s/it] 84%|████████▍ | 2095/2496 [14:49:23<2:43:03, 24.40s/it]                                                        {'loss': 0.6797, 'learning_rate': 1.323571029722589e-06, 'epoch': 0.84}
 84%|████████▍ | 2095/2496 [14:49:23<2:43:03, 24.40s/it] 84%|████████▍ | 2096/2496 [14:49:50<2:48:06, 25.22s/it]                                                        {'loss': 0.6442, 'learning_rate': 1.3171266147833207e-06, 'epoch': 0.84}
 84%|████████▍ | 2096/2496 [14:49:50<2:48:06, 25.22s/it] 84%|████████▍ | 2097/2496 [14:50:16<2:48:19, 25.31s/it]                                                        {'loss': 0.655, 'learning_rate': 1.3106968207261073e-06, 'epoch': 0.84}
 84%|████████▍ | 2097/2496 [14:50:16<2:48:19, 25.31s/it] 84%|████████▍ | 2098/2496 [14:50:40<2:46:13, 25.06s/it]                                                        {'loss': 0.6572, 'learning_rate': 1.3042816583779217e-06, 'epoch': 0.84}
 84%|████████▍ | 2098/2496 [14:50:40<2:46:13, 25.06s/it] 84%|████████▍ | 2099/2496 [14:51:06<2:46:07, 25.11s/it]                                                        {'loss': 0.6532, 'learning_rate': 1.2978811385411027e-06, 'epoch': 0.84}
 84%|████████▍ | 2099/2496 [14:51:06<2:46:07, 25.11s/it] 84%|████████▍ | 2100/2496 [14:51:30<2:45:05, 25.01s/it]                                                        {'loss': 0.6438, 'learning_rate': 1.291495271993337e-06, 'epoch': 0.84}
 84%|████████▍ | 2100/2496 [14:51:30<2:45:05, 25.01s/it] 84%|████████▍ | 2101/2496 [14:51:57<2:48:46, 25.64s/it]                                                        {'loss': 0.6226, 'learning_rate': 1.2851240694876254e-06, 'epoch': 0.84}
 84%|████████▍ | 2101/2496 [14:51:57<2:48:46, 25.64s/it] 84%|████████▍ | 2102/2496 [14:52:22<2:45:44, 25.24s/it]                                                        {'loss': 0.6628, 'learning_rate': 1.2787675417522883e-06, 'epoch': 0.84}
 84%|████████▍ | 2102/2496 [14:52:22<2:45:44, 25.24s/it] 84%|████████▍ | 2103/2496 [14:52:46<2:43:53, 25.02s/it]                                                        {'loss': 0.6554, 'learning_rate': 1.2724256994909268e-06, 'epoch': 0.84}
 84%|████████▍ | 2103/2496 [14:52:46<2:43:53, 25.02s/it] 84%|████████▍ | 2104/2496 [14:53:13<2:46:53, 25.54s/it]                                                        {'loss': 0.6682, 'learning_rate': 1.2660985533824155e-06, 'epoch': 0.84}
 84%|████████▍ | 2104/2496 [14:53:13<2:46:53, 25.54s/it] 84%|████████▍ | 2105/2496 [14:53:40<2:49:21, 25.99s/it]                                                        {'loss': 0.6693, 'learning_rate': 1.2597861140808864e-06, 'epoch': 0.84}
 84%|████████▍ | 2105/2496 [14:53:40<2:49:21, 25.99s/it] 84%|████████▍ | 2106/2496 [14:54:05<2:46:49, 25.67s/it]                                                        {'loss': 0.2452, 'learning_rate': 1.253488392215706e-06, 'epoch': 0.84}
 84%|████████▍ | 2106/2496 [14:54:05<2:46:49, 25.67s/it] 84%|████████▍ | 2107/2496 [14:54:27<2:39:03, 24.53s/it]                                                        {'loss': 0.6479, 'learning_rate': 1.2472053983914522e-06, 'epoch': 0.84}
 84%|████████▍ | 2107/2496 [14:54:27<2:39:03, 24.53s/it] 84%|████████▍ | 2108/2496 [14:54:51<2:38:34, 24.52s/it]                                                        {'loss': 0.6863, 'learning_rate': 1.2409371431879136e-06, 'epoch': 0.84}
 84%|████████▍ | 2108/2496 [14:54:51<2:38:34, 24.52s/it] 84%|████████▍ | 2109/2496 [14:55:15<2:36:06, 24.20s/it]                                                        {'loss': 0.6813, 'learning_rate': 1.234683637160048e-06, 'epoch': 0.84}
 84%|████████▍ | 2109/2496 [14:55:15<2:36:06, 24.20s/it] 85%|████████▍ | 2110/2496 [14:55:40<2:38:14, 24.60s/it]                                                        {'loss': 0.6599, 'learning_rate': 1.2284448908379908e-06, 'epoch': 0.85}
 85%|████████▍ | 2110/2496 [14:55:40<2:38:14, 24.60s/it] 85%|████████▍ | 2111/2496 [14:56:09<2:45:32, 25.80s/it]                                                        {'loss': 0.6208, 'learning_rate': 1.2222209147270103e-06, 'epoch': 0.85}
 85%|████████▍ | 2111/2496 [14:56:09<2:45:32, 25.80s/it]this iter is wrong in something... skip...
 85%|████████▍ | 2112/2496 [14:56:33<2:42:32, 25.40s/it]                                                        {'loss': 0.2326, 'learning_rate': 1.2160117193075171e-06, 'epoch': 0.85}
 85%|████████▍ | 2112/2496 [14:56:33<2:42:32, 25.40s/it]this iter is wrong in something... skip...
 85%|████████▍ | 2113/2496 [14:56:59<2:42:23, 25.44s/it]                                                        {'loss': 0.6788, 'learning_rate': 1.2098173150350223e-06, 'epoch': 0.85}
 85%|████████▍ | 2113/2496 [14:56:59<2:42:23, 25.44s/it] 85%|████████▍ | 2114/2496 [14:57:24<2:40:39, 25.24s/it]                                                        {'loss': 0.6889, 'learning_rate': 1.2036377123401322e-06, 'epoch': 0.85}
 85%|████████▍ | 2114/2496 [14:57:24<2:40:39, 25.24s/it] 85%|████████▍ | 2115/2496 [14:57:52<2:46:38, 26.24s/it]                                                        {'loss': 0.6624, 'learning_rate': 1.1974729216285386e-06, 'epoch': 0.85}
 85%|████████▍ | 2115/2496 [14:57:52<2:46:38, 26.24s/it] 85%|████████▍ | 2116/2496 [14:58:19<2:47:06, 26.39s/it]                                                        {'loss': 0.6363, 'learning_rate': 1.19132295328098e-06, 'epoch': 0.85}
 85%|████████▍ | 2116/2496 [14:58:19<2:47:06, 26.39s/it] 85%|████████▍ | 2117/2496 [14:58:43<2:41:44, 25.61s/it]                                                        {'loss': 0.6932, 'learning_rate': 1.1851878176532395e-06, 'epoch': 0.85}
 85%|████████▍ | 2117/2496 [14:58:43<2:41:44, 25.61s/it] 85%|████████▍ | 2118/2496 [14:59:08<2:39:46, 25.36s/it]                                                        {'loss': 0.6898, 'learning_rate': 1.1790675250761263e-06, 'epoch': 0.85}
 85%|████████▍ | 2118/2496 [14:59:08<2:39:46, 25.36s/it] 85%|████████▍ | 2119/2496 [14:59:34<2:42:01, 25.79s/it]                                                        {'loss': 0.641, 'learning_rate': 1.1729620858554559e-06, 'epoch': 0.85}
 85%|████████▍ | 2119/2496 [14:59:34<2:42:01, 25.79s/it] 85%|████████▍ | 2120/2496 [14:59:59<2:38:55, 25.36s/it]                                                        {'loss': 0.6772, 'learning_rate': 1.1668715102720263e-06, 'epoch': 0.85}
 85%|████████▍ | 2120/2496 [14:59:59<2:38:55, 25.36s/it] 85%|████████▍ | 2121/2496 [15:00:23<2:36:43, 25.08s/it]                                                        {'loss': 0.6627, 'learning_rate': 1.1607958085816173e-06, 'epoch': 0.85}
 85%|████████▍ | 2121/2496 [15:00:23<2:36:43, 25.08s/it] 85%|████████▌ | 2122/2496 [15:00:47<2:34:56, 24.86s/it]                                                        {'loss': 0.6496, 'learning_rate': 1.154734991014954e-06, 'epoch': 0.85}
 85%|████████▌ | 2122/2496 [15:00:47<2:34:56, 24.86s/it] 85%|████████▌ | 2123/2496 [15:01:15<2:39:27, 25.65s/it]                                                        {'loss': 0.686, 'learning_rate': 1.1486890677776996e-06, 'epoch': 0.85}
 85%|████████▌ | 2123/2496 [15:01:15<2:39:27, 25.65s/it] 85%|████████▌ | 2124/2496 [15:01:39<2:36:51, 25.30s/it]                                                        {'loss': 0.6807, 'learning_rate': 1.1426580490504413e-06, 'epoch': 0.85}
 85%|████████▌ | 2124/2496 [15:01:39<2:36:51, 25.30s/it] 85%|████████▌ | 2125/2496 [15:02:04<2:34:55, 25.05s/it]                                                        {'loss': 0.6749, 'learning_rate': 1.1366419449886689e-06, 'epoch': 0.85}
 85%|████████▌ | 2125/2496 [15:02:04<2:34:55, 25.05s/it]this iter is wrong in something... skip...
 85%|████████▌ | 2126/2496 [15:02:29<2:34:00, 24.97s/it]                                                        {'loss': 0.683, 'learning_rate': 1.1306407657227535e-06, 'epoch': 0.85}
 85%|████████▌ | 2126/2496 [15:02:29<2:34:00, 24.97s/it] 85%|████████▌ | 2127/2496 [15:02:57<2:40:36, 26.12s/it]                                                        {'loss': 0.6442, 'learning_rate': 1.124654521357934e-06, 'epoch': 0.85}
 85%|████████▌ | 2127/2496 [15:02:57<2:40:36, 26.12s/it] 85%|████████▌ | 2128/2496 [15:03:23<2:39:28, 26.00s/it]                                                        {'loss': 0.6651, 'learning_rate': 1.118683221974307e-06, 'epoch': 0.85}
 85%|████████▌ | 2128/2496 [15:03:23<2:39:28, 26.00s/it] 85%|████████▌ | 2129/2496 [15:03:47<2:34:39, 25.28s/it]                                                        {'loss': 0.6502, 'learning_rate': 1.1127268776268007e-06, 'epoch': 0.85}
 85%|████████▌ | 2129/2496 [15:03:47<2:34:39, 25.28s/it]WARNING: tokenization mismatch: 1 vs. 737. (ignored)
 85%|████████▌ | 2130/2496 [15:04:12<2:34:50, 25.38s/it]                                                        {'loss': 0.6639, 'learning_rate': 1.1067854983451575e-06, 'epoch': 0.85}
 85%|████████▌ | 2130/2496 [15:04:12<2:34:50, 25.38s/it] 85%|████████▌ | 2131/2496 [15:04:37<2:33:32, 25.24s/it]                                                        {'loss': 0.6583, 'learning_rate': 1.100859094133927e-06, 'epoch': 0.85}
 85%|████████▌ | 2131/2496 [15:04:37<2:33:32, 25.24s/it] 85%|████████▌ | 2132/2496 [15:05:03<2:33:13, 25.26s/it]                                                        {'loss': 0.669, 'learning_rate': 1.0949476749724375e-06, 'epoch': 0.85}
 85%|████████▌ | 2132/2496 [15:05:03<2:33:13, 25.26s/it] 85%|████████▌ | 2133/2496 [15:05:29<2:34:39, 25.56s/it]                                                        {'loss': 0.6994, 'learning_rate': 1.0890512508147822e-06, 'epoch': 0.85}
 85%|████████▌ | 2133/2496 [15:05:29<2:34:39, 25.56s/it] 85%|████████▌ | 2134/2496 [15:05:55<2:34:41, 25.64s/it]                                                        {'loss': 0.6912, 'learning_rate': 1.0831698315898121e-06, 'epoch': 0.85}
 85%|████████▌ | 2134/2496 [15:05:55<2:34:41, 25.64s/it] 86%|████████▌ | 2135/2496 [15:06:20<2:33:19, 25.48s/it]                                                        {'loss': 0.2295, 'learning_rate': 1.0773034272011086e-06, 'epoch': 0.86}
 86%|████████▌ | 2135/2496 [15:06:20<2:33:19, 25.48s/it] 86%|████████▌ | 2136/2496 [15:06:44<2:29:36, 24.93s/it]                                                        {'loss': 0.6282, 'learning_rate': 1.0714520475269653e-06, 'epoch': 0.86}
 86%|████████▌ | 2136/2496 [15:06:44<2:29:36, 24.93s/it] 86%|████████▌ | 2137/2496 [15:07:08<2:28:16, 24.78s/it]                                                        {'loss': 0.6628, 'learning_rate': 1.0656157024203829e-06, 'epoch': 0.86}
 86%|████████▌ | 2137/2496 [15:07:08<2:28:16, 24.78s/it] 86%|████████▌ | 2138/2496 [15:07:31<2:25:07, 24.32s/it]                                                        {'loss': 0.6663, 'learning_rate': 1.0597944017090434e-06, 'epoch': 0.86}
 86%|████████▌ | 2138/2496 [15:07:31<2:25:07, 24.32s/it] 86%|████████▌ | 2139/2496 [15:07:56<2:26:19, 24.59s/it]                                                        {'loss': 0.6323, 'learning_rate': 1.0539881551952946e-06, 'epoch': 0.86}
 86%|████████▌ | 2139/2496 [15:07:56<2:26:19, 24.59s/it] 86%|████████▌ | 2140/2496 [15:08:22<2:27:57, 24.94s/it]                                                        {'loss': 0.6696, 'learning_rate': 1.0481969726561335e-06, 'epoch': 0.86}
 86%|████████▌ | 2140/2496 [15:08:22<2:27:57, 24.94s/it] 86%|████████▌ | 2141/2496 [15:08:48<2:29:46, 25.31s/it]                                                        {'loss': 0.6719, 'learning_rate': 1.0424208638431965e-06, 'epoch': 0.86}
 86%|████████▌ | 2141/2496 [15:08:48<2:29:46, 25.31s/it] 86%|████████▌ | 2142/2496 [15:09:15<2:31:12, 25.63s/it]                                                        {'loss': 0.6605, 'learning_rate': 1.036659838482732e-06, 'epoch': 0.86}
 86%|████████▌ | 2142/2496 [15:09:15<2:31:12, 25.63s/it] 86%|████████▌ | 2143/2496 [15:09:40<2:30:27, 25.57s/it]                                                        {'loss': 0.6466, 'learning_rate': 1.0309139062755923e-06, 'epoch': 0.86}
 86%|████████▌ | 2143/2496 [15:09:40<2:30:27, 25.57s/it] 86%|████████▌ | 2144/2496 [15:10:04<2:27:46, 25.19s/it]                                                        {'loss': 0.6435, 'learning_rate': 1.0251830768972181e-06, 'epoch': 0.86}
 86%|████████▌ | 2144/2496 [15:10:04<2:27:46, 25.19s/it] 86%|████████▌ | 2145/2496 [15:10:32<2:31:33, 25.91s/it]                                                        {'loss': 0.6556, 'learning_rate': 1.0194673599976134e-06, 'epoch': 0.86}
 86%|████████▌ | 2145/2496 [15:10:32<2:31:33, 25.91s/it] 86%|████████▌ | 2146/2496 [15:11:00<2:33:52, 26.38s/it]                                                        {'loss': 0.6558, 'learning_rate': 1.013766765201334e-06, 'epoch': 0.86}
 86%|████████▌ | 2146/2496 [15:11:00<2:33:52, 26.38s/it] 86%|████████▌ | 2147/2496 [15:11:25<2:31:35, 26.06s/it]                                                        {'loss': 0.6861, 'learning_rate': 1.0080813021074775e-06, 'epoch': 0.86}
 86%|████████▌ | 2147/2496 [15:11:25<2:31:35, 26.06s/it] 86%|████████▌ | 2148/2496 [15:11:50<2:29:29, 25.77s/it]                                                        {'loss': 0.6663, 'learning_rate': 1.0024109802896598e-06, 'epoch': 0.86}
 86%|████████▌ | 2148/2496 [15:11:50<2:29:29, 25.77s/it] 86%|████████▌ | 2149/2496 [15:12:17<2:31:34, 26.21s/it]                                                        {'loss': 0.6332, 'learning_rate': 9.967558092959961e-07, 'epoch': 0.86}
 86%|████████▌ | 2149/2496 [15:12:17<2:31:34, 26.21s/it] 86%|████████▌ | 2150/2496 [15:12:42<2:28:38, 25.78s/it]                                                        {'loss': 0.6401, 'learning_rate': 9.91115798649097e-07, 'epoch': 0.86}
 86%|████████▌ | 2150/2496 [15:12:42<2:28:38, 25.78s/it] 86%|████████▌ | 2151/2496 [15:13:06<2:25:35, 25.32s/it]                                                        {'loss': 0.655, 'learning_rate': 9.854909578460392e-07, 'epoch': 0.86}
 86%|████████▌ | 2151/2496 [15:13:06<2:25:35, 25.32s/it] 86%|████████▌ | 2152/2496 [15:13:31<2:25:10, 25.32s/it]                                                        {'loss': 0.6274, 'learning_rate': 9.79881296358356e-07, 'epoch': 0.86}
 86%|████████▌ | 2152/2496 [15:13:31<2:25:10, 25.32s/it]this iter is wrong in something... skip...
 86%|████████▋ | 2153/2496 [15:13:56<2:23:49, 25.16s/it]                                                        {'loss': 0.2374, 'learning_rate': 9.742868236320214e-07, 'epoch': 0.86}
 86%|████████▋ | 2153/2496 [15:13:56<2:23:49, 25.16s/it] 86%|████████▋ | 2154/2496 [15:14:22<2:24:23, 25.33s/it]                                                        {'loss': 0.6624, 'learning_rate': 9.687075490874376e-07, 'epoch': 0.86}
 86%|████████▋ | 2154/2496 [15:14:22<2:24:23, 25.33s/it] 86%|████████▋ | 2155/2496 [15:14:48<2:24:54, 25.50s/it]                                                        {'loss': 0.6649, 'learning_rate': 9.631434821194085e-07, 'epoch': 0.86}
 86%|████████▋ | 2155/2496 [15:14:48<2:24:54, 25.50s/it] 86%|████████▋ | 2156/2496 [15:15:12<2:22:15, 25.10s/it]                                                        {'loss': 0.6854, 'learning_rate': 9.575946320971296e-07, 'epoch': 0.86}
 86%|████████▋ | 2156/2496 [15:15:12<2:22:15, 25.10s/it] 86%|████████▋ | 2157/2496 [15:15:37<2:21:33, 25.06s/it]                                                        {'loss': 0.6994, 'learning_rate': 9.520610083641823e-07, 'epoch': 0.86}
 86%|████████▋ | 2157/2496 [15:15:37<2:21:33, 25.06s/it] 86%|████████▋ | 2158/2496 [15:16:01<2:19:38, 24.79s/it]                                                        {'loss': 0.7015, 'learning_rate': 9.465426202385008e-07, 'epoch': 0.86}
 86%|████████▋ | 2158/2496 [15:16:01<2:19:38, 24.79s/it] 86%|████████▋ | 2159/2496 [15:16:27<2:20:07, 24.95s/it]                                                        {'loss': 0.6467, 'learning_rate': 9.410394770123643e-07, 'epoch': 0.86}
 86%|████████▋ | 2159/2496 [15:16:27<2:20:07, 24.95s/it] 87%|████████▋ | 2160/2496 [15:16:53<2:22:01, 25.36s/it]                                                        {'loss': 0.6396, 'learning_rate': 9.355515879523858e-07, 'epoch': 0.87}
 87%|████████▋ | 2160/2496 [15:16:53<2:22:01, 25.36s/it] 87%|████████▋ | 2161/2496 [15:17:24<2:30:44, 27.00s/it]                                                        {'loss': 0.6554, 'learning_rate': 9.300789622994877e-07, 'epoch': 0.87}
 87%|████████▋ | 2161/2496 [15:17:24<2:30:44, 27.00s/it] 87%|████████▋ | 2162/2496 [15:17:48<2:26:03, 26.24s/it]                                                        {'loss': 0.237, 'learning_rate': 9.246216092688965e-07, 'epoch': 0.87}
 87%|████████▋ | 2162/2496 [15:17:48<2:26:03, 26.24s/it] 87%|████████▋ | 2163/2496 [15:18:13<2:22:31, 25.68s/it]                                                        {'loss': 0.6922, 'learning_rate': 9.191795380501133e-07, 'epoch': 0.87}
 87%|████████▋ | 2163/2496 [15:18:13<2:22:31, 25.68s/it] 87%|████████▋ | 2164/2496 [15:18:38<2:21:30, 25.57s/it]                                                        {'loss': 0.6689, 'learning_rate': 9.137527578069161e-07, 'epoch': 0.87}
 87%|████████▋ | 2164/2496 [15:18:38<2:21:30, 25.57s/it] 87%|████████▋ | 2165/2496 [15:19:02<2:18:50, 25.17s/it]                                                        {'loss': 0.6673, 'learning_rate': 9.083412776773248e-07, 'epoch': 0.87}
 87%|████████▋ | 2165/2496 [15:19:02<2:18:50, 25.17s/it] 87%|████████▋ | 2166/2496 [15:19:30<2:22:26, 25.90s/it]                                                        {'loss': 0.6853, 'learning_rate': 9.029451067736039e-07, 'epoch': 0.87}
 87%|████████▋ | 2166/2496 [15:19:30<2:22:26, 25.90s/it] 87%|████████▋ | 2167/2496 [15:19:55<2:21:25, 25.79s/it]                                                        {'loss': 0.6909, 'learning_rate': 8.975642541822372e-07, 'epoch': 0.87}
 87%|████████▋ | 2167/2496 [15:19:55<2:21:25, 25.79s/it] 87%|████████▋ | 2168/2496 [15:20:22<2:22:54, 26.14s/it]                                                        {'loss': 0.6727, 'learning_rate': 8.921987289639122e-07, 'epoch': 0.87}
 87%|████████▋ | 2168/2496 [15:20:22<2:22:54, 26.14s/it] 87%|████████▋ | 2169/2496 [15:20:48<2:21:38, 25.99s/it]                                                        {'loss': 0.6295, 'learning_rate': 8.868485401535054e-07, 'epoch': 0.87}
 87%|████████▋ | 2169/2496 [15:20:48<2:21:38, 25.99s/it] 87%|████████▋ | 2170/2496 [15:21:15<2:22:49, 26.29s/it]                                                        {'loss': 0.6479, 'learning_rate': 8.815136967600757e-07, 'epoch': 0.87}
 87%|████████▋ | 2170/2496 [15:21:15<2:22:49, 26.29s/it] 87%|████████▋ | 2171/2496 [15:21:39<2:18:31, 25.57s/it]                                                        {'loss': 0.6577, 'learning_rate': 8.76194207766834e-07, 'epoch': 0.87}
 87%|████████▋ | 2171/2496 [15:21:39<2:18:31, 25.57s/it] 87%|████████▋ | 2172/2496 [15:22:05<2:18:47, 25.70s/it]                                                        {'loss': 0.6528, 'learning_rate': 8.708900821311405e-07, 'epoch': 0.87}
 87%|████████▋ | 2172/2496 [15:22:05<2:18:47, 25.70s/it] 87%|████████▋ | 2173/2496 [15:22:31<2:19:38, 25.94s/it]                                                        {'loss': 0.6694, 'learning_rate': 8.656013287844889e-07, 'epoch': 0.87}
 87%|████████▋ | 2173/2496 [15:22:31<2:19:38, 25.94s/it] 87%|████████▋ | 2174/2496 [15:22:59<2:21:50, 26.43s/it]                                                        {'loss': 0.6552, 'learning_rate': 8.603279566324807e-07, 'epoch': 0.87}
 87%|████████▋ | 2174/2496 [15:22:59<2:21:50, 26.43s/it] 87%|████████▋ | 2175/2496 [15:23:25<2:20:27, 26.25s/it]                                                        {'loss': 0.6626, 'learning_rate': 8.550699745548196e-07, 'epoch': 0.87}
 87%|████████▋ | 2175/2496 [15:23:25<2:20:27, 26.25s/it] 87%|████████▋ | 2176/2496 [15:23:49<2:16:48, 25.65s/it]                                                        {'loss': 0.6702, 'learning_rate': 8.498273914052968e-07, 'epoch': 0.87}
 87%|████████▋ | 2176/2496 [15:23:49<2:16:48, 25.65s/it] 87%|████████▋ | 2177/2496 [15:24:14<2:15:10, 25.43s/it]                                                        {'loss': 0.6356, 'learning_rate': 8.44600216011775e-07, 'epoch': 0.87}
 87%|████████▋ | 2177/2496 [15:24:14<2:15:10, 25.43s/it] 87%|████████▋ | 2178/2496 [15:24:41<2:17:44, 25.99s/it]                                                        {'loss': 0.6713, 'learning_rate': 8.393884571761646e-07, 'epoch': 0.87}
 87%|████████▋ | 2178/2496 [15:24:41<2:17:44, 25.99s/it] 87%|████████▋ | 2179/2496 [15:25:06<2:16:04, 25.76s/it]                                                        {'loss': 0.6804, 'learning_rate': 8.341921236744244e-07, 'epoch': 0.87}
 87%|████████▋ | 2179/2496 [15:25:06<2:16:04, 25.76s/it] 87%|████████▋ | 2180/2496 [15:25:32<2:15:59, 25.82s/it]                                                        {'loss': 0.6547, 'learning_rate': 8.290112242565341e-07, 'epoch': 0.87}
 87%|████████▋ | 2180/2496 [15:25:32<2:15:59, 25.82s/it] 87%|████████▋ | 2181/2496 [15:25:56<2:11:44, 25.09s/it]                                                        {'loss': 0.6904, 'learning_rate': 8.238457676464873e-07, 'epoch': 0.87}
 87%|████████▋ | 2181/2496 [15:25:56<2:11:44, 25.09s/it] 87%|████████▋ | 2182/2496 [15:26:20<2:10:56, 25.02s/it]                                                        {'loss': 0.6555, 'learning_rate': 8.186957625422698e-07, 'epoch': 0.87}
 87%|████████▋ | 2182/2496 [15:26:20<2:10:56, 25.02s/it] 87%|████████▋ | 2183/2496 [15:26:47<2:12:35, 25.42s/it]                                                        {'loss': 0.6496, 'learning_rate': 8.135612176158558e-07, 'epoch': 0.87}
 87%|████████▋ | 2183/2496 [15:26:47<2:12:35, 25.42s/it] 88%|████████▊ | 2184/2496 [15:27:14<2:14:22, 25.84s/it]                                                        {'loss': 0.6635, 'learning_rate': 8.084421415131793e-07, 'epoch': 0.87}
 88%|████████▊ | 2184/2496 [15:27:14<2:14:22, 25.84s/it] 88%|████████▊ | 2185/2496 [15:27:39<2:12:50, 25.63s/it]                                                        {'loss': 0.6728, 'learning_rate': 8.033385428541263e-07, 'epoch': 0.88}
 88%|████████▊ | 2185/2496 [15:27:39<2:12:50, 25.63s/it]this iter is wrong in something... skip...
 88%|████████▊ | 2186/2496 [15:28:05<2:13:08, 25.77s/it]                                                        {'loss': 0.6708, 'learning_rate': 7.982504302325311e-07, 'epoch': 0.88}
 88%|████████▊ | 2186/2496 [15:28:05<2:13:08, 25.77s/it] 88%|████████▊ | 2187/2496 [15:28:31<2:13:02, 25.83s/it]                                                        {'loss': 0.687, 'learning_rate': 7.931778122161415e-07, 'epoch': 0.88}
 88%|████████▊ | 2187/2496 [15:28:31<2:13:02, 25.83s/it] 88%|████████▊ | 2188/2496 [15:28:57<2:13:42, 26.05s/it]                                                        {'loss': 0.6544, 'learning_rate': 7.881206973466149e-07, 'epoch': 0.88}
 88%|████████▊ | 2188/2496 [15:28:57<2:13:42, 26.05s/it] 88%|████████▊ | 2189/2496 [15:29:29<2:21:20, 27.62s/it]                                                        {'loss': 0.6504, 'learning_rate': 7.830790941395106e-07, 'epoch': 0.88}
 88%|████████▊ | 2189/2496 [15:29:29<2:21:20, 27.62s/it] 88%|████████▊ | 2190/2496 [15:29:54<2:16:36, 26.78s/it]                                                        {'loss': 0.6708, 'learning_rate': 7.780530110842566e-07, 'epoch': 0.88}
 88%|████████▊ | 2190/2496 [15:29:54<2:16:36, 26.78s/it] 88%|████████▊ | 2191/2496 [15:30:20<2:15:51, 26.73s/it]                                                        {'loss': 0.6602, 'learning_rate': 7.730424566441597e-07, 'epoch': 0.88}
 88%|████████▊ | 2191/2496 [15:30:20<2:15:51, 26.73s/it] 88%|████████▊ | 2192/2496 [15:30:44<2:11:07, 25.88s/it]                                                        {'loss': 0.7129, 'learning_rate': 7.680474392563675e-07, 'epoch': 0.88}
 88%|████████▊ | 2192/2496 [15:30:44<2:11:07, 25.88s/it] 88%|████████▊ | 2193/2496 [15:31:09<2:08:51, 25.52s/it]                                                        {'loss': 0.6401, 'learning_rate': 7.630679673318742e-07, 'epoch': 0.88}
 88%|████████▊ | 2193/2496 [15:31:09<2:08:51, 25.52s/it] 88%|████████▊ | 2194/2496 [15:31:33<2:05:57, 25.03s/it]                                                        {'loss': 0.6794, 'learning_rate': 7.581040492554892e-07, 'epoch': 0.88}
 88%|████████▊ | 2194/2496 [15:31:33<2:05:57, 25.03s/it] 88%|████████▊ | 2195/2496 [15:32:00<2:09:17, 25.77s/it]                                                        {'loss': 0.6607, 'learning_rate': 7.531556933858364e-07, 'epoch': 0.88}
 88%|████████▊ | 2195/2496 [15:32:00<2:09:17, 25.77s/it] 88%|████████▊ | 2196/2496 [15:32:25<2:07:19, 25.46s/it]                                                        {'loss': 0.2261, 'learning_rate': 7.482229080553349e-07, 'epoch': 0.88}
 88%|████████▊ | 2196/2496 [15:32:25<2:07:19, 25.46s/it] 88%|████████▊ | 2197/2496 [15:32:51<2:07:14, 25.53s/it]                                                        {'loss': 0.6416, 'learning_rate': 7.433057015701827e-07, 'epoch': 0.88}
 88%|████████▊ | 2197/2496 [15:32:51<2:07:14, 25.53s/it] 88%|████████▊ | 2198/2496 [15:33:14<2:03:06, 24.79s/it]                                                        {'loss': 0.6533, 'learning_rate': 7.384040822103434e-07, 'epoch': 0.88}
 88%|████████▊ | 2198/2496 [15:33:14<2:03:06, 24.79s/it] 88%|████████▊ | 2199/2496 [15:33:37<2:00:36, 24.37s/it]                                                        {'loss': 0.6855, 'learning_rate': 7.335180582295387e-07, 'epoch': 0.88}
 88%|████████▊ | 2199/2496 [15:33:37<2:00:36, 24.37s/it] 88%|████████▊ | 2200/2496 [15:34:07<2:08:24, 26.03s/it]                                                        {'loss': 0.7017, 'learning_rate': 7.286476378552277e-07, 'epoch': 0.88}
 88%|████████▊ | 2200/2496 [15:34:07<2:08:24, 26.03s/it] 88%|████████▊ | 2201/2496 [15:34:32<2:06:22, 25.70s/it]                                                        {'loss': 0.2451, 'learning_rate': 7.23792829288591e-07, 'epoch': 0.88}
 88%|████████▊ | 2201/2496 [15:34:32<2:06:22, 25.70s/it] 88%|████████▊ | 2202/2496 [15:34:56<2:03:31, 25.21s/it]                                                        {'loss': 0.6641, 'learning_rate': 7.189536407045283e-07, 'epoch': 0.88}
 88%|████████▊ | 2202/2496 [15:34:56<2:03:31, 25.21s/it] 88%|████████▊ | 2203/2496 [15:35:20<2:02:04, 25.00s/it]                                                        {'loss': 0.6542, 'learning_rate': 7.141300802516316e-07, 'epoch': 0.88}
 88%|████████▊ | 2203/2496 [15:35:20<2:02:04, 25.00s/it] 88%|████████▊ | 2204/2496 [15:35:44<2:00:03, 24.67s/it]                                                        {'loss': 0.6666, 'learning_rate': 7.093221560521768e-07, 'epoch': 0.88}
 88%|████████▊ | 2204/2496 [15:35:44<2:00:03, 24.67s/it] 88%|████████▊ | 2205/2496 [15:36:10<2:01:07, 24.97s/it]                                                        {'loss': 0.669, 'learning_rate': 7.045298762021125e-07, 'epoch': 0.88}
 88%|████████▊ | 2205/2496 [15:36:10<2:01:07, 24.97s/it] 88%|████████▊ | 2206/2496 [15:36:41<2:09:52, 26.87s/it]                                                        {'loss': 0.6482, 'learning_rate': 6.997532487710457e-07, 'epoch': 0.88}
 88%|████████▊ | 2206/2496 [15:36:41<2:09:52, 26.87s/it] 88%|████████▊ | 2207/2496 [15:37:08<2:09:30, 26.89s/it]                                                        {'loss': 0.6914, 'learning_rate': 6.949922818022225e-07, 'epoch': 0.88}
 88%|████████▊ | 2207/2496 [15:37:08<2:09:30, 26.89s/it] 88%|████████▊ | 2208/2496 [15:37:32<2:04:15, 25.89s/it]                                                        {'loss': 0.6439, 'learning_rate': 6.902469833125236e-07, 'epoch': 0.88}
 88%|████████▊ | 2208/2496 [15:37:32<2:04:15, 25.89s/it] 89%|████████▊ | 2209/2496 [15:37:59<2:05:04, 26.15s/it]                                                        {'loss': 0.6561, 'learning_rate': 6.855173612924404e-07, 'epoch': 0.88}
 89%|████████▊ | 2209/2496 [15:37:59<2:05:04, 26.15s/it] 89%|████████▊ | 2210/2496 [15:38:24<2:04:09, 26.05s/it]                                                        {'loss': 0.6541, 'learning_rate': 6.808034237060723e-07, 'epoch': 0.89}
 89%|████████▊ | 2210/2496 [15:38:24<2:04:09, 26.05s/it]this iter is wrong in something... skip...
 89%|████████▊ | 2211/2496 [15:38:50<2:03:41, 26.04s/it]                                                        {'loss': 0.6472, 'learning_rate': 6.761051784911021e-07, 'epoch': 0.89}
 89%|████████▊ | 2211/2496 [15:38:50<2:03:41, 26.04s/it] 89%|████████▊ | 2212/2496 [15:39:16<2:02:02, 25.78s/it]                                                        {'loss': 0.6364, 'learning_rate': 6.714226335587959e-07, 'epoch': 0.89}
 89%|████████▊ | 2212/2496 [15:39:16<2:02:02, 25.78s/it]this iter is wrong in something... skip...
 89%|████████▊ | 2213/2496 [15:39:40<1:59:37, 25.36s/it]                                                        {'loss': 0.677, 'learning_rate': 6.667557967939764e-07, 'epoch': 0.89}
 89%|████████▊ | 2213/2496 [15:39:40<1:59:37, 25.36s/it] 89%|████████▊ | 2214/2496 [15:40:04<1:57:46, 25.06s/it]                                                        {'loss': 0.6944, 'learning_rate': 6.621046760550176e-07, 'epoch': 0.89}
 89%|████████▊ | 2214/2496 [15:40:04<1:57:46, 25.06s/it] 89%|████████▊ | 2215/2496 [15:40:29<1:57:15, 25.04s/it]                                                        {'loss': 0.6649, 'learning_rate': 6.574692791738335e-07, 'epoch': 0.89}
 89%|████████▊ | 2215/2496 [15:40:29<1:57:15, 25.04s/it] 89%|████████▉ | 2216/2496 [15:40:54<1:56:46, 25.02s/it]                                                        {'loss': 0.6523, 'learning_rate': 6.528496139558549e-07, 'epoch': 0.89}
 89%|████████▉ | 2216/2496 [15:40:54<1:56:46, 25.02s/it] 89%|████████▉ | 2217/2496 [15:41:23<2:01:45, 26.18s/it]                                                        {'loss': 0.6428, 'learning_rate': 6.482456881800248e-07, 'epoch': 0.89}
 89%|████████▉ | 2217/2496 [15:41:23<2:01:45, 26.18s/it] 89%|████████▉ | 2218/2496 [15:41:48<1:59:21, 25.76s/it]                                                        {'loss': 0.6628, 'learning_rate': 6.43657509598784e-07, 'epoch': 0.89}
 89%|████████▉ | 2218/2496 [15:41:48<1:59:21, 25.76s/it] 89%|████████▉ | 2219/2496 [15:42:12<1:57:01, 25.35s/it]                                                        {'loss': 0.6884, 'learning_rate': 6.390850859380571e-07, 'epoch': 0.89}
 89%|████████▉ | 2219/2496 [15:42:12<1:57:01, 25.35s/it] 89%|████████▉ | 2220/2496 [15:42:37<1:56:18, 25.28s/it]                                                        {'loss': 0.673, 'learning_rate': 6.345284248972383e-07, 'epoch': 0.89}
 89%|████████▉ | 2220/2496 [15:42:37<1:56:18, 25.28s/it] 89%|████████▉ | 2221/2496 [15:43:01<1:54:00, 24.88s/it]                                                        {'loss': 0.6937, 'learning_rate': 6.29987534149178e-07, 'epoch': 0.89}
 89%|████████▉ | 2221/2496 [15:43:01<1:54:00, 24.88s/it] 89%|████████▉ | 2222/2496 [15:43:27<1:54:50, 25.15s/it]                                                        {'loss': 0.6476, 'learning_rate': 6.25462421340175e-07, 'epoch': 0.89}
 89%|████████▉ | 2222/2496 [15:43:27<1:54:50, 25.15s/it] 89%|████████▉ | 2223/2496 [15:43:52<1:53:55, 25.04s/it]                                                        {'loss': 0.2417, 'learning_rate': 6.209530940899567e-07, 'epoch': 0.89}
 89%|████████▉ | 2223/2496 [15:43:52<1:53:55, 25.04s/it] 89%|████████▉ | 2224/2496 [15:44:18<1:54:54, 25.35s/it]                                                        {'loss': 0.6624, 'learning_rate': 6.164595599916712e-07, 'epoch': 0.89}
 89%|████████▉ | 2224/2496 [15:44:18<1:54:54, 25.35s/it] 89%|████████▉ | 2225/2496 [15:44:44<1:55:07, 25.49s/it]                                                        {'loss': 0.6789, 'learning_rate': 6.11981826611876e-07, 'epoch': 0.89}
 89%|████████▉ | 2225/2496 [15:44:44<1:55:07, 25.49s/it] 89%|████████▉ | 2226/2496 [15:45:10<1:56:02, 25.79s/it]                                                        {'loss': 0.6802, 'learning_rate': 6.075199014905153e-07, 'epoch': 0.89}
 89%|████████▉ | 2226/2496 [15:45:10<1:56:02, 25.79s/it] 89%|████████▉ | 2227/2496 [15:45:35<1:54:31, 25.55s/it]                                                        {'loss': 0.6732, 'learning_rate': 6.030737921409169e-07, 'epoch': 0.89}
 89%|████████▉ | 2227/2496 [15:45:35<1:54:31, 25.55s/it] 89%|████████▉ | 2228/2496 [15:46:02<1:55:23, 25.84s/it]                                                        {'loss': 0.652, 'learning_rate': 5.986435060497797e-07, 'epoch': 0.89}
 89%|████████▉ | 2228/2496 [15:46:02<1:55:23, 25.84s/it] 89%|████████▉ | 2229/2496 [15:46:28<1:55:05, 25.86s/it]                                                        {'loss': 0.6516, 'learning_rate': 5.942290506771565e-07, 'epoch': 0.89}
 89%|████████▉ | 2229/2496 [15:46:28<1:55:05, 25.86s/it] 89%|████████▉ | 2230/2496 [15:46:53<1:54:08, 25.75s/it]                                                        {'loss': 0.662, 'learning_rate': 5.898304334564409e-07, 'epoch': 0.89}
 89%|████████▉ | 2230/2496 [15:46:53<1:54:08, 25.75s/it] 89%|████████▉ | 2231/2496 [15:47:20<1:55:45, 26.21s/it]                                                        {'loss': 0.6732, 'learning_rate': 5.854476617943606e-07, 'epoch': 0.89}
 89%|████████▉ | 2231/2496 [15:47:20<1:55:45, 26.21s/it] 89%|████████▉ | 2232/2496 [15:47:48<1:57:11, 26.64s/it]                                                        {'loss': 0.6835, 'learning_rate': 5.810807430709597e-07, 'epoch': 0.89}
 89%|████████▉ | 2232/2496 [15:47:48<1:57:11, 26.64s/it] 89%|████████▉ | 2233/2496 [15:48:13<1:54:12, 26.05s/it]                                                        {'loss': 0.6803, 'learning_rate': 5.767296846395854e-07, 'epoch': 0.89}
 89%|████████▉ | 2233/2496 [15:48:13<1:54:12, 26.05s/it] 90%|████████▉ | 2234/2496 [15:48:39<1:54:04, 26.12s/it]                                                        {'loss': 0.6237, 'learning_rate': 5.72394493826881e-07, 'epoch': 0.89}
 90%|████████▉ | 2234/2496 [15:48:39<1:54:04, 26.12s/it] 90%|████████▉ | 2235/2496 [15:49:04<1:51:59, 25.75s/it]                                                        {'loss': 0.6767, 'learning_rate': 5.680751779327742e-07, 'epoch': 0.9}
 90%|████████▉ | 2235/2496 [15:49:04<1:51:59, 25.75s/it] 90%|████████▉ | 2236/2496 [15:49:28<1:48:50, 25.12s/it]                                                        {'loss': 0.6887, 'learning_rate': 5.637717442304513e-07, 'epoch': 0.9}
 90%|████████▉ | 2236/2496 [15:49:28<1:48:50, 25.12s/it] 90%|████████▉ | 2237/2496 [15:49:51<1:45:42, 24.49s/it]                                                        {'loss': 0.6914, 'learning_rate': 5.594841999663659e-07, 'epoch': 0.9}
 90%|████████▉ | 2237/2496 [15:49:51<1:45:42, 24.49s/it] 90%|████████▉ | 2238/2496 [15:50:14<1:44:30, 24.30s/it]                                                        {'loss': 0.6606, 'learning_rate': 5.552125523602092e-07, 'epoch': 0.9}
 90%|████████▉ | 2238/2496 [15:50:14<1:44:30, 24.30s/it] 90%|████████▉ | 2239/2496 [15:50:43<1:49:47, 25.63s/it]                                                        {'loss': 0.6789, 'learning_rate': 5.509568086049066e-07, 'epoch': 0.9}
 90%|████████▉ | 2239/2496 [15:50:43<1:49:47, 25.63s/it] 90%|████████▉ | 2240/2496 [15:51:07<1:47:28, 25.19s/it]                                                        {'loss': 0.6821, 'learning_rate': 5.467169758666002e-07, 'epoch': 0.9}
 90%|████████▉ | 2240/2496 [15:51:07<1:47:28, 25.19s/it] 90%|████████▉ | 2241/2496 [15:51:33<1:47:10, 25.22s/it]                                                        {'loss': 0.2369, 'learning_rate': 5.424930612846468e-07, 'epoch': 0.9}
 90%|████████▉ | 2241/2496 [15:51:33<1:47:10, 25.22s/it] 90%|████████▉ | 2242/2496 [15:52:02<1:52:19, 26.53s/it]                                                        {'loss': 0.6527, 'learning_rate': 5.382850719715905e-07, 'epoch': 0.9}
 90%|████████▉ | 2242/2496 [15:52:02<1:52:19, 26.53s/it] 90%|████████▉ | 2243/2496 [15:52:26<1:48:30, 25.73s/it]                                                        {'loss': 0.7131, 'learning_rate': 5.340930150131662e-07, 'epoch': 0.9}
 90%|████████▉ | 2243/2496 [15:52:26<1:48:30, 25.73s/it] 90%|████████▉ | 2244/2496 [15:52:52<1:48:08, 25.75s/it]                                                        {'loss': 0.6863, 'learning_rate': 5.299168974682789e-07, 'epoch': 0.9}
 90%|████████▉ | 2244/2496 [15:52:52<1:48:08, 25.75s/it] 90%|████████▉ | 2245/2496 [15:53:16<1:45:20, 25.18s/it]                                                        {'loss': 0.6639, 'learning_rate': 5.2575672636899e-07, 'epoch': 0.9}
 90%|████████▉ | 2245/2496 [15:53:16<1:45:20, 25.18s/it] 90%|████████▉ | 2246/2496 [15:53:40<1:43:23, 24.82s/it]                                                        {'loss': 0.6756, 'learning_rate': 5.216125087205115e-07, 'epoch': 0.9}
 90%|████████▉ | 2246/2496 [15:53:40<1:43:23, 24.82s/it] 90%|█████████ | 2247/2496 [15:54:06<1:45:25, 25.40s/it]                                                        {'loss': 0.653, 'learning_rate': 5.174842515011946e-07, 'epoch': 0.9}
 90%|█████████ | 2247/2496 [15:54:06<1:45:25, 25.40s/it]this iter is wrong in something... skip...
 90%|█████████ | 2248/2496 [15:54:34<1:47:09, 25.92s/it]                                                        {'loss': 0.6509, 'learning_rate': 5.13371961662511e-07, 'epoch': 0.9}
 90%|█████████ | 2248/2496 [15:54:34<1:47:09, 25.92s/it] 90%|█████████ | 2249/2496 [15:54:58<1:44:23, 25.36s/it]                                                        {'loss': 0.6385, 'learning_rate': 5.092756461290482e-07, 'epoch': 0.9}
 90%|█████████ | 2249/2496 [15:54:58<1:44:23, 25.36s/it] 90%|█████████ | 2250/2496 [15:55:23<1:43:55, 25.35s/it]                                                        {'loss': 0.6808, 'learning_rate': 5.05195311798491e-07, 'epoch': 0.9}
 90%|█████████ | 2250/2496 [15:55:23<1:43:55, 25.35s/it] 90%|█████████ | 2251/2496 [15:55:53<1:48:43, 26.63s/it]                                                        {'loss': 0.6573, 'learning_rate': 5.011309655416197e-07, 'epoch': 0.9}
 90%|█████████ | 2251/2496 [15:55:53<1:48:43, 26.63s/it] 90%|█████████ | 2252/2496 [15:56:17<1:46:00, 26.07s/it]                                                        {'loss': 0.6675, 'learning_rate': 4.970826142022856e-07, 'epoch': 0.9}
 90%|█████████ | 2252/2496 [15:56:17<1:46:00, 26.07s/it] 90%|█████████ | 2253/2496 [15:56:41<1:42:29, 25.31s/it]                                                        {'loss': 0.6655, 'learning_rate': 4.930502645974122e-07, 'epoch': 0.9}
 90%|█████████ | 2253/2496 [15:56:41<1:42:29, 25.31s/it] 90%|█████████ | 2254/2496 [15:57:09<1:45:03, 26.05s/it]                                                        {'loss': 0.6822, 'learning_rate': 4.890339235169783e-07, 'epoch': 0.9}
 90%|█████████ | 2254/2496 [15:57:09<1:45:03, 26.05s/it] 90%|█████████ | 2255/2496 [15:57:33<1:42:41, 25.57s/it]                                                        {'loss': 0.6618, 'learning_rate': 4.850335977240028e-07, 'epoch': 0.9}
 90%|█████████ | 2255/2496 [15:57:33<1:42:41, 25.57s/it]this iter is wrong in something... skip...
 90%|█████████ | 2256/2496 [15:57:57<1:40:37, 25.16s/it]                                                        {'loss': 0.6683, 'learning_rate': 4.810492939545341e-07, 'epoch': 0.9}
 90%|█████████ | 2256/2496 [15:57:57<1:40:37, 25.16s/it] 90%|█████████ | 2257/2496 [15:58:21<1:38:53, 24.83s/it]                                                        {'loss': 0.6539, 'learning_rate': 4.770810189176522e-07, 'epoch': 0.9}
 90%|█████████ | 2257/2496 [15:58:21<1:38:53, 24.83s/it] 90%|█████████ | 2258/2496 [15:58:46<1:38:18, 24.78s/it]                                                        {'loss': 0.6728, 'learning_rate': 4.7312877929543754e-07, 'epoch': 0.9}
 90%|█████████ | 2258/2496 [15:58:46<1:38:18, 24.78s/it] 91%|█████████ | 2259/2496 [15:59:11<1:37:59, 24.81s/it]                                                        {'loss': 0.6694, 'learning_rate': 4.691925817429699e-07, 'epoch': 0.9}
 91%|█████████ | 2259/2496 [15:59:11<1:37:59, 24.81s/it]this iter is wrong in something... skip...
 91%|█████████ | 2260/2496 [15:59:37<1:38:49, 25.12s/it]                                                        {'loss': 0.6852, 'learning_rate': 4.652724328883207e-07, 'epoch': 0.91}
 91%|█████████ | 2260/2496 [15:59:37<1:38:49, 25.12s/it] 91%|█████████ | 2261/2496 [16:00:03<1:39:38, 25.44s/it]                                                        {'loss': 0.6656, 'learning_rate': 4.6136833933253075e-07, 'epoch': 0.91}
 91%|█████████ | 2261/2496 [16:00:03<1:39:38, 25.44s/it] 91%|█████████ | 2262/2496 [16:00:28<1:38:20, 25.22s/it]                                                        {'loss': 0.6681, 'learning_rate': 4.574803076496148e-07, 'epoch': 0.91}
 91%|█████████ | 2262/2496 [16:00:28<1:38:20, 25.22s/it] 91%|█████████ | 2263/2496 [16:00:56<1:41:43, 26.19s/it]                                                        {'loss': 0.6474, 'learning_rate': 4.536083443865302e-07, 'epoch': 0.91}
 91%|█████████ | 2263/2496 [16:00:56<1:41:43, 26.19s/it] 91%|█████████ | 2264/2496 [16:01:22<1:40:29, 25.99s/it]                                                        {'loss': 0.6617, 'learning_rate': 4.497524560631883e-07, 'epoch': 0.91}
 91%|█████████ | 2264/2496 [16:01:22<1:40:29, 25.99s/it] 91%|█████████ | 2265/2496 [16:01:47<1:39:25, 25.83s/it]                                                        {'loss': 0.671, 'learning_rate': 4.4591264917242195e-07, 'epoch': 0.91}
 91%|█████████ | 2265/2496 [16:01:47<1:39:25, 25.83s/it] 91%|█████████ | 2266/2496 [16:02:12<1:37:56, 25.55s/it]                                                        {'loss': 0.6642, 'learning_rate': 4.4208893017999243e-07, 'epoch': 0.91}
 91%|█████████ | 2266/2496 [16:02:12<1:37:56, 25.55s/it] 91%|█████████ | 2267/2496 [16:02:36<1:35:19, 24.98s/it]                                                        {'loss': 0.6572, 'learning_rate': 4.3828130552457047e-07, 'epoch': 0.91}
 91%|█████████ | 2267/2496 [16:02:36<1:35:19, 24.98s/it] 91%|█████████ | 2268/2496 [16:03:03<1:37:48, 25.74s/it]                                                        {'loss': 0.6677, 'learning_rate': 4.344897816177207e-07, 'epoch': 0.91}
 91%|█████████ | 2268/2496 [16:03:03<1:37:48, 25.74s/it] 91%|█████████ | 2269/2496 [16:03:29<1:37:20, 25.73s/it]                                                        {'loss': 0.6591, 'learning_rate': 4.3071436484389826e-07, 'epoch': 0.91}
 91%|█████████ | 2269/2496 [16:03:29<1:37:20, 25.73s/it] 91%|█████████ | 2270/2496 [16:03:55<1:37:20, 25.84s/it]                                                        {'loss': 0.7015, 'learning_rate': 4.269550615604401e-07, 'epoch': 0.91}
 91%|█████████ | 2270/2496 [16:03:55<1:37:20, 25.84s/it] 91%|█████████ | 2271/2496 [16:04:19<1:34:41, 25.25s/it]                                                        {'loss': 0.651, 'learning_rate': 4.232118780975447e-07, 'epoch': 0.91}
 91%|█████████ | 2271/2496 [16:04:19<1:34:41, 25.25s/it] 91%|█████████ | 2272/2496 [16:04:44<1:34:21, 25.27s/it]                                                        {'loss': 0.6694, 'learning_rate': 4.1948482075826914e-07, 'epoch': 0.91}
 91%|█████████ | 2272/2496 [16:04:44<1:34:21, 25.27s/it] 91%|█████████ | 2273/2496 [16:05:11<1:35:50, 25.79s/it]                                                        {'loss': 0.6425, 'learning_rate': 4.1577389581851644e-07, 'epoch': 0.91}
 91%|█████████ | 2273/2496 [16:05:11<1:35:50, 25.79s/it] 91%|█████████ | 2274/2496 [16:05:37<1:35:17, 25.76s/it]                                                        {'loss': 0.6947, 'learning_rate': 4.120791095270249e-07, 'epoch': 0.91}
 91%|█████████ | 2274/2496 [16:05:37<1:35:17, 25.76s/it] 91%|█████████ | 2275/2496 [16:06:04<1:36:01, 26.07s/it]                                                        {'loss': 0.6543, 'learning_rate': 4.0840046810535325e-07, 'epoch': 0.91}
 91%|█████████ | 2275/2496 [16:06:04<1:36:01, 26.07s/it] 91%|█████████ | 2276/2496 [16:06:28<1:34:05, 25.66s/it]                                                        {'loss': 0.6662, 'learning_rate': 4.047379777478788e-07, 'epoch': 0.91}
 91%|█████████ | 2276/2496 [16:06:28<1:34:05, 25.66s/it] 91%|█████████ | 2277/2496 [16:06:56<1:36:05, 26.32s/it]                                                        {'loss': 0.6625, 'learning_rate': 4.0109164462178384e-07, 'epoch': 0.91}
 91%|█████████ | 2277/2496 [16:06:56<1:36:05, 26.32s/it] 91%|█████████▏| 2278/2496 [16:07:22<1:35:10, 26.19s/it]                                                        {'loss': 0.6359, 'learning_rate': 3.97461474867038e-07, 'epoch': 0.91}
 91%|█████████▏| 2278/2496 [16:07:22<1:35:10, 26.19s/it] 91%|█████████▏| 2279/2496 [16:07:49<1:35:33, 26.42s/it]                                                        {'loss': 0.6423, 'learning_rate': 3.9384747459639827e-07, 'epoch': 0.91}
 91%|█████████▏| 2279/2496 [16:07:49<1:35:33, 26.42s/it] 91%|█████████▏| 2280/2496 [16:08:14<1:33:25, 25.95s/it]                                                        {'loss': 0.2399, 'learning_rate': 3.9024964989539227e-07, 'epoch': 0.91}
 91%|█████████▏| 2280/2496 [16:08:14<1:33:25, 25.95s/it] 91%|█████████▏| 2281/2496 [16:08:41<1:33:51, 26.19s/it]                                                        {'loss': 0.6565, 'learning_rate': 3.8666800682231274e-07, 'epoch': 0.91}
 91%|█████████▏| 2281/2496 [16:08:41<1:33:51, 26.19s/it] 91%|█████████▏| 2282/2496 [16:09:05<1:31:52, 25.76s/it]                                                        {'loss': 0.678, 'learning_rate': 3.8310255140819875e-07, 'epoch': 0.91}
 91%|█████████▏| 2282/2496 [16:09:05<1:31:52, 25.76s/it] 91%|█████████▏| 2283/2496 [16:09:30<1:29:50, 25.31s/it]                                                        {'loss': 0.6285, 'learning_rate': 3.795532896568388e-07, 'epoch': 0.91}
 91%|█████████▏| 2283/2496 [16:09:30<1:29:50, 25.31s/it] 92%|█████████▏| 2284/2496 [16:09:55<1:29:07, 25.22s/it]                                                        {'loss': 0.6317, 'learning_rate': 3.760202275447478e-07, 'epoch': 0.91}
 92%|█████████▏| 2284/2496 [16:09:55<1:29:07, 25.22s/it] 92%|█████████▏| 2285/2496 [16:10:19<1:27:52, 24.99s/it]                                                        {'loss': 0.6448, 'learning_rate': 3.725033710211623e-07, 'epoch': 0.92}
 92%|█████████▏| 2285/2496 [16:10:19<1:27:52, 24.99s/it] 92%|█████████▏| 2286/2496 [16:10:45<1:28:31, 25.29s/it]                                                        {'loss': 0.6371, 'learning_rate': 3.6900272600803646e-07, 'epoch': 0.92}
 92%|█████████▏| 2286/2496 [16:10:45<1:28:31, 25.29s/it] 92%|█████████▏| 2287/2496 [16:11:10<1:27:27, 25.11s/it]                                                        {'loss': 0.2267, 'learning_rate': 3.655182984000205e-07, 'epoch': 0.92}
 92%|█████████▏| 2287/2496 [16:11:10<1:27:27, 25.11s/it]this iter is wrong in something... skip...
 92%|█████████▏| 2288/2496 [16:11:34<1:25:33, 24.68s/it]                                                        {'loss': 0.659, 'learning_rate': 3.620500940644578e-07, 'epoch': 0.92}
 92%|█████████▏| 2288/2496 [16:11:34<1:25:33, 24.68s/it] 92%|█████████▏| 2289/2496 [16:11:59<1:25:33, 24.80s/it]                                                        {'loss': 0.7114, 'learning_rate': 3.585981188413767e-07, 'epoch': 0.92}
 92%|█████████▏| 2289/2496 [16:11:59<1:25:33, 24.80s/it] 92%|█████████▏| 2290/2496 [16:12:22<1:24:12, 24.53s/it]                                                        {'loss': 0.6228, 'learning_rate': 3.551623785434721e-07, 'epoch': 0.92}
 92%|█████████▏| 2290/2496 [16:12:22<1:24:12, 24.53s/it] 92%|█████████▏| 2291/2496 [16:12:46<1:23:16, 24.37s/it]                                                        {'loss': 0.7163, 'learning_rate': 3.5174287895610724e-07, 'epoch': 0.92}
 92%|█████████▏| 2291/2496 [16:12:47<1:23:16, 24.37s/it] 92%|█████████▏| 2292/2496 [16:13:12<1:24:15, 24.78s/it]                                                        {'loss': 0.659, 'learning_rate': 3.483396258372929e-07, 'epoch': 0.92}
 92%|█████████▏| 2292/2496 [16:13:12<1:24:15, 24.78s/it] 92%|█████████▏| 2293/2496 [16:13:38<1:24:46, 25.06s/it]                                                        {'loss': 0.6402, 'learning_rate': 3.4495262491768933e-07, 'epoch': 0.92}
 92%|█████████▏| 2293/2496 [16:13:38<1:24:46, 25.06s/it] 92%|█████████▏| 2294/2496 [16:14:03<1:24:27, 25.09s/it]                                                        {'loss': 0.6498, 'learning_rate': 3.4158188190058117e-07, 'epoch': 0.92}
 92%|█████████▏| 2294/2496 [16:14:03<1:24:27, 25.09s/it] 92%|█████████▏| 2295/2496 [16:14:27<1:23:14, 24.85s/it]                                                        {'loss': 0.6428, 'learning_rate': 3.3822740246188477e-07, 'epoch': 0.92}
 92%|█████████▏| 2295/2496 [16:14:27<1:23:14, 24.85s/it] 92%|█████████▏| 2296/2496 [16:14:53<1:23:29, 25.05s/it]                                                        {'loss': 0.6311, 'learning_rate': 3.348891922501274e-07, 'epoch': 0.92}
 92%|█████████▏| 2296/2496 [16:14:53<1:23:29, 25.05s/it] 92%|█████████▏| 2297/2496 [16:15:19<1:24:12, 25.39s/it]                                                        {'loss': 0.6573, 'learning_rate': 3.315672568864414e-07, 'epoch': 0.92}
 92%|█████████▏| 2297/2496 [16:15:19<1:24:12, 25.39s/it] 92%|█████████▏| 2298/2496 [16:15:45<1:24:08, 25.50s/it]                                                        {'loss': 0.6928, 'learning_rate': 3.2826160196455124e-07, 'epoch': 0.92}
 92%|█████████▏| 2298/2496 [16:15:45<1:24:08, 25.50s/it] 92%|█████████▏| 2299/2496 [16:16:11<1:24:38, 25.78s/it]                                                        {'loss': 0.6709, 'learning_rate': 3.249722330507721e-07, 'epoch': 0.92}
 92%|█████████▏| 2299/2496 [16:16:11<1:24:38, 25.78s/it] 92%|█████████▏| 2300/2496 [16:16:37<1:24:10, 25.77s/it]                                                        {'loss': 0.6767, 'learning_rate': 3.216991556839932e-07, 'epoch': 0.92}
 92%|█████████▏| 2300/2496 [16:16:37<1:24:10, 25.77s/it] 92%|█████████▏| 2301/2496 [16:17:05<1:25:52, 26.43s/it]                                                        {'loss': 0.6247, 'learning_rate': 3.184423753756716e-07, 'epoch': 0.92}
 92%|█████████▏| 2301/2496 [16:17:05<1:25:52, 26.43s/it] 92%|█████████▏| 2302/2496 [16:17:28<1:22:13, 25.43s/it]                                                        {'loss': 0.6617, 'learning_rate': 3.1520189760982033e-07, 'epoch': 0.92}
 92%|█████████▏| 2302/2496 [16:17:28<1:22:13, 25.43s/it] 92%|█████████▏| 2303/2496 [16:17:55<1:23:01, 25.81s/it]                                                        {'loss': 0.6157, 'learning_rate': 3.1197772784300253e-07, 'epoch': 0.92}
 92%|█████████▏| 2303/2496 [16:17:55<1:23:01, 25.81s/it] 92%|█████████▏| 2304/2496 [16:18:20<1:22:25, 25.76s/it]                                                        {'loss': 0.6904, 'learning_rate': 3.087698715043186e-07, 'epoch': 0.92}
 92%|█████████▏| 2304/2496 [16:18:20<1:22:25, 25.76s/it] 92%|█████████▏| 2305/2496 [16:18:46<1:22:18, 25.86s/it]                                                        {'loss': 0.6517, 'learning_rate': 3.0557833399540326e-07, 'epoch': 0.92}
 92%|█████████▏| 2305/2496 [16:18:46<1:22:18, 25.86s/it] 92%|█████████▏| 2306/2496 [16:19:11<1:20:50, 25.53s/it]                                                        {'loss': 0.616, 'learning_rate': 3.024031206904099e-07, 'epoch': 0.92}
 92%|█████████▏| 2306/2496 [16:19:11<1:20:50, 25.53s/it] 92%|█████████▏| 2307/2496 [16:19:37<1:20:44, 25.63s/it]                                                        {'loss': 0.6608, 'learning_rate': 2.9924423693600157e-07, 'epoch': 0.92}
 92%|█████████▏| 2307/2496 [16:19:37<1:20:44, 25.63s/it] 92%|█████████▏| 2308/2496 [16:20:02<1:19:30, 25.38s/it]                                                        {'loss': 0.6845, 'learning_rate': 2.961016880513501e-07, 'epoch': 0.92}
 92%|█████████▏| 2308/2496 [16:20:02<1:19:30, 25.38s/it] 93%|█████████▎| 2309/2496 [16:20:27<1:18:47, 25.28s/it]                                                        {'loss': 0.6803, 'learning_rate': 2.9297547932811476e-07, 'epoch': 0.92}
 93%|█████████▎| 2309/2496 [16:20:27<1:18:47, 25.28s/it] 93%|█████████▎| 2310/2496 [16:20:51<1:16:59, 24.84s/it]                                                        {'loss': 0.6351, 'learning_rate': 2.8986561603044694e-07, 'epoch': 0.93}
 93%|█████████▎| 2310/2496 [16:20:51<1:16:59, 24.84s/it] 93%|█████████▎| 2311/2496 [16:21:16<1:17:19, 25.08s/it]                                                        {'loss': 0.6656, 'learning_rate': 2.867721033949666e-07, 'epoch': 0.93}
 93%|█████████▎| 2311/2496 [16:21:16<1:17:19, 25.08s/it] 93%|█████████▎| 2312/2496 [16:21:41<1:16:25, 24.92s/it]                                                        {'loss': 0.6713, 'learning_rate': 2.8369494663076925e-07, 'epoch': 0.93}
 93%|█████████▎| 2312/2496 [16:21:41<1:16:25, 24.92s/it] 93%|█████████▎| 2313/2496 [16:22:05<1:14:47, 24.52s/it]                                                        {'loss': 0.6433, 'learning_rate': 2.806341509194022e-07, 'epoch': 0.93}
 93%|█████████▎| 2313/2496 [16:22:05<1:14:47, 24.52s/it] 93%|█████████▎| 2314/2496 [16:22:33<1:17:35, 25.58s/it]                                                        {'loss': 0.685, 'learning_rate': 2.775897214148671e-07, 'epoch': 0.93}
 93%|█████████▎| 2314/2496 [16:22:33<1:17:35, 25.58s/it] 93%|█████████▎| 2315/2496 [16:22:57<1:16:31, 25.37s/it]                                                        {'loss': 0.2417, 'learning_rate': 2.7456166324360767e-07, 'epoch': 0.93}
 93%|█████████▎| 2315/2496 [16:22:57<1:16:31, 25.37s/it] 93%|█████████▎| 2316/2496 [16:23:23<1:16:39, 25.55s/it]                                                        {'loss': 0.6728, 'learning_rate': 2.7154998150449643e-07, 'epoch': 0.93}
 93%|█████████▎| 2316/2496 [16:23:23<1:16:39, 25.55s/it] 93%|█████████▎| 2317/2496 [16:23:49<1:16:21, 25.59s/it]                                                        {'loss': 0.6715, 'learning_rate': 2.685546812688311e-07, 'epoch': 0.93}
 93%|█████████▎| 2317/2496 [16:23:49<1:16:21, 25.59s/it] 93%|█████████▎| 2318/2496 [16:24:15<1:16:23, 25.75s/it]                                                        {'loss': 0.6671, 'learning_rate': 2.6557576758032723e-07, 'epoch': 0.93}
 93%|█████████▎| 2318/2496 [16:24:15<1:16:23, 25.75s/it] 93%|█████████▎| 2319/2496 [16:24:45<1:19:46, 27.04s/it]                                                        {'loss': 0.6762, 'learning_rate': 2.626132454551067e-07, 'epoch': 0.93}
 93%|█████████▎| 2319/2496 [16:24:45<1:19:46, 27.04s/it]this iter is wrong in something... skip...
 93%|█████████▎| 2320/2496 [16:25:11<1:17:55, 26.57s/it]                                                        {'loss': 0.6691, 'learning_rate': 2.59667119881688e-07, 'epoch': 0.93}
 93%|█████████▎| 2320/2496 [16:25:11<1:17:55, 26.57s/it] 93%|█████████▎| 2321/2496 [16:25:35<1:15:07, 25.76s/it]                                                        {'loss': 0.63, 'learning_rate': 2.567373958209807e-07, 'epoch': 0.93}
 93%|█████████▎| 2321/2496 [16:25:35<1:15:07, 25.76s/it]this iter is wrong in something... skip...
this iter is wrong in something... skip...
 93%|█████████▎| 2322/2496 [16:26:02<1:16:20, 26.33s/it]                                                        {'loss': 0.6731, 'learning_rate': 2.538240782062784e-07, 'epoch': 0.93}
 93%|█████████▎| 2322/2496 [16:26:02<1:16:20, 26.33s/it] 93%|█████████▎| 2323/2496 [16:26:27<1:14:40, 25.90s/it]                                                        {'loss': 0.2512, 'learning_rate': 2.50927171943246e-07, 'epoch': 0.93}
 93%|█████████▎| 2323/2496 [16:26:27<1:14:40, 25.90s/it]this iter is wrong in something... skip...
 93%|█████████▎| 2324/2496 [16:26:52<1:13:30, 25.65s/it]                                                        {'loss': 0.6345, 'learning_rate': 2.4804668190991475e-07, 'epoch': 0.93}
 93%|█████████▎| 2324/2496 [16:26:52<1:13:30, 25.65s/it] 93%|█████████▎| 2325/2496 [16:27:18<1:13:09, 25.67s/it]                                                        {'loss': 0.6627, 'learning_rate': 2.4518261295667255e-07, 'epoch': 0.93}
 93%|█████████▎| 2325/2496 [16:27:18<1:13:09, 25.67s/it] 93%|█████████▎| 2326/2496 [16:27:43<1:12:03, 25.43s/it]                                                        {'loss': 0.6686, 'learning_rate': 2.4233496990625717e-07, 'epoch': 0.93}
 93%|█████████▎| 2326/2496 [16:27:43<1:12:03, 25.43s/it] 93%|█████████▎| 2327/2496 [16:28:07<1:10:30, 25.03s/it]                                                        {'loss': 0.649, 'learning_rate': 2.39503757553744e-07, 'epoch': 0.93}
 93%|█████████▎| 2327/2496 [16:28:07<1:10:30, 25.03s/it] 93%|█████████▎| 2328/2496 [16:28:33<1:10:52, 25.32s/it]                                                        {'loss': 0.6675, 'learning_rate': 2.3668898066654512e-07, 'epoch': 0.93}
 93%|█████████▎| 2328/2496 [16:28:33<1:10:52, 25.32s/it] 93%|█████████▎| 2329/2496 [16:28:58<1:10:00, 25.15s/it]                                                        {'loss': 0.6711, 'learning_rate': 2.3389064398439577e-07, 'epoch': 0.93}
 93%|█████████▎| 2329/2496 [16:28:58<1:10:00, 25.15s/it] 93%|█████████▎| 2330/2496 [16:29:24<1:10:26, 25.46s/it]                                                        {'loss': 0.6775, 'learning_rate': 2.3110875221934782e-07, 'epoch': 0.93}
 93%|█████████▎| 2330/2496 [16:29:24<1:10:26, 25.46s/it] 93%|█████████▎| 2331/2496 [16:29:48<1:09:08, 25.14s/it]                                                        {'loss': 0.678, 'learning_rate': 2.2834331005576305e-07, 'epoch': 0.93}
 93%|█████████▎| 2331/2496 [16:29:48<1:09:08, 25.14s/it] 93%|█████████▎| 2332/2496 [16:30:14<1:08:56, 25.22s/it]                                                        {'loss': 0.6869, 'learning_rate': 2.2559432215030097e-07, 'epoch': 0.93}
 93%|█████████▎| 2332/2496 [16:30:14<1:08:56, 25.22s/it] 93%|█████████▎| 2333/2496 [16:30:40<1:09:41, 25.65s/it]                                                        {'loss': 0.7117, 'learning_rate': 2.228617931319177e-07, 'epoch': 0.93}
 93%|█████████▎| 2333/2496 [16:30:40<1:09:41, 25.65s/it] 94%|█████████▎| 2334/2496 [16:31:05<1:08:39, 25.43s/it]                                                        {'loss': 0.649, 'learning_rate': 2.201457276018526e-07, 'epoch': 0.93}
 94%|█████████▎| 2334/2496 [16:31:05<1:08:39, 25.43s/it] 94%|█████████▎| 2335/2496 [16:31:30<1:07:54, 25.31s/it]                                                        {'loss': 0.6762, 'learning_rate': 2.1744613013362503e-07, 'epoch': 0.94}
 94%|█████████▎| 2335/2496 [16:31:30<1:07:54, 25.31s/it] 94%|█████████▎| 2336/2496 [16:31:54<1:06:26, 24.92s/it]                                                        {'loss': 0.6643, 'learning_rate': 2.1476300527301875e-07, 'epoch': 0.94}
 94%|█████████▎| 2336/2496 [16:31:54<1:06:26, 24.92s/it] 94%|█████████▎| 2337/2496 [16:32:20<1:07:03, 25.31s/it]                                                        {'loss': 0.6744, 'learning_rate': 2.1209635753808744e-07, 'epoch': 0.94}
 94%|█████████▎| 2337/2496 [16:32:20<1:07:03, 25.31s/it] 94%|█████████▎| 2338/2496 [16:32:46<1:06:33, 25.27s/it]                                                        {'loss': 0.6402, 'learning_rate': 2.094461914191326e-07, 'epoch': 0.94}
 94%|█████████▎| 2338/2496 [16:32:46<1:06:33, 25.27s/it] 94%|█████████▎| 2339/2496 [16:33:11<1:05:51, 25.17s/it]                                                        {'loss': 0.6307, 'learning_rate': 2.0681251137870672e-07, 'epoch': 0.94}
 94%|█████████▎| 2339/2496 [16:33:11<1:05:51, 25.17s/it]this iter is wrong in something... skip...
 94%|█████████▍| 2340/2496 [16:33:39<1:07:39, 26.02s/it]                                                        {'loss': 0.6759, 'learning_rate': 2.0419532185159796e-07, 'epoch': 0.94}
 94%|█████████▍| 2340/2496 [16:33:39<1:07:39, 26.02s/it] 94%|█████████▍| 2341/2496 [16:34:03<1:06:16, 25.66s/it]                                                        {'loss': 0.6801, 'learning_rate': 2.0159462724483214e-07, 'epoch': 0.94}
 94%|█████████▍| 2341/2496 [16:34:03<1:06:16, 25.66s/it] 94%|█████████▍| 2342/2496 [16:34:28<1:05:13, 25.41s/it]                                                        {'loss': 0.6691, 'learning_rate': 1.9901043193765513e-07, 'epoch': 0.94}
 94%|█████████▍| 2342/2496 [16:34:28<1:05:13, 25.41s/it] 94%|█████████▍| 2343/2496 [16:34:53<1:04:37, 25.34s/it]                                                        {'loss': 0.2264, 'learning_rate': 1.9644274028152944e-07, 'epoch': 0.94}
 94%|█████████▍| 2343/2496 [16:34:53<1:04:37, 25.34s/it] 94%|█████████▍| 2344/2496 [16:35:19<1:04:27, 25.44s/it]                                                        {'loss': 0.6721, 'learning_rate': 1.9389155660013314e-07, 'epoch': 0.94}
 94%|█████████▍| 2344/2496 [16:35:19<1:04:27, 25.44s/it] 94%|█████████▍| 2345/2496 [16:35:44<1:03:23, 25.19s/it]                                                        {'loss': 0.6661, 'learning_rate': 1.9135688518934102e-07, 'epoch': 0.94}
 94%|█████████▍| 2345/2496 [16:35:44<1:03:23, 25.19s/it] 94%|█████████▍| 2346/2496 [16:36:09<1:02:45, 25.10s/it]                                                        {'loss': 0.6586, 'learning_rate': 1.8883873031722455e-07, 'epoch': 0.94}
 94%|█████████▍| 2346/2496 [16:36:09<1:02:45, 25.10s/it] 94%|█████████▍| 2347/2496 [16:36:32<1:00:54, 24.52s/it]                                                        {'loss': 0.6736, 'learning_rate': 1.863370962240463e-07, 'epoch': 0.94}
 94%|█████████▍| 2347/2496 [16:36:32<1:00:54, 24.52s/it] 94%|█████████▍| 2348/2496 [16:36:57<1:01:11, 24.81s/it]                                                        {'loss': 0.6455, 'learning_rate': 1.838519871222466e-07, 'epoch': 0.94}
 94%|█████████▍| 2348/2496 [16:36:57<1:01:11, 24.81s/it] 94%|█████████▍| 2349/2496 [16:37:22<1:00:52, 24.85s/it]                                                        {'loss': 0.6976, 'learning_rate': 1.8138340719644266e-07, 'epoch': 0.94}
 94%|█████████▍| 2349/2496 [16:37:22<1:00:52, 24.85s/it] 94%|█████████▍| 2350/2496 [16:37:47<1:00:13, 24.75s/it]                                                        {'loss': 0.6581, 'learning_rate': 1.7893136060341376e-07, 'epoch': 0.94}
 94%|█████████▍| 2350/2496 [16:37:47<1:00:13, 24.75s/it] 94%|█████████▍| 2351/2496 [16:38:13<1:00:43, 25.13s/it]                                                        {'loss': 0.6243, 'learning_rate': 1.7649585147210491e-07, 'epoch': 0.94}
 94%|█████████▍| 2351/2496 [16:38:13<1:00:43, 25.13s/it] 94%|█████████▍| 2352/2496 [16:38:39<1:01:22, 25.57s/it]                                                        {'loss': 0.6986, 'learning_rate': 1.740768839036111e-07, 'epoch': 0.94}
 94%|█████████▍| 2352/2496 [16:38:39<1:01:22, 25.57s/it] 94%|█████████▍| 2353/2496 [16:39:05<1:01:06, 25.64s/it]                                                        {'loss': 0.6692, 'learning_rate': 1.7167446197117188e-07, 'epoch': 0.94}
 94%|█████████▍| 2353/2496 [16:39:05<1:01:06, 25.64s/it] 94%|█████████▍| 2354/2496 [16:39:30<1:00:02, 25.37s/it]                                                        {'loss': 0.6805, 'learning_rate': 1.6928858972017125e-07, 'epoch': 0.94}
 94%|█████████▍| 2354/2496 [16:39:30<1:00:02, 25.37s/it] 94%|█████████▍| 2355/2496 [16:39:55<59:43, 25.41s/it]                                                        {'loss': 0.6815, 'learning_rate': 1.6691927116812002e-07, 'epoch': 0.94}
 94%|█████████▍| 2355/2496 [16:39:55<59:43, 25.41s/it] 94%|█████████▍| 2356/2496 [16:40:21<59:21, 25.44s/it]                                                      {'loss': 0.6635, 'learning_rate': 1.6456651030465564e-07, 'epoch': 0.94}
 94%|█████████▍| 2356/2496 [16:40:21<59:21, 25.44s/it]this iter is wrong in something... skip...
 94%|█████████▍| 2357/2496 [16:40:47<59:27, 25.66s/it]                                                      {'loss': 0.6564, 'learning_rate': 1.622303110915391e-07, 'epoch': 0.94}
 94%|█████████▍| 2357/2496 [16:40:47<59:27, 25.66s/it] 94%|█████████▍| 2358/2496 [16:41:12<58:32, 25.45s/it]                                                      {'loss': 0.6466, 'learning_rate': 1.59910677462638e-07, 'epoch': 0.94}
 94%|█████████▍| 2358/2496 [16:41:12<58:32, 25.45s/it] 95%|█████████▍| 2359/2496 [16:41:39<59:11, 25.93s/it]                                                      {'loss': 0.6835, 'learning_rate': 1.5760761332392683e-07, 'epoch': 0.94}
 95%|█████████▍| 2359/2496 [16:41:39<59:11, 25.93s/it] 95%|█████████▍| 2360/2496 [16:42:04<57:57, 25.57s/it]                                                      {'loss': 0.6485, 'learning_rate': 1.553211225534823e-07, 'epoch': 0.95}
 95%|█████████▍| 2360/2496 [16:42:04<57:57, 25.57s/it] 95%|█████████▍| 2361/2496 [16:42:31<58:48, 26.14s/it]                                                      {'loss': 0.6647, 'learning_rate': 1.5305120900146908e-07, 'epoch': 0.95}
 95%|█████████▍| 2361/2496 [16:42:31<58:48, 26.14s/it] 95%|█████████▍| 2362/2496 [16:43:00<1:00:09, 26.94s/it]                                                        {'loss': 0.6406, 'learning_rate': 1.5079787649014189e-07, 'epoch': 0.95}
 95%|█████████▍| 2362/2496 [16:43:00<1:00:09, 26.94s/it] 95%|█████████▍| 2363/2496 [16:43:24<57:53, 26.12s/it]                                                        {'loss': 0.6824, 'learning_rate': 1.485611288138322e-07, 'epoch': 0.95}
 95%|█████████▍| 2363/2496 [16:43:24<57:53, 26.12s/it] 95%|█████████▍| 2364/2496 [16:43:50<57:24, 26.10s/it]                                                      {'loss': 0.6499, 'learning_rate': 1.463409697389473e-07, 'epoch': 0.95}
 95%|█████████▍| 2364/2496 [16:43:50<57:24, 26.10s/it] 95%|█████████▍| 2365/2496 [16:44:14<55:21, 25.35s/it]                                                      {'loss': 0.6825, 'learning_rate': 1.4413740300395662e-07, 'epoch': 0.95}
 95%|█████████▍| 2365/2496 [16:44:14<55:21, 25.35s/it] 95%|█████████▍| 2366/2496 [16:44:38<54:09, 25.00s/it]                                                      {'loss': 0.6734, 'learning_rate': 1.4195043231939543e-07, 'epoch': 0.95}
 95%|█████████▍| 2366/2496 [16:44:38<54:09, 25.00s/it] 95%|█████████▍| 2367/2496 [16:45:04<54:22, 25.29s/it]                                                      {'loss': 0.6648, 'learning_rate': 1.397800613678524e-07, 'epoch': 0.95}
 95%|█████████▍| 2367/2496 [16:45:04<54:22, 25.29s/it] 95%|█████████▍| 2368/2496 [16:45:29<53:43, 25.19s/it]                                                      {'loss': 0.672, 'learning_rate': 1.3762629380396187e-07, 'epoch': 0.95}
 95%|█████████▍| 2368/2496 [16:45:29<53:43, 25.19s/it] 95%|█████████▍| 2369/2496 [16:45:56<54:10, 25.60s/it]                                                      {'loss': 0.672, 'learning_rate': 1.354891332543995e-07, 'epoch': 0.95}
 95%|█████████▍| 2369/2496 [16:45:56<54:10, 25.60s/it] 95%|█████████▍| 2370/2496 [16:46:27<57:32, 27.40s/it]                                                      {'loss': 0.6794, 'learning_rate': 1.3336858331787993e-07, 'epoch': 0.95}
 95%|█████████▍| 2370/2496 [16:46:27<57:32, 27.40s/it] 95%|█████████▍| 2371/2496 [16:46:53<56:01, 26.90s/it]                                                      {'loss': 0.6624, 'learning_rate': 1.31264647565148e-07, 'epoch': 0.95}
 95%|█████████▍| 2371/2496 [16:46:53<56:01, 26.90s/it] 95%|█████████▌| 2372/2496 [16:47:19<55:05, 26.66s/it]                                                      {'loss': 0.6473, 'learning_rate': 1.2917732953896867e-07, 'epoch': 0.95}
 95%|█████████▌| 2372/2496 [16:47:19<55:05, 26.66s/it] 95%|█████████▌| 2373/2496 [16:47:46<54:37, 26.65s/it]                                                      {'loss': 0.6669, 'learning_rate': 1.2710663275412705e-07, 'epoch': 0.95}
 95%|█████████▌| 2373/2496 [16:47:46<54:37, 26.65s/it] 95%|█████████▌| 2374/2496 [16:48:10<52:55, 26.03s/it]                                                      {'loss': 0.6676, 'learning_rate': 1.2505256069742066e-07, 'epoch': 0.95}
 95%|█████████▌| 2374/2496 [16:48:10<52:55, 26.03s/it] 95%|█████████▌| 2375/2496 [16:48:36<52:27, 26.02s/it]                                                      {'loss': 0.6575, 'learning_rate': 1.2301511682765055e-07, 'epoch': 0.95}
 95%|█████████▌| 2375/2496 [16:48:36<52:27, 26.02s/it]this iter is wrong in something... skip...
this iter is wrong in something... skip...
 95%|█████████▌| 2376/2496 [16:49:01<51:13, 25.61s/it]                                                      {'loss': 0.2379, 'learning_rate': 1.209943045756201e-07, 'epoch': 0.95}
 95%|█████████▌| 2376/2496 [16:49:01<51:13, 25.61s/it] 95%|█████████▌| 2377/2496 [16:49:25<49:51, 25.13s/it]                                                      {'loss': 0.7049, 'learning_rate': 1.1899012734412852e-07, 'epoch': 0.95}
 95%|█████████▌| 2377/2496 [16:49:25<49:51, 25.13s/it] 95%|█████████▌| 2378/2496 [16:49:50<49:16, 25.05s/it]                                                      {'loss': 0.237, 'learning_rate': 1.1700258850795843e-07, 'epoch': 0.95}
 95%|█████████▌| 2378/2496 [16:49:50<49:16, 25.05s/it] 95%|█████████▌| 2379/2496 [16:50:15<49:06, 25.18s/it]                                                      {'loss': 0.6417, 'learning_rate': 1.1503169141388049e-07, 'epoch': 0.95}
 95%|█████████▌| 2379/2496 [16:50:15<49:06, 25.18s/it] 95%|█████████▌| 2380/2496 [16:50:41<48:56, 25.32s/it]                                                      {'loss': 0.6478, 'learning_rate': 1.1307743938064109e-07, 'epoch': 0.95}
 95%|█████████▌| 2380/2496 [16:50:41<48:56, 25.32s/it] 95%|█████████▌| 2381/2496 [16:51:06<48:13, 25.16s/it]                                                      {'loss': 0.6464, 'learning_rate': 1.1113983569895791e-07, 'epoch': 0.95}
 95%|█████████▌| 2381/2496 [16:51:06<48:13, 25.16s/it] 95%|█████████▌| 2382/2496 [16:51:31<48:02, 25.29s/it]                                                      {'loss': 0.6716, 'learning_rate': 1.0921888363151556e-07, 'epoch': 0.95}
 95%|█████████▌| 2382/2496 [16:51:31<48:02, 25.29s/it]this iter is wrong in something... skip...
 95%|█████████▌| 2383/2496 [16:51:56<47:29, 25.22s/it]                                                      {'loss': 0.2426, 'learning_rate': 1.0731458641295989e-07, 'epoch': 0.95}
 95%|█████████▌| 2383/2496 [16:51:56<47:29, 25.22s/it] 96%|█████████▌| 2384/2496 [16:52:20<46:29, 24.91s/it]                                                      {'loss': 0.7, 'learning_rate': 1.0542694724988923e-07, 'epoch': 0.95}
 96%|█████████▌| 2384/2496 [16:52:21<46:29, 24.91s/it] 96%|█████████▌| 2385/2496 [16:52:45<45:34, 24.64s/it]                                                      {'loss': 0.6535, 'learning_rate': 1.0355596932085432e-07, 'epoch': 0.96}
 96%|█████████▌| 2385/2496 [16:52:45<45:34, 24.64s/it] 96%|█████████▌| 2386/2496 [16:53:11<45:56, 25.06s/it]                                                      {'loss': 0.6773, 'learning_rate': 1.0170165577635282e-07, 'epoch': 0.96}
 96%|█████████▌| 2386/2496 [16:53:11<45:56, 25.06s/it]this iter is wrong in something... skip...
 96%|█████████▌| 2387/2496 [16:53:34<44:40, 24.59s/it]                                                      {'loss': 0.6812, 'learning_rate': 9.986400973881593e-08, 'epoch': 0.96}
 96%|█████████▌| 2387/2496 [16:53:34<44:40, 24.59s/it] 96%|█████████▌| 2388/2496 [16:53:59<44:33, 24.75s/it]                                                      {'loss': 0.6704, 'learning_rate': 9.804303430261175e-08, 'epoch': 0.96}
 96%|█████████▌| 2388/2496 [16:53:59<44:33, 24.75s/it]this iter is wrong in something... skip...
 96%|█████████▌| 2389/2496 [16:54:24<44:26, 24.92s/it]                                                      {'loss': 0.6851, 'learning_rate': 9.623873253403748e-08, 'epoch': 0.96}
 96%|█████████▌| 2389/2496 [16:54:25<44:26, 24.92s/it] 96%|█████████▌| 2390/2496 [16:54:50<44:35, 25.24s/it]                                                      {'loss': 0.6375, 'learning_rate': 9.445110747131503e-08, 'epoch': 0.96}
 96%|█████████▌| 2390/2496 [16:54:51<44:35, 25.24s/it] 96%|█████████▌| 2391/2496 [16:55:16<44:18, 25.32s/it]                                                      {'loss': 0.6916, 'learning_rate': 9.268016212458097e-08, 'epoch': 0.96}
 96%|█████████▌| 2391/2496 [16:55:16<44:18, 25.32s/it] 96%|█████████▌| 2392/2496 [16:55:41<43:55, 25.34s/it]                                                      {'loss': 0.6806, 'learning_rate': 9.092589947588992e-08, 'epoch': 0.96}
 96%|█████████▌| 2392/2496 [16:55:41<43:55, 25.34s/it] 96%|█████████▌| 2393/2496 [16:56:05<42:24, 24.71s/it]                                                      {'loss': 0.6437, 'learning_rate': 8.918832247920117e-08, 'epoch': 0.96}
 96%|█████████▌| 2393/2496 [16:56:05<42:24, 24.71s/it] 96%|█████████▌| 2394/2496 [16:56:30<42:26, 24.96s/it]                                                      {'loss': 0.6601, 'learning_rate': 8.746743406037872e-08, 'epoch': 0.96}
 96%|█████████▌| 2394/2496 [16:56:30<42:26, 24.96s/it] 96%|█████████▌| 2395/2496 [16:56:55<41:52, 24.88s/it]                                                      {'loss': 0.6312, 'learning_rate': 8.576323711718571e-08, 'epoch': 0.96}
 96%|█████████▌| 2395/2496 [16:56:55<41:52, 24.88s/it] 96%|█████████▌| 2396/2496 [16:57:20<41:31, 24.91s/it]                                                      {'loss': 0.6475, 'learning_rate': 8.407573451927997e-08, 'epoch': 0.96}
 96%|█████████▌| 2396/2496 [16:57:20<41:31, 24.91s/it]WARNING: tokenization mismatch: 1 vs. 1473. (ignored)
 96%|█████████▌| 2397/2496 [16:57:46<41:51, 25.37s/it]                                                      {'loss': 0.6711, 'learning_rate': 8.240492910820407e-08, 'epoch': 0.96}
 96%|█████████▌| 2397/2496 [16:57:46<41:51, 25.37s/it] 96%|█████████▌| 2398/2496 [16:58:11<41:11, 25.22s/it]                                                      {'loss': 0.6789, 'learning_rate': 8.075082369738863e-08, 'epoch': 0.96}
 96%|█████████▌| 2398/2496 [16:58:11<41:11, 25.22s/it] 96%|█████████▌| 2399/2496 [16:58:37<41:13, 25.51s/it]                                                      {'loss': 0.6451, 'learning_rate': 7.911342107214227e-08, 'epoch': 0.96}
 96%|█████████▌| 2399/2496 [16:58:37<41:13, 25.51s/it]this iter is wrong in something... skip...
 96%|█████████▌| 2400/2496 [16:59:02<40:38, 25.41s/it]                                                      {'loss': 0.6883, 'learning_rate': 7.749272398964613e-08, 'epoch': 0.96}
 96%|█████████▌| 2400/2496 [16:59:03<40:38, 25.41s/it] 96%|█████████▌| 2401/2496 [16:59:27<40:01, 25.28s/it]                                                      {'loss': 0.2459, 'learning_rate': 7.588873517895501e-08, 'epoch': 0.96}
 96%|█████████▌| 2401/2496 [16:59:27<40:01, 25.28s/it] 96%|█████████▌| 2402/2496 [16:59:51<38:56, 24.85s/it]                                                      {'loss': 0.638, 'learning_rate': 7.430145734098726e-08, 'epoch': 0.96}
 96%|█████████▌| 2402/2496 [16:59:51<38:56, 24.85s/it] 96%|█████████▋| 2403/2496 [17:00:17<38:42, 24.97s/it]                                                      {'loss': 0.6694, 'learning_rate': 7.273089314852155e-08, 'epoch': 0.96}
 96%|█████████▋| 2403/2496 [17:00:17<38:42, 24.97s/it] 96%|█████████▋| 2404/2496 [17:00:41<37:59, 24.78s/it]                                                      {'loss': 0.6863, 'learning_rate': 7.117704524619128e-08, 'epoch': 0.96}
 96%|█████████▋| 2404/2496 [17:00:41<37:59, 24.78s/it] 96%|█████████▋| 2405/2496 [17:01:05<37:09, 24.50s/it]                                                      {'loss': 0.6817, 'learning_rate': 6.963991625048571e-08, 'epoch': 0.96}
 96%|█████████▋| 2405/2496 [17:01:05<37:09, 24.50s/it] 96%|█████████▋| 2406/2496 [17:01:32<37:50, 25.22s/it]                                                      {'loss': 0.6842, 'learning_rate': 6.811950874973994e-08, 'epoch': 0.96}
 96%|█████████▋| 2406/2496 [17:01:32<37:50, 25.22s/it] 96%|█████████▋| 2407/2496 [17:01:57<37:34, 25.33s/it]                                                      {'loss': 0.6562, 'learning_rate': 6.661582530412936e-08, 'epoch': 0.96}
 96%|█████████▋| 2407/2496 [17:01:57<37:34, 25.33s/it] 96%|█████████▋| 2408/2496 [17:02:22<36:56, 25.19s/it]                                                      {'loss': 0.6717, 'learning_rate': 6.512886844567301e-08, 'epoch': 0.96}
 96%|█████████▋| 2408/2496 [17:02:22<36:56, 25.19s/it] 97%|█████████▋| 2409/2496 [17:02:48<36:40, 25.29s/it]                                                      {'loss': 0.6489, 'learning_rate': 6.365864067821914e-08, 'epoch': 0.96}
 97%|█████████▋| 2409/2496 [17:02:48<36:40, 25.29s/it] 97%|█████████▋| 2410/2496 [17:03:13<36:10, 25.24s/it]                                                      {'loss': 0.6476, 'learning_rate': 6.220514447745185e-08, 'epoch': 0.97}
 97%|█████████▋| 2410/2496 [17:03:13<36:10, 25.24s/it] 97%|█████████▋| 2411/2496 [17:03:44<38:14, 27.00s/it]                                                      {'loss': 0.6799, 'learning_rate': 6.076838229087667e-08, 'epoch': 0.97}
 97%|█████████▋| 2411/2496 [17:03:44<38:14, 27.00s/it] 97%|█████████▋| 2412/2496 [17:04:10<37:20, 26.67s/it]                                                      {'loss': 0.6545, 'learning_rate': 5.934835653782389e-08, 'epoch': 0.97}
 97%|█████████▋| 2412/2496 [17:04:10<37:20, 26.67s/it] 97%|█████████▋| 2413/2496 [17:04:35<36:11, 26.16s/it]                                                      {'loss': 0.6918, 'learning_rate': 5.794506960943969e-08, 'epoch': 0.97}
 97%|█████████▋| 2413/2496 [17:04:35<36:11, 26.16s/it] 97%|█████████▋| 2414/2496 [17:05:00<35:23, 25.90s/it]                                                      {'loss': 0.6524, 'learning_rate': 5.655852386868499e-08, 'epoch': 0.97}
 97%|█████████▋| 2414/2496 [17:05:00<35:23, 25.90s/it] 97%|█████████▋| 2415/2496 [17:05:26<35:00, 25.93s/it]                                                      {'loss': 0.6819, 'learning_rate': 5.518872165033329e-08, 'epoch': 0.97}
 97%|█████████▋| 2415/2496 [17:05:26<35:00, 25.93s/it] 97%|█████████▋| 2416/2496 [17:05:50<33:48, 25.35s/it]                                                      {'loss': 0.676, 'learning_rate': 5.383566526095951e-08, 'epoch': 0.97}
 97%|█████████▋| 2416/2496 [17:05:50<33:48, 25.35s/it] 97%|█████████▋| 2417/2496 [17:06:15<33:06, 25.14s/it]                                                      {'loss': 0.6406, 'learning_rate': 5.2499356978943373e-08, 'epoch': 0.97}
 97%|█████████▋| 2417/2496 [17:06:15<33:06, 25.14s/it]this iter is wrong in something... skip...
this iter is wrong in something... skip...
 97%|█████████▋| 2418/2496 [17:06:39<32:20, 24.88s/it]                                                      {'loss': 0.6667, 'learning_rate': 5.117979905446269e-08, 'epoch': 0.97}
 97%|█████████▋| 2418/2496 [17:06:39<32:20, 24.88s/it] 97%|█████████▋| 2419/2496 [17:07:04<31:56, 24.89s/it]                                                      {'loss': 0.6862, 'learning_rate': 4.987699370948895e-08, 'epoch': 0.97}
 97%|█████████▋| 2419/2496 [17:07:04<31:56, 24.89s/it] 97%|█████████▋| 2420/2496 [17:07:31<32:13, 25.45s/it]                                                      {'loss': 0.6448, 'learning_rate': 4.859094313778401e-08, 'epoch': 0.97}
 97%|█████████▋| 2420/2496 [17:07:31<32:13, 25.45s/it] 97%|█████████▋| 2421/2496 [17:07:57<32:10, 25.74s/it]                                                      {'loss': 0.6735, 'learning_rate': 4.732164950490004e-08, 'epoch': 0.97}
 97%|█████████▋| 2421/2496 [17:07:57<32:10, 25.74s/it] 97%|█████████▋| 2422/2496 [17:08:22<31:25, 25.48s/it]                                                      {'loss': 0.6531, 'learning_rate': 4.606911494816735e-08, 'epoch': 0.97}
 97%|█████████▋| 2422/2496 [17:08:22<31:25, 25.48s/it] 97%|█████████▋| 2423/2496 [17:08:47<30:46, 25.29s/it]                                                      {'loss': 0.6846, 'learning_rate': 4.483334157669994e-08, 'epoch': 0.97}
 97%|█████████▋| 2423/2496 [17:08:47<30:46, 25.29s/it]this iter is wrong in something... skip...
 97%|█████████▋| 2424/2496 [17:09:14<31:02, 25.87s/it]                                                      {'loss': 0.6457, 'learning_rate': 4.361433147138772e-08, 'epoch': 0.97}
 97%|█████████▋| 2424/2496 [17:09:14<31:02, 25.87s/it] 97%|█████████▋| 2425/2496 [17:09:40<30:41, 25.94s/it]                                                      {'loss': 0.6452, 'learning_rate': 4.241208668489094e-08, 'epoch': 0.97}
 97%|█████████▋| 2425/2496 [17:09:40<30:41, 25.94s/it] 97%|█████████▋| 2426/2496 [17:10:06<30:11, 25.88s/it]                                                      {'loss': 0.6828, 'learning_rate': 4.122660924164246e-08, 'epoch': 0.97}
 97%|█████████▋| 2426/2496 [17:10:06<30:11, 25.88s/it] 97%|█████████▋| 2427/2496 [17:10:30<29:04, 25.28s/it]                                                      {'loss': 0.6812, 'learning_rate': 4.0057901137837697e-08, 'epoch': 0.97}
 97%|█████████▋| 2427/2496 [17:10:30<29:04, 25.28s/it] 97%|█████████▋| 2428/2496 [17:11:00<30:18, 26.74s/it]                                                      {'loss': 0.6472, 'learning_rate': 3.8905964341436896e-08, 'epoch': 0.97}
 97%|█████████▋| 2428/2496 [17:11:00<30:18, 26.74s/it] 97%|█████████▋| 2429/2496 [17:11:25<29:15, 26.20s/it]                                                      {'loss': 0.2373, 'learning_rate': 3.7770800792159556e-08, 'epoch': 0.97}
 97%|█████████▋| 2429/2496 [17:11:25<29:15, 26.20s/it] 97%|█████████▋| 2430/2496 [17:11:51<28:46, 26.16s/it]                                                      {'loss': 0.685, 'learning_rate': 3.6652412401478875e-08, 'epoch': 0.97}
 97%|█████████▋| 2430/2496 [17:11:51<28:46, 26.16s/it] 97%|█████████▋| 2431/2496 [17:12:18<28:38, 26.43s/it]                                                      {'loss': 0.6807, 'learning_rate': 3.555080105262287e-08, 'epoch': 0.97}
 97%|█████████▋| 2431/2496 [17:12:18<28:38, 26.43s/it] 97%|█████████▋| 2432/2496 [17:12:42<27:20, 25.63s/it]                                                      {'loss': 0.6835, 'learning_rate': 3.4465968600568835e-08, 'epoch': 0.97}
 97%|█████████▋| 2432/2496 [17:12:42<27:20, 25.63s/it] 97%|█████████▋| 2433/2496 [17:13:04<25:54, 24.68s/it]                                                      {'loss': 0.6568, 'learning_rate': 3.339791687203997e-08, 'epoch': 0.97}
 97%|█████████▋| 2433/2496 [17:13:04<25:54, 24.68s/it] 98%|█████████▊| 2434/2496 [17:13:30<25:52, 25.04s/it]                                                      {'loss': 0.6289, 'learning_rate': 3.234664766550211e-08, 'epoch': 0.97}
 98%|█████████▊| 2434/2496 [17:13:30<25:52, 25.04s/it] 98%|█████████▊| 2435/2496 [17:13:56<25:40, 25.26s/it]                                                      {'loss': 0.6836, 'learning_rate': 3.131216275116256e-08, 'epoch': 0.98}
 98%|█████████▊| 2435/2496 [17:13:56<25:40, 25.26s/it] 98%|█████████▊| 2436/2496 [17:14:19<24:32, 24.54s/it]                                                      {'loss': 0.6724, 'learning_rate': 3.0294463870966795e-08, 'epoch': 0.98}
 98%|█████████▊| 2436/2496 [17:14:19<24:32, 24.54s/it] 98%|█████████▊| 2437/2496 [17:14:43<24:06, 24.51s/it]                                                      {'loss': 0.7196, 'learning_rate': 2.9293552738591803e-08, 'epoch': 0.98}
 98%|█████████▊| 2437/2496 [17:14:43<24:06, 24.51s/it] 98%|█████████▊| 2438/2496 [17:15:10<24:24, 25.24s/it]                                                      {'loss': 0.63, 'learning_rate': 2.8309431039449386e-08, 'epoch': 0.98}
 98%|█████████▊| 2438/2496 [17:15:10<24:24, 25.24s/it] 98%|█████████▊| 2439/2496 [17:15:35<23:50, 25.10s/it]                                                      {'loss': 0.7136, 'learning_rate': 2.734210043067731e-08, 'epoch': 0.98}
 98%|█████████▊| 2439/2496 [17:15:35<23:50, 25.10s/it] 98%|█████████▊| 2440/2496 [17:16:00<23:19, 25.00s/it]                                                      {'loss': 0.6508, 'learning_rate': 2.639156254114039e-08, 'epoch': 0.98}
 98%|█████████▊| 2440/2496 [17:16:00<23:19, 25.00s/it] 98%|█████████▊| 2441/2496 [17:16:25<23:05, 25.19s/it]                                                      {'loss': 0.6507, 'learning_rate': 2.5457818971427184e-08, 'epoch': 0.98}
 98%|█████████▊| 2441/2496 [17:16:25<23:05, 25.19s/it] 98%|█████████▊| 2442/2496 [17:16:49<22:14, 24.72s/it]                                                      {'loss': 0.6368, 'learning_rate': 2.4540871293845526e-08, 'epoch': 0.98}
 98%|█████████▊| 2442/2496 [17:16:49<22:14, 24.72s/it] 98%|█████████▊| 2443/2496 [17:17:14<22:02, 24.95s/it]                                                      {'loss': 0.6672, 'learning_rate': 2.3640721052422545e-08, 'epoch': 0.98}
 98%|█████████▊| 2443/2496 [17:17:14<22:02, 24.95s/it] 98%|█████████▊| 2444/2496 [17:17:38<21:21, 24.64s/it]                                                      {'loss': 0.6563, 'learning_rate': 2.2757369762899105e-08, 'epoch': 0.98}
 98%|█████████▊| 2444/2496 [17:17:38<21:21, 24.64s/it] 98%|█████████▊| 2445/2496 [17:18:03<21:02, 24.76s/it]                                                      {'loss': 0.6457, 'learning_rate': 2.1890818912728706e-08, 'epoch': 0.98}
 98%|█████████▊| 2445/2496 [17:18:03<21:02, 24.76s/it] 98%|█████████▊| 2446/2496 [17:18:26<20:13, 24.26s/it]                                                      {'loss': 0.6881, 'learning_rate': 2.1041069961075245e-08, 'epoch': 0.98}
 98%|█████████▊| 2446/2496 [17:18:26<20:13, 24.26s/it]this iter is wrong in something... skip...
 98%|█████████▊| 2447/2496 [17:18:52<20:15, 24.80s/it]                                                      {'loss': 0.682, 'learning_rate': 2.020812433881192e-08, 'epoch': 0.98}
 98%|█████████▊| 2447/2496 [17:18:52<20:15, 24.80s/it] 98%|█████████▊| 2448/2496 [17:19:17<19:50, 24.80s/it]                                                      {'loss': 0.6474, 'learning_rate': 1.939198344851456e-08, 'epoch': 0.98}
 98%|█████████▊| 2448/2496 [17:19:17<19:50, 24.80s/it] 98%|█████████▊| 2449/2496 [17:19:42<19:27, 24.84s/it]                                                      {'loss': 0.2272, 'learning_rate': 1.8592648664464975e-08, 'epoch': 0.98}
 98%|█████████▊| 2449/2496 [17:19:42<19:27, 24.84s/it] 98%|█████████▊| 2450/2496 [17:20:06<18:49, 24.56s/it]                                                      {'loss': 0.6647, 'learning_rate': 1.781012133264204e-08, 'epoch': 0.98}
 98%|█████████▊| 2450/2496 [17:20:06<18:49, 24.56s/it] 98%|█████████▊| 2451/2496 [17:20:35<19:21, 25.82s/it]                                                      {'loss': 0.6712, 'learning_rate': 1.7044402770725055e-08, 'epoch': 0.98}
 98%|█████████▊| 2451/2496 [17:20:35<19:21, 25.82s/it] 98%|█████████▊| 2452/2496 [17:21:02<19:08, 26.11s/it]                                                      {'loss': 0.6865, 'learning_rate': 1.6295494268090404e-08, 'epoch': 0.98}
 98%|█████████▊| 2452/2496 [17:21:02<19:08, 26.11s/it] 98%|█████████▊| 2453/2496 [17:21:31<19:27, 27.14s/it]                                                      {'loss': 0.6351, 'learning_rate': 1.55633970858049e-08, 'epoch': 0.98}
 98%|█████████▊| 2453/2496 [17:21:31<19:27, 27.14s/it] 98%|█████████▊| 2454/2496 [17:21:58<18:57, 27.08s/it]                                                      {'loss': 0.6601, 'learning_rate': 1.4848112456632424e-08, 'epoch': 0.98}
 98%|█████████▊| 2454/2496 [17:21:58<18:57, 27.08s/it] 98%|█████████▊| 2455/2496 [17:22:25<18:33, 27.15s/it]                                                      {'loss': 0.6602, 'learning_rate': 1.4149641585020635e-08, 'epoch': 0.98}
 98%|█████████▊| 2455/2496 [17:22:25<18:33, 27.15s/it] 98%|█████████▊| 2456/2496 [17:22:49<17:25, 26.15s/it]                                                      {'loss': 0.6433, 'learning_rate': 1.3467985647108717e-08, 'epoch': 0.98}
 98%|█████████▊| 2456/2496 [17:22:49<17:25, 26.15s/it] 98%|█████████▊| 2457/2496 [17:23:16<17:04, 26.26s/it]                                                      {'loss': 0.69, 'learning_rate': 1.2803145790722948e-08, 'epoch': 0.98}
 98%|█████████▊| 2457/2496 [17:23:16<17:04, 26.26s/it] 98%|█████████▊| 2458/2496 [17:23:41<16:28, 26.01s/it]                                                      {'loss': 0.6538, 'learning_rate': 1.215512313536782e-08, 'epoch': 0.98}
 98%|█████████▊| 2458/2496 [17:23:41<16:28, 26.01s/it] 99%|█████████▊| 2459/2496 [17:24:05<15:33, 25.23s/it]                                                      {'loss': 0.6794, 'learning_rate': 1.152391877223491e-08, 'epoch': 0.98}
 99%|█████████▊| 2459/2496 [17:24:05<15:33, 25.23s/it] 99%|█████████▊| 2460/2496 [17:24:29<15:03, 25.10s/it]                                                      {'loss': 0.65, 'learning_rate': 1.0909533764194013e-08, 'epoch': 0.99}
 99%|█████████▊| 2460/2496 [17:24:29<15:03, 25.10s/it] 99%|█████████▊| 2461/2496 [17:24:54<14:33, 24.97s/it]                                                      {'loss': 0.6742, 'learning_rate': 1.0311969145794242e-08, 'epoch': 0.99}
 99%|█████████▊| 2461/2496 [17:24:54<14:33, 24.97s/it] 99%|█████████▊| 2462/2496 [17:25:17<13:51, 24.46s/it]                                                      {'loss': 0.6752, 'learning_rate': 9.73122592325737e-09, 'epoch': 0.99}
 99%|█████████▊| 2462/2496 [17:25:17<13:51, 24.46s/it] 99%|█████████▊| 2463/2496 [17:25:43<13:42, 24.91s/it]                                                      {'loss': 0.6503, 'learning_rate': 9.167305074486709e-09, 'epoch': 0.99}
 99%|█████████▊| 2463/2496 [17:25:43<13:42, 24.91s/it] 99%|█████████▊| 2464/2496 [17:26:10<13:39, 25.60s/it]                                                      {'loss': 0.6543, 'learning_rate': 8.620207549051574e-09, 'epoch': 0.99}
 99%|█████████▊| 2464/2496 [17:26:11<13:39, 25.60s/it] 99%|█████████▉| 2465/2496 [17:26:36<13:09, 25.46s/it]                                                      {'loss': 0.6885, 'learning_rate': 8.089934268198374e-09, 'epoch': 0.99}
 99%|█████████▉| 2465/2496 [17:26:36<13:09, 25.46s/it] 99%|█████████▉| 2466/2496 [17:26:59<12:27, 24.92s/it]                                                      {'loss': 0.672, 'learning_rate': 7.576486124841741e-09, 'epoch': 0.99}
 99%|█████████▉| 2466/2496 [17:26:59<12:27, 24.92s/it]this iter is wrong in something... skip...
 99%|█████████▉| 2467/2496 [17:27:24<12:03, 24.95s/it]                                                      {'loss': 0.6502, 'learning_rate': 7.0798639835634175e-09, 'epoch': 0.99}
 99%|█████████▉| 2467/2496 [17:27:24<12:03, 24.95s/it] 99%|█████████▉| 2468/2496 [17:27:48<11:30, 24.66s/it]                                                      {'loss': 0.6749, 'learning_rate': 6.600068680614469e-09, 'epoch': 0.99}
 99%|█████████▉| 2468/2496 [17:27:48<11:30, 24.66s/it] 99%|█████████▉| 2469/2496 [17:28:15<11:25, 25.40s/it]                                                      {'loss': 0.6667, 'learning_rate': 6.137101023910852e-09, 'epoch': 0.99}
 99%|█████████▉| 2469/2496 [17:28:15<11:25, 25.40s/it] 99%|█████████▉| 2470/2496 [17:28:41<10:58, 25.33s/it]                                                      {'loss': 0.222, 'learning_rate': 5.690961793031191e-09, 'epoch': 0.99}
 99%|█████████▉| 2470/2496 [17:28:41<10:58, 25.33s/it] 99%|█████████▉| 2471/2496 [17:29:05<10:29, 25.17s/it]                                                      {'loss': 0.6316, 'learning_rate': 5.261651739220109e-09, 'epoch': 0.99}
 99%|█████████▉| 2471/2496 [17:29:05<10:29, 25.17s/it] 99%|█████████▉| 2472/2496 [17:29:30<09:57, 24.89s/it]                                                      {'loss': 0.6629, 'learning_rate': 4.849171585381562e-09, 'epoch': 0.99}
 99%|█████████▉| 2472/2496 [17:29:30<09:57, 24.89s/it] 99%|█████████▉| 2473/2496 [17:29:55<09:38, 25.17s/it]                                                      {'loss': 0.649, 'learning_rate': 4.45352202608218e-09, 'epoch': 0.99}
 99%|█████████▉| 2473/2496 [17:29:55<09:38, 25.17s/it] 99%|█████████▉| 2474/2496 [17:30:21<09:16, 25.29s/it]                                                      {'loss': 0.6487, 'learning_rate': 4.074703727545703e-09, 'epoch': 0.99}
 99%|█████████▉| 2474/2496 [17:30:21<09:16, 25.29s/it] 99%|█████████▉| 2475/2496 [17:30:45<08:42, 24.88s/it]                                                      {'loss': 0.674, 'learning_rate': 3.7127173276563234e-09, 'epoch': 0.99}
 99%|█████████▉| 2475/2496 [17:30:45<08:42, 24.88s/it] 99%|█████████▉| 2476/2496 [17:31:08<08:06, 24.34s/it]                                                      {'loss': 0.6499, 'learning_rate': 3.367563435952015e-09, 'epoch': 0.99}
 99%|█████████▉| 2476/2496 [17:31:08<08:06, 24.34s/it] 99%|█████████▉| 2477/2496 [17:31:34<07:53, 24.93s/it]                                                      {'loss': 0.66, 'learning_rate': 3.0392426336312007e-09, 'epoch': 0.99}
 99%|█████████▉| 2477/2496 [17:31:34<07:53, 24.93s/it] 99%|█████████▉| 2478/2496 [17:31:59<07:25, 24.77s/it]                                                      {'loss': 0.6707, 'learning_rate': 2.7277554735449797e-09, 'epoch': 0.99}
 99%|█████████▉| 2478/2496 [17:31:59<07:25, 24.77s/it] 99%|█████████▉| 2479/2496 [17:32:22<06:53, 24.32s/it]                                                      {'loss': 0.6686, 'learning_rate': 2.433102480198235e-09, 'epoch': 0.99}
 99%|█████████▉| 2479/2496 [17:32:22<06:53, 24.32s/it] 99%|█████████▉| 2480/2496 [17:32:47<06:31, 24.44s/it]                                                      {'loss': 0.7066, 'learning_rate': 2.155284149750747e-09, 'epoch': 0.99}
 99%|█████████▉| 2480/2496 [17:32:47<06:31, 24.44s/it] 99%|█████████▉| 2481/2496 [17:33:16<06:27, 25.86s/it]                                                      {'loss': 0.6729, 'learning_rate': 1.894300950014971e-09, 'epoch': 0.99}
 99%|█████████▉| 2481/2496 [17:33:16<06:27, 25.86s/it] 99%|█████████▉| 2482/2496 [17:33:40<05:54, 25.32s/it]                                                      {'loss': 0.6401, 'learning_rate': 1.6501533204527075e-09, 'epoch': 0.99}
 99%|█████████▉| 2482/2496 [17:33:40<05:54, 25.32s/it] 99%|█████████▉| 2483/2496 [17:34:04<05:24, 24.97s/it]                                                      {'loss': 0.6454, 'learning_rate': 1.4228416721795423e-09, 'epoch': 0.99}
 99%|█████████▉| 2483/2496 [17:34:04<05:24, 24.97s/it]100%|█████████▉| 2484/2496 [17:34:27<04:53, 24.49s/it]                                                      {'loss': 0.6962, 'learning_rate': 1.212366387958186e-09, 'epoch': 0.99}
100%|█████████▉| 2484/2496 [17:34:27<04:53, 24.49s/it]100%|█████████▉| 2485/2496 [17:34:52<04:28, 24.42s/it]                                                      {'loss': 0.6556, 'learning_rate': 1.0187278222051345e-09, 'epoch': 1.0}
100%|█████████▉| 2485/2496 [17:34:52<04:28, 24.42s/it]100%|█████████▉| 2486/2496 [17:35:16<04:02, 24.27s/it]                                                      {'loss': 0.6494, 'learning_rate': 8.419263009828982e-10, 'epoch': 1.0}
100%|█████████▉| 2486/2496 [17:35:16<04:02, 24.27s/it]100%|█████████▉| 2487/2496 [17:35:41<03:42, 24.69s/it]                                                      {'loss': 0.6953, 'learning_rate': 6.819621220033323e-10, 'epoch': 1.0}
100%|█████████▉| 2487/2496 [17:35:41<03:42, 24.69s/it]100%|█████████▉| 2488/2496 [17:36:08<03:22, 25.28s/it]                                                      {'loss': 0.6645, 'learning_rate': 5.388355546254165e-10, 'epoch': 1.0}
100%|█████████▉| 2488/2496 [17:36:08<03:22, 25.28s/it]100%|█████████▉| 2489/2496 [17:36:33<02:57, 25.34s/it]                                                      {'loss': 0.6643, 'learning_rate': 4.12546839857475e-10, 'epoch': 1.0}
100%|█████████▉| 2489/2496 [17:36:33<02:57, 25.34s/it]100%|█████████▉| 2490/2496 [17:36:58<02:31, 25.25s/it]                                                      {'loss': 0.6764, 'learning_rate': 3.0309619035495675e-10, 'epoch': 1.0}
100%|█████████▉| 2490/2496 [17:36:58<02:31, 25.25s/it]100%|█████████▉| 2491/2496 [17:37:25<02:08, 25.73s/it]                                                      {'loss': 0.6373, 'learning_rate': 2.104837904171042e-10, 'epoch': 1.0}
100%|█████████▉| 2491/2496 [17:37:25<02:08, 25.73s/it]100%|█████████▉| 2492/2496 [17:37:51<01:43, 25.81s/it]                                                      {'loss': 0.6993, 'learning_rate': 1.3470979599250477e-10, 'epoch': 1.0}
100%|█████████▉| 2492/2496 [17:37:51<01:43, 25.81s/it]100%|█████████▉| 2493/2496 [17:38:14<01:14, 24.92s/it]                                                      {'loss': 0.6974, 'learning_rate': 7.577433467576001e-11, 'epoch': 1.0}
100%|█████████▉| 2493/2496 [17:38:14<01:14, 24.92s/it]100%|█████████▉| 2494/2496 [17:38:39<00:49, 24.81s/it]                                                      {'loss': 0.6604, 'learning_rate': 3.367750570748563e-11, 'epoch': 1.0}
100%|█████████▉| 2494/2496 [17:38:39<00:49, 24.81s/it]100%|█████████▉| 2495/2496 [17:39:04<00:24, 24.82s/it]                                                      {'loss': 0.6788, 'learning_rate': 8.419379970980857e-12, 'epoch': 1.0}
100%|█████████▉| 2495/2496 [17:39:04<00:24, 24.82s/it]100%|██████████| 2496/2496 [17:39:30<00:00, 25.29s/it]                                                      {'loss': 0.3611, 'learning_rate': 0.0, 'epoch': 1.0}
100%|██████████| 2496/2496 [17:39:30<00:00, 25.29s/it]                                                      {'train_runtime': 63574.4133, 'train_samples_per_second': 15.078, 'train_steps_per_second': 0.039, 'train_loss': 0.6852827473268963, 'epoch': 1.0}
100%|██████████| 2496/2496 [17:39:31<00:00, 25.29s/it]100%|██████████| 2496/2496 [17:39:31<00:00, 25.47s/it]
Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.
Non-default generation parameters: {'max_length': 4096}
Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.
wandb: 
wandb: Run history:
wandb:                    train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:              train/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:            train/learning_rate ▄▇██████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb:                     train/loss ██▇▇▆▇▇▇▆▆▆▆▆▂▆▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▆▆▆▁▆▆▆▆▆▂
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                    train/epoch 1.0
wandb:              train/global_step 2496
wandb:            train/learning_rate 0.0
wandb:                     train/loss 0.3611
wandb:               train/total_flos 5.238338001861765e+19
wandb:               train/train_loss 0.68528
wandb:            train/train_runtime 63574.4133
wandb: train/train_samples_per_second 15.078
wandb:   train/train_steps_per_second 0.039
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/test/test08/gzh/LLaVA-UHD/wandb/offline-run-20240829_164846-0baoukt0
wandb: Find logs at: ./wandb/offline-run-20240829_164846-0baoukt0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
